{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-22T08:50:14.239727Z","iopub.status.busy":"2024-02-22T08:50:14.238932Z","iopub.status.idle":"2024-02-22T08:50:35.634525Z","shell.execute_reply":"2024-02-22T08:50:35.633714Z","shell.execute_reply.started":"2024-02-22T08:50:14.239697Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26421880/26421880 [00:00<00:00, 117379010.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting /data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 29515/29515 [00:00<00:00, 4413522.14it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting /data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 4422102/4422102 [00:00<00:00, 58480204.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting /data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5148/5148 [00:00<00:00, 9371648.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting /data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /data/FashionMNIST/raw\n","\n"]}],"source":["import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","import torchvision\n","import torch.optim as optim\n","import math\n","\n","device = torch.device('cuda')\n","device_ids=[0,1]\n","\n","def process_data(X,device=device):\n","    temp_x=[i[0][0].unsqueeze_(0) for i in X]#升维再导入\n","    data_x=torch.cat(temp_x).reshape(-1,28,28)#加上通道数\n","    data_y=torch.tensor([i[1] for i in X])\n","    return data_x.to(device),data_y.to(device)\n","\n","trans = torchvision.transforms.ToTensor()\n","mnist_train = torchvision.datasets.FashionMNIST(\n","    root=\"/data\", train=True, transform=trans, download=True)\n","mnist_test = torchvision.datasets.FashionMNIST(\n","    root=\"/data\", train=False, transform=trans, download=True)\n","\n","(train_x0,train_y0)=process_data(mnist_train,device=\"cuda:1\")\n","(test_x0,test_y0)=process_data(mnist_test,device=\"cuda:1\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T08:50:50.105682Z","iopub.status.busy":"2024-02-22T08:50:50.105194Z","iopub.status.idle":"2024-02-22T08:50:51.033549Z","shell.execute_reply":"2024-02-22T08:50:51.032657Z","shell.execute_reply.started":"2024-02-22T08:50:50.105651Z"},"trusted":true},"outputs":[{"data":{"text/plain":["ViT(\n","  (ec): EncoderLayer(\n","    (self_attn): MultiHeadAttention(\n","      (W_q): Linear(in_features=16, out_features=16, bias=True)\n","      (W_k): Linear(in_features=16, out_features=16, bias=True)\n","      (W_v): Linear(in_features=16, out_features=16, bias=True)\n","      (W_o): Linear(in_features=16, out_features=16, bias=True)\n","    )\n","    (feed_forward): PositionWiseFeedForward(\n","      (fc1): Linear(in_features=16, out_features=64, bias=True)\n","      (fc2): Linear(in_features=64, out_features=16, bias=True)\n","      (relu): ReLU()\n","    )\n","    (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (ec1): EncoderLayer(\n","    (self_attn): MultiHeadAttention(\n","      (W_q): Linear(in_features=16, out_features=16, bias=True)\n","      (W_k): Linear(in_features=16, out_features=16, bias=True)\n","      (W_v): Linear(in_features=16, out_features=16, bias=True)\n","      (W_o): Linear(in_features=16, out_features=16, bias=True)\n","    )\n","    (feed_forward): PositionWiseFeedForward(\n","      (fc1): Linear(in_features=16, out_features=64, bias=True)\n","      (fc2): Linear(in_features=64, out_features=16, bias=True)\n","      (relu): ReLU()\n","    )\n","    (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (ec2): EncoderLayer(\n","    (self_attn): MultiHeadAttention(\n","      (W_q): Linear(in_features=16, out_features=16, bias=True)\n","      (W_k): Linear(in_features=16, out_features=16, bias=True)\n","      (W_v): Linear(in_features=16, out_features=16, bias=True)\n","      (W_o): Linear(in_features=16, out_features=16, bias=True)\n","    )\n","    (feed_forward): PositionWiseFeedForward(\n","      (fc1): Linear(in_features=16, out_features=64, bias=True)\n","      (fc2): Linear(in_features=64, out_features=16, bias=True)\n","      (relu): ReLU()\n","    )\n","    (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (ec3): EncoderLayer(\n","    (self_attn): MultiHeadAttention(\n","      (W_q): Linear(in_features=16, out_features=16, bias=True)\n","      (W_k): Linear(in_features=16, out_features=16, bias=True)\n","      (W_v): Linear(in_features=16, out_features=16, bias=True)\n","      (W_o): Linear(in_features=16, out_features=16, bias=True)\n","    )\n","    (feed_forward): PositionWiseFeedForward(\n","      (fc1): Linear(in_features=16, out_features=64, bias=True)\n","      (fc2): Linear(in_features=64, out_features=16, bias=True)\n","      (relu): ReLU()\n","    )\n","    (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (ec4): EncoderLayer(\n","    (self_attn): MultiHeadAttention(\n","      (W_q): Linear(in_features=16, out_features=16, bias=True)\n","      (W_k): Linear(in_features=16, out_features=16, bias=True)\n","      (W_v): Linear(in_features=16, out_features=16, bias=True)\n","      (W_o): Linear(in_features=16, out_features=16, bias=True)\n","    )\n","    (feed_forward): PositionWiseFeedForward(\n","      (fc1): Linear(in_features=16, out_features=64, bias=True)\n","      (fc2): Linear(in_features=64, out_features=16, bias=True)\n","      (relu): ReLU()\n","    )\n","    (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (fc): Linear(in_features=16, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=10, bias=True)\n","  (sf): Softmax(dim=1)\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_y=torch.nn.functional.one_hot(train_y0, num_classes=10).to(torch.float32)\n","\n","patch_size=4\n","train_x=train_x0.unsqueeze(1)\n","\n","patches=nn.functional.unfold(train_x,kernel_size=(patch_size,patch_size),stride=patch_size).transpose(-1,-2)\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self,d_model,num_heads):\n","        super(MultiHeadAttention, self).__init__() #初始化 nn.Module\n","        assert d_model % num_heads == 0 # 能够等分 h 为头数目\n","        self.num_heads=num_heads\n","        self.d_model=d_model\n","        self.d_k = d_model // num_heads # key 通过类似CNN的多通道机制进行分离\n","        self.W_q = nn.Linear(d_model, d_model).to(device)\n","        self.W_k = nn.Linear(d_model, d_model).to(device)\n","        self.W_v = nn.Linear(d_model, d_model).to(device)\n","        self.W_o = nn.Linear(d_model, d_model).to(device)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k) # 表示对倒数第二个和最后一个维度进行转置。\n","        if mask is not None:\n","            attn_scores = attn_scores.masked_fill(mask == 0, -1e9) # 传入mask\n","        attn_probs = torch.softmax(attn_scores, dim=-1) #对dk进行\n","        output = torch.matmul(attn_probs, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        batch_size, seq_length, _ = x.size()\n","        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)#先分成两个维度 不破坏原始数据结构\n","        # (batch_size, self.h, seq_length, self.d_k)\n","\n","    def combine_heads(self, x):\n","        batch_size, _, seq_length, _ = x.size() #split 的逆向操作\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n","        #.contiguous() 可以确保张量在内存中是按照顺序排列的，以便后续的操作。\n","\n","    def forward(self, Q, K, V, mask=None):\n","        Q = self.split_heads(self.W_q(Q))\n","        K = self.split_heads(self.W_k(K))\n","        V = self.split_heads(self.W_v(V))\n","\n","        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n","        output = self.W_o(self.combine_heads(attn_output))\n","        return output\n","\n","class PositionWiseFeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super(PositionWiseFeedForward, self).__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff).to(device)\n","        self.fc2 = nn.Linear(d_ff, d_model).to(device)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_seq_length):\n","        super(PositionalEncoding, self).__init__()\n","\n","        pe = torch.zeros(max_seq_length, d_model) # position ecoding 矩阵，对小于最大长度所有序列计算\n","        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1) #插入维度 batch_size\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.register_buffer('pe', pe.unsqueeze(0)) #它会与模型的参数一起被 PyTorch 的 state_dict() 保存和加载\n","         # 同时加了一维 batch_size self.pe 是一个形状为 (1, max_seq_length, d_model) 的张量\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1)] # 利用广播机制相加 x.size(1) 说明超出seq_length 的部分不加\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(EncoderLayer, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model,device=device) #最后一个维度\n","        self.norm2 = nn.LayerNorm(d_model,device=device)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        attn_output = self.self_attn(x, x, x)\n","        x = self.norm1(x + self.dropout(attn_output)) # 残差连接\n","        ff_output = self.feed_forward(x)\n","        x = self.norm2(x + self.dropout(ff_output))\n","        return x\n","\n","class ViT(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout,cls):\n","        super(ViT, self).__init__()\n","        self.ec=EncoderLayer(d_model, num_heads, d_ff, dropout).to('cuda:0')\n","        self.ec1=EncoderLayer(d_model, num_heads, d_ff, dropout).to('cuda:0')\n","        self.ec2=EncoderLayer(d_model, num_heads, d_ff, dropout).to('cuda:0')\n","        self.ec3=EncoderLayer(d_model, num_heads, d_ff, dropout).to('cuda:1')\n","        self.ec4=EncoderLayer(d_model, num_heads, d_ff, dropout).to('cuda:1')\n","        self.cls=cls.to('cuda:0')\n","        self.fc=nn.Linear(d_model, 128).to('cuda:1')\n","        self.fc2=nn.Linear(128, 10).to('cuda:1')\n","        self.sf = nn.Softmax(dim=1).to('cuda:1')\n","\n","    def forward(self,x):\n","        ec_output0=self.ec2(self.ec1(self.ec(torch.cat((cls,x.to(\"cuda:0\")),dim=1))))\n","        ec_output=self.ec4(self.ec3(ec_output0.to(\"cuda:1\")))[:,0,:]\n","        return self.sf(self.fc2(self.fc(ec_output)))\n","\n","\n","train_x=train_x0.unsqueeze(1) # 最后一维为通道数\n","train_x=nn.functional.unfold(train_x,kernel_size=(patch_size,patch_size),stride=patch_size).transpose(-1,-2).to(device)\n","\n","cls=torch.randn(60000,1,16).to(device)\n","vit=ViT(16,2,64,0.1,cls)\n","# vit= nn.DataParallel(vit,device_ids=device_ids)\n","# vit.to(device)\n","vit.train()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T08:50:53.662930Z","iopub.status.busy":"2024-02-22T08:50:53.662607Z","iopub.status.idle":"2024-02-22T09:33:45.772404Z","shell.execute_reply":"2024-02-22T09:33:45.771484Z","shell.execute_reply.started":"2024-02-22T08:50:53.662906Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1, Loss: 2.302617311477661\n","Epoch: 2, Loss: 2.3002283573150635\n","Epoch: 3, Loss: 2.2929179668426514\n","Epoch: 4, Loss: 2.272113084793091\n","Epoch: 5, Loss: 2.2460567951202393\n","Epoch: 6, Loss: 2.2430148124694824\n","Epoch: 7, Loss: 2.240355968475342\n","Epoch: 8, Loss: 2.2343459129333496\n","Epoch: 9, Loss: 2.233771324157715\n","Epoch: 10, Loss: 2.2220051288604736\n","Epoch: 11, Loss: 2.2155678272247314\n","Epoch: 12, Loss: 2.213329792022705\n","Epoch: 13, Loss: 2.21610951423645\n","Epoch: 14, Loss: 2.1971776485443115\n","Epoch: 15, Loss: 2.210327386856079\n","Epoch: 16, Loss: 2.194064140319824\n","Epoch: 17, Loss: 2.1889307498931885\n","Epoch: 18, Loss: 2.1878581047058105\n","Epoch: 19, Loss: 2.173678159713745\n","Epoch: 20, Loss: 2.181079864501953\n","Epoch: 21, Loss: 2.1640243530273438\n","Epoch: 22, Loss: 2.1724190711975098\n","Epoch: 23, Loss: 2.1540911197662354\n","Epoch: 24, Loss: 2.1585235595703125\n","Epoch: 25, Loss: 2.1424648761749268\n","Epoch: 26, Loss: 2.1367039680480957\n","Epoch: 27, Loss: 2.1290009021759033\n","Epoch: 28, Loss: 2.1076836585998535\n","Epoch: 29, Loss: 2.122649669647217\n","Epoch: 30, Loss: 2.1071937084198\n","Epoch: 31, Loss: 2.073005199432373\n","Epoch: 32, Loss: 2.0867061614990234\n","Epoch: 33, Loss: 2.058610677719116\n","Epoch: 34, Loss: 2.1035382747650146\n","Epoch: 35, Loss: 2.117461681365967\n","Epoch: 36, Loss: 2.100672960281372\n","Epoch: 37, Loss: 2.0627880096435547\n","Epoch: 38, Loss: 2.0637776851654053\n","Epoch: 39, Loss: 2.07167911529541\n","Epoch: 40, Loss: 2.069471597671509\n","Epoch: 41, Loss: 2.0537607669830322\n","Epoch: 42, Loss: 2.0402817726135254\n","Epoch: 43, Loss: 2.0485029220581055\n","Epoch: 44, Loss: 2.0332508087158203\n","Epoch: 45, Loss: 2.027172565460205\n","Epoch: 46, Loss: 2.0247747898101807\n","Epoch: 47, Loss: 2.025394916534424\n","Epoch: 48, Loss: 2.0204062461853027\n","Epoch: 49, Loss: 2.00494647026062\n","Epoch: 50, Loss: 2.0018744468688965\n","Epoch: 51, Loss: 1.9996823072433472\n","Epoch: 52, Loss: 2.000544786453247\n","Epoch: 53, Loss: 1.9847630262374878\n","Epoch: 54, Loss: 1.9790335893630981\n","Epoch: 55, Loss: 1.9799675941467285\n","Epoch: 56, Loss: 1.9721840620040894\n","Epoch: 57, Loss: 1.9677789211273193\n","Epoch: 58, Loss: 1.9640305042266846\n","Epoch: 59, Loss: 1.9613037109375\n","Epoch: 60, Loss: 1.955145239830017\n","Epoch: 61, Loss: 1.9582005739212036\n","Epoch: 62, Loss: 1.948325514793396\n","Epoch: 63, Loss: 1.951161503791809\n","Epoch: 64, Loss: 1.941935420036316\n","Epoch: 65, Loss: 1.9423357248306274\n","Epoch: 66, Loss: 1.9351146221160889\n","Epoch: 67, Loss: 1.934356927871704\n","Epoch: 68, Loss: 1.9275107383728027\n","Epoch: 69, Loss: 1.9237643480300903\n","Epoch: 70, Loss: 1.9210622310638428\n","Epoch: 71, Loss: 1.919030785560608\n","Epoch: 72, Loss: 1.9147329330444336\n","Epoch: 73, Loss: 1.9213356971740723\n","Epoch: 74, Loss: 1.9571330547332764\n","Epoch: 75, Loss: 1.9282807111740112\n","Epoch: 76, Loss: 1.9071872234344482\n","Epoch: 77, Loss: 1.927089810371399\n","Epoch: 78, Loss: 1.9067012071609497\n","Epoch: 79, Loss: 1.9157794713974\n","Epoch: 80, Loss: 1.9028990268707275\n","Epoch: 81, Loss: 1.9145749807357788\n","Epoch: 82, Loss: 1.9028981924057007\n","Epoch: 83, Loss: 1.9027538299560547\n","Epoch: 84, Loss: 1.901854157447815\n","Epoch: 85, Loss: 1.8978434801101685\n","Epoch: 86, Loss: 1.8939592838287354\n","Epoch: 87, Loss: 1.8943387269973755\n","Epoch: 88, Loss: 1.8903203010559082\n","Epoch: 89, Loss: 1.8854554891586304\n","Epoch: 90, Loss: 1.8862828016281128\n","Epoch: 91, Loss: 1.882763147354126\n","Epoch: 92, Loss: 1.8839911222457886\n","Epoch: 93, Loss: 1.8769487142562866\n","Epoch: 94, Loss: 1.8820286989212036\n","Epoch: 95, Loss: 1.876674771308899\n","Epoch: 96, Loss: 1.8747315406799316\n","Epoch: 97, Loss: 1.8738268613815308\n","Epoch: 98, Loss: 1.8715312480926514\n","Epoch: 99, Loss: 1.8706483840942383\n","Epoch: 100, Loss: 1.8733311891555786\n","Epoch: 101, Loss: 1.878868818283081\n","Epoch: 102, Loss: 1.875794768333435\n","Epoch: 103, Loss: 1.866299033164978\n","Epoch: 104, Loss: 1.871597170829773\n","Epoch: 105, Loss: 1.8759570121765137\n","Epoch: 106, Loss: 1.8656432628631592\n","Epoch: 107, Loss: 1.8600289821624756\n","Epoch: 108, Loss: 1.8692336082458496\n","Epoch: 109, Loss: 1.869734287261963\n","Epoch: 110, Loss: 1.860954761505127\n","Epoch: 111, Loss: 1.859771966934204\n","Epoch: 112, Loss: 1.8641034364700317\n","Epoch: 113, Loss: 1.8538819551467896\n","Epoch: 114, Loss: 1.8577061891555786\n","Epoch: 115, Loss: 1.855987310409546\n","Epoch: 116, Loss: 1.8532320261001587\n","Epoch: 117, Loss: 1.8560593128204346\n","Epoch: 118, Loss: 1.8566083908081055\n","Epoch: 119, Loss: 1.8509083986282349\n","Epoch: 120, Loss: 1.851356863975525\n","Epoch: 121, Loss: 1.8537629842758179\n","Epoch: 122, Loss: 1.848076581954956\n","Epoch: 123, Loss: 1.8502227067947388\n","Epoch: 124, Loss: 1.8519935607910156\n","Epoch: 125, Loss: 1.847739815711975\n","Epoch: 126, Loss: 1.850738763809204\n","Epoch: 127, Loss: 1.8494797945022583\n","Epoch: 128, Loss: 1.8542747497558594\n","Epoch: 129, Loss: 1.8510756492614746\n","Epoch: 130, Loss: 1.8403799533843994\n","Epoch: 131, Loss: 1.850351095199585\n","Epoch: 132, Loss: 1.840276837348938\n","Epoch: 133, Loss: 1.8424819707870483\n","Epoch: 134, Loss: 1.8397314548492432\n","Epoch: 135, Loss: 1.8436579704284668\n","Epoch: 136, Loss: 1.8518924713134766\n","Epoch: 137, Loss: 1.843624472618103\n","Epoch: 138, Loss: 1.850924015045166\n","Epoch: 139, Loss: 1.8508108854293823\n","Epoch: 140, Loss: 1.8450407981872559\n","Epoch: 141, Loss: 1.8365806341171265\n","Epoch: 142, Loss: 1.845726490020752\n","Epoch: 143, Loss: 1.8402985334396362\n","Epoch: 144, Loss: 1.8373146057128906\n","Epoch: 145, Loss: 1.8390040397644043\n","Epoch: 146, Loss: 1.8314917087554932\n","Epoch: 147, Loss: 1.835402011871338\n","Epoch: 148, Loss: 1.832094669342041\n","Epoch: 149, Loss: 1.8295135498046875\n","Epoch: 150, Loss: 1.8316155672073364\n","Epoch: 151, Loss: 1.8297194242477417\n","Epoch: 152, Loss: 1.8276807069778442\n","Epoch: 153, Loss: 1.8284826278686523\n","Epoch: 154, Loss: 1.8293979167938232\n","Epoch: 155, Loss: 1.828904151916504\n","Epoch: 156, Loss: 1.828665018081665\n","Epoch: 157, Loss: 1.8286511898040771\n","Epoch: 158, Loss: 1.8270838260650635\n","Epoch: 159, Loss: 1.8277957439422607\n","Epoch: 160, Loss: 1.821785807609558\n","Epoch: 161, Loss: 1.8247740268707275\n","Epoch: 162, Loss: 1.8289610147476196\n","Epoch: 163, Loss: 1.8212978839874268\n","Epoch: 164, Loss: 1.8240669965744019\n","Epoch: 165, Loss: 1.824992299079895\n","Epoch: 166, Loss: 1.827322006225586\n","Epoch: 167, Loss: 1.8238110542297363\n","Epoch: 168, Loss: 1.8307209014892578\n","Epoch: 169, Loss: 1.8204984664916992\n","Epoch: 170, Loss: 1.8186383247375488\n","Epoch: 171, Loss: 1.8231393098831177\n","Epoch: 172, Loss: 1.8225481510162354\n","Epoch: 173, Loss: 1.814770221710205\n","Epoch: 174, Loss: 1.8201302289962769\n","Epoch: 175, Loss: 1.8201227188110352\n","Epoch: 176, Loss: 1.8172755241394043\n","Epoch: 177, Loss: 1.8149288892745972\n","Epoch: 178, Loss: 1.8218914270401\n","Epoch: 179, Loss: 1.8190605640411377\n","Epoch: 180, Loss: 1.8126235008239746\n","Epoch: 181, Loss: 1.8156112432479858\n","Epoch: 182, Loss: 1.8227745294570923\n","Epoch: 183, Loss: 1.8276249170303345\n","Epoch: 184, Loss: 1.8153293132781982\n","Epoch: 185, Loss: 1.8153430223464966\n","Epoch: 186, Loss: 1.8212463855743408\n","Epoch: 187, Loss: 1.8140182495117188\n","Epoch: 188, Loss: 1.8131173849105835\n","Epoch: 189, Loss: 1.823161244392395\n","Epoch: 190, Loss: 1.8107250928878784\n","Epoch: 191, Loss: 1.8158729076385498\n","Epoch: 192, Loss: 1.8156700134277344\n","Epoch: 193, Loss: 1.8076653480529785\n","Epoch: 194, Loss: 1.813605785369873\n","Epoch: 195, Loss: 1.808722734451294\n","Epoch: 196, Loss: 1.8107104301452637\n","Epoch: 197, Loss: 1.8132683038711548\n","Epoch: 198, Loss: 1.8123422861099243\n","Epoch: 199, Loss: 1.810868501663208\n","Epoch: 200, Loss: 1.8125393390655518\n","Epoch: 201, Loss: 1.8170520067214966\n","Epoch: 202, Loss: 1.8062783479690552\n","Epoch: 203, Loss: 1.8083933591842651\n","Epoch: 204, Loss: 1.8069193363189697\n","Epoch: 205, Loss: 1.8061671257019043\n","Epoch: 206, Loss: 1.8058860301971436\n","Epoch: 207, Loss: 1.8147659301757812\n","Epoch: 208, Loss: 1.81564199924469\n","Epoch: 209, Loss: 1.8193353414535522\n","Epoch: 210, Loss: 1.8125356435775757\n","Epoch: 211, Loss: 1.8158560991287231\n","Epoch: 212, Loss: 1.8074023723602295\n","Epoch: 213, Loss: 1.8158466815948486\n","Epoch: 214, Loss: 1.8100993633270264\n","Epoch: 215, Loss: 1.8132439851760864\n","Epoch: 216, Loss: 1.8071213960647583\n","Epoch: 217, Loss: 1.8078750371932983\n","Epoch: 218, Loss: 1.8078068494796753\n","Epoch: 219, Loss: 1.8106880187988281\n","Epoch: 220, Loss: 1.802364706993103\n","Epoch: 221, Loss: 1.8059039115905762\n","Epoch: 222, Loss: 1.8075127601623535\n","Epoch: 223, Loss: 1.8024309873580933\n","Epoch: 224, Loss: 1.8017610311508179\n","Epoch: 225, Loss: 1.8015190362930298\n","Epoch: 226, Loss: 1.8003931045532227\n","Epoch: 227, Loss: 1.8013625144958496\n","Epoch: 228, Loss: 1.7974567413330078\n","Epoch: 229, Loss: 1.8007792234420776\n","Epoch: 230, Loss: 1.801148772239685\n","Epoch: 231, Loss: 1.8072073459625244\n","Epoch: 232, Loss: 1.7990179061889648\n","Epoch: 233, Loss: 1.7991868257522583\n","Epoch: 234, Loss: 1.8008843660354614\n","Epoch: 235, Loss: 1.7989232540130615\n","Epoch: 236, Loss: 1.7966114282608032\n","Epoch: 237, Loss: 1.7948890924453735\n","Epoch: 238, Loss: 1.7974175214767456\n","Epoch: 239, Loss: 1.7996349334716797\n","Epoch: 240, Loss: 1.7967945337295532\n","Epoch: 241, Loss: 1.7958461046218872\n","Epoch: 242, Loss: 1.7935513257980347\n","Epoch: 243, Loss: 1.7975167036056519\n","Epoch: 244, Loss: 1.8007903099060059\n","Epoch: 245, Loss: 1.7949321269989014\n","Epoch: 246, Loss: 1.792798399925232\n","Epoch: 247, Loss: 1.7947906255722046\n","Epoch: 248, Loss: 1.8045682907104492\n","Epoch: 249, Loss: 1.7955741882324219\n","Epoch: 250, Loss: 1.7940157651901245\n","Epoch: 251, Loss: 1.7954851388931274\n","Epoch: 252, Loss: 1.7999036312103271\n","Epoch: 253, Loss: 1.7990633249282837\n","Epoch: 254, Loss: 1.7962414026260376\n","Epoch: 255, Loss: 1.7931853532791138\n","Epoch: 256, Loss: 1.7961795330047607\n","Epoch: 257, Loss: 1.79029381275177\n","Epoch: 258, Loss: 1.7897056341171265\n","Epoch: 259, Loss: 1.7900961637496948\n","Epoch: 260, Loss: 1.7907363176345825\n","Epoch: 261, Loss: 1.7907685041427612\n","Epoch: 262, Loss: 1.7901206016540527\n","Epoch: 263, Loss: 1.7907239198684692\n","Epoch: 264, Loss: 1.789223551750183\n","Epoch: 265, Loss: 1.7966443300247192\n","Epoch: 266, Loss: 1.8113484382629395\n","Epoch: 267, Loss: 1.812902569770813\n","Epoch: 268, Loss: 1.8015309572219849\n","Epoch: 269, Loss: 1.8033215999603271\n","Epoch: 270, Loss: 1.798537254333496\n","Epoch: 271, Loss: 1.7938051223754883\n","Epoch: 272, Loss: 1.8105683326721191\n","Epoch: 273, Loss: 1.7900469303131104\n","Epoch: 274, Loss: 1.7994757890701294\n","Epoch: 275, Loss: 1.7956591844558716\n","Epoch: 276, Loss: 1.8010708093643188\n","Epoch: 277, Loss: 1.794175386428833\n","Epoch: 278, Loss: 1.800459861755371\n","Epoch: 279, Loss: 1.7915892601013184\n","Epoch: 280, Loss: 1.7973661422729492\n","Epoch: 281, Loss: 1.7908847332000732\n","Epoch: 282, Loss: 1.7922855615615845\n","Epoch: 283, Loss: 1.7919843196868896\n","Epoch: 284, Loss: 1.7877094745635986\n","Epoch: 285, Loss: 1.7916771173477173\n","Epoch: 286, Loss: 1.787906289100647\n","Epoch: 287, Loss: 1.7883572578430176\n","Epoch: 288, Loss: 1.7897201776504517\n","Epoch: 289, Loss: 1.7920624017715454\n","Epoch: 290, Loss: 1.7891260385513306\n","Epoch: 291, Loss: 1.7868716716766357\n","Epoch: 292, Loss: 1.795868992805481\n","Epoch: 293, Loss: 1.7973698377609253\n","Epoch: 294, Loss: 1.7937164306640625\n","Epoch: 295, Loss: 1.7919161319732666\n","Epoch: 296, Loss: 1.792813777923584\n","Epoch: 297, Loss: 1.7997359037399292\n","Epoch: 298, Loss: 1.7975304126739502\n","Epoch: 299, Loss: 1.789453387260437\n","Epoch: 300, Loss: 1.7969200611114502\n","Epoch: 1, Loss: 1.79878830909729\n","Epoch: 2, Loss: 1.7886991500854492\n","Epoch: 3, Loss: 1.7908986806869507\n","Epoch: 4, Loss: 1.7841295003890991\n","Epoch: 5, Loss: 1.783068299293518\n","Epoch: 6, Loss: 1.7866982221603394\n","Epoch: 7, Loss: 1.7840899229049683\n","Epoch: 8, Loss: 1.7818349599838257\n","Epoch: 9, Loss: 1.7817106246948242\n","Epoch: 10, Loss: 1.7830560207366943\n","Epoch: 11, Loss: 1.7821919918060303\n","Epoch: 12, Loss: 1.7814905643463135\n","Epoch: 13, Loss: 1.779759407043457\n","Epoch: 14, Loss: 1.77935791015625\n","Epoch: 15, Loss: 1.7804059982299805\n","Epoch: 16, Loss: 1.7799574136734009\n","Epoch: 17, Loss: 1.7795249223709106\n","Epoch: 18, Loss: 1.777771234512329\n","Epoch: 19, Loss: 1.7799478769302368\n","Epoch: 20, Loss: 1.778637409210205\n","Epoch: 21, Loss: 1.7783831357955933\n","Epoch: 22, Loss: 1.7776552438735962\n","Epoch: 23, Loss: 1.7787461280822754\n","Epoch: 24, Loss: 1.7777433395385742\n","Epoch: 25, Loss: 1.7773568630218506\n","Epoch: 26, Loss: 1.7773072719573975\n","Epoch: 27, Loss: 1.7780336141586304\n","Epoch: 28, Loss: 1.7773241996765137\n","Epoch: 29, Loss: 1.7768152952194214\n","Epoch: 30, Loss: 1.7777364253997803\n","Epoch: 31, Loss: 1.7778924703598022\n","Epoch: 32, Loss: 1.776687741279602\n","Epoch: 33, Loss: 1.7763315439224243\n","Epoch: 34, Loss: 1.7755995988845825\n","Epoch: 35, Loss: 1.7750930786132812\n","Epoch: 36, Loss: 1.7760889530181885\n","Epoch: 37, Loss: 1.7765676975250244\n","Epoch: 38, Loss: 1.7758711576461792\n","Epoch: 39, Loss: 1.7751716375350952\n","Epoch: 40, Loss: 1.776153564453125\n","Epoch: 41, Loss: 1.775183081626892\n","Epoch: 42, Loss: 1.7749617099761963\n","Epoch: 43, Loss: 1.7755084037780762\n","Epoch: 44, Loss: 1.7760605812072754\n","Epoch: 45, Loss: 1.7753492593765259\n","Epoch: 46, Loss: 1.7750654220581055\n","Epoch: 47, Loss: 1.7751630544662476\n","Epoch: 48, Loss: 1.774052381515503\n","Epoch: 49, Loss: 1.7760437726974487\n","Epoch: 50, Loss: 1.7742003202438354\n","Epoch: 51, Loss: 1.7731471061706543\n","Epoch: 52, Loss: 1.7747244834899902\n","Epoch: 53, Loss: 1.7740896940231323\n","Epoch: 54, Loss: 1.7728608846664429\n","Epoch: 55, Loss: 1.7742624282836914\n","Epoch: 56, Loss: 1.7723476886749268\n","Epoch: 57, Loss: 1.7727198600769043\n","Epoch: 58, Loss: 1.7738829851150513\n","Epoch: 59, Loss: 1.7724117040634155\n","Epoch: 60, Loss: 1.7727484703063965\n","Epoch: 61, Loss: 1.772349238395691\n","Epoch: 62, Loss: 1.7721936702728271\n","Epoch: 63, Loss: 1.7728118896484375\n","Epoch: 64, Loss: 1.7717373371124268\n","Epoch: 65, Loss: 1.772292971611023\n","Epoch: 66, Loss: 1.7702800035476685\n","Epoch: 67, Loss: 1.7720357179641724\n","Epoch: 68, Loss: 1.7706513404846191\n","Epoch: 69, Loss: 1.7713687419891357\n","Epoch: 70, Loss: 1.771316409111023\n","Epoch: 71, Loss: 1.770308256149292\n","Epoch: 72, Loss: 1.7697330713272095\n","Epoch: 73, Loss: 1.7694215774536133\n","Epoch: 74, Loss: 1.7691410779953003\n","Epoch: 75, Loss: 1.7674789428710938\n","Epoch: 76, Loss: 1.7658289670944214\n","Epoch: 77, Loss: 1.765417456626892\n","Epoch: 78, Loss: 1.763166904449463\n","Epoch: 79, Loss: 1.7614768743515015\n","Epoch: 80, Loss: 1.7599915266036987\n","Epoch: 81, Loss: 1.7573970556259155\n","Epoch: 82, Loss: 1.7555944919586182\n","Epoch: 83, Loss: 1.7530577182769775\n","Epoch: 84, Loss: 1.7518726587295532\n","Epoch: 85, Loss: 1.751393437385559\n","Epoch: 86, Loss: 1.750584602355957\n","Epoch: 87, Loss: 1.7501565217971802\n","Epoch: 88, Loss: 1.7472385168075562\n","Epoch: 89, Loss: 1.7456533908843994\n","Epoch: 90, Loss: 1.7456612586975098\n","Epoch: 91, Loss: 1.743855357170105\n","Epoch: 92, Loss: 1.7434757947921753\n","Epoch: 93, Loss: 1.741239309310913\n","Epoch: 94, Loss: 1.7411586046218872\n","Epoch: 95, Loss: 1.7390949726104736\n","Epoch: 96, Loss: 1.7380725145339966\n","Epoch: 97, Loss: 1.73811936378479\n","Epoch: 98, Loss: 1.7365299463272095\n","Epoch: 99, Loss: 1.7363125085830688\n","Epoch: 100, Loss: 1.7356877326965332\n","Epoch: 101, Loss: 1.7344549894332886\n","Epoch: 102, Loss: 1.734275460243225\n","Epoch: 103, Loss: 1.7323479652404785\n","Epoch: 104, Loss: 1.7326923608779907\n","Epoch: 105, Loss: 1.7321609258651733\n","Epoch: 106, Loss: 1.7312852144241333\n","Epoch: 107, Loss: 1.7295950651168823\n","Epoch: 108, Loss: 1.729672908782959\n","Epoch: 109, Loss: 1.7282323837280273\n","Epoch: 110, Loss: 1.728935718536377\n","Epoch: 111, Loss: 1.7275437116622925\n","Epoch: 112, Loss: 1.7262520790100098\n","Epoch: 113, Loss: 1.7264807224273682\n","Epoch: 114, Loss: 1.7257856130599976\n","Epoch: 115, Loss: 1.7255349159240723\n","Epoch: 116, Loss: 1.7242158651351929\n","Epoch: 117, Loss: 1.7248163223266602\n","Epoch: 118, Loss: 1.7234735488891602\n","Epoch: 119, Loss: 1.723884105682373\n","Epoch: 120, Loss: 1.7222167253494263\n","Epoch: 121, Loss: 1.7230530977249146\n","Epoch: 122, Loss: 1.7217518091201782\n","Epoch: 123, Loss: 1.7221534252166748\n","Epoch: 124, Loss: 1.7206766605377197\n","Epoch: 125, Loss: 1.721744179725647\n","Epoch: 126, Loss: 1.7197632789611816\n","Epoch: 127, Loss: 1.7187888622283936\n","Epoch: 128, Loss: 1.7206171751022339\n","Epoch: 129, Loss: 1.718920111656189\n","Epoch: 130, Loss: 1.718892216682434\n","Epoch: 131, Loss: 1.7195398807525635\n","Epoch: 132, Loss: 1.7185794115066528\n","Epoch: 133, Loss: 1.7175469398498535\n","Epoch: 134, Loss: 1.7190698385238647\n","Epoch: 135, Loss: 1.7161628007888794\n","Epoch: 136, Loss: 1.7185109853744507\n","Epoch: 137, Loss: 1.7164411544799805\n","Epoch: 138, Loss: 1.7155663967132568\n","Epoch: 139, Loss: 1.7150472402572632\n","Epoch: 140, Loss: 1.7167706489562988\n","Epoch: 141, Loss: 1.7157906293869019\n","Epoch: 142, Loss: 1.715680480003357\n","Epoch: 143, Loss: 1.7142752408981323\n","Epoch: 144, Loss: 1.7145413160324097\n","Epoch: 145, Loss: 1.714269757270813\n","Epoch: 146, Loss: 1.714009404182434\n","Epoch: 147, Loss: 1.713092565536499\n","Epoch: 148, Loss: 1.712194561958313\n","Epoch: 149, Loss: 1.7136036157608032\n","Epoch: 150, Loss: 1.7125720977783203\n","Epoch: 151, Loss: 1.7128660678863525\n","Epoch: 152, Loss: 1.7133238315582275\n","Epoch: 153, Loss: 1.711837649345398\n","Epoch: 154, Loss: 1.7102961540222168\n","Epoch: 155, Loss: 1.7121870517730713\n","Epoch: 156, Loss: 1.7100679874420166\n","Epoch: 157, Loss: 1.7109869718551636\n","Epoch: 158, Loss: 1.7095322608947754\n","Epoch: 159, Loss: 1.7101083993911743\n","Epoch: 160, Loss: 1.7112997770309448\n","Epoch: 161, Loss: 1.7099066972732544\n","Epoch: 162, Loss: 1.7104424238204956\n","Epoch: 163, Loss: 1.7090071439743042\n","Epoch: 164, Loss: 1.7111601829528809\n","Epoch: 165, Loss: 1.70989191532135\n","Epoch: 166, Loss: 1.7088489532470703\n","Epoch: 167, Loss: 1.7085154056549072\n","Epoch: 168, Loss: 1.7110753059387207\n","Epoch: 169, Loss: 1.7078319787979126\n","Epoch: 170, Loss: 1.7077789306640625\n","Epoch: 171, Loss: 1.7080047130584717\n","Epoch: 172, Loss: 1.705722451210022\n","Epoch: 173, Loss: 1.707617998123169\n","Epoch: 174, Loss: 1.707051157951355\n","Epoch: 175, Loss: 1.707856297492981\n","Epoch: 176, Loss: 1.7050343751907349\n","Epoch: 177, Loss: 1.7051875591278076\n","Epoch: 178, Loss: 1.704742431640625\n","Epoch: 179, Loss: 1.7054040431976318\n","Epoch: 180, Loss: 1.70598566532135\n","Epoch: 181, Loss: 1.7047609090805054\n","Epoch: 182, Loss: 1.7049211263656616\n","Epoch: 183, Loss: 1.7057154178619385\n","Epoch: 184, Loss: 1.7034560441970825\n","Epoch: 185, Loss: 1.7061563730239868\n","Epoch: 186, Loss: 1.7050445079803467\n","Epoch: 187, Loss: 1.7045577764511108\n","Epoch: 188, Loss: 1.7028875350952148\n","Epoch: 189, Loss: 1.7045202255249023\n","Epoch: 190, Loss: 1.703654408454895\n","Epoch: 191, Loss: 1.7023972272872925\n","Epoch: 192, Loss: 1.702757477760315\n","Epoch: 193, Loss: 1.7027539014816284\n","Epoch: 194, Loss: 1.7025302648544312\n","Epoch: 195, Loss: 1.70140540599823\n","Epoch: 196, Loss: 1.7033140659332275\n","Epoch: 197, Loss: 1.7026050090789795\n","Epoch: 198, Loss: 1.70192551612854\n","Epoch: 199, Loss: 1.7008230686187744\n","Epoch: 200, Loss: 1.702192783355713\n","Epoch: 201, Loss: 1.701027512550354\n","Epoch: 202, Loss: 1.7018330097198486\n","Epoch: 203, Loss: 1.7015607357025146\n","Epoch: 204, Loss: 1.700522541999817\n","Epoch: 205, Loss: 1.700487494468689\n","Epoch: 206, Loss: 1.6991455554962158\n","Epoch: 207, Loss: 1.7002999782562256\n","Epoch: 208, Loss: 1.7005209922790527\n","Epoch: 209, Loss: 1.698814034461975\n","Epoch: 210, Loss: 1.6997709274291992\n","Epoch: 211, Loss: 1.698502779006958\n","Epoch: 212, Loss: 1.7007189989089966\n","Epoch: 213, Loss: 1.6983588933944702\n","Epoch: 214, Loss: 1.6967393159866333\n","Epoch: 215, Loss: 1.699164867401123\n","Epoch: 216, Loss: 1.6978338956832886\n","Epoch: 217, Loss: 1.6991137266159058\n","Epoch: 218, Loss: 1.6983989477157593\n","Epoch: 219, Loss: 1.6974056959152222\n","Epoch: 220, Loss: 1.6981925964355469\n","Epoch: 221, Loss: 1.69775390625\n","Epoch: 222, Loss: 1.6978689432144165\n","Epoch: 223, Loss: 1.6967477798461914\n","Epoch: 224, Loss: 1.6966941356658936\n","Epoch: 225, Loss: 1.6960875988006592\n","Epoch: 226, Loss: 1.6961390972137451\n","Epoch: 227, Loss: 1.6957656145095825\n","Epoch: 228, Loss: 1.6975606679916382\n","Epoch: 229, Loss: 1.6963688135147095\n","Epoch: 230, Loss: 1.696540117263794\n","Epoch: 231, Loss: 1.69492506980896\n","Epoch: 232, Loss: 1.6957865953445435\n","Epoch: 233, Loss: 1.6950013637542725\n","Epoch: 234, Loss: 1.6948044300079346\n","Epoch: 235, Loss: 1.695730209350586\n","Epoch: 236, Loss: 1.6953665018081665\n","Epoch: 237, Loss: 1.6931482553482056\n","Epoch: 238, Loss: 1.6941583156585693\n","Epoch: 239, Loss: 1.693617343902588\n","Epoch: 240, Loss: 1.6942956447601318\n","Epoch: 241, Loss: 1.6928026676177979\n","Epoch: 242, Loss: 1.6939349174499512\n","Epoch: 243, Loss: 1.693963646888733\n","Epoch: 244, Loss: 1.695361614227295\n","Epoch: 245, Loss: 1.6930174827575684\n","Epoch: 246, Loss: 1.6954325437545776\n","Epoch: 247, Loss: 1.6927697658538818\n","Epoch: 248, Loss: 1.6939260959625244\n","Epoch: 249, Loss: 1.69301176071167\n","Epoch: 250, Loss: 1.694087266921997\n","Epoch: 251, Loss: 1.6928120851516724\n","Epoch: 252, Loss: 1.6919691562652588\n","Epoch: 253, Loss: 1.6927646398544312\n","Epoch: 254, Loss: 1.6910762786865234\n","Epoch: 255, Loss: 1.691706895828247\n","Epoch: 256, Loss: 1.6928681135177612\n","Epoch: 257, Loss: 1.6924021244049072\n","Epoch: 258, Loss: 1.690598726272583\n","Epoch: 259, Loss: 1.6888443231582642\n","Epoch: 260, Loss: 1.691559076309204\n","Epoch: 261, Loss: 1.6912213563919067\n","Epoch: 262, Loss: 1.6915524005889893\n","Epoch: 263, Loss: 1.6913526058197021\n","Epoch: 264, Loss: 1.6908611059188843\n","Epoch: 265, Loss: 1.6907390356063843\n","Epoch: 266, Loss: 1.688846230506897\n","Epoch: 267, Loss: 1.6887471675872803\n","Epoch: 268, Loss: 1.6911263465881348\n","Epoch: 269, Loss: 1.68798828125\n","Epoch: 270, Loss: 1.6905630826950073\n","Epoch: 271, Loss: 1.6888309717178345\n","Epoch: 272, Loss: 1.688126564025879\n","Epoch: 273, Loss: 1.6896412372589111\n","Epoch: 274, Loss: 1.6888318061828613\n","Epoch: 275, Loss: 1.6884796619415283\n","Epoch: 276, Loss: 1.6895102262496948\n","Epoch: 277, Loss: 1.6889418363571167\n","Epoch: 278, Loss: 1.68893301486969\n","Epoch: 279, Loss: 1.6877919435501099\n","Epoch: 280, Loss: 1.6885497570037842\n","Epoch: 281, Loss: 1.6876384019851685\n","Epoch: 282, Loss: 1.686835527420044\n","Epoch: 283, Loss: 1.6858611106872559\n","Epoch: 284, Loss: 1.6878989934921265\n","Epoch: 285, Loss: 1.6861039400100708\n","Epoch: 286, Loss: 1.6879512071609497\n","Epoch: 287, Loss: 1.6872293949127197\n","Epoch: 288, Loss: 1.6868854761123657\n","Epoch: 289, Loss: 1.6874282360076904\n","Epoch: 290, Loss: 1.6872485876083374\n","Epoch: 291, Loss: 1.6864627599716187\n","Epoch: 292, Loss: 1.685754656791687\n","Epoch: 293, Loss: 1.6874258518218994\n","Epoch: 294, Loss: 1.6865750551223755\n","Epoch: 295, Loss: 1.6862525939941406\n","Epoch: 296, Loss: 1.6859461069107056\n","Epoch: 297, Loss: 1.6855305433273315\n","Epoch: 298, Loss: 1.6862218379974365\n","Epoch: 299, Loss: 1.6856876611709595\n","Epoch: 300, Loss: 1.6856745481491089\n","Epoch: 301, Loss: 1.6842774152755737\n","Epoch: 302, Loss: 1.6864969730377197\n","Epoch: 303, Loss: 1.6854263544082642\n","Epoch: 304, Loss: 1.6841435432434082\n","Epoch: 305, Loss: 1.6845709085464478\n","Epoch: 306, Loss: 1.685619592666626\n","Epoch: 307, Loss: 1.6840605735778809\n","Epoch: 308, Loss: 1.686161756515503\n","Epoch: 309, Loss: 1.6838546991348267\n","Epoch: 310, Loss: 1.685173511505127\n","Epoch: 311, Loss: 1.6834505796432495\n","Epoch: 312, Loss: 1.6844418048858643\n","Epoch: 313, Loss: 1.6839934587478638\n","Epoch: 314, Loss: 1.6823492050170898\n","Epoch: 315, Loss: 1.6848362684249878\n","Epoch: 316, Loss: 1.6838312149047852\n","Epoch: 317, Loss: 1.6830780506134033\n","Epoch: 318, Loss: 1.682421326637268\n","Epoch: 319, Loss: 1.6830713748931885\n","Epoch: 320, Loss: 1.682893991470337\n","Epoch: 321, Loss: 1.6831614971160889\n","Epoch: 322, Loss: 1.6823087930679321\n","Epoch: 323, Loss: 1.6817210912704468\n","Epoch: 324, Loss: 1.6815754175186157\n","Epoch: 325, Loss: 1.6817573308944702\n","Epoch: 326, Loss: 1.6825716495513916\n","Epoch: 327, Loss: 1.6821280717849731\n","Epoch: 328, Loss: 1.682130217552185\n","Epoch: 329, Loss: 1.6812067031860352\n","Epoch: 330, Loss: 1.6812313795089722\n","Epoch: 331, Loss: 1.680971622467041\n","Epoch: 332, Loss: 1.6802510023117065\n","Epoch: 333, Loss: 1.681942105293274\n","Epoch: 334, Loss: 1.6812330484390259\n","Epoch: 335, Loss: 1.681260585784912\n","Epoch: 336, Loss: 1.678989052772522\n","Epoch: 337, Loss: 1.6819266080856323\n","Epoch: 338, Loss: 1.680009365081787\n","Epoch: 339, Loss: 1.6804029941558838\n","Epoch: 340, Loss: 1.6795070171356201\n","Epoch: 341, Loss: 1.68204927444458\n","Epoch: 342, Loss: 1.6804332733154297\n","Epoch: 343, Loss: 1.6812442541122437\n","Epoch: 344, Loss: 1.6796369552612305\n","Epoch: 345, Loss: 1.68053138256073\n","Epoch: 346, Loss: 1.6798776388168335\n","Epoch: 347, Loss: 1.6796241998672485\n","Epoch: 348, Loss: 1.680102825164795\n","Epoch: 349, Loss: 1.6790387630462646\n","Epoch: 350, Loss: 1.6793180704116821\n","Epoch: 351, Loss: 1.6795474290847778\n","Epoch: 352, Loss: 1.6781612634658813\n","Epoch: 353, Loss: 1.6795421838760376\n","Epoch: 354, Loss: 1.6793466806411743\n","Epoch: 355, Loss: 1.6790536642074585\n","Epoch: 356, Loss: 1.6799838542938232\n","Epoch: 357, Loss: 1.6803187131881714\n","Epoch: 358, Loss: 1.6777268648147583\n","Epoch: 359, Loss: 1.679242491722107\n","Epoch: 360, Loss: 1.6788063049316406\n","Epoch: 361, Loss: 1.6786854267120361\n","Epoch: 362, Loss: 1.6790554523468018\n","Epoch: 363, Loss: 1.678331732749939\n","Epoch: 364, Loss: 1.679882287979126\n","Epoch: 365, Loss: 1.677714228630066\n","Epoch: 366, Loss: 1.678962230682373\n","Epoch: 367, Loss: 1.6775751113891602\n","Epoch: 368, Loss: 1.6794143915176392\n","Epoch: 369, Loss: 1.6765481233596802\n","Epoch: 370, Loss: 1.6773937940597534\n","Epoch: 371, Loss: 1.6789889335632324\n","Epoch: 372, Loss: 1.676851749420166\n","Epoch: 373, Loss: 1.6770312786102295\n","Epoch: 374, Loss: 1.6759148836135864\n","Epoch: 375, Loss: 1.6758962869644165\n","Epoch: 376, Loss: 1.675516128540039\n","Epoch: 377, Loss: 1.6762863397598267\n","Epoch: 378, Loss: 1.6753082275390625\n","Epoch: 379, Loss: 1.6755452156066895\n","Epoch: 380, Loss: 1.676169753074646\n","Epoch: 381, Loss: 1.6755189895629883\n","Epoch: 382, Loss: 1.6768596172332764\n","Epoch: 383, Loss: 1.675163984298706\n","Epoch: 384, Loss: 1.6759947538375854\n","Epoch: 385, Loss: 1.6759968996047974\n","Epoch: 386, Loss: 1.6751954555511475\n","Epoch: 387, Loss: 1.6752140522003174\n","Epoch: 388, Loss: 1.675477385520935\n","Epoch: 389, Loss: 1.6757614612579346\n","Epoch: 390, Loss: 1.6748700141906738\n","Epoch: 391, Loss: 1.6746551990509033\n","Epoch: 392, Loss: 1.6739897727966309\n","Epoch: 393, Loss: 1.6752283573150635\n","Epoch: 394, Loss: 1.6730738878250122\n","Epoch: 395, Loss: 1.6730810403823853\n","Epoch: 396, Loss: 1.675101637840271\n","Epoch: 397, Loss: 1.673856496810913\n","Epoch: 398, Loss: 1.6727532148361206\n","Epoch: 399, Loss: 1.6744885444641113\n","Epoch: 400, Loss: 1.6736619472503662\n","Epoch: 401, Loss: 1.6737221479415894\n","Epoch: 402, Loss: 1.6765321493148804\n","Epoch: 403, Loss: 1.6731749773025513\n","Epoch: 404, Loss: 1.6742198467254639\n","Epoch: 405, Loss: 1.671917200088501\n","Epoch: 406, Loss: 1.6736551523208618\n","Epoch: 407, Loss: 1.6731197834014893\n","Epoch: 408, Loss: 1.6742147207260132\n","Epoch: 409, Loss: 1.6739299297332764\n","Epoch: 410, Loss: 1.6730276346206665\n","Epoch: 411, Loss: 1.6737474203109741\n","Epoch: 412, Loss: 1.6735236644744873\n","Epoch: 413, Loss: 1.6723099946975708\n","Epoch: 414, Loss: 1.6721510887145996\n","Epoch: 415, Loss: 1.6727310419082642\n","Epoch: 416, Loss: 1.6713342666625977\n","Epoch: 417, Loss: 1.672775149345398\n","Epoch: 418, Loss: 1.674074411392212\n","Epoch: 419, Loss: 1.6742452383041382\n","Epoch: 420, Loss: 1.671181082725525\n","Epoch: 421, Loss: 1.671938419342041\n","Epoch: 422, Loss: 1.6717605590820312\n","Epoch: 423, Loss: 1.6719152927398682\n","Epoch: 424, Loss: 1.6715892553329468\n","Epoch: 425, Loss: 1.6723825931549072\n","Epoch: 426, Loss: 1.6717859506607056\n","Epoch: 427, Loss: 1.6730629205703735\n","Epoch: 428, Loss: 1.672041654586792\n","Epoch: 429, Loss: 1.6732616424560547\n","Epoch: 430, Loss: 1.6713554859161377\n","Epoch: 431, Loss: 1.6729145050048828\n","Epoch: 432, Loss: 1.67104172706604\n","Epoch: 433, Loss: 1.6740299463272095\n","Epoch: 434, Loss: 1.6706587076187134\n","Epoch: 435, Loss: 1.6745035648345947\n","Epoch: 436, Loss: 1.67099928855896\n","Epoch: 437, Loss: 1.6733440160751343\n","Epoch: 438, Loss: 1.6706146001815796\n","Epoch: 439, Loss: 1.6725807189941406\n","Epoch: 440, Loss: 1.6726816892623901\n","Epoch: 441, Loss: 1.6711268424987793\n","Epoch: 442, Loss: 1.6711328029632568\n","Epoch: 443, Loss: 1.6692677736282349\n","Epoch: 444, Loss: 1.6702218055725098\n","Epoch: 445, Loss: 1.6708499193191528\n","Epoch: 446, Loss: 1.6696751117706299\n","Epoch: 447, Loss: 1.6699185371398926\n","Epoch: 448, Loss: 1.6717734336853027\n","Epoch: 449, Loss: 1.66938054561615\n","Epoch: 450, Loss: 1.670622706413269\n","Epoch: 451, Loss: 1.668727159500122\n","Epoch: 452, Loss: 1.6704295873641968\n","Epoch: 453, Loss: 1.6714155673980713\n","Epoch: 454, Loss: 1.6702654361724854\n","Epoch: 455, Loss: 1.6700842380523682\n","Epoch: 456, Loss: 1.6709190607070923\n","Epoch: 457, Loss: 1.6701045036315918\n","Epoch: 458, Loss: 1.6701122522354126\n","Epoch: 459, Loss: 1.6689224243164062\n","Epoch: 460, Loss: 1.6692042350769043\n","Epoch: 461, Loss: 1.6681081056594849\n","Epoch: 462, Loss: 1.6682279109954834\n","Epoch: 463, Loss: 1.6707313060760498\n","Epoch: 464, Loss: 1.6689826250076294\n","Epoch: 465, Loss: 1.667363166809082\n","Epoch: 466, Loss: 1.6688294410705566\n","Epoch: 467, Loss: 1.6685818433761597\n","Epoch: 468, Loss: 1.6680749654769897\n","Epoch: 469, Loss: 1.6690959930419922\n","Epoch: 470, Loss: 1.6673505306243896\n","Epoch: 471, Loss: 1.6678564548492432\n","Epoch: 472, Loss: 1.6686921119689941\n","Epoch: 473, Loss: 1.6687856912612915\n","Epoch: 474, Loss: 1.6678754091262817\n","Epoch: 475, Loss: 1.6676141023635864\n","Epoch: 476, Loss: 1.6684372425079346\n","Epoch: 477, Loss: 1.6684266328811646\n","Epoch: 478, Loss: 1.6691721677780151\n","Epoch: 479, Loss: 1.6685034036636353\n","Epoch: 480, Loss: 1.6689682006835938\n","Epoch: 481, Loss: 1.6689423322677612\n","Epoch: 482, Loss: 1.6662367582321167\n","Epoch: 483, Loss: 1.6678645610809326\n","Epoch: 484, Loss: 1.6682771444320679\n","Epoch: 485, Loss: 1.6685881614685059\n","Epoch: 486, Loss: 1.6670818328857422\n","Epoch: 487, Loss: 1.6672651767730713\n","Epoch: 488, Loss: 1.666701316833496\n","Epoch: 489, Loss: 1.668436884880066\n","Epoch: 490, Loss: 1.6670658588409424\n","Epoch: 491, Loss: 1.668786883354187\n","Epoch: 492, Loss: 1.6661906242370605\n","Epoch: 493, Loss: 1.6665211915969849\n","Epoch: 494, Loss: 1.6667357683181763\n","Epoch: 495, Loss: 1.6671607494354248\n","Epoch: 496, Loss: 1.6672348976135254\n","Epoch: 497, Loss: 1.6663185358047485\n","Epoch: 498, Loss: 1.6668791770935059\n","Epoch: 499, Loss: 1.667473554611206\n","Epoch: 500, Loss: 1.6653085947036743\n","Epoch: 501, Loss: 1.6666080951690674\n","Epoch: 502, Loss: 1.6657238006591797\n","Epoch: 503, Loss: 1.665474772453308\n","Epoch: 504, Loss: 1.66475510597229\n","Epoch: 505, Loss: 1.6668646335601807\n","Epoch: 506, Loss: 1.6663997173309326\n","Epoch: 507, Loss: 1.6649116277694702\n","Epoch: 508, Loss: 1.6662112474441528\n","Epoch: 509, Loss: 1.6661112308502197\n","Epoch: 510, Loss: 1.6661796569824219\n","Epoch: 511, Loss: 1.664533019065857\n","Epoch: 512, Loss: 1.666343092918396\n","Epoch: 513, Loss: 1.6647261381149292\n","Epoch: 514, Loss: 1.6646685600280762\n","Epoch: 515, Loss: 1.6665065288543701\n","Epoch: 516, Loss: 1.666283369064331\n","Epoch: 517, Loss: 1.6654210090637207\n","Epoch: 518, Loss: 1.6655408143997192\n","Epoch: 519, Loss: 1.6650906801223755\n","Epoch: 520, Loss: 1.6652697324752808\n","Epoch: 521, Loss: 1.6648039817810059\n","Epoch: 522, Loss: 1.664453387260437\n","Epoch: 523, Loss: 1.6648333072662354\n","Epoch: 524, Loss: 1.6643939018249512\n","Epoch: 525, Loss: 1.665184497833252\n","Epoch: 526, Loss: 1.665714979171753\n","Epoch: 527, Loss: 1.6646068096160889\n","Epoch: 528, Loss: 1.6644842624664307\n","Epoch: 529, Loss: 1.664202094078064\n","Epoch: 530, Loss: 1.665164828300476\n","Epoch: 531, Loss: 1.6645480394363403\n","Epoch: 532, Loss: 1.6630617380142212\n","Epoch: 533, Loss: 1.6654831171035767\n","Epoch: 534, Loss: 1.6648948192596436\n","Epoch: 535, Loss: 1.6648057699203491\n","Epoch: 536, Loss: 1.6647965908050537\n","Epoch: 537, Loss: 1.6662671566009521\n","Epoch: 538, Loss: 1.6638760566711426\n","Epoch: 539, Loss: 1.6644697189331055\n","Epoch: 540, Loss: 1.6645911931991577\n","Epoch: 541, Loss: 1.665024995803833\n","Epoch: 542, Loss: 1.6636883020401\n","Epoch: 543, Loss: 1.664697289466858\n","Epoch: 544, Loss: 1.664316177368164\n","Epoch: 545, Loss: 1.6649597883224487\n","Epoch: 546, Loss: 1.663831114768982\n","Epoch: 547, Loss: 1.6629434823989868\n","Epoch: 548, Loss: 1.6635162830352783\n","Epoch: 549, Loss: 1.6635832786560059\n","Epoch: 550, Loss: 1.6640708446502686\n","Epoch: 551, Loss: 1.6632410287857056\n","Epoch: 552, Loss: 1.6629843711853027\n","Epoch: 553, Loss: 1.6635046005249023\n","Epoch: 554, Loss: 1.6637098789215088\n","Epoch: 555, Loss: 1.6623239517211914\n","Epoch: 556, Loss: 1.662762999534607\n","Epoch: 557, Loss: 1.663045048713684\n","Epoch: 558, Loss: 1.6626437902450562\n","Epoch: 559, Loss: 1.6627179384231567\n","Epoch: 560, Loss: 1.6612534523010254\n","Epoch: 561, Loss: 1.6619787216186523\n","Epoch: 562, Loss: 1.6622291803359985\n","Epoch: 563, Loss: 1.6631585359573364\n","Epoch: 564, Loss: 1.662192463874817\n","Epoch: 565, Loss: 1.6628978252410889\n","Epoch: 566, Loss: 1.6614986658096313\n","Epoch: 567, Loss: 1.662961483001709\n","Epoch: 568, Loss: 1.6617178916931152\n","Epoch: 569, Loss: 1.661312222480774\n","Epoch: 570, Loss: 1.6622313261032104\n","Epoch: 571, Loss: 1.6619724035263062\n","Epoch: 572, Loss: 1.6606148481369019\n","Epoch: 573, Loss: 1.6608695983886719\n","Epoch: 574, Loss: 1.6614079475402832\n","Epoch: 575, Loss: 1.6611789464950562\n","Epoch: 576, Loss: 1.6629093885421753\n","Epoch: 577, Loss: 1.6613011360168457\n","Epoch: 578, Loss: 1.661360740661621\n","Epoch: 579, Loss: 1.6610137224197388\n","Epoch: 580, Loss: 1.6617335081100464\n","Epoch: 581, Loss: 1.6619411706924438\n","Epoch: 582, Loss: 1.662474274635315\n","Epoch: 583, Loss: 1.6602956056594849\n","Epoch: 584, Loss: 1.662172555923462\n","Epoch: 585, Loss: 1.6611701250076294\n","Epoch: 586, Loss: 1.6624938249588013\n","Epoch: 587, Loss: 1.6607028245925903\n","Epoch: 588, Loss: 1.6601896286010742\n","Epoch: 589, Loss: 1.6619887351989746\n","Epoch: 590, Loss: 1.661526083946228\n","Epoch: 591, Loss: 1.6608860492706299\n","Epoch: 592, Loss: 1.6622008085250854\n","Epoch: 593, Loss: 1.6621513366699219\n","Epoch: 594, Loss: 1.659602403640747\n","Epoch: 595, Loss: 1.6628597974777222\n","Epoch: 596, Loss: 1.6602758169174194\n","Epoch: 597, Loss: 1.6604106426239014\n","Epoch: 598, Loss: 1.6618385314941406\n","Epoch: 599, Loss: 1.6600406169891357\n","Epoch: 600, Loss: 1.6604406833648682\n","Epoch: 601, Loss: 1.6610376834869385\n","Epoch: 602, Loss: 1.6613764762878418\n","Epoch: 603, Loss: 1.6603450775146484\n","Epoch: 604, Loss: 1.6602507829666138\n","Epoch: 605, Loss: 1.65890371799469\n","Epoch: 606, Loss: 1.6602516174316406\n","Epoch: 607, Loss: 1.6596553325653076\n","Epoch: 608, Loss: 1.6586250066757202\n","Epoch: 609, Loss: 1.6605008840560913\n","Epoch: 610, Loss: 1.6604773998260498\n","Epoch: 611, Loss: 1.660768985748291\n","Epoch: 612, Loss: 1.6596266031265259\n","Epoch: 613, Loss: 1.6609447002410889\n","Epoch: 614, Loss: 1.658361554145813\n","Epoch: 615, Loss: 1.6590534448623657\n","Epoch: 616, Loss: 1.6596776247024536\n","Epoch: 617, Loss: 1.6587567329406738\n","Epoch: 618, Loss: 1.6584055423736572\n","Epoch: 619, Loss: 1.6581745147705078\n","Epoch: 620, Loss: 1.6584396362304688\n","Epoch: 621, Loss: 1.6583921909332275\n","Epoch: 622, Loss: 1.6589356660842896\n","Epoch: 623, Loss: 1.6584404706954956\n","Epoch: 624, Loss: 1.6579911708831787\n","Epoch: 625, Loss: 1.658815622329712\n","Epoch: 626, Loss: 1.6593787670135498\n","Epoch: 627, Loss: 1.658129096031189\n","Epoch: 628, Loss: 1.658594012260437\n","Epoch: 629, Loss: 1.660070538520813\n","Epoch: 630, Loss: 1.6578054428100586\n","Epoch: 631, Loss: 1.6577343940734863\n","Epoch: 632, Loss: 1.657849907875061\n","Epoch: 633, Loss: 1.6582653522491455\n","Epoch: 634, Loss: 1.6578760147094727\n","Epoch: 635, Loss: 1.6581072807312012\n","Epoch: 636, Loss: 1.6585427522659302\n","Epoch: 637, Loss: 1.6592884063720703\n","Epoch: 638, Loss: 1.6598037481307983\n","Epoch: 639, Loss: 1.6578001976013184\n","Epoch: 640, Loss: 1.6588428020477295\n","Epoch: 641, Loss: 1.657887578010559\n","Epoch: 642, Loss: 1.658286213874817\n","Epoch: 643, Loss: 1.658418893814087\n","Epoch: 644, Loss: 1.6575404405593872\n","Epoch: 645, Loss: 1.6565701961517334\n","Epoch: 646, Loss: 1.6570197343826294\n","Epoch: 647, Loss: 1.6570160388946533\n","Epoch: 648, Loss: 1.6592012643814087\n","Epoch: 649, Loss: 1.6575359106063843\n","Epoch: 650, Loss: 1.6570096015930176\n","Epoch: 651, Loss: 1.6565808057785034\n","Epoch: 652, Loss: 1.6571321487426758\n","Epoch: 653, Loss: 1.6596542596817017\n","Epoch: 654, Loss: 1.6569576263427734\n","Epoch: 655, Loss: 1.6590607166290283\n","Epoch: 656, Loss: 1.6579316854476929\n","Epoch: 657, Loss: 1.658254623413086\n","Epoch: 658, Loss: 1.657363772392273\n","Epoch: 659, Loss: 1.6576789617538452\n","Epoch: 660, Loss: 1.6571749448776245\n","Epoch: 661, Loss: 1.659688949584961\n","Epoch: 662, Loss: 1.6575281620025635\n","Epoch: 663, Loss: 1.6579958200454712\n","Epoch: 664, Loss: 1.6582127809524536\n","Epoch: 665, Loss: 1.6576387882232666\n","Epoch: 666, Loss: 1.657845377922058\n","Epoch: 667, Loss: 1.6574947834014893\n","Epoch: 668, Loss: 1.65770423412323\n","Epoch: 669, Loss: 1.656880259513855\n","Epoch: 670, Loss: 1.6572858095169067\n","Epoch: 671, Loss: 1.6568495035171509\n","Epoch: 672, Loss: 1.6571846008300781\n","Epoch: 673, Loss: 1.6574426889419556\n","Epoch: 674, Loss: 1.657700777053833\n","Epoch: 675, Loss: 1.6566095352172852\n","Epoch: 676, Loss: 1.656891942024231\n","Epoch: 677, Loss: 1.6568695306777954\n","Epoch: 678, Loss: 1.6563318967819214\n","Epoch: 679, Loss: 1.655970573425293\n","Epoch: 680, Loss: 1.6561075448989868\n","Epoch: 681, Loss: 1.6555445194244385\n","Epoch: 682, Loss: 1.6560742855072021\n","Epoch: 683, Loss: 1.6552764177322388\n","Epoch: 684, Loss: 1.6552388668060303\n","Epoch: 685, Loss: 1.6562161445617676\n","Epoch: 686, Loss: 1.6553993225097656\n","Epoch: 687, Loss: 1.6548939943313599\n","Epoch: 688, Loss: 1.6563756465911865\n","Epoch: 689, Loss: 1.654269814491272\n","Epoch: 690, Loss: 1.6547845602035522\n","Epoch: 691, Loss: 1.6557179689407349\n","Epoch: 692, Loss: 1.6559321880340576\n","Epoch: 693, Loss: 1.6553199291229248\n","Epoch: 694, Loss: 1.6563607454299927\n","Epoch: 695, Loss: 1.655293583869934\n","Epoch: 696, Loss: 1.6573561429977417\n","Epoch: 697, Loss: 1.6555776596069336\n","Epoch: 698, Loss: 1.6550718545913696\n","Epoch: 699, Loss: 1.6551223993301392\n","Epoch: 700, Loss: 1.6550700664520264\n","Epoch: 701, Loss: 1.6550287008285522\n","Epoch: 702, Loss: 1.6546927690505981\n","Epoch: 703, Loss: 1.6543350219726562\n","Epoch: 704, Loss: 1.6539828777313232\n","Epoch: 705, Loss: 1.6549067497253418\n","Epoch: 706, Loss: 1.6539804935455322\n","Epoch: 707, Loss: 1.6545554399490356\n","Epoch: 708, Loss: 1.654358148574829\n","Epoch: 709, Loss: 1.655134677886963\n","Epoch: 710, Loss: 1.6540192365646362\n","Epoch: 711, Loss: 1.6534987688064575\n","Epoch: 712, Loss: 1.6540815830230713\n","Epoch: 713, Loss: 1.6535860300064087\n","Epoch: 714, Loss: 1.6533658504486084\n","Epoch: 715, Loss: 1.6539387702941895\n","Epoch: 716, Loss: 1.655024766921997\n","Epoch: 717, Loss: 1.6532835960388184\n","Epoch: 718, Loss: 1.653738021850586\n","Epoch: 719, Loss: 1.6546581983566284\n","Epoch: 720, Loss: 1.652565598487854\n","Epoch: 721, Loss: 1.6545307636260986\n","Epoch: 722, Loss: 1.6544249057769775\n","Epoch: 723, Loss: 1.6545369625091553\n","Epoch: 724, Loss: 1.6537901163101196\n","Epoch: 725, Loss: 1.6532974243164062\n","Epoch: 726, Loss: 1.654658555984497\n","Epoch: 727, Loss: 1.6540963649749756\n","Epoch: 728, Loss: 1.6536993980407715\n","Epoch: 729, Loss: 1.6537210941314697\n","Epoch: 730, Loss: 1.6545928716659546\n","Epoch: 731, Loss: 1.6543911695480347\n","Epoch: 732, Loss: 1.6521587371826172\n","Epoch: 733, Loss: 1.6522812843322754\n","Epoch: 734, Loss: 1.652221918106079\n","Epoch: 735, Loss: 1.652382493019104\n","Epoch: 736, Loss: 1.6526381969451904\n","Epoch: 737, Loss: 1.6538604497909546\n","Epoch: 738, Loss: 1.6538845300674438\n","Epoch: 739, Loss: 1.6520847082138062\n","Epoch: 740, Loss: 1.6529138088226318\n","Epoch: 741, Loss: 1.652990698814392\n","Epoch: 742, Loss: 1.6527655124664307\n","Epoch: 743, Loss: 1.652858853340149\n","Epoch: 744, Loss: 1.6524935960769653\n","Epoch: 745, Loss: 1.654304027557373\n","Epoch: 746, Loss: 1.653454065322876\n","Epoch: 747, Loss: 1.6543753147125244\n","Epoch: 748, Loss: 1.6536003351211548\n","Epoch: 749, Loss: 1.6537754535675049\n","Epoch: 750, Loss: 1.6528981924057007\n","Epoch: 751, Loss: 1.6530787944793701\n","Epoch: 752, Loss: 1.6519749164581299\n","Epoch: 753, Loss: 1.6526983976364136\n","Epoch: 754, Loss: 1.6517633199691772\n","Epoch: 755, Loss: 1.6549427509307861\n","Epoch: 756, Loss: 1.652310848236084\n","Epoch: 757, Loss: 1.6543922424316406\n","Epoch: 758, Loss: 1.6520419120788574\n","Epoch: 759, Loss: 1.6557762622833252\n","Epoch: 760, Loss: 1.6538738012313843\n","Epoch: 761, Loss: 1.6524348258972168\n","Epoch: 762, Loss: 1.6523021459579468\n","Epoch: 763, Loss: 1.6524842977523804\n","Epoch: 764, Loss: 1.6537848711013794\n","Epoch: 765, Loss: 1.6516621112823486\n","Epoch: 766, Loss: 1.6535383462905884\n","Epoch: 767, Loss: 1.654561996459961\n","Epoch: 768, Loss: 1.6517914533615112\n","Epoch: 769, Loss: 1.6534276008605957\n","Epoch: 770, Loss: 1.6525555849075317\n","Epoch: 771, Loss: 1.652263879776001\n","Epoch: 772, Loss: 1.651827335357666\n","Epoch: 773, Loss: 1.6516616344451904\n","Epoch: 774, Loss: 1.650743007659912\n","Epoch: 775, Loss: 1.650919795036316\n","Epoch: 776, Loss: 1.650916337966919\n","Epoch: 777, Loss: 1.651520013809204\n","Epoch: 778, Loss: 1.6531943082809448\n","Epoch: 779, Loss: 1.6517999172210693\n","Epoch: 780, Loss: 1.6509904861450195\n","Epoch: 781, Loss: 1.6505286693572998\n","Epoch: 782, Loss: 1.6513937711715698\n","Epoch: 783, Loss: 1.6514867544174194\n","Epoch: 784, Loss: 1.6525732278823853\n","Epoch: 785, Loss: 1.6517480611801147\n","Epoch: 786, Loss: 1.651965618133545\n","Epoch: 787, Loss: 1.6506683826446533\n","Epoch: 788, Loss: 1.6504448652267456\n","Epoch: 789, Loss: 1.651367425918579\n","Epoch: 790, Loss: 1.6508588790893555\n","Epoch: 791, Loss: 1.650594711303711\n","Epoch: 792, Loss: 1.6521793603897095\n","Epoch: 793, Loss: 1.6505554914474487\n","Epoch: 794, Loss: 1.6503453254699707\n","Epoch: 795, Loss: 1.651118278503418\n","Epoch: 796, Loss: 1.6498500108718872\n","Epoch: 797, Loss: 1.6508114337921143\n","Epoch: 798, Loss: 1.6509934663772583\n","Epoch: 799, Loss: 1.6507083177566528\n","Epoch: 800, Loss: 1.6514956951141357\n","Epoch: 801, Loss: 1.6510294675827026\n","Epoch: 802, Loss: 1.6507951021194458\n","Epoch: 803, Loss: 1.651737928390503\n","Epoch: 804, Loss: 1.6498526334762573\n","Epoch: 805, Loss: 1.6509783267974854\n","Epoch: 806, Loss: 1.651341199874878\n","Epoch: 807, Loss: 1.6503400802612305\n","Epoch: 808, Loss: 1.6518917083740234\n","Epoch: 809, Loss: 1.650505542755127\n","Epoch: 810, Loss: 1.650181770324707\n","Epoch: 811, Loss: 1.6494390964508057\n","Epoch: 812, Loss: 1.6504894495010376\n","Epoch: 813, Loss: 1.6512476205825806\n","Epoch: 814, Loss: 1.6513452529907227\n","Epoch: 815, Loss: 1.6501104831695557\n","Epoch: 816, Loss: 1.6495293378829956\n","Epoch: 817, Loss: 1.6500539779663086\n","Epoch: 818, Loss: 1.6499825716018677\n","Epoch: 819, Loss: 1.6482840776443481\n","Epoch: 820, Loss: 1.649626612663269\n","Epoch: 821, Loss: 1.6494864225387573\n","Epoch: 822, Loss: 1.648239254951477\n","Epoch: 823, Loss: 1.6502193212509155\n","Epoch: 824, Loss: 1.649332046508789\n","Epoch: 825, Loss: 1.6492234468460083\n","Epoch: 826, Loss: 1.649939775466919\n","Epoch: 827, Loss: 1.650072455406189\n","Epoch: 828, Loss: 1.649376630783081\n","Epoch: 829, Loss: 1.6496734619140625\n","Epoch: 830, Loss: 1.650634527206421\n","Epoch: 831, Loss: 1.6489969491958618\n","Epoch: 832, Loss: 1.6506993770599365\n","Epoch: 833, Loss: 1.6505062580108643\n","Epoch: 834, Loss: 1.6488137245178223\n","Epoch: 835, Loss: 1.6495426893234253\n","Epoch: 836, Loss: 1.6513540744781494\n","Epoch: 837, Loss: 1.6495755910873413\n","Epoch: 838, Loss: 1.6492197513580322\n","Epoch: 839, Loss: 1.64967942237854\n","Epoch: 840, Loss: 1.6480419635772705\n","Epoch: 841, Loss: 1.6507289409637451\n","Epoch: 842, Loss: 1.6482458114624023\n","Epoch: 843, Loss: 1.6493489742279053\n","Epoch: 844, Loss: 1.6489428281784058\n","Epoch: 845, Loss: 1.6486566066741943\n","Epoch: 846, Loss: 1.6487656831741333\n","Epoch: 847, Loss: 1.648727536201477\n","Epoch: 848, Loss: 1.6490681171417236\n","Epoch: 849, Loss: 1.6478164196014404\n","Epoch: 850, Loss: 1.6491565704345703\n","Epoch: 851, Loss: 1.6477882862091064\n","Epoch: 852, Loss: 1.64749276638031\n","Epoch: 853, Loss: 1.6486574411392212\n","Epoch: 854, Loss: 1.6475508213043213\n","Epoch: 855, Loss: 1.64798104763031\n","Epoch: 856, Loss: 1.6486124992370605\n","Epoch: 857, Loss: 1.6496963500976562\n","Epoch: 858, Loss: 1.6480356454849243\n","Epoch: 859, Loss: 1.6507015228271484\n","Epoch: 860, Loss: 1.649547815322876\n","Epoch: 861, Loss: 1.651300311088562\n","Epoch: 862, Loss: 1.6485060453414917\n","Epoch: 863, Loss: 1.6503477096557617\n","Epoch: 864, Loss: 1.648807168006897\n","Epoch: 865, Loss: 1.6491132974624634\n","Epoch: 866, Loss: 1.6494659185409546\n","Epoch: 867, Loss: 1.6493779420852661\n","Epoch: 868, Loss: 1.6485933065414429\n","Epoch: 869, Loss: 1.648663878440857\n","Epoch: 870, Loss: 1.6472690105438232\n","Epoch: 871, Loss: 1.6481903791427612\n","Epoch: 872, Loss: 1.6487270593643188\n","Epoch: 873, Loss: 1.6479060649871826\n","Epoch: 874, Loss: 1.6489633321762085\n","Epoch: 875, Loss: 1.6469210386276245\n","Epoch: 876, Loss: 1.6490612030029297\n","Epoch: 877, Loss: 1.6476496458053589\n","Epoch: 878, Loss: 1.6486557722091675\n","Epoch: 879, Loss: 1.64795982837677\n","Epoch: 880, Loss: 1.646781325340271\n","Epoch: 881, Loss: 1.647335410118103\n","Epoch: 882, Loss: 1.6484473943710327\n","Epoch: 883, Loss: 1.6472325325012207\n","Epoch: 884, Loss: 1.6473349332809448\n","Epoch: 885, Loss: 1.647080659866333\n","Epoch: 886, Loss: 1.646580457687378\n","Epoch: 887, Loss: 1.647288203239441\n","Epoch: 888, Loss: 1.6466038227081299\n","Epoch: 889, Loss: 1.6481051445007324\n","Epoch: 890, Loss: 1.6482317447662354\n","Epoch: 891, Loss: 1.6474734544754028\n","Epoch: 892, Loss: 1.6473971605300903\n","Epoch: 893, Loss: 1.6461073160171509\n","Epoch: 894, Loss: 1.6477012634277344\n","Epoch: 895, Loss: 1.6492544412612915\n","Epoch: 896, Loss: 1.6469310522079468\n","Epoch: 897, Loss: 1.6485247611999512\n","Epoch: 898, Loss: 1.6463596820831299\n","Epoch: 899, Loss: 1.645998239517212\n","Epoch: 900, Loss: 1.6461418867111206\n","Epoch: 901, Loss: 1.6463348865509033\n","Epoch: 902, Loss: 1.646209955215454\n","Epoch: 903, Loss: 1.645409345626831\n","Epoch: 904, Loss: 1.6466974020004272\n","Epoch: 905, Loss: 1.6463699340820312\n","Epoch: 906, Loss: 1.6463522911071777\n","Epoch: 907, Loss: 1.6464393138885498\n","Epoch: 908, Loss: 1.6450140476226807\n","Epoch: 909, Loss: 1.6468514204025269\n","Epoch: 910, Loss: 1.647094964981079\n","Epoch: 911, Loss: 1.6471539735794067\n","Epoch: 912, Loss: 1.6463619470596313\n","Epoch: 913, Loss: 1.6455968618392944\n","Epoch: 914, Loss: 1.6472712755203247\n","Epoch: 915, Loss: 1.6458337306976318\n","Epoch: 916, Loss: 1.6459510326385498\n","Epoch: 917, Loss: 1.6456011533737183\n","Epoch: 918, Loss: 1.6467763185501099\n","Epoch: 919, Loss: 1.6450098752975464\n","Epoch: 920, Loss: 1.6466059684753418\n","Epoch: 921, Loss: 1.6448252201080322\n","Epoch: 922, Loss: 1.645677089691162\n","Epoch: 923, Loss: 1.6454640626907349\n","Epoch: 924, Loss: 1.6469693183898926\n","Epoch: 925, Loss: 1.6453585624694824\n","Epoch: 926, Loss: 1.6456271409988403\n","Epoch: 927, Loss: 1.6451338529586792\n","Epoch: 928, Loss: 1.645131230354309\n","Epoch: 929, Loss: 1.6465437412261963\n","Epoch: 930, Loss: 1.6474933624267578\n","Epoch: 931, Loss: 1.6465853452682495\n","Epoch: 932, Loss: 1.6453522443771362\n","Epoch: 933, Loss: 1.6478590965270996\n","Epoch: 934, Loss: 1.6464577913284302\n","Epoch: 935, Loss: 1.645871877670288\n","Epoch: 936, Loss: 1.6463184356689453\n","Epoch: 937, Loss: 1.6462315320968628\n","Epoch: 938, Loss: 1.647355079650879\n","Epoch: 939, Loss: 1.6450703144073486\n","Epoch: 940, Loss: 1.6445716619491577\n","Epoch: 941, Loss: 1.6464447975158691\n","Epoch: 942, Loss: 1.6465986967086792\n","Epoch: 943, Loss: 1.6454534530639648\n","Epoch: 944, Loss: 1.6470849514007568\n","Epoch: 945, Loss: 1.6462764739990234\n","Epoch: 946, Loss: 1.6456208229064941\n","Epoch: 947, Loss: 1.6462479829788208\n","Epoch: 948, Loss: 1.6487637758255005\n","Epoch: 949, Loss: 1.6458098888397217\n","Epoch: 950, Loss: 1.646960735321045\n","Epoch: 951, Loss: 1.647153615951538\n","Epoch: 952, Loss: 1.6479791402816772\n","Epoch: 953, Loss: 1.6453633308410645\n","Epoch: 954, Loss: 1.6470493078231812\n","Epoch: 955, Loss: 1.6471190452575684\n","Epoch: 956, Loss: 1.6461101770401\n","Epoch: 957, Loss: 1.6450308561325073\n","Epoch: 958, Loss: 1.6462088823318481\n","Epoch: 959, Loss: 1.646835207939148\n","Epoch: 960, Loss: 1.6449416875839233\n","Epoch: 961, Loss: 1.6457886695861816\n","Epoch: 962, Loss: 1.6441199779510498\n","Epoch: 963, Loss: 1.6466240882873535\n","Epoch: 964, Loss: 1.6441258192062378\n","Epoch: 965, Loss: 1.64400315284729\n","Epoch: 966, Loss: 1.6435307264328003\n","Epoch: 967, Loss: 1.6456632614135742\n","Epoch: 968, Loss: 1.6446796655654907\n","Epoch: 969, Loss: 1.645172357559204\n","Epoch: 970, Loss: 1.6440761089324951\n","Epoch: 971, Loss: 1.6445688009262085\n","Epoch: 972, Loss: 1.6438829898834229\n","Epoch: 973, Loss: 1.6457645893096924\n","Epoch: 974, Loss: 1.646527647972107\n","Epoch: 975, Loss: 1.6437700986862183\n","Epoch: 976, Loss: 1.6453479528427124\n","Epoch: 977, Loss: 1.6449601650238037\n","Epoch: 978, Loss: 1.6464762687683105\n","Epoch: 979, Loss: 1.6455422639846802\n","Epoch: 980, Loss: 1.6458817720413208\n","Epoch: 981, Loss: 1.6453301906585693\n","Epoch: 982, Loss: 1.6443672180175781\n","Epoch: 983, Loss: 1.645886778831482\n","Epoch: 984, Loss: 1.6450328826904297\n","Epoch: 985, Loss: 1.6443568468093872\n","Epoch: 986, Loss: 1.645090937614441\n","Epoch: 987, Loss: 1.6444878578186035\n","Epoch: 988, Loss: 1.644853115081787\n","Epoch: 989, Loss: 1.6444320678710938\n","Epoch: 990, Loss: 1.644336223602295\n","Epoch: 991, Loss: 1.6440953016281128\n","Epoch: 992, Loss: 1.6434292793273926\n","Epoch: 993, Loss: 1.6443194150924683\n","Epoch: 994, Loss: 1.6441915035247803\n","Epoch: 995, Loss: 1.6440602540969849\n","Epoch: 996, Loss: 1.6450999975204468\n","Epoch: 997, Loss: 1.6436861753463745\n","Epoch: 998, Loss: 1.6429193019866943\n","Epoch: 999, Loss: 1.64402437210083\n","Epoch: 1000, Loss: 1.643261432647705\n"]}],"source":["loss_list=[]\n","criterion = nn.CrossEntropyLoss()\n","# param=torch.load('/kaggle/working/mnist.params')\n","# vit.load_state_dict(param)\n","optimizer = optim.Adam(vit.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9)\n","\n","\n","for epoch in range(300):\n","    optimizer.zero_grad()\n","    output = vit(train_x)\n","    loss = criterion(output, train_y)\n","    loss.backward()\n","    optimizer.step()\n","    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n","    loss_list.append(loss.item())\n","\n","optimizer = optim.Adam(vit.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n","\n","for epoch in range(1000):\n","    optimizer.zero_grad()\n","    output = vit(train_x)\n","    loss = criterion(output, train_y)\n","    loss.backward()\n","    optimizer.step()\n","    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n","    loss_list.append(loss.item())\n","    \n","# optimizer = optim.Adam(vit.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n","\n","# for epoch in range(100):\n","#     optimizer.zero_grad()\n","#     output = vit(train_x)\n","#     loss = criterion(output, train_y)\n","#     loss.backward()\n","#     optimizer.step()\n","#     print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n","#     loss_list.append(loss.item())"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T09:35:01.782476Z","iopub.status.busy":"2024-02-22T09:35:01.782093Z","iopub.status.idle":"2024-02-22T09:35:02.507046Z","shell.execute_reply":"2024-02-22T09:35:02.506142Z","shell.execute_reply.started":"2024-02-22T09:35:01.782448Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd \n","pd.Series(loss_list).plot()\n","torch.save(vit.state_dict(), \"/kaggle/working/mnist.params\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T09:35:13.126633Z","iopub.status.busy":"2024-02-22T09:35:13.126107Z","iopub.status.idle":"2024-02-22T09:35:13.132408Z","shell.execute_reply":"2024-02-22T09:35:13.131454Z","shell.execute_reply.started":"2024-02-22T09:35:13.126605Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of parameters: 19866\n"]}],"source":["total_params = sum(p.numel() for p in vit.parameters())\n","print(f\"Total number of parameters: {total_params}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T09:44:00.956771Z","iopub.status.busy":"2024-02-22T09:44:00.955939Z","iopub.status.idle":"2024-02-22T09:44:03.974751Z","shell.execute_reply":"2024-02-22T09:44:03.973796Z","shell.execute_reply.started":"2024-02-22T09:44:00.956744Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.8169"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["param=torch.load('/kaggle/working/mnist.params')\n","vit.load_state_dict(param)\n","_, result = torch.max(vit(train_x), dim=1)\n","len=60000\n","num=0\n","for index,value in enumerate(train_y0):\n","    if(value==result[index]):\n","        \n","        num+=1\n","num/len"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
