{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=x64\n",
      "epoch 0 tensor([ 0.0072,  0.0784,  0.0941, -0.0851, -0.0033], grad_fn=<AddBackward0>) 2\n",
      "Epoch: 1, Loss: 6.699367523193359\n",
      "Epoch: 2, Loss: 6.513133525848389\n",
      "Epoch: 3, Loss: 6.357296943664551\n",
      "Epoch: 4, Loss: 6.209814071655273\n",
      "Epoch: 5, Loss: 6.072033882141113\n",
      "Epoch: 6, Loss: 5.940725803375244\n",
      "Epoch: 7, Loss: 5.816893100738525\n",
      "Epoch: 8, Loss: 5.698294162750244\n",
      "Epoch: 9, Loss: 5.5852370262146\n",
      "Epoch: 10, Loss: 5.484014987945557\n",
      "Epoch: 11, Loss: 5.398417949676514\n",
      "Epoch: 12, Loss: 5.330167770385742\n",
      "Epoch: 13, Loss: 5.277236461639404\n",
      "Epoch: 14, Loss: 5.235803604125977\n",
      "Epoch: 15, Loss: 5.199899673461914\n",
      "Epoch: 16, Loss: 5.164413928985596\n",
      "Epoch: 17, Loss: 5.125647068023682\n",
      "Epoch: 18, Loss: 5.081981658935547\n",
      "Epoch: 19, Loss: 5.033998012542725\n",
      "Epoch: 20, Loss: 4.980964183807373\n",
      "Epoch: 21, Loss: 4.926678657531738\n",
      "Epoch: 22, Loss: 4.872839450836182\n",
      "Epoch: 23, Loss: 4.819921493530273\n",
      "Epoch: 24, Loss: 4.76891565322876\n",
      "Epoch: 25, Loss: 4.721401691436768\n",
      "Epoch: 26, Loss: 4.676792621612549\n",
      "Epoch: 27, Loss: 4.632757186889648\n",
      "Epoch: 28, Loss: 4.587012767791748\n",
      "Epoch: 29, Loss: 4.539849758148193\n",
      "Epoch: 30, Loss: 4.4910359382629395\n",
      "Epoch: 31, Loss: 4.4413251876831055\n",
      "Epoch: 32, Loss: 4.39259147644043\n",
      "Epoch: 33, Loss: 4.343533992767334\n",
      "Epoch: 34, Loss: 4.295393943786621\n",
      "Epoch: 35, Loss: 4.248782634735107\n",
      "Epoch: 36, Loss: 4.203697681427002\n",
      "Epoch: 37, Loss: 4.1602253913879395\n",
      "Epoch: 38, Loss: 4.1186747550964355\n",
      "Epoch: 39, Loss: 4.07847785949707\n",
      "Epoch: 40, Loss: 4.038883686065674\n",
      "Epoch: 41, Loss: 3.9986343383789062\n",
      "Epoch: 42, Loss: 3.958214044570923\n",
      "Epoch: 43, Loss: 3.9188709259033203\n",
      "Epoch: 44, Loss: 3.8809642791748047\n",
      "Epoch: 45, Loss: 3.843416213989258\n",
      "Epoch: 46, Loss: 3.8057303428649902\n",
      "Epoch: 47, Loss: 3.767482042312622\n",
      "Epoch: 48, Loss: 3.7285709381103516\n",
      "Epoch: 49, Loss: 3.6890947818756104\n",
      "Epoch: 50, Loss: 3.6480045318603516\n",
      "epoch 0 tensor([-1.0443, -2.4027, -1.6458, -0.9128, -1.8070], grad_fn=<AddBackward0>) 3\n",
      "Epoch: 1, Loss: 4.899857521057129\n",
      "Epoch: 2, Loss: 4.7842936515808105\n",
      "Epoch: 3, Loss: 4.632952690124512\n",
      "Epoch: 4, Loss: 4.468954563140869\n",
      "Epoch: 5, Loss: 4.306049346923828\n",
      "Epoch: 6, Loss: 4.150835990905762\n",
      "Epoch: 7, Loss: 4.007654190063477\n",
      "Epoch: 8, Loss: 3.8763725757598877\n",
      "Epoch: 9, Loss: 3.7545464038848877\n",
      "Epoch: 10, Loss: 3.6405932903289795\n",
      "Epoch: 11, Loss: 3.5338778495788574\n",
      "Epoch: 12, Loss: 3.43550443649292\n",
      "Epoch: 13, Loss: 3.342233180999756\n",
      "Epoch: 14, Loss: 3.253603458404541\n",
      "Epoch: 15, Loss: 3.1678595542907715\n",
      "Epoch: 16, Loss: 3.084789752960205\n",
      "Epoch: 17, Loss: 3.003085136413574\n",
      "Epoch: 18, Loss: 2.922361135482788\n",
      "Epoch: 19, Loss: 2.843233108520508\n",
      "Epoch: 20, Loss: 2.767530918121338\n",
      "Epoch: 21, Loss: 2.6962904930114746\n",
      "Epoch: 22, Loss: 2.6265532970428467\n",
      "Epoch: 23, Loss: 2.5581581592559814\n",
      "Epoch: 24, Loss: 2.4916045665740967\n",
      "Epoch: 25, Loss: 2.428110361099243\n",
      "Epoch: 26, Loss: 2.3666787147521973\n",
      "Epoch: 27, Loss: 2.307145357131958\n",
      "Epoch: 28, Loss: 2.249504327774048\n",
      "Epoch: 29, Loss: 2.1941030025482178\n",
      "Epoch: 30, Loss: 2.1416985988616943\n",
      "Epoch: 31, Loss: 2.0926618576049805\n",
      "Epoch: 32, Loss: 2.0456933975219727\n",
      "Epoch: 33, Loss: 2.0011074542999268\n",
      "Epoch: 34, Loss: 1.9578590393066406\n",
      "Epoch: 35, Loss: 1.916985034942627\n",
      "Epoch: 36, Loss: 1.8790855407714844\n",
      "Epoch: 37, Loss: 1.8437565565109253\n",
      "Epoch: 38, Loss: 1.810908555984497\n",
      "Epoch: 39, Loss: 1.7804063558578491\n",
      "Epoch: 40, Loss: 1.752455472946167\n",
      "Epoch: 41, Loss: 1.7273056507110596\n",
      "Epoch: 42, Loss: 1.7038573026657104\n",
      "Epoch: 43, Loss: 1.6826350688934326\n",
      "Epoch: 44, Loss: 1.6625744104385376\n",
      "Epoch: 45, Loss: 1.644087314605713\n",
      "Epoch: 46, Loss: 1.6269230842590332\n",
      "Epoch: 47, Loss: 1.6107351779937744\n",
      "Epoch: 48, Loss: 1.595821738243103\n",
      "Epoch: 49, Loss: 1.5817561149597168\n",
      "Epoch: 50, Loss: 1.5678918361663818\n",
      "epoch 0 tensor([-3.6310, -5.1326, -0.1534, -1.0919, -2.9176], grad_fn=<AddBackward0>) 2\n",
      "Epoch: 1, Loss: 3.2686688899993896\n",
      "Epoch: 2, Loss: 3.121150255203247\n",
      "Epoch: 3, Loss: 2.979257583618164\n",
      "Epoch: 4, Loss: 2.877715826034546\n",
      "Epoch: 5, Loss: 2.7926244735717773\n",
      "Epoch: 6, Loss: 2.6950135231018066\n",
      "Epoch: 7, Loss: 2.579888105392456\n",
      "Epoch: 8, Loss: 2.45369291305542\n",
      "Epoch: 9, Loss: 2.3324286937713623\n",
      "Epoch: 10, Loss: 2.2334859371185303\n",
      "Epoch: 11, Loss: 2.1695454120635986\n",
      "Epoch: 12, Loss: 2.1321983337402344\n",
      "Epoch: 13, Loss: 2.097111463546753\n",
      "Epoch: 14, Loss: 2.055098533630371\n",
      "Epoch: 15, Loss: 2.006131649017334\n",
      "Epoch: 16, Loss: 1.9601502418518066\n",
      "Epoch: 17, Loss: 1.9250563383102417\n",
      "Epoch: 18, Loss: 1.8951083421707153\n",
      "Epoch: 19, Loss: 1.8638986349105835\n",
      "Epoch: 20, Loss: 1.8278471231460571\n",
      "Epoch: 21, Loss: 1.7873584032058716\n",
      "Epoch: 22, Loss: 1.7469191551208496\n",
      "Epoch: 23, Loss: 1.7118239402770996\n",
      "Epoch: 24, Loss: 1.684736967086792\n",
      "Epoch: 25, Loss: 1.6644597053527832\n",
      "Epoch: 26, Loss: 1.6446986198425293\n",
      "Epoch: 27, Loss: 1.625391960144043\n",
      "Epoch: 28, Loss: 1.6063554286956787\n",
      "Epoch: 29, Loss: 1.588902473449707\n",
      "Epoch: 30, Loss: 1.5736570358276367\n",
      "Epoch: 31, Loss: 1.5609019994735718\n",
      "Epoch: 32, Loss: 1.5501426458358765\n",
      "Epoch: 33, Loss: 1.5396157503128052\n",
      "Epoch: 34, Loss: 1.527578592300415\n",
      "Epoch: 35, Loss: 1.5137929916381836\n",
      "Epoch: 36, Loss: 1.4998619556427002\n",
      "Epoch: 37, Loss: 1.4872334003448486\n",
      "Epoch: 38, Loss: 1.477349042892456\n",
      "Epoch: 39, Loss: 1.467954158782959\n",
      "Epoch: 40, Loss: 1.4576600790023804\n",
      "Epoch: 41, Loss: 1.4471015930175781\n",
      "Epoch: 42, Loss: 1.4371304512023926\n",
      "Epoch: 43, Loss: 1.4293739795684814\n",
      "Epoch: 44, Loss: 1.4224281311035156\n",
      "Epoch: 45, Loss: 1.4159802198410034\n",
      "Epoch: 46, Loss: 1.4088788032531738\n",
      "Epoch: 47, Loss: 1.4015469551086426\n",
      "Epoch: 48, Loss: 1.3942217826843262\n",
      "Epoch: 49, Loss: 1.3877148628234863\n",
      "Epoch: 50, Loss: 1.3816472291946411\n",
      "epoch 0 tensor([-4.1596, -4.9708, -1.2609, -1.0964, -1.1087], grad_fn=<AddBackward0>) 3\n",
      "Epoch: 1, Loss: 5.5336833000183105\n",
      "Epoch: 2, Loss: 5.349269866943359\n",
      "Epoch: 3, Loss: 5.091144561767578\n",
      "Epoch: 4, Loss: 4.812829494476318\n",
      "Epoch: 5, Loss: 4.544203281402588\n",
      "Epoch: 6, Loss: 4.2875165939331055\n",
      "Epoch: 7, Loss: 4.046938896179199\n",
      "Epoch: 8, Loss: 3.8276355266571045\n",
      "Epoch: 9, Loss: 3.635298490524292\n",
      "Epoch: 10, Loss: 3.474102735519409\n",
      "Epoch: 11, Loss: 3.344442844390869\n",
      "Epoch: 12, Loss: 3.2491164207458496\n",
      "Epoch: 13, Loss: 3.183211326599121\n",
      "Epoch: 14, Loss: 3.137753963470459\n",
      "Epoch: 15, Loss: 3.1033289432525635\n",
      "Epoch: 16, Loss: 3.072361707687378\n",
      "Epoch: 17, Loss: 3.0362207889556885\n",
      "Epoch: 18, Loss: 2.9893198013305664\n",
      "Epoch: 19, Loss: 2.9380416870117188\n",
      "Epoch: 20, Loss: 2.88615345954895\n",
      "Epoch: 21, Loss: 2.8359081745147705\n",
      "Epoch: 22, Loss: 2.790910005569458\n",
      "Epoch: 23, Loss: 2.750305414199829\n",
      "Epoch: 24, Loss: 2.7135863304138184\n",
      "Epoch: 25, Loss: 2.6800734996795654\n",
      "Epoch: 26, Loss: 2.6501832008361816\n",
      "Epoch: 27, Loss: 2.623481512069702\n",
      "Epoch: 28, Loss: 2.5982825756073\n",
      "Epoch: 29, Loss: 2.5742783546447754\n",
      "Epoch: 30, Loss: 2.5518531799316406\n",
      "Epoch: 31, Loss: 2.5301735401153564\n",
      "Epoch: 32, Loss: 2.5084428787231445\n",
      "Epoch: 33, Loss: 2.4886388778686523\n",
      "Epoch: 34, Loss: 2.470503807067871\n",
      "Epoch: 35, Loss: 2.4529218673706055\n",
      "Epoch: 36, Loss: 2.4356813430786133\n",
      "Epoch: 37, Loss: 2.4187405109405518\n",
      "Epoch: 38, Loss: 2.402891159057617\n",
      "Epoch: 39, Loss: 2.3871915340423584\n",
      "Epoch: 40, Loss: 2.3708548545837402\n",
      "Epoch: 41, Loss: 2.353555202484131\n",
      "Epoch: 42, Loss: 2.337247610092163\n",
      "Epoch: 43, Loss: 2.3228039741516113\n",
      "Epoch: 44, Loss: 2.3083465099334717\n",
      "Epoch: 45, Loss: 2.2949562072753906\n",
      "Epoch: 46, Loss: 2.2827014923095703\n",
      "Epoch: 47, Loss: 2.2698843479156494\n",
      "Epoch: 48, Loss: 2.2582433223724365\n",
      "Epoch: 49, Loss: 2.246803045272827\n",
      "Epoch: 50, Loss: 2.2348177433013916\n",
      "epoch 0 tensor([-1.8795, -3.2669, -0.4000, -0.4226, -0.3133], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 2.8172719478607178\n",
      "Epoch: 2, Loss: 2.621035099029541\n",
      "Epoch: 3, Loss: 2.433842658996582\n",
      "Epoch: 4, Loss: 2.346836805343628\n",
      "Epoch: 5, Loss: 2.334657669067383\n",
      "Epoch: 6, Loss: 2.347395896911621\n",
      "Epoch: 7, Loss: 2.339601516723633\n",
      "Epoch: 8, Loss: 2.299887180328369\n",
      "Epoch: 9, Loss: 2.232562780380249\n",
      "Epoch: 10, Loss: 2.148928165435791\n",
      "Epoch: 11, Loss: 2.066174268722534\n",
      "Epoch: 12, Loss: 2.004199981689453\n",
      "Epoch: 13, Loss: 1.969031810760498\n",
      "Epoch: 14, Loss: 1.9577279090881348\n",
      "Epoch: 15, Loss: 1.9572906494140625\n",
      "Epoch: 16, Loss: 1.938582181930542\n",
      "Epoch: 17, Loss: 1.8971037864685059\n",
      "Epoch: 18, Loss: 1.8467309474945068\n",
      "Epoch: 19, Loss: 1.8095734119415283\n",
      "Epoch: 20, Loss: 1.7886292934417725\n",
      "Epoch: 21, Loss: 1.7769643068313599\n",
      "Epoch: 22, Loss: 1.7692331075668335\n",
      "Epoch: 23, Loss: 1.7606703042984009\n",
      "Epoch: 24, Loss: 1.747047781944275\n",
      "Epoch: 25, Loss: 1.728153109550476\n",
      "Epoch: 26, Loss: 1.7072117328643799\n",
      "Epoch: 27, Loss: 1.688279390335083\n",
      "Epoch: 28, Loss: 1.6753013134002686\n",
      "Epoch: 29, Loss: 1.6667108535766602\n",
      "Epoch: 30, Loss: 1.660530686378479\n",
      "Epoch: 31, Loss: 1.6532602310180664\n",
      "Epoch: 32, Loss: 1.641560673713684\n",
      "Epoch: 33, Loss: 1.6260812282562256\n",
      "Epoch: 34, Loss: 1.6100956201553345\n",
      "Epoch: 35, Loss: 1.5973092317581177\n",
      "Epoch: 36, Loss: 1.5870559215545654\n",
      "Epoch: 37, Loss: 1.5778499841690063\n",
      "Epoch: 38, Loss: 1.5685250759124756\n",
      "Epoch: 39, Loss: 1.5584437847137451\n",
      "Epoch: 40, Loss: 1.547013521194458\n",
      "Epoch: 41, Loss: 1.535101294517517\n",
      "Epoch: 42, Loss: 1.5246294736862183\n",
      "Epoch: 43, Loss: 1.5161198377609253\n",
      "Epoch: 44, Loss: 1.5090529918670654\n",
      "Epoch: 45, Loss: 1.5015345811843872\n",
      "Epoch: 46, Loss: 1.4919781684875488\n",
      "Epoch: 47, Loss: 1.4822266101837158\n",
      "Epoch: 48, Loss: 1.4734019041061401\n",
      "Epoch: 49, Loss: 1.4664753675460815\n",
      "Epoch: 50, Loss: 1.4596960544586182\n",
      "epoch 0 tensor([-0.3650, -4.8737,  0.1541, -0.8399, -0.0181], grad_fn=<AddBackward0>) 2\n",
      "Epoch: 1, Loss: 3.600555419921875\n",
      "Epoch: 2, Loss: 3.5495498180389404\n",
      "Epoch: 3, Loss: 3.4654700756073\n",
      "Epoch: 4, Loss: 3.367384672164917\n",
      "Epoch: 5, Loss: 3.264482021331787\n",
      "Epoch: 6, Loss: 3.16719913482666\n",
      "Epoch: 7, Loss: 3.079862594604492\n",
      "Epoch: 8, Loss: 3.0024099349975586\n",
      "Epoch: 9, Loss: 2.9311602115631104\n",
      "Epoch: 10, Loss: 2.862889051437378\n",
      "Epoch: 11, Loss: 2.7968084812164307\n",
      "Epoch: 12, Loss: 2.733468532562256\n",
      "Epoch: 13, Loss: 2.6738903522491455\n",
      "Epoch: 14, Loss: 2.618245840072632\n",
      "Epoch: 15, Loss: 2.5684988498687744\n",
      "Epoch: 16, Loss: 2.522930860519409\n",
      "Epoch: 17, Loss: 2.484957695007324\n",
      "Epoch: 18, Loss: 2.449345827102661\n",
      "Epoch: 19, Loss: 2.4146459102630615\n",
      "Epoch: 20, Loss: 2.3813626766204834\n",
      "Epoch: 21, Loss: 2.3559813499450684\n",
      "Epoch: 22, Loss: 2.330871820449829\n",
      "Epoch: 23, Loss: 2.3033788204193115\n",
      "Epoch: 24, Loss: 2.274305820465088\n",
      "Epoch: 25, Loss: 2.2463951110839844\n",
      "Epoch: 26, Loss: 2.219355583190918\n",
      "Epoch: 27, Loss: 2.194967746734619\n",
      "Epoch: 28, Loss: 2.1724579334259033\n",
      "Epoch: 29, Loss: 2.1520659923553467\n",
      "Epoch: 30, Loss: 2.132985830307007\n",
      "Epoch: 31, Loss: 2.117072105407715\n",
      "Epoch: 32, Loss: 2.102024555206299\n",
      "Epoch: 33, Loss: 2.086820125579834\n",
      "Epoch: 34, Loss: 2.0711922645568848\n",
      "Epoch: 35, Loss: 2.0559356212615967\n",
      "Epoch: 36, Loss: 2.0405690670013428\n",
      "Epoch: 37, Loss: 2.024955987930298\n",
      "Epoch: 38, Loss: 2.009220600128174\n",
      "Epoch: 39, Loss: 1.9949039220809937\n",
      "Epoch: 40, Loss: 1.9812369346618652\n",
      "Epoch: 41, Loss: 1.9684170484542847\n",
      "Epoch: 42, Loss: 1.9556362628936768\n",
      "Epoch: 43, Loss: 1.9423049688339233\n",
      "Epoch: 44, Loss: 1.9301059246063232\n",
      "Epoch: 45, Loss: 1.9193285703659058\n",
      "Epoch: 46, Loss: 1.9066952466964722\n",
      "Epoch: 47, Loss: 1.8927011489868164\n",
      "Epoch: 48, Loss: 1.8825231790542603\n",
      "Epoch: 49, Loss: 1.8708528280258179\n",
      "Epoch: 50, Loss: 1.8592852354049683\n",
      "epoch 0 tensor([-1.5904, -5.0035, -1.0779, -0.8786, -1.8540], grad_fn=<AddBackward0>) 3\n",
      "Epoch: 1, Loss: 2.563854455947876\n",
      "Epoch: 2, Loss: 2.472663164138794\n",
      "Epoch: 3, Loss: 2.350940465927124\n",
      "Epoch: 4, Loss: 2.2312865257263184\n",
      "Epoch: 5, Loss: 2.1302056312561035\n",
      "Epoch: 6, Loss: 2.050252914428711\n",
      "Epoch: 7, Loss: 1.9898608922958374\n",
      "Epoch: 8, Loss: 1.9404643774032593\n",
      "Epoch: 9, Loss: 1.8935679197311401\n",
      "Epoch: 10, Loss: 1.850331425666809\n",
      "Epoch: 11, Loss: 1.8061909675598145\n",
      "Epoch: 12, Loss: 1.7637683153152466\n",
      "Epoch: 13, Loss: 1.7204182147979736\n",
      "Epoch: 14, Loss: 1.6770424842834473\n",
      "Epoch: 15, Loss: 1.6378060579299927\n",
      "Epoch: 16, Loss: 1.6005319356918335\n",
      "Epoch: 17, Loss: 1.5663882493972778\n",
      "Epoch: 18, Loss: 1.5349395275115967\n",
      "Epoch: 19, Loss: 1.5056532621383667\n",
      "Epoch: 20, Loss: 1.4776053428649902\n",
      "Epoch: 21, Loss: 1.449161410331726\n",
      "Epoch: 22, Loss: 1.420230746269226\n",
      "Epoch: 23, Loss: 1.3910006284713745\n",
      "Epoch: 24, Loss: 1.362367868423462\n",
      "Epoch: 25, Loss: 1.3352646827697754\n",
      "Epoch: 26, Loss: 1.3109800815582275\n",
      "Epoch: 27, Loss: 1.2888538837432861\n",
      "Epoch: 28, Loss: 1.2675807476043701\n",
      "Epoch: 29, Loss: 1.2471295595169067\n",
      "Epoch: 30, Loss: 1.2271329164505005\n",
      "Epoch: 31, Loss: 1.2071499824523926\n",
      "Epoch: 32, Loss: 1.1871752738952637\n",
      "Epoch: 33, Loss: 1.168519139289856\n",
      "Epoch: 34, Loss: 1.149938702583313\n",
      "Epoch: 35, Loss: 1.1326550245285034\n",
      "Epoch: 36, Loss: 1.117835521697998\n",
      "Epoch: 37, Loss: 1.1032437086105347\n",
      "Epoch: 38, Loss: 1.0882419347763062\n",
      "Epoch: 39, Loss: 1.073447585105896\n",
      "Epoch: 40, Loss: 1.0591392517089844\n",
      "Epoch: 41, Loss: 1.046101689338684\n",
      "Epoch: 42, Loss: 1.033206582069397\n",
      "Epoch: 43, Loss: 1.0208334922790527\n",
      "Epoch: 44, Loss: 1.0093450546264648\n",
      "Epoch: 45, Loss: 0.9978410601615906\n",
      "Epoch: 46, Loss: 0.9863312244415283\n",
      "Epoch: 47, Loss: 0.97581946849823\n",
      "Epoch: 48, Loss: 0.9651622772216797\n",
      "Epoch: 49, Loss: 0.9550445079803467\n",
      "Epoch: 50, Loss: 0.9445616006851196\n",
      "epoch 0 tensor([-0.4499, -5.1125, -0.7534, -1.2549, -0.7963], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 2.843721389770508\n",
      "Epoch: 2, Loss: 2.7752840518951416\n",
      "Epoch: 3, Loss: 2.6828479766845703\n",
      "Epoch: 4, Loss: 2.5955474376678467\n",
      "Epoch: 5, Loss: 2.522390127182007\n",
      "Epoch: 6, Loss: 2.4683279991149902\n",
      "Epoch: 7, Loss: 2.424137830734253\n",
      "Epoch: 8, Loss: 2.381046772003174\n",
      "Epoch: 9, Loss: 2.3331804275512695\n",
      "Epoch: 10, Loss: 2.2814934253692627\n",
      "Epoch: 11, Loss: 2.2275564670562744\n",
      "Epoch: 12, Loss: 2.1738882064819336\n",
      "Epoch: 13, Loss: 2.1269712448120117\n",
      "Epoch: 14, Loss: 2.0861711502075195\n",
      "Epoch: 15, Loss: 2.053330898284912\n",
      "Epoch: 16, Loss: 2.023641586303711\n",
      "Epoch: 17, Loss: 1.9970184564590454\n",
      "Epoch: 18, Loss: 1.9699069261550903\n",
      "Epoch: 19, Loss: 1.9345835447311401\n",
      "Epoch: 20, Loss: 1.9011746644973755\n",
      "Epoch: 21, Loss: 1.8710565567016602\n",
      "Epoch: 22, Loss: 1.8456180095672607\n",
      "Epoch: 23, Loss: 1.8259468078613281\n",
      "Epoch: 24, Loss: 1.8083148002624512\n",
      "Epoch: 25, Loss: 1.7902288436889648\n",
      "Epoch: 26, Loss: 1.7704970836639404\n",
      "Epoch: 27, Loss: 1.7507323026657104\n",
      "Epoch: 28, Loss: 1.7317465543746948\n",
      "Epoch: 29, Loss: 1.7145057916641235\n",
      "Epoch: 30, Loss: 1.6984665393829346\n",
      "Epoch: 31, Loss: 1.6847338676452637\n",
      "Epoch: 32, Loss: 1.6724835634231567\n",
      "Epoch: 33, Loss: 1.6588581800460815\n",
      "Epoch: 34, Loss: 1.6444177627563477\n",
      "Epoch: 35, Loss: 1.6311448812484741\n",
      "Epoch: 36, Loss: 1.6181126832962036\n",
      "Epoch: 37, Loss: 1.605000615119934\n",
      "Epoch: 38, Loss: 1.5924935340881348\n",
      "Epoch: 39, Loss: 1.5800482034683228\n",
      "Epoch: 40, Loss: 1.5681393146514893\n",
      "Epoch: 41, Loss: 1.5563889741897583\n",
      "Epoch: 42, Loss: 1.5444002151489258\n",
      "Epoch: 43, Loss: 1.5316412448883057\n",
      "Epoch: 44, Loss: 1.5187461376190186\n",
      "Epoch: 45, Loss: 1.5063698291778564\n",
      "Epoch: 46, Loss: 1.4941394329071045\n",
      "Epoch: 47, Loss: 1.4819800853729248\n",
      "Epoch: 48, Loss: 1.4702293872833252\n",
      "Epoch: 49, Loss: 1.4582226276397705\n",
      "Epoch: 50, Loss: 1.4471429586410522\n",
      "epoch 0 tensor([-0.2873, -5.0940, -0.3272, -0.8885,  0.0918], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 2.068148612976074\n",
      "Epoch: 2, Loss: 2.020613670349121\n",
      "Epoch: 3, Loss: 1.95417058467865\n",
      "Epoch: 4, Loss: 1.8863000869750977\n",
      "Epoch: 5, Loss: 1.8273603916168213\n",
      "Epoch: 6, Loss: 1.7809242010116577\n",
      "Epoch: 7, Loss: 1.7472935914993286\n",
      "Epoch: 8, Loss: 1.7214064598083496\n",
      "Epoch: 9, Loss: 1.6939802169799805\n",
      "Epoch: 10, Loss: 1.6652876138687134\n",
      "Epoch: 11, Loss: 1.632867693901062\n",
      "Epoch: 12, Loss: 1.5970005989074707\n",
      "Epoch: 13, Loss: 1.5629162788391113\n",
      "Epoch: 14, Loss: 1.5346795320510864\n",
      "Epoch: 15, Loss: 1.5096946954727173\n",
      "Epoch: 16, Loss: 1.4891738891601562\n",
      "Epoch: 17, Loss: 1.4715896844863892\n",
      "Epoch: 18, Loss: 1.4529894590377808\n",
      "Epoch: 19, Loss: 1.43377685546875\n",
      "Epoch: 20, Loss: 1.4156701564788818\n",
      "Epoch: 21, Loss: 1.3982237577438354\n",
      "Epoch: 22, Loss: 1.3800402879714966\n",
      "Epoch: 23, Loss: 1.3630295991897583\n",
      "Epoch: 24, Loss: 1.3483151197433472\n",
      "Epoch: 25, Loss: 1.3354804515838623\n",
      "Epoch: 26, Loss: 1.3245984315872192\n",
      "Epoch: 27, Loss: 1.314674973487854\n",
      "Epoch: 28, Loss: 1.302786111831665\n",
      "Epoch: 29, Loss: 1.289627194404602\n",
      "Epoch: 30, Loss: 1.275608777999878\n",
      "Epoch: 31, Loss: 1.2610453367233276\n",
      "Epoch: 32, Loss: 1.246505856513977\n",
      "Epoch: 33, Loss: 1.2322615385055542\n",
      "Epoch: 34, Loss: 1.2191277742385864\n",
      "Epoch: 35, Loss: 1.2065529823303223\n",
      "Epoch: 36, Loss: 1.194338321685791\n",
      "Epoch: 37, Loss: 1.182544231414795\n",
      "Epoch: 38, Loss: 1.1733421087265015\n",
      "Epoch: 39, Loss: 1.1643116474151611\n",
      "Epoch: 40, Loss: 1.155279517173767\n",
      "Epoch: 41, Loss: 1.145308256149292\n",
      "Epoch: 42, Loss: 1.1363670825958252\n",
      "Epoch: 43, Loss: 1.1274362802505493\n",
      "Epoch: 44, Loss: 1.1183000802993774\n",
      "Epoch: 45, Loss: 1.1094908714294434\n",
      "Epoch: 46, Loss: 1.1003526449203491\n",
      "Epoch: 47, Loss: 1.0912957191467285\n",
      "Epoch: 48, Loss: 1.0826939344406128\n",
      "Epoch: 49, Loss: 1.0739669799804688\n",
      "Epoch: 50, Loss: 1.0652952194213867\n",
      "epoch 0 tensor([ 0.0566, -4.8866, -1.0163, -0.8169,  0.1462], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 1.8908668756484985\n",
      "Epoch: 2, Loss: 1.7018704414367676\n",
      "Epoch: 3, Loss: 1.5289397239685059\n",
      "Epoch: 4, Loss: 1.4269436597824097\n",
      "Epoch: 5, Loss: 1.3904919624328613\n",
      "Epoch: 6, Loss: 1.3950340747833252\n",
      "Epoch: 7, Loss: 1.4021633863449097\n",
      "Epoch: 8, Loss: 1.3990952968597412\n",
      "Epoch: 9, Loss: 1.3787994384765625\n",
      "Epoch: 10, Loss: 1.3411688804626465\n",
      "Epoch: 11, Loss: 1.2986661195755005\n",
      "Epoch: 12, Loss: 1.2567739486694336\n",
      "Epoch: 13, Loss: 1.218821406364441\n",
      "Epoch: 14, Loss: 1.1895883083343506\n",
      "Epoch: 15, Loss: 1.1743892431259155\n",
      "Epoch: 16, Loss: 1.167726755142212\n",
      "Epoch: 17, Loss: 1.1576333045959473\n",
      "Epoch: 18, Loss: 1.1361823081970215\n",
      "Epoch: 19, Loss: 1.1055610179901123\n",
      "Epoch: 20, Loss: 1.0736545324325562\n",
      "Epoch: 21, Loss: 1.0467288494110107\n",
      "Epoch: 22, Loss: 1.0262714624404907\n",
      "Epoch: 23, Loss: 1.0110118389129639\n",
      "Epoch: 24, Loss: 0.9982431530952454\n",
      "Epoch: 25, Loss: 0.9866152405738831\n",
      "Epoch: 26, Loss: 0.9724271893501282\n",
      "Epoch: 27, Loss: 0.9560028314590454\n",
      "Epoch: 28, Loss: 0.9400998950004578\n",
      "Epoch: 29, Loss: 0.9243919849395752\n",
      "Epoch: 30, Loss: 0.9100184440612793\n",
      "Epoch: 31, Loss: 0.8966660499572754\n",
      "Epoch: 32, Loss: 0.8858680725097656\n",
      "Epoch: 33, Loss: 0.8750010132789612\n",
      "Epoch: 34, Loss: 0.8642635941505432\n",
      "Epoch: 35, Loss: 0.8548278212547302\n",
      "Epoch: 36, Loss: 0.8471325635910034\n",
      "Epoch: 37, Loss: 0.8402469158172607\n",
      "Epoch: 38, Loss: 0.831946611404419\n",
      "Epoch: 39, Loss: 0.8220428228378296\n",
      "Epoch: 40, Loss: 0.8113468885421753\n",
      "Epoch: 41, Loss: 0.8005425930023193\n",
      "Epoch: 42, Loss: 0.7914945483207703\n",
      "Epoch: 43, Loss: 0.7833341360092163\n",
      "Epoch: 44, Loss: 0.7753856778144836\n",
      "Epoch: 45, Loss: 0.7674494981765747\n",
      "Epoch: 46, Loss: 0.7594491839408875\n",
      "Epoch: 47, Loss: 0.7517253160476685\n",
      "Epoch: 48, Loss: 0.744301974773407\n",
      "Epoch: 49, Loss: 0.735481321811676\n",
      "Epoch: 50, Loss: 0.7267177104949951\n",
      "________________________________________\n",
      "epoch 1 tensor([-0.0164, -4.6906, -1.4831, -0.8067,  0.2059], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 4.600747108459473\n",
      "Epoch: 2, Loss: 4.46281099319458\n",
      "Epoch: 3, Loss: 4.277294158935547\n",
      "Epoch: 4, Loss: 4.0671515464782715\n",
      "Epoch: 5, Loss: 3.8583953380584717\n",
      "Epoch: 6, Loss: 3.6764132976531982\n",
      "Epoch: 7, Loss: 3.5267021656036377\n",
      "Epoch: 8, Loss: 3.3979692459106445\n",
      "Epoch: 9, Loss: 3.295391321182251\n",
      "Epoch: 10, Loss: 3.2122504711151123\n",
      "Epoch: 11, Loss: 3.132009506225586\n",
      "Epoch: 12, Loss: 3.047168254852295\n",
      "Epoch: 13, Loss: 2.9677700996398926\n",
      "Epoch: 14, Loss: 2.8916585445404053\n",
      "Epoch: 15, Loss: 2.827598810195923\n",
      "Epoch: 16, Loss: 2.7763800621032715\n",
      "Epoch: 17, Loss: 2.733259677886963\n",
      "Epoch: 18, Loss: 2.6934523582458496\n",
      "Epoch: 19, Loss: 2.65169620513916\n",
      "Epoch: 20, Loss: 2.608126640319824\n",
      "Epoch: 21, Loss: 2.5614635944366455\n",
      "Epoch: 22, Loss: 2.5121212005615234\n",
      "Epoch: 23, Loss: 2.466240167617798\n",
      "Epoch: 24, Loss: 2.427523136138916\n",
      "Epoch: 25, Loss: 2.394052505493164\n",
      "Epoch: 26, Loss: 2.3641138076782227\n",
      "Epoch: 27, Loss: 2.3356940746307373\n",
      "Epoch: 28, Loss: 2.3090929985046387\n",
      "Epoch: 29, Loss: 2.2793686389923096\n",
      "Epoch: 30, Loss: 2.2462687492370605\n",
      "Epoch: 31, Loss: 2.207758903503418\n",
      "Epoch: 32, Loss: 2.1711297035217285\n",
      "Epoch: 33, Loss: 2.1389877796173096\n",
      "Epoch: 34, Loss: 2.118840456008911\n",
      "Epoch: 35, Loss: 2.097095251083374\n",
      "Epoch: 36, Loss: 2.0730345249176025\n",
      "Epoch: 37, Loss: 2.0499119758605957\n",
      "Epoch: 38, Loss: 2.023948907852173\n",
      "Epoch: 39, Loss: 1.9947391748428345\n",
      "Epoch: 40, Loss: 1.9613850116729736\n",
      "Epoch: 41, Loss: 1.93839430809021\n",
      "Epoch: 42, Loss: 1.9255627393722534\n",
      "Epoch: 43, Loss: 1.91172194480896\n",
      "Epoch: 44, Loss: 1.8969218730926514\n",
      "Epoch: 45, Loss: 1.8794643878936768\n",
      "Epoch: 46, Loss: 1.8607473373413086\n",
      "Epoch: 47, Loss: 1.8419758081436157\n",
      "Epoch: 48, Loss: 1.8258519172668457\n",
      "Epoch: 49, Loss: 1.811159610748291\n",
      "Epoch: 50, Loss: 1.7961602210998535\n",
      "epoch 1 tensor([-1.0630, -3.3730, -0.8295,  0.2501,  0.4652], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 2.720576286315918\n",
      "Epoch: 2, Loss: 2.6634247303009033\n",
      "Epoch: 3, Loss: 2.582921028137207\n",
      "Epoch: 4, Loss: 2.5045995712280273\n",
      "Epoch: 5, Loss: 2.437676429748535\n",
      "Epoch: 6, Loss: 2.3808069229125977\n",
      "Epoch: 7, Loss: 2.3283143043518066\n",
      "Epoch: 8, Loss: 2.277681350708008\n",
      "Epoch: 9, Loss: 2.2387919425964355\n",
      "Epoch: 10, Loss: 2.2010276317596436\n",
      "Epoch: 11, Loss: 2.1600542068481445\n",
      "Epoch: 12, Loss: 2.117882251739502\n",
      "Epoch: 13, Loss: 2.077754497528076\n",
      "Epoch: 14, Loss: 2.0386388301849365\n",
      "Epoch: 15, Loss: 2.001614809036255\n",
      "Epoch: 16, Loss: 1.9643638134002686\n",
      "Epoch: 17, Loss: 1.9260319471359253\n",
      "Epoch: 18, Loss: 1.892846703529358\n",
      "Epoch: 19, Loss: 1.8629217147827148\n",
      "Epoch: 20, Loss: 1.8346610069274902\n",
      "Epoch: 21, Loss: 1.8081233501434326\n",
      "Epoch: 22, Loss: 1.7833443880081177\n",
      "Epoch: 23, Loss: 1.7598861455917358\n",
      "Epoch: 24, Loss: 1.7356284856796265\n",
      "Epoch: 25, Loss: 1.7110623121261597\n",
      "Epoch: 26, Loss: 1.6897141933441162\n",
      "Epoch: 27, Loss: 1.6699776649475098\n",
      "Epoch: 28, Loss: 1.648259162902832\n",
      "Epoch: 29, Loss: 1.6275874376296997\n",
      "Epoch: 30, Loss: 1.610554814338684\n",
      "Epoch: 31, Loss: 1.5962105989456177\n",
      "Epoch: 32, Loss: 1.582252860069275\n",
      "Epoch: 33, Loss: 1.5672554969787598\n",
      "Epoch: 34, Loss: 1.5516357421875\n",
      "Epoch: 35, Loss: 1.5369770526885986\n",
      "Epoch: 36, Loss: 1.5219801664352417\n",
      "Epoch: 37, Loss: 1.5062142610549927\n",
      "Epoch: 38, Loss: 1.489858865737915\n",
      "Epoch: 39, Loss: 1.4734023809432983\n",
      "Epoch: 40, Loss: 1.4580421447753906\n",
      "Epoch: 41, Loss: 1.4415712356567383\n",
      "Epoch: 42, Loss: 1.4245643615722656\n",
      "Epoch: 43, Loss: 1.4082348346710205\n",
      "Epoch: 44, Loss: 1.3932594060897827\n",
      "Epoch: 45, Loss: 1.3780239820480347\n",
      "Epoch: 46, Loss: 1.3623286485671997\n",
      "Epoch: 47, Loss: 1.34747314453125\n",
      "Epoch: 48, Loss: 1.3351854085922241\n",
      "Epoch: 49, Loss: 1.3205053806304932\n",
      "Epoch: 50, Loss: 1.3078919649124146\n",
      "epoch 1 tensor([ 0.4211, -4.7399, -1.1632,  0.6566,  0.2534], grad_fn=<AddBackward0>) 3\n",
      "Epoch: 1, Loss: 1.680692434310913\n",
      "Epoch: 2, Loss: 1.6216833591461182\n",
      "Epoch: 3, Loss: 1.5608618259429932\n",
      "Epoch: 4, Loss: 1.5093275308609009\n",
      "Epoch: 5, Loss: 1.4698469638824463\n",
      "Epoch: 6, Loss: 1.4304749965667725\n",
      "Epoch: 7, Loss: 1.389111042022705\n",
      "Epoch: 8, Loss: 1.352195143699646\n",
      "Epoch: 9, Loss: 1.3200125694274902\n",
      "Epoch: 10, Loss: 1.297597050666809\n",
      "Epoch: 11, Loss: 1.2774627208709717\n",
      "Epoch: 12, Loss: 1.2578110694885254\n",
      "Epoch: 13, Loss: 1.235825777053833\n",
      "Epoch: 14, Loss: 1.2120904922485352\n",
      "Epoch: 15, Loss: 1.188613772392273\n",
      "Epoch: 16, Loss: 1.168427586555481\n",
      "Epoch: 17, Loss: 1.1464530229568481\n",
      "Epoch: 18, Loss: 1.1271612644195557\n",
      "Epoch: 19, Loss: 1.1095991134643555\n",
      "Epoch: 20, Loss: 1.0932520627975464\n",
      "Epoch: 21, Loss: 1.0761955976486206\n",
      "Epoch: 22, Loss: 1.057755947113037\n",
      "Epoch: 23, Loss: 1.0380806922912598\n",
      "Epoch: 24, Loss: 1.0192204713821411\n",
      "Epoch: 25, Loss: 1.0054229497909546\n",
      "Epoch: 26, Loss: 0.991737961769104\n",
      "Epoch: 27, Loss: 0.9759153127670288\n",
      "Epoch: 28, Loss: 0.9601081013679504\n",
      "Epoch: 29, Loss: 0.9452700614929199\n",
      "Epoch: 30, Loss: 0.9334253668785095\n",
      "Epoch: 31, Loss: 0.922422468662262\n",
      "Epoch: 32, Loss: 0.9112091064453125\n",
      "Epoch: 33, Loss: 0.8984960913658142\n",
      "Epoch: 34, Loss: 0.8853764533996582\n",
      "Epoch: 35, Loss: 0.8730123043060303\n",
      "Epoch: 36, Loss: 0.8620225787162781\n",
      "Epoch: 37, Loss: 0.851366400718689\n",
      "Epoch: 38, Loss: 0.8396039605140686\n",
      "Epoch: 39, Loss: 0.828644871711731\n",
      "Epoch: 40, Loss: 0.8184561133384705\n",
      "Epoch: 41, Loss: 0.8089684247970581\n",
      "Epoch: 42, Loss: 0.7993847131729126\n",
      "Epoch: 43, Loss: 0.7909196615219116\n",
      "Epoch: 44, Loss: 0.7826173901557922\n",
      "Epoch: 45, Loss: 0.7739264965057373\n",
      "Epoch: 46, Loss: 0.7652658820152283\n",
      "Epoch: 47, Loss: 0.7573462724685669\n",
      "Epoch: 48, Loss: 0.7491828203201294\n",
      "Epoch: 49, Loss: 0.7401574850082397\n",
      "Epoch: 50, Loss: 0.7332382798194885\n",
      "epoch 1 tensor([ 0.5415, -6.3331, -0.3237, -1.3790,  0.1569], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 1.6676990985870361\n",
      "Epoch: 2, Loss: 1.586672067642212\n",
      "Epoch: 3, Loss: 1.4883744716644287\n",
      "Epoch: 4, Loss: 1.3980823755264282\n",
      "Epoch: 5, Loss: 1.323975682258606\n",
      "Epoch: 6, Loss: 1.277821660041809\n",
      "Epoch: 7, Loss: 1.2445834875106812\n",
      "Epoch: 8, Loss: 1.2145450115203857\n",
      "Epoch: 9, Loss: 1.1829004287719727\n",
      "Epoch: 10, Loss: 1.1552801132202148\n",
      "Epoch: 11, Loss: 1.1371161937713623\n",
      "Epoch: 12, Loss: 1.1241015195846558\n",
      "Epoch: 13, Loss: 1.1054953336715698\n",
      "Epoch: 14, Loss: 1.0826514959335327\n",
      "Epoch: 15, Loss: 1.0579365491867065\n",
      "Epoch: 16, Loss: 1.0317494869232178\n",
      "Epoch: 17, Loss: 1.0064738988876343\n",
      "Epoch: 18, Loss: 0.9797822833061218\n",
      "Epoch: 19, Loss: 0.9560381174087524\n",
      "Epoch: 20, Loss: 0.9348551034927368\n",
      "Epoch: 21, Loss: 0.9185243844985962\n",
      "Epoch: 22, Loss: 0.9022889733314514\n",
      "Epoch: 23, Loss: 0.8890982270240784\n",
      "Epoch: 24, Loss: 0.8786338567733765\n",
      "Epoch: 25, Loss: 0.8681822419166565\n",
      "Epoch: 26, Loss: 0.8601616024971008\n",
      "Epoch: 27, Loss: 0.8496606349945068\n",
      "Epoch: 28, Loss: 0.8372941613197327\n",
      "Epoch: 29, Loss: 0.8253928422927856\n",
      "Epoch: 30, Loss: 0.815442681312561\n",
      "Epoch: 31, Loss: 0.8063265085220337\n",
      "Epoch: 32, Loss: 0.7965370416641235\n",
      "Epoch: 33, Loss: 0.7876126170158386\n",
      "Epoch: 34, Loss: 0.7779342532157898\n",
      "Epoch: 35, Loss: 0.7676002979278564\n",
      "Epoch: 36, Loss: 0.7607811689376831\n",
      "Epoch: 37, Loss: 0.7550402879714966\n",
      "Epoch: 38, Loss: 0.7456209659576416\n",
      "Epoch: 39, Loss: 0.7392479777336121\n",
      "Epoch: 40, Loss: 0.7318742275238037\n",
      "Epoch: 41, Loss: 0.7259564995765686\n",
      "Epoch: 42, Loss: 0.7186451554298401\n",
      "Epoch: 43, Loss: 0.711524248123169\n",
      "Epoch: 44, Loss: 0.7052291631698608\n",
      "Epoch: 45, Loss: 0.6977460980415344\n",
      "Epoch: 46, Loss: 0.6917570233345032\n",
      "Epoch: 47, Loss: 0.6861089468002319\n",
      "Epoch: 48, Loss: 0.6808283925056458\n",
      "Epoch: 49, Loss: 0.6760453581809998\n",
      "Epoch: 50, Loss: 0.670426607131958\n",
      "epoch 1 tensor([-0.2394, -4.8393, -1.7845, -0.8379,  0.2365], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 1.410555362701416\n",
      "Epoch: 2, Loss: 1.3764985799789429\n",
      "Epoch: 3, Loss: 1.3235924243927002\n",
      "Epoch: 4, Loss: 1.2646217346191406\n",
      "Epoch: 5, Loss: 1.2102731466293335\n",
      "Epoch: 6, Loss: 1.1616082191467285\n",
      "Epoch: 7, Loss: 1.1221163272857666\n",
      "Epoch: 8, Loss: 1.089600920677185\n",
      "Epoch: 9, Loss: 1.0618969202041626\n",
      "Epoch: 10, Loss: 1.0359582901000977\n",
      "Epoch: 11, Loss: 1.0095194578170776\n",
      "Epoch: 12, Loss: 0.985282838344574\n",
      "Epoch: 13, Loss: 0.9628273248672485\n",
      "Epoch: 14, Loss: 0.943955659866333\n",
      "Epoch: 15, Loss: 0.9278402924537659\n",
      "Epoch: 16, Loss: 0.916073739528656\n",
      "Epoch: 17, Loss: 0.9061762094497681\n",
      "Epoch: 18, Loss: 0.8945425152778625\n",
      "Epoch: 19, Loss: 0.8825628757476807\n",
      "Epoch: 20, Loss: 0.8697316646575928\n",
      "Epoch: 21, Loss: 0.8573795557022095\n",
      "Epoch: 22, Loss: 0.844586968421936\n",
      "Epoch: 23, Loss: 0.8325535655021667\n",
      "Epoch: 24, Loss: 0.8210688829421997\n",
      "Epoch: 25, Loss: 0.8098589181900024\n",
      "Epoch: 26, Loss: 0.7990967035293579\n",
      "Epoch: 27, Loss: 0.7889986634254456\n",
      "Epoch: 28, Loss: 0.7795559167861938\n",
      "Epoch: 29, Loss: 0.7697097659111023\n",
      "Epoch: 30, Loss: 0.7611638903617859\n",
      "Epoch: 31, Loss: 0.7513653635978699\n",
      "Epoch: 32, Loss: 0.7418056726455688\n",
      "Epoch: 33, Loss: 0.7345367670059204\n",
      "Epoch: 34, Loss: 0.7256603240966797\n",
      "Epoch: 35, Loss: 0.7158017754554749\n",
      "Epoch: 36, Loss: 0.7073622941970825\n",
      "Epoch: 37, Loss: 0.7003994584083557\n",
      "Epoch: 38, Loss: 0.6937256455421448\n",
      "Epoch: 39, Loss: 0.6861253380775452\n",
      "Epoch: 40, Loss: 0.6785262823104858\n",
      "Epoch: 41, Loss: 0.6718998551368713\n",
      "Epoch: 42, Loss: 0.6640864014625549\n",
      "Epoch: 43, Loss: 0.658009946346283\n",
      "Epoch: 44, Loss: 0.6516693234443665\n",
      "Epoch: 45, Loss: 0.6438258290290833\n",
      "Epoch: 46, Loss: 0.6380930542945862\n",
      "Epoch: 47, Loss: 0.6318749189376831\n",
      "Epoch: 48, Loss: 0.6269014477729797\n",
      "Epoch: 49, Loss: 0.6203559041023254\n",
      "Epoch: 50, Loss: 0.615135133266449\n",
      "epoch 1 tensor([ 0.6634, -4.8580, -0.8272, -0.8328,  0.1620], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 1.4597147703170776\n",
      "Epoch: 2, Loss: 1.4137784242630005\n",
      "Epoch: 3, Loss: 1.3619922399520874\n",
      "Epoch: 4, Loss: 1.3104276657104492\n",
      "Epoch: 5, Loss: 1.2641769647598267\n",
      "Epoch: 6, Loss: 1.223097801208496\n",
      "Epoch: 7, Loss: 1.1889492273330688\n",
      "Epoch: 8, Loss: 1.159226417541504\n",
      "Epoch: 9, Loss: 1.1319481134414673\n",
      "Epoch: 10, Loss: 1.1057735681533813\n",
      "Epoch: 11, Loss: 1.0793551206588745\n",
      "Epoch: 12, Loss: 1.0528764724731445\n",
      "Epoch: 13, Loss: 1.0269230604171753\n",
      "Epoch: 14, Loss: 1.0017529726028442\n",
      "Epoch: 15, Loss: 0.9791169166564941\n",
      "Epoch: 16, Loss: 0.9577876329421997\n",
      "Epoch: 17, Loss: 0.9383364319801331\n",
      "Epoch: 18, Loss: 0.918534517288208\n",
      "Epoch: 19, Loss: 0.9007156491279602\n",
      "Epoch: 20, Loss: 0.8818157911300659\n",
      "Epoch: 21, Loss: 0.8643864989280701\n",
      "Epoch: 22, Loss: 0.8462068438529968\n",
      "Epoch: 23, Loss: 0.8294916749000549\n",
      "Epoch: 24, Loss: 0.8130857944488525\n",
      "Epoch: 25, Loss: 0.7980679273605347\n",
      "Epoch: 26, Loss: 0.7838205695152283\n",
      "Epoch: 27, Loss: 0.7710831165313721\n",
      "Epoch: 28, Loss: 0.7578700184822083\n",
      "Epoch: 29, Loss: 0.7444308400154114\n",
      "Epoch: 30, Loss: 0.7313504815101624\n",
      "Epoch: 31, Loss: 0.7168216705322266\n",
      "Epoch: 32, Loss: 0.701575756072998\n",
      "Epoch: 33, Loss: 0.687580406665802\n",
      "Epoch: 34, Loss: 0.6769779324531555\n",
      "Epoch: 35, Loss: 0.663444459438324\n",
      "Epoch: 36, Loss: 0.65345299243927\n",
      "Epoch: 37, Loss: 0.641938328742981\n",
      "Epoch: 38, Loss: 0.6305920481681824\n",
      "Epoch: 39, Loss: 0.6177323460578918\n",
      "Epoch: 40, Loss: 0.6067796945571899\n",
      "Epoch: 41, Loss: 0.5953895449638367\n",
      "Epoch: 42, Loss: 0.5861898064613342\n",
      "Epoch: 43, Loss: 0.5768160223960876\n",
      "Epoch: 44, Loss: 0.5685432553291321\n",
      "Epoch: 45, Loss: 0.5603191256523132\n",
      "Epoch: 46, Loss: 0.5512294173240662\n",
      "Epoch: 47, Loss: 0.5427840352058411\n",
      "Epoch: 48, Loss: 0.5346029996871948\n",
      "Epoch: 49, Loss: 0.5270946025848389\n",
      "Epoch: 50, Loss: 0.5202133655548096\n",
      "epoch 1 tensor([ 0.7213, -5.6437,  0.1996, -0.8110,  0.1890], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 1.6251858472824097\n",
      "Epoch: 2, Loss: 1.3692617416381836\n",
      "Epoch: 3, Loss: 1.0992774963378906\n",
      "Epoch: 4, Loss: 0.8665465712547302\n",
      "Epoch: 5, Loss: 0.7171913385391235\n",
      "Epoch: 6, Loss: 0.6574394106864929\n",
      "Epoch: 7, Loss: 0.6487064957618713\n",
      "Epoch: 8, Loss: 0.6804230213165283\n",
      "Epoch: 9, Loss: 0.7056991457939148\n",
      "Epoch: 10, Loss: 0.6974403858184814\n",
      "Epoch: 11, Loss: 0.6799110174179077\n",
      "Epoch: 12, Loss: 0.6443517208099365\n",
      "Epoch: 13, Loss: 0.6016743779182434\n",
      "Epoch: 14, Loss: 0.5664398670196533\n",
      "Epoch: 15, Loss: 0.5313820242881775\n",
      "Epoch: 16, Loss: 0.505372941493988\n",
      "Epoch: 17, Loss: 0.48520317673683167\n",
      "Epoch: 18, Loss: 0.46862849593162537\n",
      "Epoch: 19, Loss: 0.46245333552360535\n",
      "Epoch: 20, Loss: 0.45864903926849365\n",
      "Epoch: 21, Loss: 0.45385560393333435\n",
      "Epoch: 22, Loss: 0.44732582569122314\n",
      "Epoch: 23, Loss: 0.43578121066093445\n",
      "Epoch: 24, Loss: 0.42196720838546753\n",
      "Epoch: 25, Loss: 0.4059009552001953\n",
      "Epoch: 26, Loss: 0.3897091746330261\n",
      "Epoch: 27, Loss: 0.3751411736011505\n",
      "Epoch: 28, Loss: 0.3622879087924957\n",
      "Epoch: 29, Loss: 0.3526421785354614\n",
      "Epoch: 30, Loss: 0.34518131613731384\n",
      "Epoch: 31, Loss: 0.3396793603897095\n",
      "Epoch: 32, Loss: 0.33417075872421265\n",
      "Epoch: 33, Loss: 0.32714080810546875\n",
      "Epoch: 34, Loss: 0.3192625045776367\n",
      "Epoch: 35, Loss: 0.31090760231018066\n",
      "Epoch: 36, Loss: 0.3023141026496887\n",
      "Epoch: 37, Loss: 0.29358431696891785\n",
      "Epoch: 38, Loss: 0.2851814031600952\n",
      "Epoch: 39, Loss: 0.2774685025215149\n",
      "Epoch: 40, Loss: 0.2720493972301483\n",
      "Epoch: 41, Loss: 0.26783615350723267\n",
      "Epoch: 42, Loss: 0.26398012042045593\n",
      "Epoch: 43, Loss: 0.26002687215805054\n",
      "Epoch: 44, Loss: 0.25571778416633606\n",
      "Epoch: 45, Loss: 0.250009149312973\n",
      "Epoch: 46, Loss: 0.24426256120204926\n",
      "Epoch: 47, Loss: 0.23890604078769684\n",
      "Epoch: 48, Loss: 0.23381347954273224\n",
      "Epoch: 49, Loss: 0.22985167801380157\n",
      "Epoch: 50, Loss: 0.22562412917613983\n",
      "epoch 1 tensor([ 1.1555, -5.1435,  0.3427, -0.8434,  0.1385], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 2.162745952606201\n",
      "Epoch: 2, Loss: 2.0588326454162598\n",
      "Epoch: 3, Loss: 1.9761688709259033\n",
      "Epoch: 4, Loss: 1.8656562566757202\n",
      "Epoch: 5, Loss: 1.743177056312561\n",
      "Epoch: 6, Loss: 1.6685786247253418\n",
      "Epoch: 7, Loss: 1.6174726486206055\n",
      "Epoch: 8, Loss: 1.540350317955017\n",
      "Epoch: 9, Loss: 1.478113055229187\n",
      "Epoch: 10, Loss: 1.4337821006774902\n",
      "Epoch: 11, Loss: 1.3771945238113403\n",
      "Epoch: 12, Loss: 1.3220524787902832\n",
      "Epoch: 13, Loss: 1.27016019821167\n",
      "Epoch: 14, Loss: 1.2233046293258667\n",
      "Epoch: 15, Loss: 1.1816173791885376\n",
      "Epoch: 16, Loss: 1.140773892402649\n",
      "Epoch: 17, Loss: 1.1077731847763062\n",
      "Epoch: 18, Loss: 1.0851155519485474\n",
      "Epoch: 19, Loss: 1.0648596286773682\n",
      "Epoch: 20, Loss: 1.0427029132843018\n",
      "Epoch: 21, Loss: 1.022873044013977\n",
      "Epoch: 22, Loss: 1.0021820068359375\n",
      "Epoch: 23, Loss: 0.9774385094642639\n",
      "Epoch: 24, Loss: 0.9542444348335266\n",
      "Epoch: 25, Loss: 0.9346945285797119\n",
      "Epoch: 26, Loss: 0.9193687438964844\n",
      "Epoch: 27, Loss: 0.8960263133049011\n",
      "Epoch: 28, Loss: 0.8796074390411377\n",
      "Epoch: 29, Loss: 0.8650195598602295\n",
      "Epoch: 30, Loss: 0.8499393463134766\n",
      "Epoch: 31, Loss: 0.8349226117134094\n",
      "Epoch: 32, Loss: 0.8214634656906128\n",
      "Epoch: 33, Loss: 0.8092142343521118\n",
      "Epoch: 34, Loss: 0.7994121313095093\n",
      "Epoch: 35, Loss: 0.7876607775688171\n",
      "Epoch: 36, Loss: 0.7732995748519897\n",
      "Epoch: 37, Loss: 0.7600665092468262\n",
      "Epoch: 38, Loss: 0.747789740562439\n",
      "Epoch: 39, Loss: 0.7347027063369751\n",
      "Epoch: 40, Loss: 0.7232388257980347\n",
      "Epoch: 41, Loss: 0.7150528430938721\n",
      "Epoch: 42, Loss: 0.7044683694839478\n",
      "Epoch: 43, Loss: 0.6921998858451843\n",
      "Epoch: 44, Loss: 0.681510329246521\n",
      "Epoch: 45, Loss: 0.67201828956604\n",
      "Epoch: 46, Loss: 0.6607824563980103\n",
      "Epoch: 47, Loss: 0.6506080627441406\n",
      "Epoch: 48, Loss: 0.6391662955284119\n",
      "Epoch: 49, Loss: 0.6260093450546265\n",
      "Epoch: 50, Loss: 0.6154653429985046\n",
      "epoch 1 tensor([ 0.6844, -4.1377, -0.5758, -0.8949,  0.0671], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.8549986481666565\n",
      "Epoch: 2, Loss: 0.7982872128486633\n",
      "Epoch: 3, Loss: 0.7267566919326782\n",
      "Epoch: 4, Loss: 0.6602249145507812\n",
      "Epoch: 5, Loss: 0.6041266322135925\n",
      "Epoch: 6, Loss: 0.5600030422210693\n",
      "Epoch: 7, Loss: 0.5280269384384155\n",
      "Epoch: 8, Loss: 0.5020902156829834\n",
      "Epoch: 9, Loss: 0.48053017258644104\n",
      "Epoch: 10, Loss: 0.4570481479167938\n",
      "Epoch: 11, Loss: 0.43466341495513916\n",
      "Epoch: 12, Loss: 0.4128224551677704\n",
      "Epoch: 13, Loss: 0.3919127583503723\n",
      "Epoch: 14, Loss: 0.37410861253738403\n",
      "Epoch: 15, Loss: 0.35916316509246826\n",
      "Epoch: 16, Loss: 0.3464196026325226\n",
      "Epoch: 17, Loss: 0.3346203863620758\n",
      "Epoch: 18, Loss: 0.3214285373687744\n",
      "Epoch: 19, Loss: 0.30886754393577576\n",
      "Epoch: 20, Loss: 0.2958337366580963\n",
      "Epoch: 21, Loss: 0.2820528745651245\n",
      "Epoch: 22, Loss: 0.26856961846351624\n",
      "Epoch: 23, Loss: 0.25799819827079773\n",
      "Epoch: 24, Loss: 0.24573354423046112\n",
      "Epoch: 25, Loss: 0.23581060767173767\n",
      "Epoch: 26, Loss: 0.22843308746814728\n",
      "Epoch: 27, Loss: 0.22216816246509552\n",
      "Epoch: 28, Loss: 0.2151462733745575\n",
      "Epoch: 29, Loss: 0.20717798173427582\n",
      "Epoch: 30, Loss: 0.19996199011802673\n",
      "Epoch: 31, Loss: 0.19406409561634064\n",
      "Epoch: 32, Loss: 0.1866098791360855\n",
      "Epoch: 33, Loss: 0.18010883033275604\n",
      "Epoch: 34, Loss: 0.17476558685302734\n",
      "Epoch: 35, Loss: 0.16845285892486572\n",
      "Epoch: 36, Loss: 0.16228879988193512\n",
      "Epoch: 37, Loss: 0.15729862451553345\n",
      "Epoch: 38, Loss: 0.15186837315559387\n",
      "Epoch: 39, Loss: 0.146884948015213\n",
      "Epoch: 40, Loss: 0.14196127653121948\n",
      "Epoch: 41, Loss: 0.13692477345466614\n",
      "Epoch: 42, Loss: 0.13178275525569916\n",
      "Epoch: 43, Loss: 0.12744809687137604\n",
      "Epoch: 44, Loss: 0.12228158861398697\n",
      "Epoch: 45, Loss: 0.11797104775905609\n",
      "Epoch: 46, Loss: 0.11435094475746155\n",
      "Epoch: 47, Loss: 0.11061505228281021\n",
      "Epoch: 48, Loss: 0.10747524350881577\n",
      "Epoch: 49, Loss: 0.10412460565567017\n",
      "Epoch: 50, Loss: 0.1007523313164711\n",
      "epoch 1 tensor([ 0.6158, -4.7644,  0.5645, -0.7264,  0.1173], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 1.0629475116729736\n",
      "Epoch: 2, Loss: 0.9231765866279602\n",
      "Epoch: 3, Loss: 0.765903651714325\n",
      "Epoch: 4, Loss: 0.6390607953071594\n",
      "Epoch: 5, Loss: 0.5566496253013611\n",
      "Epoch: 6, Loss: 0.5125501751899719\n",
      "Epoch: 7, Loss: 0.4898380935192108\n",
      "Epoch: 8, Loss: 0.4748344123363495\n",
      "Epoch: 9, Loss: 0.45455726981163025\n",
      "Epoch: 10, Loss: 0.4228779971599579\n",
      "Epoch: 11, Loss: 0.3854334354400635\n",
      "Epoch: 12, Loss: 0.3563392162322998\n",
      "Epoch: 13, Loss: 0.32787948846817017\n",
      "Epoch: 14, Loss: 0.30288052558898926\n",
      "Epoch: 15, Loss: 0.28411999344825745\n",
      "Epoch: 16, Loss: 0.26915672421455383\n",
      "Epoch: 17, Loss: 0.2556300461292267\n",
      "Epoch: 18, Loss: 0.2402474582195282\n",
      "Epoch: 19, Loss: 0.22341814637184143\n",
      "Epoch: 20, Loss: 0.20890182256698608\n",
      "Epoch: 21, Loss: 0.19745159149169922\n",
      "Epoch: 22, Loss: 0.1881840080022812\n",
      "Epoch: 23, Loss: 0.17993375658988953\n",
      "Epoch: 24, Loss: 0.17130161821842194\n",
      "Epoch: 25, Loss: 0.16191986203193665\n",
      "Epoch: 26, Loss: 0.15368735790252686\n",
      "Epoch: 27, Loss: 0.14541175961494446\n",
      "Epoch: 28, Loss: 0.13682228326797485\n",
      "Epoch: 29, Loss: 0.1283692866563797\n",
      "Epoch: 30, Loss: 0.121125228703022\n",
      "Epoch: 31, Loss: 0.11480125784873962\n",
      "Epoch: 32, Loss: 0.10940232127904892\n",
      "Epoch: 33, Loss: 0.10537046194076538\n",
      "Epoch: 34, Loss: 0.10124113410711288\n",
      "Epoch: 35, Loss: 0.09688844531774521\n",
      "Epoch: 36, Loss: 0.09244979172945023\n",
      "Epoch: 37, Loss: 0.08826126158237457\n",
      "Epoch: 38, Loss: 0.08456853777170181\n",
      "Epoch: 39, Loss: 0.08077406883239746\n",
      "Epoch: 40, Loss: 0.07683104276657104\n",
      "Epoch: 41, Loss: 0.07293809950351715\n",
      "Epoch: 42, Loss: 0.06940185278654099\n",
      "Epoch: 43, Loss: 0.06643657386302948\n",
      "Epoch: 44, Loss: 0.0632186010479927\n",
      "Epoch: 45, Loss: 0.06045299395918846\n",
      "Epoch: 46, Loss: 0.057927895337343216\n",
      "Epoch: 47, Loss: 0.055583443492650986\n",
      "Epoch: 48, Loss: 0.05289849266409874\n",
      "Epoch: 49, Loss: 0.050738535821437836\n",
      "Epoch: 50, Loss: 0.04853493720293045\n",
      "________________________________________\n",
      "epoch 2 tensor([ 1.1593, -4.5405,  0.2521, -0.6019,  0.1925], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 1.4543898105621338\n",
      "Epoch: 2, Loss: 1.3273524045944214\n",
      "Epoch: 3, Loss: 1.1824442148208618\n",
      "Epoch: 4, Loss: 1.0514415502548218\n",
      "Epoch: 5, Loss: 0.9477636814117432\n",
      "Epoch: 6, Loss: 0.8693112134933472\n",
      "Epoch: 7, Loss: 0.8068283200263977\n",
      "Epoch: 8, Loss: 0.7467514276504517\n",
      "Epoch: 9, Loss: 0.6726529598236084\n",
      "Epoch: 10, Loss: 0.5920544266700745\n",
      "Epoch: 11, Loss: 0.5220473408699036\n",
      "Epoch: 12, Loss: 0.4680880606174469\n",
      "Epoch: 13, Loss: 0.42228713631629944\n",
      "Epoch: 14, Loss: 0.3818497061729431\n",
      "Epoch: 15, Loss: 0.34777337312698364\n",
      "Epoch: 16, Loss: 0.3147513270378113\n",
      "Epoch: 17, Loss: 0.2798824608325958\n",
      "Epoch: 18, Loss: 0.24647364020347595\n",
      "Epoch: 19, Loss: 0.21928875148296356\n",
      "Epoch: 20, Loss: 0.20076113939285278\n",
      "Epoch: 21, Loss: 0.18859367072582245\n",
      "Epoch: 22, Loss: 0.17942483723163605\n",
      "Epoch: 23, Loss: 0.1702696681022644\n",
      "Epoch: 24, Loss: 0.159645214676857\n",
      "Epoch: 25, Loss: 0.14791472256183624\n",
      "Epoch: 26, Loss: 0.1368645578622818\n",
      "Epoch: 27, Loss: 0.12693478167057037\n",
      "Epoch: 28, Loss: 0.11921507120132446\n",
      "Epoch: 29, Loss: 0.11300314962863922\n",
      "Epoch: 30, Loss: 0.1069483757019043\n",
      "Epoch: 31, Loss: 0.10055305808782578\n",
      "Epoch: 32, Loss: 0.09445261210203171\n",
      "Epoch: 33, Loss: 0.08813872933387756\n",
      "Epoch: 34, Loss: 0.08211920410394669\n",
      "Epoch: 35, Loss: 0.07680467516183853\n",
      "Epoch: 36, Loss: 0.07225712388753891\n",
      "Epoch: 37, Loss: 0.06828649342060089\n",
      "Epoch: 38, Loss: 0.06423220038414001\n",
      "Epoch: 39, Loss: 0.05999307334423065\n",
      "Epoch: 40, Loss: 0.05597776547074318\n",
      "Epoch: 41, Loss: 0.052454352378845215\n",
      "Epoch: 42, Loss: 0.049331922084093094\n",
      "Epoch: 43, Loss: 0.04653181880712509\n",
      "Epoch: 44, Loss: 0.04401283338665962\n",
      "Epoch: 45, Loss: 0.041985005140304565\n",
      "Epoch: 46, Loss: 0.04012920707464218\n",
      "Epoch: 47, Loss: 0.03838242217898369\n",
      "Epoch: 48, Loss: 0.03691760078072548\n",
      "Epoch: 49, Loss: 0.03557982295751572\n",
      "Epoch: 50, Loss: 0.034260090440511703\n",
      "epoch 2 tensor([ 0.5383, -3.6142, -0.6610,  0.0190, -0.1164], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 1.1359448432922363\n",
      "Epoch: 2, Loss: 0.8733912110328674\n",
      "Epoch: 3, Loss: 0.7163105010986328\n",
      "Epoch: 4, Loss: 0.6811572909355164\n",
      "Epoch: 5, Loss: 0.6154535412788391\n",
      "Epoch: 6, Loss: 0.4976448714733124\n",
      "Epoch: 7, Loss: 0.3988158702850342\n",
      "Epoch: 8, Loss: 0.36147820949554443\n",
      "Epoch: 9, Loss: 0.35329869389533997\n",
      "Epoch: 10, Loss: 0.33118048310279846\n",
      "Epoch: 11, Loss: 0.2867027819156647\n",
      "Epoch: 12, Loss: 0.25298047065734863\n",
      "Epoch: 13, Loss: 0.2449522763490677\n",
      "Epoch: 14, Loss: 0.25096771121025085\n",
      "Epoch: 15, Loss: 0.24336187541484833\n",
      "Epoch: 16, Loss: 0.21178406476974487\n",
      "Epoch: 17, Loss: 0.17236271500587463\n",
      "Epoch: 18, Loss: 0.14675037562847137\n",
      "Epoch: 19, Loss: 0.13914179801940918\n",
      "Epoch: 20, Loss: 0.1362820416688919\n",
      "Epoch: 21, Loss: 0.12582264840602875\n",
      "Epoch: 22, Loss: 0.10925881564617157\n",
      "Epoch: 23, Loss: 0.09818240255117416\n",
      "Epoch: 24, Loss: 0.09710822999477386\n",
      "Epoch: 25, Loss: 0.09941691160202026\n",
      "Epoch: 26, Loss: 0.09598509967327118\n",
      "Epoch: 27, Loss: 0.08654971420764923\n",
      "Epoch: 28, Loss: 0.07795757055282593\n",
      "Epoch: 29, Loss: 0.07466989755630493\n",
      "Epoch: 30, Loss: 0.07395145297050476\n",
      "Epoch: 31, Loss: 0.07035239040851593\n",
      "Epoch: 32, Loss: 0.06380187720060349\n",
      "Epoch: 33, Loss: 0.05817463994026184\n",
      "Epoch: 34, Loss: 0.056050099432468414\n",
      "Epoch: 35, Loss: 0.05560844764113426\n",
      "Epoch: 36, Loss: 0.05355817452073097\n",
      "Epoch: 37, Loss: 0.049992647022008896\n",
      "Epoch: 38, Loss: 0.04752419516444206\n",
      "Epoch: 39, Loss: 0.04716560244560242\n",
      "Epoch: 40, Loss: 0.046995196491479874\n",
      "Epoch: 41, Loss: 0.04513685405254364\n",
      "Epoch: 42, Loss: 0.04213886335492134\n",
      "Epoch: 43, Loss: 0.03991033881902695\n",
      "Epoch: 44, Loss: 0.03895218297839165\n",
      "Epoch: 45, Loss: 0.038007691502571106\n",
      "Epoch: 46, Loss: 0.036287371069192886\n",
      "Epoch: 47, Loss: 0.034482039511203766\n",
      "Epoch: 48, Loss: 0.03358366712927818\n",
      "Epoch: 49, Loss: 0.033343203365802765\n",
      "Epoch: 50, Loss: 0.03275251016020775\n",
      "epoch 2 tensor([ 0.6962, -4.0052, -0.2501, -0.2058,  0.5338], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.4515015482902527\n",
      "Epoch: 2, Loss: 0.4184642434120178\n",
      "Epoch: 3, Loss: 0.3734319806098938\n",
      "Epoch: 4, Loss: 0.3294503688812256\n",
      "Epoch: 5, Loss: 0.29555270075798035\n",
      "Epoch: 6, Loss: 0.2686316967010498\n",
      "Epoch: 7, Loss: 0.2436654418706894\n",
      "Epoch: 8, Loss: 0.21834507584571838\n",
      "Epoch: 9, Loss: 0.19584104418754578\n",
      "Epoch: 10, Loss: 0.17588309943675995\n",
      "Epoch: 11, Loss: 0.15967650711536407\n",
      "Epoch: 12, Loss: 0.14649897813796997\n",
      "Epoch: 13, Loss: 0.13503046333789825\n",
      "Epoch: 14, Loss: 0.12491412460803986\n",
      "Epoch: 15, Loss: 0.11457579582929611\n",
      "Epoch: 16, Loss: 0.1031755730509758\n",
      "Epoch: 17, Loss: 0.09131141752004623\n",
      "Epoch: 18, Loss: 0.08014409244060516\n",
      "Epoch: 19, Loss: 0.07147709280252457\n",
      "Epoch: 20, Loss: 0.06545303016901016\n",
      "Epoch: 21, Loss: 0.06147756054997444\n",
      "Epoch: 22, Loss: 0.05741052329540253\n",
      "Epoch: 23, Loss: 0.052270956337451935\n",
      "Epoch: 24, Loss: 0.046961210668087006\n",
      "Epoch: 25, Loss: 0.04282800108194351\n",
      "Epoch: 26, Loss: 0.0397685244679451\n",
      "Epoch: 27, Loss: 0.03717609867453575\n",
      "Epoch: 28, Loss: 0.034281764179468155\n",
      "Epoch: 29, Loss: 0.03093484789133072\n",
      "Epoch: 30, Loss: 0.027678223326802254\n",
      "Epoch: 31, Loss: 0.024708203971385956\n",
      "Epoch: 32, Loss: 0.02225853130221367\n",
      "Epoch: 33, Loss: 0.02025185152888298\n",
      "Epoch: 34, Loss: 0.018372926861047745\n",
      "Epoch: 35, Loss: 0.016334926709532738\n",
      "Epoch: 36, Loss: 0.014261913485825062\n",
      "Epoch: 37, Loss: 0.012583051808178425\n",
      "Epoch: 38, Loss: 0.011427082121372223\n",
      "Epoch: 39, Loss: 0.010645362548530102\n",
      "Epoch: 40, Loss: 0.00995224341750145\n",
      "Epoch: 41, Loss: 0.009223967790603638\n",
      "Epoch: 42, Loss: 0.008465287275612354\n",
      "Epoch: 43, Loss: 0.0077887289226055145\n",
      "Epoch: 44, Loss: 0.007231965661048889\n",
      "Epoch: 45, Loss: 0.0066869319416582584\n",
      "Epoch: 46, Loss: 0.006076543126255274\n",
      "Epoch: 47, Loss: 0.005448245909065008\n",
      "Epoch: 48, Loss: 0.004925377666950226\n",
      "Epoch: 49, Loss: 0.0045964717864990234\n",
      "Epoch: 50, Loss: 0.004435619805008173\n",
      "epoch 2 tensor([ 0.5068, -3.8211,  0.8941, -0.2691,  0.5584], grad_fn=<AddBackward0>) 2\n",
      "Epoch: 1, Loss: 0.7717721462249756\n",
      "Epoch: 2, Loss: 0.6690936088562012\n",
      "Epoch: 3, Loss: 0.548736572265625\n",
      "Epoch: 4, Loss: 0.4539225399494171\n",
      "Epoch: 5, Loss: 0.39896300435066223\n",
      "Epoch: 6, Loss: 0.3648746609687805\n",
      "Epoch: 7, Loss: 0.3407936096191406\n",
      "Epoch: 8, Loss: 0.31717249751091003\n",
      "Epoch: 9, Loss: 0.2928731441497803\n",
      "Epoch: 10, Loss: 0.27221232652664185\n",
      "Epoch: 11, Loss: 0.25711590051651\n",
      "Epoch: 12, Loss: 0.24752512574195862\n",
      "Epoch: 13, Loss: 0.23814713954925537\n",
      "Epoch: 14, Loss: 0.2186955213546753\n",
      "Epoch: 15, Loss: 0.1927294135093689\n",
      "Epoch: 16, Loss: 0.17061281204223633\n",
      "Epoch: 17, Loss: 0.15557365119457245\n",
      "Epoch: 18, Loss: 0.14303873479366302\n",
      "Epoch: 19, Loss: 0.13129550218582153\n",
      "Epoch: 20, Loss: 0.12363361567258835\n",
      "Epoch: 21, Loss: 0.11922594159841537\n",
      "Epoch: 22, Loss: 0.11441928893327713\n",
      "Epoch: 23, Loss: 0.10714661329984665\n",
      "Epoch: 24, Loss: 0.10103996098041534\n",
      "Epoch: 25, Loss: 0.09649897366762161\n",
      "Epoch: 26, Loss: 0.09142439812421799\n",
      "Epoch: 27, Loss: 0.08554822206497192\n",
      "Epoch: 28, Loss: 0.08008673042058945\n",
      "Epoch: 29, Loss: 0.07535427063703537\n",
      "Epoch: 30, Loss: 0.07060079276561737\n",
      "Epoch: 31, Loss: 0.0669085755944252\n",
      "Epoch: 32, Loss: 0.06414666771888733\n",
      "Epoch: 33, Loss: 0.06114182993769646\n",
      "Epoch: 34, Loss: 0.057975731790065765\n",
      "Epoch: 35, Loss: 0.05522005632519722\n",
      "Epoch: 36, Loss: 0.0532522015273571\n",
      "Epoch: 37, Loss: 0.05210774019360542\n",
      "Epoch: 38, Loss: 0.05026788264513016\n",
      "Epoch: 39, Loss: 0.0482202023267746\n",
      "Epoch: 40, Loss: 0.04628714546561241\n",
      "Epoch: 41, Loss: 0.04447945952415466\n",
      "Epoch: 42, Loss: 0.043124571442604065\n",
      "Epoch: 43, Loss: 0.04163474217057228\n",
      "Epoch: 44, Loss: 0.03973492234945297\n",
      "Epoch: 45, Loss: 0.038224633783102036\n",
      "Epoch: 46, Loss: 0.03707887977361679\n",
      "Epoch: 47, Loss: 0.0358070433139801\n",
      "Epoch: 48, Loss: 0.034604061394929886\n",
      "Epoch: 49, Loss: 0.03343816474080086\n",
      "Epoch: 50, Loss: 0.03251217305660248\n",
      "epoch 2 tensor([ 1.6330, -3.8033,  0.1076, -0.1116,  0.8829], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.7376207113265991\n",
      "Epoch: 2, Loss: 0.6349033117294312\n",
      "Epoch: 3, Loss: 0.5125539302825928\n",
      "Epoch: 4, Loss: 0.413521945476532\n",
      "Epoch: 5, Loss: 0.3410663902759552\n",
      "Epoch: 6, Loss: 0.284325510263443\n",
      "Epoch: 7, Loss: 0.23833519220352173\n",
      "Epoch: 8, Loss: 0.20279589295387268\n",
      "Epoch: 9, Loss: 0.1762576848268509\n",
      "Epoch: 10, Loss: 0.15927308797836304\n",
      "Epoch: 11, Loss: 0.1496621072292328\n",
      "Epoch: 12, Loss: 0.14381219446659088\n",
      "Epoch: 13, Loss: 0.13869339227676392\n",
      "Epoch: 14, Loss: 0.13005946576595306\n",
      "Epoch: 15, Loss: 0.11845068633556366\n",
      "Epoch: 16, Loss: 0.10675638169050217\n",
      "Epoch: 17, Loss: 0.09633638709783554\n",
      "Epoch: 18, Loss: 0.08654578030109406\n",
      "Epoch: 19, Loss: 0.07596731930971146\n",
      "Epoch: 20, Loss: 0.06594142317771912\n",
      "Epoch: 21, Loss: 0.05714133381843567\n",
      "Epoch: 22, Loss: 0.049503859132528305\n",
      "Epoch: 23, Loss: 0.042987946420907974\n",
      "Epoch: 24, Loss: 0.03789357841014862\n",
      "Epoch: 25, Loss: 0.03380311280488968\n",
      "Epoch: 26, Loss: 0.02982044219970703\n",
      "Epoch: 27, Loss: 0.025872820988297462\n",
      "Epoch: 28, Loss: 0.023081693798303604\n",
      "Epoch: 29, Loss: 0.022122317925095558\n",
      "Epoch: 30, Loss: 0.021987268701195717\n",
      "Epoch: 31, Loss: 0.021312212571501732\n",
      "Epoch: 32, Loss: 0.01999834179878235\n",
      "Epoch: 33, Loss: 0.018753547221422195\n",
      "Epoch: 34, Loss: 0.017701925709843636\n",
      "Epoch: 35, Loss: 0.0164212454110384\n",
      "Epoch: 36, Loss: 0.014729509130120277\n",
      "Epoch: 37, Loss: 0.012786025181412697\n",
      "Epoch: 38, Loss: 0.010693293064832687\n",
      "Epoch: 39, Loss: 0.008668262511491776\n",
      "Epoch: 40, Loss: 0.007204706780612469\n",
      "Epoch: 41, Loss: 0.006543174386024475\n",
      "Epoch: 42, Loss: 0.006330435164272785\n",
      "Epoch: 43, Loss: 0.006131386384367943\n",
      "Epoch: 44, Loss: 0.00597800500690937\n",
      "Epoch: 45, Loss: 0.006043614819645882\n",
      "Epoch: 46, Loss: 0.006239380221813917\n",
      "Epoch: 47, Loss: 0.0063476236537098885\n",
      "Epoch: 48, Loss: 0.006256709806621075\n",
      "Epoch: 49, Loss: 0.005900602322071791\n",
      "Epoch: 50, Loss: 0.005270803347229958\n",
      "epoch 2 tensor([ 0.6190, -3.6242, -0.0663, -0.0205,  0.8310], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.4230063259601593\n",
      "Epoch: 2, Loss: 0.3593794107437134\n",
      "Epoch: 3, Loss: 0.3103662431240082\n",
      "Epoch: 4, Loss: 0.2881026268005371\n",
      "Epoch: 5, Loss: 0.25986191630363464\n",
      "Epoch: 6, Loss: 0.21490615606307983\n",
      "Epoch: 7, Loss: 0.1780078113079071\n",
      "Epoch: 8, Loss: 0.1609320044517517\n",
      "Epoch: 9, Loss: 0.15126682817935944\n",
      "Epoch: 10, Loss: 0.1392248570919037\n",
      "Epoch: 11, Loss: 0.12526732683181763\n",
      "Epoch: 12, Loss: 0.11367934197187424\n",
      "Epoch: 13, Loss: 0.10672923177480698\n",
      "Epoch: 14, Loss: 0.1013006716966629\n",
      "Epoch: 15, Loss: 0.09086284041404724\n",
      "Epoch: 16, Loss: 0.07794765383005142\n",
      "Epoch: 17, Loss: 0.07014182209968567\n",
      "Epoch: 18, Loss: 0.068398617208004\n",
      "Epoch: 19, Loss: 0.06597950309515\n",
      "Epoch: 20, Loss: 0.05953678488731384\n",
      "Epoch: 21, Loss: 0.053582292050123215\n",
      "Epoch: 22, Loss: 0.05143941938877106\n",
      "Epoch: 23, Loss: 0.05162136256694794\n",
      "Epoch: 24, Loss: 0.05093235895037651\n",
      "Epoch: 25, Loss: 0.04852363094687462\n",
      "Epoch: 26, Loss: 0.04575276002287865\n",
      "Epoch: 27, Loss: 0.043539971113204956\n",
      "Epoch: 28, Loss: 0.04195880517363548\n",
      "Epoch: 29, Loss: 0.04013390839099884\n",
      "Epoch: 30, Loss: 0.03785323724150658\n",
      "Epoch: 31, Loss: 0.03562673181295395\n",
      "Epoch: 32, Loss: 0.0347600020468235\n",
      "Epoch: 33, Loss: 0.03368767723441124\n",
      "Epoch: 34, Loss: 0.03216496482491493\n",
      "Epoch: 35, Loss: 0.03111186996102333\n",
      "Epoch: 36, Loss: 0.030804285779595375\n",
      "Epoch: 37, Loss: 0.03038584627211094\n",
      "Epoch: 38, Loss: 0.029238495975732803\n",
      "Epoch: 39, Loss: 0.02786519005894661\n",
      "Epoch: 40, Loss: 0.026946283876895905\n",
      "Epoch: 41, Loss: 0.026227185502648354\n",
      "Epoch: 42, Loss: 0.025162944570183754\n",
      "Epoch: 43, Loss: 0.024079546332359314\n",
      "Epoch: 44, Loss: 0.023241087794303894\n",
      "Epoch: 45, Loss: 0.02283763326704502\n",
      "Epoch: 46, Loss: 0.022465800866484642\n",
      "Epoch: 47, Loss: 0.021952107548713684\n",
      "Epoch: 48, Loss: 0.02123533934354782\n",
      "Epoch: 49, Loss: 0.02053520269691944\n",
      "Epoch: 50, Loss: 0.019938256591558456\n",
      "epoch 2 tensor([ 0.5414, -3.7999, -0.1176,  0.0833,  0.8841], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.4962906241416931\n",
      "Epoch: 2, Loss: 0.3914508819580078\n",
      "Epoch: 3, Loss: 0.3243127465248108\n",
      "Epoch: 4, Loss: 0.3105725944042206\n",
      "Epoch: 5, Loss: 0.2933204174041748\n",
      "Epoch: 6, Loss: 0.24493877589702606\n",
      "Epoch: 7, Loss: 0.19451050460338593\n",
      "Epoch: 8, Loss: 0.17349191009998322\n",
      "Epoch: 9, Loss: 0.17970308661460876\n",
      "Epoch: 10, Loss: 0.17366540431976318\n",
      "Epoch: 11, Loss: 0.14576752483844757\n",
      "Epoch: 12, Loss: 0.12245655059814453\n",
      "Epoch: 13, Loss: 0.11415297538042068\n",
      "Epoch: 14, Loss: 0.11276314407587051\n",
      "Epoch: 15, Loss: 0.10469020158052444\n",
      "Epoch: 16, Loss: 0.09131284803152084\n",
      "Epoch: 17, Loss: 0.08115503937005997\n",
      "Epoch: 18, Loss: 0.07643856853246689\n",
      "Epoch: 19, Loss: 0.07248186320066452\n",
      "Epoch: 20, Loss: 0.06519482284784317\n",
      "Epoch: 21, Loss: 0.05577048286795616\n",
      "Epoch: 22, Loss: 0.04865354672074318\n",
      "Epoch: 23, Loss: 0.04646606370806694\n",
      "Epoch: 24, Loss: 0.04598146304488182\n",
      "Epoch: 25, Loss: 0.04269099235534668\n",
      "Epoch: 26, Loss: 0.037389952689409256\n",
      "Epoch: 27, Loss: 0.03455888852477074\n",
      "Epoch: 28, Loss: 0.03517767786979675\n",
      "Epoch: 29, Loss: 0.03431118652224541\n",
      "Epoch: 30, Loss: 0.030728092417120934\n",
      "Epoch: 31, Loss: 0.02780677005648613\n",
      "Epoch: 32, Loss: 0.027045072987675667\n",
      "Epoch: 33, Loss: 0.026045288890600204\n",
      "Epoch: 34, Loss: 0.02302279882133007\n",
      "Epoch: 35, Loss: 0.01961660571396351\n",
      "Epoch: 36, Loss: 0.017966540530323982\n",
      "Epoch: 37, Loss: 0.017643213272094727\n",
      "Epoch: 38, Loss: 0.01662847027182579\n",
      "Epoch: 39, Loss: 0.014734174124896526\n",
      "Epoch: 40, Loss: 0.013611113652586937\n",
      "Epoch: 41, Loss: 0.013424144126474857\n",
      "Epoch: 42, Loss: 0.012979507446289062\n",
      "Epoch: 43, Loss: 0.011806253343820572\n",
      "Epoch: 44, Loss: 0.010689922608435154\n",
      "Epoch: 45, Loss: 0.010192377492785454\n",
      "Epoch: 46, Loss: 0.00979489367455244\n",
      "Epoch: 47, Loss: 0.008971994742751122\n",
      "Epoch: 48, Loss: 0.008109886199235916\n",
      "Epoch: 49, Loss: 0.007657374255359173\n",
      "Epoch: 50, Loss: 0.007154759019613266\n",
      "epoch 2 tensor([ 0.4195, -3.1020, -0.1196, -0.0917,  0.7396], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.7431041598320007\n",
      "Epoch: 2, Loss: 0.5884560942649841\n",
      "Epoch: 3, Loss: 0.4801269471645355\n",
      "Epoch: 4, Loss: 0.4306539297103882\n",
      "Epoch: 5, Loss: 0.40231582522392273\n",
      "Epoch: 6, Loss: 0.3758942782878876\n",
      "Epoch: 7, Loss: 0.3444513976573944\n",
      "Epoch: 8, Loss: 0.3047812581062317\n",
      "Epoch: 9, Loss: 0.26682692766189575\n",
      "Epoch: 10, Loss: 0.2456868588924408\n",
      "Epoch: 11, Loss: 0.24054856598377228\n",
      "Epoch: 12, Loss: 0.24153700470924377\n",
      "Epoch: 13, Loss: 0.23243612051010132\n",
      "Epoch: 14, Loss: 0.21134930849075317\n",
      "Epoch: 15, Loss: 0.18862731754779816\n",
      "Epoch: 16, Loss: 0.17279334366321564\n",
      "Epoch: 17, Loss: 0.16425105929374695\n",
      "Epoch: 18, Loss: 0.1590571254491806\n",
      "Epoch: 19, Loss: 0.1504741907119751\n",
      "Epoch: 20, Loss: 0.13630077242851257\n",
      "Epoch: 21, Loss: 0.12178733199834824\n",
      "Epoch: 22, Loss: 0.11451724171638489\n",
      "Epoch: 23, Loss: 0.11292802542448044\n",
      "Epoch: 24, Loss: 0.11146393418312073\n",
      "Epoch: 25, Loss: 0.10714969784021378\n",
      "Epoch: 26, Loss: 0.10119472444057465\n",
      "Epoch: 27, Loss: 0.09580263495445251\n",
      "Epoch: 28, Loss: 0.09082929790019989\n",
      "Epoch: 29, Loss: 0.08616877347230911\n",
      "Epoch: 30, Loss: 0.08103782683610916\n",
      "Epoch: 31, Loss: 0.07538533955812454\n",
      "Epoch: 32, Loss: 0.07098536938428879\n",
      "Epoch: 33, Loss: 0.06693558394908905\n",
      "Epoch: 34, Loss: 0.06364502012729645\n",
      "Epoch: 35, Loss: 0.06060531735420227\n",
      "Epoch: 36, Loss: 0.05682649463415146\n",
      "Epoch: 37, Loss: 0.05302313715219498\n",
      "Epoch: 38, Loss: 0.04990186542272568\n",
      "Epoch: 39, Loss: 0.04724689573049545\n",
      "Epoch: 40, Loss: 0.04531312361359596\n",
      "Epoch: 41, Loss: 0.04379042983055115\n",
      "Epoch: 42, Loss: 0.04181553050875664\n",
      "Epoch: 43, Loss: 0.039124228060245514\n",
      "Epoch: 44, Loss: 0.03639442101120949\n",
      "Epoch: 45, Loss: 0.03388397768139839\n",
      "Epoch: 46, Loss: 0.03168247640132904\n",
      "Epoch: 47, Loss: 0.03014688566327095\n",
      "Epoch: 48, Loss: 0.028355885297060013\n",
      "Epoch: 49, Loss: 0.02673408016562462\n",
      "Epoch: 50, Loss: 0.02532142400741577\n",
      "epoch 2 tensor([ 0.5578, -3.7989, -0.0903, -0.1941,  0.8416], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.511192798614502\n",
      "Epoch: 2, Loss: 0.4120052456855774\n",
      "Epoch: 3, Loss: 0.3138026297092438\n",
      "Epoch: 4, Loss: 0.25541579723358154\n",
      "Epoch: 5, Loss: 0.2276104986667633\n",
      "Epoch: 6, Loss: 0.20988281071186066\n",
      "Epoch: 7, Loss: 0.19725364446640015\n",
      "Epoch: 8, Loss: 0.18728309869766235\n",
      "Epoch: 9, Loss: 0.17648139595985413\n",
      "Epoch: 10, Loss: 0.16123275458812714\n",
      "Epoch: 11, Loss: 0.1387687623500824\n",
      "Epoch: 12, Loss: 0.11545053124427795\n",
      "Epoch: 13, Loss: 0.09880331158638\n",
      "Epoch: 14, Loss: 0.09066587686538696\n",
      "Epoch: 15, Loss: 0.08673269301652908\n",
      "Epoch: 16, Loss: 0.08173630386590958\n",
      "Epoch: 17, Loss: 0.07475724816322327\n",
      "Epoch: 18, Loss: 0.06697065383195877\n",
      "Epoch: 19, Loss: 0.05871584266424179\n",
      "Epoch: 20, Loss: 0.0510195717215538\n",
      "Epoch: 21, Loss: 0.045159175992012024\n",
      "Epoch: 22, Loss: 0.04116373136639595\n",
      "Epoch: 23, Loss: 0.03808022662997246\n",
      "Epoch: 24, Loss: 0.034734729677438736\n",
      "Epoch: 25, Loss: 0.030521832406520844\n",
      "Epoch: 26, Loss: 0.026203805580735207\n",
      "Epoch: 27, Loss: 0.022754447534680367\n",
      "Epoch: 28, Loss: 0.020410336554050446\n",
      "Epoch: 29, Loss: 0.018544893711805344\n",
      "Epoch: 30, Loss: 0.01643167808651924\n",
      "Epoch: 31, Loss: 0.014296431094408035\n",
      "Epoch: 32, Loss: 0.012815830297768116\n",
      "Epoch: 33, Loss: 0.01204038504511118\n",
      "Epoch: 34, Loss: 0.01128604169934988\n",
      "Epoch: 35, Loss: 0.010214557871222496\n",
      "Epoch: 36, Loss: 0.009105455130338669\n",
      "Epoch: 37, Loss: 0.008518330752849579\n",
      "Epoch: 38, Loss: 0.008339093066751957\n",
      "Epoch: 39, Loss: 0.007930086925625801\n",
      "Epoch: 40, Loss: 0.006984594278037548\n",
      "Epoch: 41, Loss: 0.005794201046228409\n",
      "Epoch: 42, Loss: 0.004858517087996006\n",
      "Epoch: 43, Loss: 0.00436397036537528\n",
      "Epoch: 44, Loss: 0.0041588665917515755\n",
      "Epoch: 45, Loss: 0.004014306236058474\n",
      "Epoch: 46, Loss: 0.0038393675349652767\n",
      "Epoch: 47, Loss: 0.003618854796513915\n",
      "Epoch: 48, Loss: 0.0033034116495400667\n",
      "Epoch: 49, Loss: 0.0028774773236364126\n",
      "Epoch: 50, Loss: 0.0024663591757416725\n",
      "epoch 2 tensor([ 0.5258, -3.8345,  0.9642, -0.4744,  0.9065], grad_fn=<AddBackward0>) 2\n",
      "Epoch: 1, Loss: 0.38894835114479065\n",
      "Epoch: 2, Loss: 0.3392505347728729\n",
      "Epoch: 3, Loss: 0.29499703645706177\n",
      "Epoch: 4, Loss: 0.27644112706184387\n",
      "Epoch: 5, Loss: 0.25868895649909973\n",
      "Epoch: 6, Loss: 0.2273845076560974\n",
      "Epoch: 7, Loss: 0.19609564542770386\n",
      "Epoch: 8, Loss: 0.1792367696762085\n",
      "Epoch: 9, Loss: 0.17002052068710327\n",
      "Epoch: 10, Loss: 0.1545594036579132\n",
      "Epoch: 11, Loss: 0.13311360776424408\n",
      "Epoch: 12, Loss: 0.11649148911237717\n",
      "Epoch: 13, Loss: 0.10867000371217728\n",
      "Epoch: 14, Loss: 0.1032177284359932\n",
      "Epoch: 15, Loss: 0.09449097514152527\n",
      "Epoch: 16, Loss: 0.08490008115768433\n",
      "Epoch: 17, Loss: 0.07720529288053513\n",
      "Epoch: 18, Loss: 0.07177569717168808\n",
      "Epoch: 19, Loss: 0.06476259231567383\n",
      "Epoch: 20, Loss: 0.05617102235555649\n",
      "Epoch: 21, Loss: 0.04982193931937218\n",
      "Epoch: 22, Loss: 0.046362753957509995\n",
      "Epoch: 23, Loss: 0.043919943273067474\n",
      "Epoch: 24, Loss: 0.040484681725502014\n",
      "Epoch: 25, Loss: 0.03645215928554535\n",
      "Epoch: 26, Loss: 0.0336502268910408\n",
      "Epoch: 27, Loss: 0.031986914575099945\n",
      "Epoch: 28, Loss: 0.029547937214374542\n",
      "Epoch: 29, Loss: 0.02588609978556633\n",
      "Epoch: 30, Loss: 0.02243782952427864\n",
      "Epoch: 31, Loss: 0.020257046446204185\n",
      "Epoch: 32, Loss: 0.018520355224609375\n",
      "Epoch: 33, Loss: 0.016347186639904976\n",
      "Epoch: 34, Loss: 0.014327914454042912\n",
      "Epoch: 35, Loss: 0.013166196644306183\n",
      "Epoch: 36, Loss: 0.012380924075841904\n",
      "Epoch: 37, Loss: 0.01112102996557951\n",
      "Epoch: 38, Loss: 0.009619758464396\n",
      "Epoch: 39, Loss: 0.008612154982984066\n",
      "Epoch: 40, Loss: 0.008094252087175846\n",
      "Epoch: 41, Loss: 0.007511993870139122\n",
      "Epoch: 42, Loss: 0.006876957602798939\n",
      "Epoch: 43, Loss: 0.006462893448770046\n",
      "Epoch: 44, Loss: 0.006153843365609646\n",
      "Epoch: 45, Loss: 0.00568435387685895\n",
      "Epoch: 46, Loss: 0.005226439796388149\n",
      "Epoch: 47, Loss: 0.004993928596377373\n",
      "Epoch: 48, Loss: 0.004832332953810692\n",
      "Epoch: 49, Loss: 0.004533184226602316\n",
      "Epoch: 50, Loss: 0.004190314561128616\n",
      "________________________________________\n",
      "epoch 3 tensor([ 0.5256, -3.7868, -0.1110, -0.0472,  1.2972], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 5.138912200927734\n",
      "Epoch: 2, Loss: 4.395129203796387\n",
      "Epoch: 3, Loss: 3.654620409011841\n",
      "Epoch: 4, Loss: 3.131716251373291\n",
      "Epoch: 5, Loss: 2.767179489135742\n",
      "Epoch: 6, Loss: 2.44661808013916\n",
      "Epoch: 7, Loss: 2.157348871231079\n",
      "Epoch: 8, Loss: 1.8606334924697876\n",
      "Epoch: 9, Loss: 1.645143985748291\n",
      "Epoch: 10, Loss: 1.5606423616409302\n",
      "Epoch: 11, Loss: 1.519951343536377\n",
      "Epoch: 12, Loss: 1.4403363466262817\n",
      "Epoch: 13, Loss: 1.3271644115447998\n",
      "Epoch: 14, Loss: 1.2179423570632935\n",
      "Epoch: 15, Loss: 1.137160301208496\n",
      "Epoch: 16, Loss: 1.0616832971572876\n",
      "Epoch: 17, Loss: 1.009339690208435\n",
      "Epoch: 18, Loss: 0.9623080492019653\n",
      "Epoch: 19, Loss: 0.9170898199081421\n",
      "Epoch: 20, Loss: 0.8655281662940979\n",
      "Epoch: 21, Loss: 0.8192579746246338\n",
      "Epoch: 22, Loss: 0.7891001105308533\n",
      "Epoch: 23, Loss: 0.7612320184707642\n",
      "Epoch: 24, Loss: 0.7368891835212708\n",
      "Epoch: 25, Loss: 0.7137706875801086\n",
      "Epoch: 26, Loss: 0.6903024315834045\n",
      "Epoch: 27, Loss: 0.6663323044776917\n",
      "Epoch: 28, Loss: 0.6436748504638672\n",
      "Epoch: 29, Loss: 0.623064398765564\n",
      "Epoch: 30, Loss: 0.6048083305358887\n",
      "Epoch: 31, Loss: 0.5888833403587341\n",
      "Epoch: 32, Loss: 0.5743931531906128\n",
      "Epoch: 33, Loss: 0.561069130897522\n",
      "Epoch: 34, Loss: 0.5485923886299133\n",
      "Epoch: 35, Loss: 0.5367700457572937\n",
      "Epoch: 36, Loss: 0.5257444977760315\n",
      "Epoch: 37, Loss: 0.5157844424247742\n",
      "Epoch: 38, Loss: 0.5064312219619751\n",
      "Epoch: 39, Loss: 0.4981346130371094\n",
      "Epoch: 40, Loss: 0.4924367070198059\n",
      "Epoch: 41, Loss: 0.48484188318252563\n",
      "Epoch: 42, Loss: 0.4759463965892792\n",
      "Epoch: 43, Loss: 0.4667271673679352\n",
      "Epoch: 44, Loss: 0.4578535556793213\n",
      "Epoch: 45, Loss: 0.4515760540962219\n",
      "Epoch: 46, Loss: 0.44612571597099304\n",
      "Epoch: 47, Loss: 0.4394223093986511\n",
      "Epoch: 48, Loss: 0.43304383754730225\n",
      "Epoch: 49, Loss: 0.42775222659111023\n",
      "Epoch: 50, Loss: 0.4225521981716156\n",
      "epoch 3 tensor([ 1.4491, -4.2918,  0.0883,  1.0662,  0.8911], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 3.452659845352173\n",
      "Epoch: 2, Loss: 3.1101415157318115\n",
      "Epoch: 3, Loss: 2.687344551086426\n",
      "Epoch: 4, Loss: 2.280643939971924\n",
      "Epoch: 5, Loss: 1.9429287910461426\n",
      "Epoch: 6, Loss: 1.703279972076416\n",
      "Epoch: 7, Loss: 1.5454963445663452\n",
      "Epoch: 8, Loss: 1.4457224607467651\n",
      "Epoch: 9, Loss: 1.3649941682815552\n",
      "Epoch: 10, Loss: 1.277519941329956\n",
      "Epoch: 11, Loss: 1.1834324598312378\n",
      "Epoch: 12, Loss: 1.0950268507003784\n",
      "Epoch: 13, Loss: 1.0237040519714355\n",
      "Epoch: 14, Loss: 0.9730632305145264\n",
      "Epoch: 15, Loss: 0.9437034726142883\n",
      "Epoch: 16, Loss: 0.935492992401123\n",
      "Epoch: 17, Loss: 0.918637752532959\n",
      "Epoch: 18, Loss: 0.8958227038383484\n",
      "Epoch: 19, Loss: 0.8666067719459534\n",
      "Epoch: 20, Loss: 0.8330221772193909\n",
      "Epoch: 21, Loss: 0.7972251176834106\n",
      "Epoch: 22, Loss: 0.7624405026435852\n",
      "Epoch: 23, Loss: 0.7317425608634949\n",
      "Epoch: 24, Loss: 0.7061773538589478\n",
      "Epoch: 25, Loss: 0.6855556964874268\n",
      "Epoch: 26, Loss: 0.6661077737808228\n",
      "Epoch: 27, Loss: 0.6469270586967468\n",
      "Epoch: 28, Loss: 0.6299477815628052\n",
      "Epoch: 29, Loss: 0.6157360076904297\n",
      "Epoch: 30, Loss: 0.6032936573028564\n",
      "Epoch: 31, Loss: 0.5924140810966492\n",
      "Epoch: 32, Loss: 0.5815061330795288\n",
      "Epoch: 33, Loss: 0.5686947107315063\n",
      "Epoch: 34, Loss: 0.5542951226234436\n",
      "Epoch: 35, Loss: 0.5415478348731995\n",
      "Epoch: 36, Loss: 0.5300869941711426\n",
      "Epoch: 37, Loss: 0.5202410221099854\n",
      "Epoch: 38, Loss: 0.5101934671401978\n",
      "Epoch: 39, Loss: 0.500428318977356\n",
      "Epoch: 40, Loss: 0.49215516448020935\n",
      "Epoch: 41, Loss: 0.48425278067588806\n",
      "Epoch: 42, Loss: 0.47568997740745544\n",
      "Epoch: 43, Loss: 0.4668983817100525\n",
      "Epoch: 44, Loss: 0.45852020382881165\n",
      "Epoch: 45, Loss: 0.45094677805900574\n",
      "Epoch: 46, Loss: 0.4442775249481201\n",
      "Epoch: 47, Loss: 0.4375858008861542\n",
      "Epoch: 48, Loss: 0.42984727025032043\n",
      "Epoch: 49, Loss: 0.42237037420272827\n",
      "Epoch: 50, Loss: 0.41712185740470886\n",
      "epoch 3 tensor([ 0.7063, -4.3855,  1.2613,  0.0349,  1.0316], grad_fn=<AddBackward0>) 2\n",
      "Epoch: 1, Loss: 0.5368587970733643\n",
      "Epoch: 2, Loss: 0.518664538860321\n",
      "Epoch: 3, Loss: 0.4891090393066406\n",
      "Epoch: 4, Loss: 0.4550288915634155\n",
      "Epoch: 5, Loss: 0.42246371507644653\n",
      "Epoch: 6, Loss: 0.3926384449005127\n",
      "Epoch: 7, Loss: 0.3674568235874176\n",
      "Epoch: 8, Loss: 0.3472081422805786\n",
      "Epoch: 9, Loss: 0.33114102482795715\n",
      "Epoch: 10, Loss: 0.318138986825943\n",
      "Epoch: 11, Loss: 0.30415457487106323\n",
      "Epoch: 12, Loss: 0.28913721442222595\n",
      "Epoch: 13, Loss: 0.275377482175827\n",
      "Epoch: 14, Loss: 0.26147496700286865\n",
      "Epoch: 15, Loss: 0.2477158010005951\n",
      "Epoch: 16, Loss: 0.23657900094985962\n",
      "Epoch: 17, Loss: 0.2277400940656662\n",
      "Epoch: 18, Loss: 0.21985569596290588\n",
      "Epoch: 19, Loss: 0.21333687007427216\n",
      "Epoch: 20, Loss: 0.20817752182483673\n",
      "Epoch: 21, Loss: 0.20310059189796448\n",
      "Epoch: 22, Loss: 0.19779805839061737\n",
      "Epoch: 23, Loss: 0.19191326200962067\n",
      "Epoch: 24, Loss: 0.18506526947021484\n",
      "Epoch: 25, Loss: 0.17882035672664642\n",
      "Epoch: 26, Loss: 0.1732553094625473\n",
      "Epoch: 27, Loss: 0.16822746396064758\n",
      "Epoch: 28, Loss: 0.16386285424232483\n",
      "Epoch: 29, Loss: 0.16007806360721588\n",
      "Epoch: 30, Loss: 0.15619024634361267\n",
      "Epoch: 31, Loss: 0.1521243155002594\n",
      "Epoch: 32, Loss: 0.14796367287635803\n",
      "Epoch: 33, Loss: 0.14372751116752625\n",
      "Epoch: 34, Loss: 0.1406228095293045\n",
      "Epoch: 35, Loss: 0.13780444860458374\n",
      "Epoch: 36, Loss: 0.13499537110328674\n",
      "Epoch: 37, Loss: 0.13179844617843628\n",
      "Epoch: 38, Loss: 0.1287723034620285\n",
      "Epoch: 39, Loss: 0.1264248788356781\n",
      "Epoch: 40, Loss: 0.12372739613056183\n",
      "Epoch: 41, Loss: 0.12120652943849564\n",
      "Epoch: 42, Loss: 0.11856689304113388\n",
      "Epoch: 43, Loss: 0.11609894037246704\n",
      "Epoch: 44, Loss: 0.11373836547136307\n",
      "Epoch: 45, Loss: 0.11135388165712357\n",
      "Epoch: 46, Loss: 0.109002485871315\n",
      "Epoch: 47, Loss: 0.10676907747983932\n",
      "Epoch: 48, Loss: 0.10451029986143112\n",
      "Epoch: 49, Loss: 0.10286293923854828\n",
      "Epoch: 50, Loss: 0.10044576972723007\n",
      "epoch 3 tensor([-0.0809, -4.1609,  1.2713,  0.0652,  1.0251], grad_fn=<AddBackward0>) 2\n",
      "Epoch: 1, Loss: 0.5410805344581604\n",
      "Epoch: 2, Loss: 0.5132088661193848\n",
      "Epoch: 3, Loss: 0.4719344675540924\n",
      "Epoch: 4, Loss: 0.4279206097126007\n",
      "Epoch: 5, Loss: 0.3856436014175415\n",
      "Epoch: 6, Loss: 0.34684041142463684\n",
      "Epoch: 7, Loss: 0.3111439347267151\n",
      "Epoch: 8, Loss: 0.27824151515960693\n",
      "Epoch: 9, Loss: 0.2512410283088684\n",
      "Epoch: 10, Loss: 0.22803321480751038\n",
      "Epoch: 11, Loss: 0.20865312218666077\n",
      "Epoch: 12, Loss: 0.19282646477222443\n",
      "Epoch: 13, Loss: 0.1791212260723114\n",
      "Epoch: 14, Loss: 0.16675502061843872\n",
      "Epoch: 15, Loss: 0.15656085312366486\n",
      "Epoch: 16, Loss: 0.1471196711063385\n",
      "Epoch: 17, Loss: 0.1386713683605194\n",
      "Epoch: 18, Loss: 0.12978537380695343\n",
      "Epoch: 19, Loss: 0.12155553698539734\n",
      "Epoch: 20, Loss: 0.1144164577126503\n",
      "Epoch: 21, Loss: 0.10810509324073792\n",
      "Epoch: 22, Loss: 0.10199256986379623\n",
      "Epoch: 23, Loss: 0.09665114432573318\n",
      "Epoch: 24, Loss: 0.09220553189516068\n",
      "Epoch: 25, Loss: 0.0877012088894844\n",
      "Epoch: 26, Loss: 0.08404766023159027\n",
      "Epoch: 27, Loss: 0.08040295541286469\n",
      "Epoch: 28, Loss: 0.07634146511554718\n",
      "Epoch: 29, Loss: 0.07192683219909668\n",
      "Epoch: 30, Loss: 0.06747289001941681\n",
      "Epoch: 31, Loss: 0.06335316598415375\n",
      "Epoch: 32, Loss: 0.059592779725790024\n",
      "Epoch: 33, Loss: 0.05608297511935234\n",
      "Epoch: 34, Loss: 0.052777525037527084\n",
      "Epoch: 35, Loss: 0.04981599748134613\n",
      "Epoch: 36, Loss: 0.04746295511722565\n",
      "Epoch: 37, Loss: 0.04546189308166504\n",
      "Epoch: 38, Loss: 0.043620165437459946\n",
      "Epoch: 39, Loss: 0.0416652075946331\n",
      "Epoch: 40, Loss: 0.03951188921928406\n",
      "Epoch: 41, Loss: 0.03766767680644989\n",
      "Epoch: 42, Loss: 0.03594841808080673\n",
      "Epoch: 43, Loss: 0.03440495952963829\n",
      "Epoch: 44, Loss: 0.03321155905723572\n",
      "Epoch: 45, Loss: 0.03205344080924988\n",
      "Epoch: 46, Loss: 0.030900919809937477\n",
      "Epoch: 47, Loss: 0.029842596501111984\n",
      "Epoch: 48, Loss: 0.028793830424547195\n",
      "Epoch: 49, Loss: 0.027597179636359215\n",
      "Epoch: 50, Loss: 0.026525981724262238\n",
      "epoch 3 tensor([ 0.6680, -4.1150,  0.0102,  0.3101,  1.0479], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.6442288160324097\n",
      "Epoch: 2, Loss: 0.6036100387573242\n",
      "Epoch: 3, Loss: 0.5542841553688049\n",
      "Epoch: 4, Loss: 0.5073798894882202\n",
      "Epoch: 5, Loss: 0.4690396189689636\n",
      "Epoch: 6, Loss: 0.44451630115509033\n",
      "Epoch: 7, Loss: 0.42534106969833374\n",
      "Epoch: 8, Loss: 0.40833932161331177\n",
      "Epoch: 9, Loss: 0.3952621519565582\n",
      "Epoch: 10, Loss: 0.37896502017974854\n",
      "Epoch: 11, Loss: 0.359669029712677\n",
      "Epoch: 12, Loss: 0.3420310318470001\n",
      "Epoch: 13, Loss: 0.32773181796073914\n",
      "Epoch: 14, Loss: 0.3172392249107361\n",
      "Epoch: 15, Loss: 0.3094337582588196\n",
      "Epoch: 16, Loss: 0.30132365226745605\n",
      "Epoch: 17, Loss: 0.29114699363708496\n",
      "Epoch: 18, Loss: 0.280195951461792\n",
      "Epoch: 19, Loss: 0.26888859272003174\n",
      "Epoch: 20, Loss: 0.2589707374572754\n",
      "Epoch: 21, Loss: 0.25116148591041565\n",
      "Epoch: 22, Loss: 0.24515563249588013\n",
      "Epoch: 23, Loss: 0.24016839265823364\n",
      "Epoch: 24, Loss: 0.2355813980102539\n",
      "Epoch: 25, Loss: 0.23035117983818054\n",
      "Epoch: 26, Loss: 0.22492198646068573\n",
      "Epoch: 27, Loss: 0.21921201050281525\n",
      "Epoch: 28, Loss: 0.2136419415473938\n",
      "Epoch: 29, Loss: 0.20821599662303925\n",
      "Epoch: 30, Loss: 0.2029360830783844\n",
      "Epoch: 31, Loss: 0.19759750366210938\n",
      "Epoch: 32, Loss: 0.19268421828746796\n",
      "Epoch: 33, Loss: 0.1883624643087387\n",
      "Epoch: 34, Loss: 0.18489229679107666\n",
      "Epoch: 35, Loss: 0.18172462284564972\n",
      "Epoch: 36, Loss: 0.17851392924785614\n",
      "Epoch: 37, Loss: 0.17484521865844727\n",
      "Epoch: 38, Loss: 0.17131464183330536\n",
      "Epoch: 39, Loss: 0.16758006811141968\n",
      "Epoch: 40, Loss: 0.16300421953201294\n",
      "Epoch: 41, Loss: 0.1586039513349533\n",
      "Epoch: 42, Loss: 0.15390628576278687\n",
      "Epoch: 43, Loss: 0.1496937870979309\n",
      "Epoch: 44, Loss: 0.14603085815906525\n",
      "Epoch: 45, Loss: 0.1422281712293625\n",
      "Epoch: 46, Loss: 0.1385156661272049\n",
      "Epoch: 47, Loss: 0.13530181348323822\n",
      "Epoch: 48, Loss: 0.13181251287460327\n",
      "Epoch: 49, Loss: 0.12815505266189575\n",
      "Epoch: 50, Loss: 0.12492018938064575\n",
      "epoch 3 tensor([ 0.6664, -4.2361,  0.0424,  0.0246,  1.0204], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.46291378140449524\n",
      "Epoch: 2, Loss: 0.39893585443496704\n",
      "Epoch: 3, Loss: 0.33366909623146057\n",
      "Epoch: 4, Loss: 0.28959667682647705\n",
      "Epoch: 5, Loss: 0.26388439536094666\n",
      "Epoch: 6, Loss: 0.2327088564634323\n",
      "Epoch: 7, Loss: 0.19722972810268402\n",
      "Epoch: 8, Loss: 0.17085592448711395\n",
      "Epoch: 9, Loss: 0.15258285403251648\n",
      "Epoch: 10, Loss: 0.13843905925750732\n",
      "Epoch: 11, Loss: 0.12649936974048615\n",
      "Epoch: 12, Loss: 0.11678900569677353\n",
      "Epoch: 13, Loss: 0.10637729614973068\n",
      "Epoch: 14, Loss: 0.09205266833305359\n",
      "Epoch: 15, Loss: 0.07873612642288208\n",
      "Epoch: 16, Loss: 0.07129831612110138\n",
      "Epoch: 17, Loss: 0.06593625247478485\n",
      "Epoch: 18, Loss: 0.060211099684238434\n",
      "Epoch: 19, Loss: 0.054732803255319595\n",
      "Epoch: 20, Loss: 0.050250887870788574\n",
      "Epoch: 21, Loss: 0.04621525853872299\n",
      "Epoch: 22, Loss: 0.0427357517182827\n",
      "Epoch: 23, Loss: 0.04044949635863304\n",
      "Epoch: 24, Loss: 0.038596611469984055\n",
      "Epoch: 25, Loss: 0.036303505301475525\n",
      "Epoch: 26, Loss: 0.03278772905468941\n",
      "Epoch: 27, Loss: 0.029353374615311623\n",
      "Epoch: 28, Loss: 0.02731950581073761\n",
      "Epoch: 29, Loss: 0.02624267339706421\n",
      "Epoch: 30, Loss: 0.024833157658576965\n",
      "Epoch: 31, Loss: 0.02260054647922516\n",
      "Epoch: 32, Loss: 0.020742712542414665\n",
      "Epoch: 33, Loss: 0.01936396211385727\n",
      "Epoch: 34, Loss: 0.0180429108440876\n",
      "Epoch: 35, Loss: 0.016516057774424553\n",
      "Epoch: 36, Loss: 0.015422807075083256\n",
      "Epoch: 37, Loss: 0.014869524165987968\n",
      "Epoch: 38, Loss: 0.013951304368674755\n",
      "Epoch: 39, Loss: 0.012468833476305008\n",
      "Epoch: 40, Loss: 0.011321080848574638\n",
      "Epoch: 41, Loss: 0.010609968565404415\n",
      "Epoch: 42, Loss: 0.009705517441034317\n",
      "Epoch: 43, Loss: 0.008446954190731049\n",
      "Epoch: 44, Loss: 0.0073895929381251335\n",
      "Epoch: 45, Loss: 0.006790452171117067\n",
      "Epoch: 46, Loss: 0.006511411629617214\n",
      "Epoch: 47, Loss: 0.00621312391012907\n",
      "Epoch: 48, Loss: 0.0056929076090455055\n",
      "Epoch: 49, Loss: 0.005127230193465948\n",
      "Epoch: 50, Loss: 0.004755154252052307\n",
      "epoch 3 tensor([ 0.6747, -4.3115, -0.3045, -0.2228,  1.0616], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.5118682384490967\n",
      "Epoch: 2, Loss: 0.47246143221855164\n",
      "Epoch: 3, Loss: 0.42795687913894653\n",
      "Epoch: 4, Loss: 0.3745032846927643\n",
      "Epoch: 5, Loss: 0.320266455411911\n",
      "Epoch: 6, Loss: 0.28213152289390564\n",
      "Epoch: 7, Loss: 0.2554444372653961\n",
      "Epoch: 8, Loss: 0.22875678539276123\n",
      "Epoch: 9, Loss: 0.2137507200241089\n",
      "Epoch: 10, Loss: 0.2032596468925476\n",
      "Epoch: 11, Loss: 0.1890622079372406\n",
      "Epoch: 12, Loss: 0.1779540479183197\n",
      "Epoch: 13, Loss: 0.16020561754703522\n",
      "Epoch: 14, Loss: 0.1469128280878067\n",
      "Epoch: 15, Loss: 0.13663019239902496\n",
      "Epoch: 16, Loss: 0.12377968430519104\n",
      "Epoch: 17, Loss: 0.11178970336914062\n",
      "Epoch: 18, Loss: 0.10149116814136505\n",
      "Epoch: 19, Loss: 0.09379762411117554\n",
      "Epoch: 20, Loss: 0.08977725356817245\n",
      "Epoch: 21, Loss: 0.08560889214277267\n",
      "Epoch: 22, Loss: 0.08176475763320923\n",
      "Epoch: 23, Loss: 0.07835894823074341\n",
      "Epoch: 24, Loss: 0.07437488436698914\n",
      "Epoch: 25, Loss: 0.06981461495161057\n",
      "Epoch: 26, Loss: 0.06601237505674362\n",
      "Epoch: 27, Loss: 0.06199479103088379\n",
      "Epoch: 28, Loss: 0.05829919874668121\n",
      "Epoch: 29, Loss: 0.05563203990459442\n",
      "Epoch: 30, Loss: 0.05340753495693207\n",
      "Epoch: 31, Loss: 0.05126176401972771\n",
      "Epoch: 32, Loss: 0.04900363087654114\n",
      "Epoch: 33, Loss: 0.04620996490120888\n",
      "Epoch: 34, Loss: 0.043627165257930756\n",
      "Epoch: 35, Loss: 0.04137053340673447\n",
      "Epoch: 36, Loss: 0.038993507623672485\n",
      "Epoch: 37, Loss: 0.03689782693982124\n",
      "Epoch: 38, Loss: 0.03532324358820915\n",
      "Epoch: 39, Loss: 0.03397345542907715\n",
      "Epoch: 40, Loss: 0.03264499455690384\n",
      "Epoch: 41, Loss: 0.031099215149879456\n",
      "Epoch: 42, Loss: 0.02960190922021866\n",
      "Epoch: 43, Loss: 0.02831309102475643\n",
      "Epoch: 44, Loss: 0.02698614075779915\n",
      "Epoch: 45, Loss: 0.025700392201542854\n",
      "Epoch: 46, Loss: 0.024574806913733482\n",
      "Epoch: 47, Loss: 0.02375630848109722\n",
      "Epoch: 48, Loss: 0.02305922657251358\n",
      "Epoch: 49, Loss: 0.02229149267077446\n",
      "Epoch: 50, Loss: 0.021510805934667587\n",
      "epoch 3 tensor([ 0.5981, -4.3204, -0.0265,  0.0700,  1.0495], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.21965469419956207\n",
      "Epoch: 2, Loss: 0.18291239440441132\n",
      "Epoch: 3, Loss: 0.1461208462715149\n",
      "Epoch: 4, Loss: 0.115415059030056\n",
      "Epoch: 5, Loss: 0.09710239619016647\n",
      "Epoch: 6, Loss: 0.0852338895201683\n",
      "Epoch: 7, Loss: 0.07906248420476913\n",
      "Epoch: 8, Loss: 0.07608280330896378\n",
      "Epoch: 9, Loss: 0.07164674997329712\n",
      "Epoch: 10, Loss: 0.06430751085281372\n",
      "Epoch: 11, Loss: 0.05708390101790428\n",
      "Epoch: 12, Loss: 0.05250578001141548\n",
      "Epoch: 13, Loss: 0.04783761128783226\n",
      "Epoch: 14, Loss: 0.04156729206442833\n",
      "Epoch: 15, Loss: 0.03528231754899025\n",
      "Epoch: 16, Loss: 0.03112543560564518\n",
      "Epoch: 17, Loss: 0.028699874877929688\n",
      "Epoch: 18, Loss: 0.02666158229112625\n",
      "Epoch: 19, Loss: 0.024684777483344078\n",
      "Epoch: 20, Loss: 0.02312476374208927\n",
      "Epoch: 21, Loss: 0.021371856331825256\n",
      "Epoch: 22, Loss: 0.018805140629410744\n",
      "Epoch: 23, Loss: 0.015914462506771088\n",
      "Epoch: 24, Loss: 0.01347222551703453\n",
      "Epoch: 25, Loss: 0.011350183747708797\n",
      "Epoch: 26, Loss: 0.00919866282492876\n",
      "Epoch: 27, Loss: 0.007934055291116238\n",
      "Epoch: 28, Loss: 0.007834326475858688\n",
      "Epoch: 29, Loss: 0.008090760558843613\n",
      "Epoch: 30, Loss: 0.007808634079992771\n",
      "Epoch: 31, Loss: 0.0070137279108166695\n",
      "Epoch: 32, Loss: 0.005881763529032469\n",
      "Epoch: 33, Loss: 0.004495211411267519\n",
      "Epoch: 34, Loss: 0.0033707248512655497\n",
      "Epoch: 35, Loss: 0.0028006562497466803\n",
      "Epoch: 36, Loss: 0.002558209700509906\n",
      "Epoch: 37, Loss: 0.002316401107236743\n",
      "Epoch: 38, Loss: 0.002099690493196249\n",
      "Epoch: 39, Loss: 0.0019964897073805332\n",
      "Epoch: 40, Loss: 0.0019495647866278887\n",
      "Epoch: 41, Loss: 0.0018760469974949956\n",
      "Epoch: 42, Loss: 0.0017234005499631166\n",
      "Epoch: 43, Loss: 0.0014914892381057143\n",
      "Epoch: 44, Loss: 0.0012528147781267762\n",
      "Epoch: 45, Loss: 0.0010689732152968645\n",
      "Epoch: 46, Loss: 0.0009625868988223374\n",
      "Epoch: 47, Loss: 0.0009270611335523427\n",
      "Epoch: 48, Loss: 0.0008865371346473694\n",
      "Epoch: 49, Loss: 0.0007772052776999772\n",
      "Epoch: 50, Loss: 0.0006753160268999636\n",
      "epoch 3 tensor([ 0.0636, -4.2852,  0.0535,  0.2317,  1.0400], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.36666131019592285\n",
      "Epoch: 2, Loss: 0.32838088274002075\n",
      "Epoch: 3, Loss: 0.2896224558353424\n",
      "Epoch: 4, Loss: 0.2587459683418274\n",
      "Epoch: 5, Loss: 0.2337610125541687\n",
      "Epoch: 6, Loss: 0.20679570734500885\n",
      "Epoch: 7, Loss: 0.17897798120975494\n",
      "Epoch: 8, Loss: 0.15388283133506775\n",
      "Epoch: 9, Loss: 0.1338496059179306\n",
      "Epoch: 10, Loss: 0.12357346713542938\n",
      "Epoch: 11, Loss: 0.11301853507757187\n",
      "Epoch: 12, Loss: 0.10376864671707153\n",
      "Epoch: 13, Loss: 0.09554984420537949\n",
      "Epoch: 14, Loss: 0.08731213212013245\n",
      "Epoch: 15, Loss: 0.08202635496854782\n",
      "Epoch: 16, Loss: 0.07793173938989639\n",
      "Epoch: 17, Loss: 0.07290039956569672\n",
      "Epoch: 18, Loss: 0.06795068085193634\n",
      "Epoch: 19, Loss: 0.06227809935808182\n",
      "Epoch: 20, Loss: 0.05683043599128723\n",
      "Epoch: 21, Loss: 0.05242270976305008\n",
      "Epoch: 22, Loss: 0.05171629786491394\n",
      "Epoch: 23, Loss: 0.04824262484908104\n",
      "Epoch: 24, Loss: 0.047118350863456726\n",
      "Epoch: 25, Loss: 0.04469389095902443\n",
      "Epoch: 26, Loss: 0.04152919724583626\n",
      "Epoch: 27, Loss: 0.04093807190656662\n",
      "Epoch: 28, Loss: 0.0388612300157547\n",
      "Epoch: 29, Loss: 0.03738125413656235\n",
      "Epoch: 30, Loss: 0.03535666689276695\n",
      "Epoch: 31, Loss: 0.03403686732053757\n",
      "Epoch: 32, Loss: 0.03243807703256607\n",
      "Epoch: 33, Loss: 0.03125196695327759\n",
      "Epoch: 34, Loss: 0.029848147183656693\n",
      "Epoch: 35, Loss: 0.02801043912768364\n",
      "Epoch: 36, Loss: 0.02721845917403698\n",
      "Epoch: 37, Loss: 0.026030292734503746\n",
      "Epoch: 38, Loss: 0.02547062560915947\n",
      "Epoch: 39, Loss: 0.024126794189214706\n",
      "Epoch: 40, Loss: 0.023044146597385406\n",
      "Epoch: 41, Loss: 0.022328000515699387\n",
      "Epoch: 42, Loss: 0.0213310569524765\n",
      "Epoch: 43, Loss: 0.020803045481443405\n",
      "Epoch: 44, Loss: 0.019785823300480843\n",
      "Epoch: 45, Loss: 0.019241565838456154\n",
      "Epoch: 46, Loss: 0.018307436257600784\n",
      "Epoch: 47, Loss: 0.01773574948310852\n",
      "Epoch: 48, Loss: 0.017132073640823364\n",
      "Epoch: 49, Loss: 0.016509687528014183\n",
      "Epoch: 50, Loss: 0.015918172895908356\n",
      "epoch 3 tensor([ 0.8565, -4.2784,  0.1084,  0.0294,  1.0270], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.4026315212249756\n",
      "Epoch: 2, Loss: 0.3210452198982239\n",
      "Epoch: 3, Loss: 0.2459726333618164\n",
      "Epoch: 4, Loss: 0.20477764308452606\n",
      "Epoch: 5, Loss: 0.18671521544456482\n",
      "Epoch: 6, Loss: 0.16215850412845612\n",
      "Epoch: 7, Loss: 0.13209208846092224\n",
      "Epoch: 8, Loss: 0.10854287445545197\n",
      "Epoch: 9, Loss: 0.09638711810112\n",
      "Epoch: 10, Loss: 0.08751454949378967\n",
      "Epoch: 11, Loss: 0.07703430950641632\n",
      "Epoch: 12, Loss: 0.06593509018421173\n",
      "Epoch: 13, Loss: 0.053569212555885315\n",
      "Epoch: 14, Loss: 0.0441371351480484\n",
      "Epoch: 15, Loss: 0.040575288236141205\n",
      "Epoch: 16, Loss: 0.04028376191854477\n",
      "Epoch: 17, Loss: 0.0389568991959095\n",
      "Epoch: 18, Loss: 0.03432817384600639\n",
      "Epoch: 19, Loss: 0.026613853871822357\n",
      "Epoch: 20, Loss: 0.019582651555538177\n",
      "Epoch: 21, Loss: 0.015312910079956055\n",
      "Epoch: 22, Loss: 0.01268812920898199\n",
      "Epoch: 23, Loss: 0.012045714072883129\n",
      "Epoch: 24, Loss: 0.011425630189478397\n",
      "Epoch: 25, Loss: 0.0100763700902462\n",
      "Epoch: 26, Loss: 0.008219057694077492\n",
      "Epoch: 27, Loss: 0.006878739222884178\n",
      "Epoch: 28, Loss: 0.006548386067152023\n",
      "Epoch: 29, Loss: 0.00634222524240613\n",
      "Epoch: 30, Loss: 0.006007479503750801\n",
      "Epoch: 31, Loss: 0.0054902262054383755\n",
      "Epoch: 32, Loss: 0.0051384880207479\n",
      "Epoch: 33, Loss: 0.005038563162088394\n",
      "Epoch: 34, Loss: 0.0052085984498262405\n",
      "Epoch: 35, Loss: 0.0050793117843568325\n",
      "Epoch: 36, Loss: 0.0043716575019061565\n",
      "Epoch: 37, Loss: 0.003316527232527733\n",
      "Epoch: 38, Loss: 0.002329825656488538\n",
      "Epoch: 39, Loss: 0.0017487891018390656\n",
      "Epoch: 40, Loss: 0.0016836582217365503\n",
      "Epoch: 41, Loss: 0.0019571927841752768\n",
      "Epoch: 42, Loss: 0.0021280222572386265\n",
      "Epoch: 43, Loss: 0.002053750678896904\n",
      "Epoch: 44, Loss: 0.0017532709753140807\n",
      "Epoch: 45, Loss: 0.001485446817241609\n",
      "Epoch: 46, Loss: 0.0013642825651913881\n",
      "Epoch: 47, Loss: 0.0013602125691249967\n",
      "Epoch: 48, Loss: 0.001307908445596695\n",
      "Epoch: 49, Loss: 0.0011939748656004667\n",
      "Epoch: 50, Loss: 0.0010680180275812745\n",
      "________________________________________\n",
      "epoch 4 tensor([ 1.0514, -4.2491,  0.8026, -0.0439,  1.0105], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 1.2774113416671753\n",
      "Epoch: 2, Loss: 1.122900128364563\n",
      "Epoch: 3, Loss: 0.946617603302002\n",
      "Epoch: 4, Loss: 0.7940542101860046\n",
      "Epoch: 5, Loss: 0.6765050292015076\n",
      "Epoch: 6, Loss: 0.5893039107322693\n",
      "Epoch: 7, Loss: 0.5260149240493774\n",
      "Epoch: 8, Loss: 0.4811713695526123\n",
      "Epoch: 9, Loss: 0.44742241501808167\n",
      "Epoch: 10, Loss: 0.4191584289073944\n",
      "Epoch: 11, Loss: 0.3896322250366211\n",
      "Epoch: 12, Loss: 0.36120423674583435\n",
      "Epoch: 13, Loss: 0.3349190652370453\n",
      "Epoch: 14, Loss: 0.31118881702423096\n",
      "Epoch: 15, Loss: 0.2879697382450104\n",
      "Epoch: 16, Loss: 0.264354944229126\n",
      "Epoch: 17, Loss: 0.2462303787469864\n",
      "Epoch: 18, Loss: 0.23024769127368927\n",
      "Epoch: 19, Loss: 0.21640457212924957\n",
      "Epoch: 20, Loss: 0.2035151869058609\n",
      "Epoch: 21, Loss: 0.19070255756378174\n",
      "Epoch: 22, Loss: 0.17779779434204102\n",
      "Epoch: 23, Loss: 0.1685602366924286\n",
      "Epoch: 24, Loss: 0.15950578451156616\n",
      "Epoch: 25, Loss: 0.14964845776557922\n",
      "Epoch: 26, Loss: 0.14017151296138763\n",
      "Epoch: 27, Loss: 0.13212399184703827\n",
      "Epoch: 28, Loss: 0.12518414855003357\n",
      "Epoch: 29, Loss: 0.11946763843297958\n",
      "Epoch: 30, Loss: 0.11455468833446503\n",
      "Epoch: 31, Loss: 0.10998621582984924\n",
      "Epoch: 32, Loss: 0.10529898852109909\n",
      "Epoch: 33, Loss: 0.10002687573432922\n",
      "Epoch: 34, Loss: 0.09497305005788803\n",
      "Epoch: 35, Loss: 0.09045089781284332\n",
      "Epoch: 36, Loss: 0.08581390231847763\n",
      "Epoch: 37, Loss: 0.08124394714832306\n",
      "Epoch: 38, Loss: 0.07735320180654526\n",
      "Epoch: 39, Loss: 0.07429617643356323\n",
      "Epoch: 40, Loss: 0.07165809720754623\n",
      "Epoch: 41, Loss: 0.06910204887390137\n",
      "Epoch: 42, Loss: 0.0664450079202652\n",
      "Epoch: 43, Loss: 0.06356744468212128\n",
      "Epoch: 44, Loss: 0.060671720653772354\n",
      "Epoch: 45, Loss: 0.0580328069627285\n",
      "Epoch: 46, Loss: 0.055615734308958054\n",
      "Epoch: 47, Loss: 0.053478922694921494\n",
      "Epoch: 48, Loss: 0.05155889689922333\n",
      "Epoch: 49, Loss: 0.04974087327718735\n",
      "Epoch: 50, Loss: 0.048245858401060104\n",
      "epoch 4 tensor([ 0.9212, -4.1907,  0.6028, -0.7276,  0.1392], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.3014732599258423\n",
      "Epoch: 2, Loss: 0.23756760358810425\n",
      "Epoch: 3, Loss: 0.1894180327653885\n",
      "Epoch: 4, Loss: 0.15333843231201172\n",
      "Epoch: 5, Loss: 0.12679347395896912\n",
      "Epoch: 6, Loss: 0.10582488030195236\n",
      "Epoch: 7, Loss: 0.08888664096593857\n",
      "Epoch: 8, Loss: 0.07304584234952927\n",
      "Epoch: 9, Loss: 0.06510280817747116\n",
      "Epoch: 10, Loss: 0.061403851956129074\n",
      "Epoch: 11, Loss: 0.05771678313612938\n",
      "Epoch: 12, Loss: 0.05256094038486481\n",
      "Epoch: 13, Loss: 0.047790851444005966\n",
      "Epoch: 14, Loss: 0.044725969433784485\n",
      "Epoch: 15, Loss: 0.04239009693264961\n",
      "Epoch: 16, Loss: 0.0399874672293663\n",
      "Epoch: 17, Loss: 0.0373985730111599\n",
      "Epoch: 18, Loss: 0.034361306577920914\n",
      "Epoch: 19, Loss: 0.030385814607143402\n",
      "Epoch: 20, Loss: 0.02684408612549305\n",
      "Epoch: 21, Loss: 0.024966895580291748\n",
      "Epoch: 22, Loss: 0.024030214175581932\n",
      "Epoch: 23, Loss: 0.022111644968390465\n",
      "Epoch: 24, Loss: 0.01950121484696865\n",
      "Epoch: 25, Loss: 0.01796823926270008\n",
      "Epoch: 26, Loss: 0.01770778000354767\n",
      "Epoch: 27, Loss: 0.017297489568591118\n",
      "Epoch: 28, Loss: 0.01597313955426216\n",
      "Epoch: 29, Loss: 0.014434004202485085\n",
      "Epoch: 30, Loss: 0.01281802635639906\n",
      "Epoch: 31, Loss: 0.011715731583535671\n",
      "Epoch: 32, Loss: 0.011128650978207588\n",
      "Epoch: 33, Loss: 0.010786984115839005\n",
      "Epoch: 34, Loss: 0.010238881222903728\n",
      "Epoch: 35, Loss: 0.009796658530831337\n",
      "Epoch: 36, Loss: 0.009426629170775414\n",
      "Epoch: 37, Loss: 0.008941615000367165\n",
      "Epoch: 38, Loss: 0.008207438513636589\n",
      "Epoch: 39, Loss: 0.007536388002336025\n",
      "Epoch: 40, Loss: 0.006765270140022039\n",
      "Epoch: 41, Loss: 0.006026512011885643\n",
      "Epoch: 42, Loss: 0.005502182990312576\n",
      "Epoch: 43, Loss: 0.005205878987908363\n",
      "Epoch: 44, Loss: 0.004982206970453262\n",
      "Epoch: 45, Loss: 0.004747958853840828\n",
      "Epoch: 46, Loss: 0.004571716766804457\n",
      "Epoch: 47, Loss: 0.004463673569262028\n",
      "Epoch: 48, Loss: 0.004324218723922968\n",
      "Epoch: 49, Loss: 0.0042244987562298775\n",
      "Epoch: 50, Loss: 0.004006122704595327\n",
      "epoch 4 tensor([ 0.9035, -4.1397,  0.6546, -0.1241,  0.2214], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.38234421610832214\n",
      "Epoch: 2, Loss: 0.34683722257614136\n",
      "Epoch: 3, Loss: 0.3149169087409973\n",
      "Epoch: 4, Loss: 0.2929375171661377\n",
      "Epoch: 5, Loss: 0.27054789662361145\n",
      "Epoch: 6, Loss: 0.24744169414043427\n",
      "Epoch: 7, Loss: 0.22763675451278687\n",
      "Epoch: 8, Loss: 0.20882217586040497\n",
      "Epoch: 9, Loss: 0.18727727234363556\n",
      "Epoch: 10, Loss: 0.16594162583351135\n",
      "Epoch: 11, Loss: 0.1511232703924179\n",
      "Epoch: 12, Loss: 0.14051735401153564\n",
      "Epoch: 13, Loss: 0.12984727323055267\n",
      "Epoch: 14, Loss: 0.12374349683523178\n",
      "Epoch: 15, Loss: 0.11669903993606567\n",
      "Epoch: 16, Loss: 0.1062026396393776\n",
      "Epoch: 17, Loss: 0.0989462286233902\n",
      "Epoch: 18, Loss: 0.09335235506296158\n",
      "Epoch: 19, Loss: 0.08690612763166428\n",
      "Epoch: 20, Loss: 0.0832400992512703\n",
      "Epoch: 21, Loss: 0.08021046966314316\n",
      "Epoch: 22, Loss: 0.07464143633842468\n",
      "Epoch: 23, Loss: 0.07016570121049881\n",
      "Epoch: 24, Loss: 0.06704944372177124\n",
      "Epoch: 25, Loss: 0.063405841588974\n",
      "Epoch: 26, Loss: 0.06086605042219162\n",
      "Epoch: 27, Loss: 0.05890756472945213\n",
      "Epoch: 28, Loss: 0.05650760233402252\n",
      "Epoch: 29, Loss: 0.05472627282142639\n",
      "Epoch: 30, Loss: 0.05241715908050537\n",
      "Epoch: 31, Loss: 0.0495840348303318\n",
      "Epoch: 32, Loss: 0.04799291118979454\n",
      "Epoch: 33, Loss: 0.04637932777404785\n",
      "Epoch: 34, Loss: 0.04421505331993103\n",
      "Epoch: 35, Loss: 0.042323436588048935\n",
      "Epoch: 36, Loss: 0.04020753875374794\n",
      "Epoch: 37, Loss: 0.03818531334400177\n",
      "Epoch: 38, Loss: 0.03670177608728409\n",
      "Epoch: 39, Loss: 0.03515904024243355\n",
      "Epoch: 40, Loss: 0.03383542597293854\n",
      "Epoch: 41, Loss: 0.03259763866662979\n",
      "Epoch: 42, Loss: 0.031015925109386444\n",
      "Epoch: 43, Loss: 0.02967377007007599\n",
      "Epoch: 44, Loss: 0.02862543985247612\n",
      "Epoch: 45, Loss: 0.027372736483812332\n",
      "Epoch: 46, Loss: 0.026299428194761276\n",
      "Epoch: 47, Loss: 0.024987995624542236\n",
      "Epoch: 48, Loss: 0.023720450699329376\n",
      "Epoch: 49, Loss: 0.022538786754012108\n",
      "Epoch: 50, Loss: 0.02128780446946621\n",
      "epoch 4 tensor([ 0.8887, -4.1986, -0.1680,  0.1078,  0.9815], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.47049853205680847\n",
      "Epoch: 2, Loss: 0.3818713426589966\n",
      "Epoch: 3, Loss: 0.3164404630661011\n",
      "Epoch: 4, Loss: 0.2840803265571594\n",
      "Epoch: 5, Loss: 0.25640860199928284\n",
      "Epoch: 6, Loss: 0.22524604201316833\n",
      "Epoch: 7, Loss: 0.1994670033454895\n",
      "Epoch: 8, Loss: 0.17950516939163208\n",
      "Epoch: 9, Loss: 0.16537891328334808\n",
      "Epoch: 10, Loss: 0.15451355278491974\n",
      "Epoch: 11, Loss: 0.1438300460577011\n",
      "Epoch: 12, Loss: 0.13285739719867706\n",
      "Epoch: 13, Loss: 0.12058024108409882\n",
      "Epoch: 14, Loss: 0.10770118981599808\n",
      "Epoch: 15, Loss: 0.09460190683603287\n",
      "Epoch: 16, Loss: 0.08565822243690491\n",
      "Epoch: 17, Loss: 0.08143582940101624\n",
      "Epoch: 18, Loss: 0.07674305140972137\n",
      "Epoch: 19, Loss: 0.06920681893825531\n",
      "Epoch: 20, Loss: 0.061154503375291824\n",
      "Epoch: 21, Loss: 0.05621924251317978\n",
      "Epoch: 22, Loss: 0.05392119288444519\n",
      "Epoch: 23, Loss: 0.049951668828725815\n",
      "Epoch: 24, Loss: 0.043663620948791504\n",
      "Epoch: 25, Loss: 0.03848817199468613\n",
      "Epoch: 26, Loss: 0.03514917194843292\n",
      "Epoch: 27, Loss: 0.03200112655758858\n",
      "Epoch: 28, Loss: 0.028493767604231834\n",
      "Epoch: 29, Loss: 0.026223164051771164\n",
      "Epoch: 30, Loss: 0.025636829435825348\n",
      "Epoch: 31, Loss: 0.02532877027988434\n",
      "Epoch: 32, Loss: 0.024074628949165344\n",
      "Epoch: 33, Loss: 0.022003307938575745\n",
      "Epoch: 34, Loss: 0.020134849473834038\n",
      "Epoch: 35, Loss: 0.018915556371212006\n",
      "Epoch: 36, Loss: 0.017842862755060196\n",
      "Epoch: 37, Loss: 0.016759725287556648\n",
      "Epoch: 38, Loss: 0.01572764851152897\n",
      "Epoch: 39, Loss: 0.014525000937283039\n",
      "Epoch: 40, Loss: 0.013576949946582317\n",
      "Epoch: 41, Loss: 0.013175051659345627\n",
      "Epoch: 42, Loss: 0.012859067879617214\n",
      "Epoch: 43, Loss: 0.012067352421581745\n",
      "Epoch: 44, Loss: 0.011029817163944244\n",
      "Epoch: 45, Loss: 0.010418768972158432\n",
      "Epoch: 46, Loss: 0.0101375887170434\n",
      "Epoch: 47, Loss: 0.0097714988514781\n",
      "Epoch: 48, Loss: 0.009110167622566223\n",
      "Epoch: 49, Loss: 0.008496166206896305\n",
      "Epoch: 50, Loss: 0.008044128306210041\n",
      "epoch 4 tensor([ 0.8879, -4.2423, -0.0957,  1.4698,  1.1016], grad_fn=<AddBackward0>) 3\n",
      "Epoch: 1, Loss: 1.0317046642303467\n",
      "Epoch: 2, Loss: 0.8566343784332275\n",
      "Epoch: 3, Loss: 0.673309326171875\n",
      "Epoch: 4, Loss: 0.5334929823875427\n",
      "Epoch: 5, Loss: 0.4428291618824005\n",
      "Epoch: 6, Loss: 0.3890324831008911\n",
      "Epoch: 7, Loss: 0.35340720415115356\n",
      "Epoch: 8, Loss: 0.32656392455101013\n",
      "Epoch: 9, Loss: 0.306009441614151\n",
      "Epoch: 10, Loss: 0.29314613342285156\n",
      "Epoch: 11, Loss: 0.2831479012966156\n",
      "Epoch: 12, Loss: 0.2706972062587738\n",
      "Epoch: 13, Loss: 0.25067251920700073\n",
      "Epoch: 14, Loss: 0.22459426522254944\n",
      "Epoch: 15, Loss: 0.195000559091568\n",
      "Epoch: 16, Loss: 0.16646766662597656\n",
      "Epoch: 17, Loss: 0.1451527625322342\n",
      "Epoch: 18, Loss: 0.13439364731311798\n",
      "Epoch: 19, Loss: 0.13007591664791107\n",
      "Epoch: 20, Loss: 0.1289764642715454\n",
      "Epoch: 21, Loss: 0.12686792016029358\n",
      "Epoch: 22, Loss: 0.12138877809047699\n",
      "Epoch: 23, Loss: 0.11260697990655899\n",
      "Epoch: 24, Loss: 0.10266132652759552\n",
      "Epoch: 25, Loss: 0.09295818209648132\n",
      "Epoch: 26, Loss: 0.08416018635034561\n",
      "Epoch: 27, Loss: 0.07794389128684998\n",
      "Epoch: 28, Loss: 0.07275472581386566\n",
      "Epoch: 29, Loss: 0.0680476650595665\n",
      "Epoch: 30, Loss: 0.06411731988191605\n",
      "Epoch: 31, Loss: 0.061183758080005646\n",
      "Epoch: 32, Loss: 0.058438610285520554\n",
      "Epoch: 33, Loss: 0.05555526167154312\n",
      "Epoch: 34, Loss: 0.05298309400677681\n",
      "Epoch: 35, Loss: 0.050632815808057785\n",
      "Epoch: 36, Loss: 0.04768076539039612\n",
      "Epoch: 37, Loss: 0.04407959058880806\n",
      "Epoch: 38, Loss: 0.04033230245113373\n",
      "Epoch: 39, Loss: 0.03698483854532242\n",
      "Epoch: 40, Loss: 0.034514304250478745\n",
      "Epoch: 41, Loss: 0.0337463915348053\n",
      "Epoch: 42, Loss: 0.03355422616004944\n",
      "Epoch: 43, Loss: 0.0330880768597126\n",
      "Epoch: 44, Loss: 0.03213505446910858\n",
      "Epoch: 45, Loss: 0.03067682683467865\n",
      "Epoch: 46, Loss: 0.028836384415626526\n",
      "Epoch: 47, Loss: 0.027242550626397133\n",
      "Epoch: 48, Loss: 0.026119990274310112\n",
      "Epoch: 49, Loss: 0.025045285001397133\n",
      "Epoch: 50, Loss: 0.02399122528731823\n",
      "epoch 4 tensor([ 0.9138, -3.9602,  0.2741, -0.1203,  1.6386], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.5399752259254456\n",
      "Epoch: 2, Loss: 0.493565171957016\n",
      "Epoch: 3, Loss: 0.44543716311454773\n",
      "Epoch: 4, Loss: 0.389871746301651\n",
      "Epoch: 5, Loss: 0.32973456382751465\n",
      "Epoch: 6, Loss: 0.2855229675769806\n",
      "Epoch: 7, Loss: 0.25621020793914795\n",
      "Epoch: 8, Loss: 0.22920967638492584\n",
      "Epoch: 9, Loss: 0.21040861308574677\n",
      "Epoch: 10, Loss: 0.19882039725780487\n",
      "Epoch: 11, Loss: 0.18301673233509064\n",
      "Epoch: 12, Loss: 0.1623726636171341\n",
      "Epoch: 13, Loss: 0.1453888863325119\n",
      "Epoch: 14, Loss: 0.12988920509815216\n",
      "Epoch: 15, Loss: 0.1128520742058754\n",
      "Epoch: 16, Loss: 0.09956088662147522\n",
      "Epoch: 17, Loss: 0.09166299551725388\n",
      "Epoch: 18, Loss: 0.08489744365215302\n",
      "Epoch: 19, Loss: 0.07677441835403442\n",
      "Epoch: 20, Loss: 0.07225498557090759\n",
      "Epoch: 21, Loss: 0.06778440624475479\n",
      "Epoch: 22, Loss: 0.0617302767932415\n",
      "Epoch: 23, Loss: 0.0571763813495636\n",
      "Epoch: 24, Loss: 0.05496728792786598\n",
      "Epoch: 25, Loss: 0.052830543369054794\n",
      "Epoch: 26, Loss: 0.05050364136695862\n",
      "Epoch: 27, Loss: 0.0489315465092659\n",
      "Epoch: 28, Loss: 0.046825140714645386\n",
      "Epoch: 29, Loss: 0.043316349387168884\n",
      "Epoch: 30, Loss: 0.03991027921438217\n",
      "Epoch: 31, Loss: 0.037059616297483444\n",
      "Epoch: 32, Loss: 0.03414047881960869\n",
      "Epoch: 33, Loss: 0.03158637881278992\n",
      "Epoch: 34, Loss: 0.02994171902537346\n",
      "Epoch: 35, Loss: 0.028148513287305832\n",
      "Epoch: 36, Loss: 0.025940537452697754\n",
      "Epoch: 37, Loss: 0.02388613484799862\n",
      "Epoch: 38, Loss: 0.02175968885421753\n",
      "Epoch: 39, Loss: 0.019375180825591087\n",
      "Epoch: 40, Loss: 0.01740293577313423\n",
      "Epoch: 41, Loss: 0.01599588245153427\n",
      "Epoch: 42, Loss: 0.0147490743547678\n",
      "Epoch: 43, Loss: 0.013817527331411839\n",
      "Epoch: 44, Loss: 0.01315708365291357\n",
      "Epoch: 45, Loss: 0.012311823666095734\n",
      "Epoch: 46, Loss: 0.011398088186979294\n",
      "Epoch: 47, Loss: 0.0106310173869133\n",
      "Epoch: 48, Loss: 0.009897318668663502\n",
      "Epoch: 49, Loss: 0.009207403287291527\n",
      "Epoch: 50, Loss: 0.008758356794714928\n",
      "epoch 4 tensor([ 0.8873, -3.7912, -0.0867, -0.0752,  1.3339], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.14683420956134796\n",
      "Epoch: 2, Loss: 0.120231993496418\n",
      "Epoch: 3, Loss: 0.09156983345746994\n",
      "Epoch: 4, Loss: 0.07164821028709412\n",
      "Epoch: 5, Loss: 0.05960552394390106\n",
      "Epoch: 6, Loss: 0.0512692965567112\n",
      "Epoch: 7, Loss: 0.046844348311424255\n",
      "Epoch: 8, Loss: 0.04513556510210037\n",
      "Epoch: 9, Loss: 0.04245996102690697\n",
      "Epoch: 10, Loss: 0.03798972815275192\n",
      "Epoch: 11, Loss: 0.03331715986132622\n",
      "Epoch: 12, Loss: 0.029362045228481293\n",
      "Epoch: 13, Loss: 0.025877414271235466\n",
      "Epoch: 14, Loss: 0.023000573739409447\n",
      "Epoch: 15, Loss: 0.021676568314433098\n",
      "Epoch: 16, Loss: 0.02153780870139599\n",
      "Epoch: 17, Loss: 0.020986191928386688\n",
      "Epoch: 18, Loss: 0.01876075752079487\n",
      "Epoch: 19, Loss: 0.01524029579013586\n",
      "Epoch: 20, Loss: 0.011866450309753418\n",
      "Epoch: 21, Loss: 0.009903308935463428\n",
      "Epoch: 22, Loss: 0.009415414184331894\n",
      "Epoch: 23, Loss: 0.009467110969126225\n",
      "Epoch: 24, Loss: 0.009270086884498596\n",
      "Epoch: 25, Loss: 0.008805384859442711\n",
      "Epoch: 26, Loss: 0.00831218995153904\n",
      "Epoch: 27, Loss: 0.0076838708482682705\n",
      "Epoch: 28, Loss: 0.006696789991110563\n",
      "Epoch: 29, Loss: 0.005692316219210625\n",
      "Epoch: 30, Loss: 0.005114387255162001\n",
      "Epoch: 31, Loss: 0.004859199747443199\n",
      "Epoch: 32, Loss: 0.004678678698837757\n",
      "Epoch: 33, Loss: 0.004603066481649876\n",
      "Epoch: 34, Loss: 0.004499341361224651\n",
      "Epoch: 35, Loss: 0.004025206435471773\n",
      "Epoch: 36, Loss: 0.0032782324124127626\n",
      "Epoch: 37, Loss: 0.0027855904772877693\n",
      "Epoch: 38, Loss: 0.0027139252051711082\n",
      "Epoch: 39, Loss: 0.0027361398097127676\n",
      "Epoch: 40, Loss: 0.0025955005548894405\n",
      "Epoch: 41, Loss: 0.0023689400404691696\n",
      "Epoch: 42, Loss: 0.002139576245099306\n",
      "Epoch: 43, Loss: 0.00184362952131778\n",
      "Epoch: 44, Loss: 0.001527369604445994\n",
      "Epoch: 45, Loss: 0.0013190608005970716\n",
      "Epoch: 46, Loss: 0.0012241839431226254\n",
      "Epoch: 47, Loss: 0.0011882419930770993\n",
      "Epoch: 48, Loss: 0.0012114905985072255\n",
      "Epoch: 49, Loss: 0.0012300302041694522\n",
      "Epoch: 50, Loss: 0.0011245610658079386\n",
      "epoch 4 tensor([ 0.8990, -4.1689, -0.1170,  0.6154,  0.9121], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.3010888993740082\n",
      "Epoch: 2, Loss: 0.26649320125579834\n",
      "Epoch: 3, Loss: 0.2371865063905716\n",
      "Epoch: 4, Loss: 0.2143152356147766\n",
      "Epoch: 5, Loss: 0.18582145869731903\n",
      "Epoch: 6, Loss: 0.15633229911327362\n",
      "Epoch: 7, Loss: 0.12980373203754425\n",
      "Epoch: 8, Loss: 0.107878677546978\n",
      "Epoch: 9, Loss: 0.08985753357410431\n",
      "Epoch: 10, Loss: 0.0758451297879219\n",
      "Epoch: 11, Loss: 0.0645923912525177\n",
      "Epoch: 12, Loss: 0.05816662311553955\n",
      "Epoch: 13, Loss: 0.0556369312107563\n",
      "Epoch: 14, Loss: 0.04671085998415947\n",
      "Epoch: 15, Loss: 0.0406171940267086\n",
      "Epoch: 16, Loss: 0.040841393172740936\n",
      "Epoch: 17, Loss: 0.039023056626319885\n",
      "Epoch: 18, Loss: 0.03484990820288658\n",
      "Epoch: 19, Loss: 0.0330275259912014\n",
      "Epoch: 20, Loss: 0.03130023181438446\n",
      "Epoch: 21, Loss: 0.027129031717777252\n",
      "Epoch: 22, Loss: 0.02417180687189102\n",
      "Epoch: 23, Loss: 0.022317513823509216\n",
      "Epoch: 24, Loss: 0.01966463029384613\n",
      "Epoch: 25, Loss: 0.016322502866387367\n",
      "Epoch: 26, Loss: 0.013879976235330105\n",
      "Epoch: 27, Loss: 0.01313684694468975\n",
      "Epoch: 28, Loss: 0.011660318821668625\n",
      "Epoch: 29, Loss: 0.010147527791559696\n",
      "Epoch: 30, Loss: 0.009419736452400684\n",
      "Epoch: 31, Loss: 0.009070653468370438\n",
      "Epoch: 32, Loss: 0.008148213848471642\n",
      "Epoch: 33, Loss: 0.007239077240228653\n",
      "Epoch: 34, Loss: 0.007057753391563892\n",
      "Epoch: 35, Loss: 0.006632972974330187\n",
      "Epoch: 36, Loss: 0.005971602629870176\n",
      "Epoch: 37, Loss: 0.005612639244645834\n",
      "Epoch: 38, Loss: 0.005516286473721266\n",
      "Epoch: 39, Loss: 0.004975209943950176\n",
      "Epoch: 40, Loss: 0.0045030247420072556\n",
      "Epoch: 41, Loss: 0.004368532449007034\n",
      "Epoch: 42, Loss: 0.004005018621683121\n",
      "Epoch: 43, Loss: 0.003595899324864149\n",
      "Epoch: 44, Loss: 0.0033681956119835377\n",
      "Epoch: 45, Loss: 0.003134039230644703\n",
      "Epoch: 46, Loss: 0.0027253562584519386\n",
      "Epoch: 47, Loss: 0.002553302329033613\n",
      "Epoch: 48, Loss: 0.0024338681250810623\n",
      "Epoch: 49, Loss: 0.00224597891792655\n",
      "Epoch: 50, Loss: 0.0021534382831305265\n",
      "epoch 4 tensor([ 0.9099, -4.2025, -0.2462, -0.1521,  0.8812], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.16478538513183594\n",
      "Epoch: 2, Loss: 0.13716667890548706\n",
      "Epoch: 3, Loss: 0.11187076568603516\n",
      "Epoch: 4, Loss: 0.09364905953407288\n",
      "Epoch: 5, Loss: 0.07812336832284927\n",
      "Epoch: 6, Loss: 0.06340257823467255\n",
      "Epoch: 7, Loss: 0.051329560577869415\n",
      "Epoch: 8, Loss: 0.044666338711977005\n",
      "Epoch: 9, Loss: 0.04048957675695419\n",
      "Epoch: 10, Loss: 0.03626829385757446\n",
      "Epoch: 11, Loss: 0.03090168535709381\n",
      "Epoch: 12, Loss: 0.026461729779839516\n",
      "Epoch: 13, Loss: 0.025258364155888557\n",
      "Epoch: 14, Loss: 0.025806527584791183\n",
      "Epoch: 15, Loss: 0.02513248473405838\n",
      "Epoch: 16, Loss: 0.022326935082674026\n",
      "Epoch: 17, Loss: 0.018530791625380516\n",
      "Epoch: 18, Loss: 0.015665734186768532\n",
      "Epoch: 19, Loss: 0.013502068817615509\n",
      "Epoch: 20, Loss: 0.01124943234026432\n",
      "Epoch: 21, Loss: 0.009002026170492172\n",
      "Epoch: 22, Loss: 0.0072120241820812225\n",
      "Epoch: 23, Loss: 0.006609365344047546\n",
      "Epoch: 24, Loss: 0.006689387373626232\n",
      "Epoch: 25, Loss: 0.006393149960786104\n",
      "Epoch: 26, Loss: 0.005434604827314615\n",
      "Epoch: 27, Loss: 0.004250543192028999\n",
      "Epoch: 28, Loss: 0.0035367137752473354\n",
      "Epoch: 29, Loss: 0.003148558083921671\n",
      "Epoch: 30, Loss: 0.0030003306455910206\n",
      "Epoch: 31, Loss: 0.003091932740062475\n",
      "Epoch: 32, Loss: 0.0032605899032205343\n",
      "Epoch: 33, Loss: 0.003390395315364003\n",
      "Epoch: 34, Loss: 0.003148486837744713\n",
      "Epoch: 35, Loss: 0.0025702184066176414\n",
      "Epoch: 36, Loss: 0.0019446462392807007\n",
      "Epoch: 37, Loss: 0.0016167208086699247\n",
      "Epoch: 38, Loss: 0.0015757572837173939\n",
      "Epoch: 39, Loss: 0.0015047485940158367\n",
      "Epoch: 40, Loss: 0.0013562622480094433\n",
      "Epoch: 41, Loss: 0.0011757219908758998\n",
      "Epoch: 42, Loss: 0.0010935774771496654\n",
      "Epoch: 43, Loss: 0.001063246512785554\n",
      "Epoch: 44, Loss: 0.0010014422005042434\n",
      "Epoch: 45, Loss: 0.0009040723671205342\n",
      "Epoch: 46, Loss: 0.0008640282321721315\n",
      "Epoch: 47, Loss: 0.0008759335614740849\n",
      "Epoch: 48, Loss: 0.0008267188095487654\n",
      "Epoch: 49, Loss: 0.0007244281587190926\n",
      "Epoch: 50, Loss: 0.0005963796866126359\n",
      "epoch 4 tensor([ 0.8960, -4.0194, -0.0392, -0.0983,  0.8256], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.11380808055400848\n",
      "Epoch: 2, Loss: 0.0940493643283844\n",
      "Epoch: 3, Loss: 0.07358039915561676\n",
      "Epoch: 4, Loss: 0.059168741106987\n",
      "Epoch: 5, Loss: 0.048831891268491745\n",
      "Epoch: 6, Loss: 0.04231547936797142\n",
      "Epoch: 7, Loss: 0.03977691009640694\n",
      "Epoch: 8, Loss: 0.03637205436825752\n",
      "Epoch: 9, Loss: 0.0313008651137352\n",
      "Epoch: 10, Loss: 0.026588890701532364\n",
      "Epoch: 11, Loss: 0.02338452637195587\n",
      "Epoch: 12, Loss: 0.021355023607611656\n",
      "Epoch: 13, Loss: 0.019147628918290138\n",
      "Epoch: 14, Loss: 0.016664450988173485\n",
      "Epoch: 15, Loss: 0.014541378244757652\n",
      "Epoch: 16, Loss: 0.012857344001531601\n",
      "Epoch: 17, Loss: 0.011537102051079273\n",
      "Epoch: 18, Loss: 0.010208959691226482\n",
      "Epoch: 19, Loss: 0.008597028441727161\n",
      "Epoch: 20, Loss: 0.006959548685699701\n",
      "Epoch: 21, Loss: 0.005731869954615831\n",
      "Epoch: 22, Loss: 0.005062574055045843\n",
      "Epoch: 23, Loss: 0.004637036472558975\n",
      "Epoch: 24, Loss: 0.004405089188367128\n",
      "Epoch: 25, Loss: 0.00413860846310854\n",
      "Epoch: 26, Loss: 0.003753510070964694\n",
      "Epoch: 27, Loss: 0.0035474197939038277\n",
      "Epoch: 28, Loss: 0.003578303148970008\n",
      "Epoch: 29, Loss: 0.003486890811473131\n",
      "Epoch: 30, Loss: 0.003227818524464965\n",
      "Epoch: 31, Loss: 0.002874084748327732\n",
      "Epoch: 32, Loss: 0.002387084998190403\n",
      "Epoch: 33, Loss: 0.0019876929000020027\n",
      "Epoch: 34, Loss: 0.0019054129952564836\n",
      "Epoch: 35, Loss: 0.0018917596898972988\n",
      "Epoch: 36, Loss: 0.0017034511547535658\n",
      "Epoch: 37, Loss: 0.0014323735376819968\n",
      "Epoch: 38, Loss: 0.0011097355745732784\n",
      "Epoch: 39, Loss: 0.0007979920483194292\n",
      "Epoch: 40, Loss: 0.0007094600587151945\n",
      "Epoch: 41, Loss: 0.0007760098087601364\n",
      "Epoch: 42, Loss: 0.0007997581269592047\n",
      "Epoch: 43, Loss: 0.0007907402468845248\n",
      "Epoch: 44, Loss: 0.0007376569556072354\n",
      "Epoch: 45, Loss: 0.0006136484444141388\n",
      "Epoch: 46, Loss: 0.0005219499580562115\n",
      "Epoch: 47, Loss: 0.0004662735154852271\n",
      "Epoch: 48, Loss: 0.0003761090338230133\n",
      "Epoch: 49, Loss: 0.0003056426648981869\n",
      "Epoch: 50, Loss: 0.00027496705297380686\n",
      "________________________________________\n",
      "epoch 5 tensor([ 0.9052, -3.8153, -0.1630,  0.5391,  0.5110], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.4702804982662201\n",
      "Epoch: 2, Loss: 0.38205215334892273\n",
      "Epoch: 3, Loss: 0.3132164478302002\n",
      "Epoch: 4, Loss: 0.25628966093063354\n",
      "Epoch: 5, Loss: 0.20766662061214447\n",
      "Epoch: 6, Loss: 0.1697157323360443\n",
      "Epoch: 7, Loss: 0.14502790570259094\n",
      "Epoch: 8, Loss: 0.12997741997241974\n",
      "Epoch: 9, Loss: 0.12232591956853867\n",
      "Epoch: 10, Loss: 0.11790162324905396\n",
      "Epoch: 11, Loss: 0.1144108772277832\n",
      "Epoch: 12, Loss: 0.10906380414962769\n",
      "Epoch: 13, Loss: 0.10238983482122421\n",
      "Epoch: 14, Loss: 0.09635672718286514\n",
      "Epoch: 15, Loss: 0.08990024775266647\n",
      "Epoch: 16, Loss: 0.08364997059106827\n",
      "Epoch: 17, Loss: 0.07904874533414841\n",
      "Epoch: 18, Loss: 0.07524624466896057\n",
      "Epoch: 19, Loss: 0.06995047628879547\n",
      "Epoch: 20, Loss: 0.06402959674596786\n",
      "Epoch: 21, Loss: 0.05915379524230957\n",
      "Epoch: 22, Loss: 0.055039528757333755\n",
      "Epoch: 23, Loss: 0.05117051675915718\n",
      "Epoch: 24, Loss: 0.047752298414707184\n",
      "Epoch: 25, Loss: 0.044920142740011215\n",
      "Epoch: 26, Loss: 0.04270203039050102\n",
      "Epoch: 27, Loss: 0.040243081748485565\n",
      "Epoch: 28, Loss: 0.03752656280994415\n",
      "Epoch: 29, Loss: 0.035112809389829636\n",
      "Epoch: 30, Loss: 0.03244754299521446\n",
      "Epoch: 31, Loss: 0.02961437962949276\n",
      "Epoch: 32, Loss: 0.02781902812421322\n",
      "Epoch: 33, Loss: 0.02621944434940815\n",
      "Epoch: 34, Loss: 0.025115065276622772\n",
      "Epoch: 35, Loss: 0.024389958009123802\n",
      "Epoch: 36, Loss: 0.023248665034770966\n",
      "Epoch: 37, Loss: 0.02185688726603985\n",
      "Epoch: 38, Loss: 0.02052721194922924\n",
      "Epoch: 39, Loss: 0.019294027239084244\n",
      "Epoch: 40, Loss: 0.01808677799999714\n",
      "Epoch: 41, Loss: 0.016944032162427902\n",
      "Epoch: 42, Loss: 0.01595223881304264\n",
      "Epoch: 43, Loss: 0.015056035481393337\n",
      "Epoch: 44, Loss: 0.014071447774767876\n",
      "Epoch: 45, Loss: 0.012979830615222454\n",
      "Epoch: 46, Loss: 0.01199671346694231\n",
      "Epoch: 47, Loss: 0.011238297447562218\n",
      "Epoch: 48, Loss: 0.010597077198326588\n",
      "Epoch: 49, Loss: 0.010148082859814167\n",
      "Epoch: 50, Loss: 0.009637964889407158\n",
      "epoch 5 tensor([ 0.7178, -3.7099, -0.3098,  1.4634,  1.1645], grad_fn=<AddBackward0>) 3\n",
      "Epoch: 1, Loss: 0.6484262943267822\n",
      "Epoch: 2, Loss: 0.6084094047546387\n",
      "Epoch: 3, Loss: 0.5650680661201477\n",
      "Epoch: 4, Loss: 0.51932692527771\n",
      "Epoch: 5, Loss: 0.4770508110523224\n",
      "Epoch: 6, Loss: 0.44263148307800293\n",
      "Epoch: 7, Loss: 0.41113266348838806\n",
      "Epoch: 8, Loss: 0.38170695304870605\n",
      "Epoch: 9, Loss: 0.3553081154823303\n",
      "Epoch: 10, Loss: 0.33702942728996277\n",
      "Epoch: 11, Loss: 0.32313424348831177\n",
      "Epoch: 12, Loss: 0.3102806806564331\n",
      "Epoch: 13, Loss: 0.296593576669693\n",
      "Epoch: 14, Loss: 0.2823389768600464\n",
      "Epoch: 15, Loss: 0.26852256059646606\n",
      "Epoch: 16, Loss: 0.2577444314956665\n",
      "Epoch: 17, Loss: 0.2487909346818924\n",
      "Epoch: 18, Loss: 0.23966361582279205\n",
      "Epoch: 19, Loss: 0.2301226258277893\n",
      "Epoch: 20, Loss: 0.22116495668888092\n",
      "Epoch: 21, Loss: 0.21039703488349915\n",
      "Epoch: 22, Loss: 0.20167534053325653\n",
      "Epoch: 23, Loss: 0.19395208358764648\n",
      "Epoch: 24, Loss: 0.18841661512851715\n",
      "Epoch: 25, Loss: 0.18186703324317932\n",
      "Epoch: 26, Loss: 0.17740081250667572\n",
      "Epoch: 27, Loss: 0.1730865240097046\n",
      "Epoch: 28, Loss: 0.169151172041893\n",
      "Epoch: 29, Loss: 0.16507039964199066\n",
      "Epoch: 30, Loss: 0.16112832725048065\n",
      "Epoch: 31, Loss: 0.15673696994781494\n",
      "Epoch: 32, Loss: 0.15283159911632538\n",
      "Epoch: 33, Loss: 0.14941224455833435\n",
      "Epoch: 34, Loss: 0.14648164808750153\n",
      "Epoch: 35, Loss: 0.1448882669210434\n",
      "Epoch: 36, Loss: 0.14223480224609375\n",
      "Epoch: 37, Loss: 0.14072099328041077\n",
      "Epoch: 38, Loss: 0.1367855668067932\n",
      "Epoch: 39, Loss: 0.13543131947517395\n",
      "Epoch: 40, Loss: 0.13240303099155426\n",
      "Epoch: 41, Loss: 0.13012650609016418\n",
      "Epoch: 42, Loss: 0.12722356617450714\n",
      "Epoch: 43, Loss: 0.12527525424957275\n",
      "Epoch: 44, Loss: 0.12274429202079773\n",
      "Epoch: 45, Loss: 0.12051057815551758\n",
      "Epoch: 46, Loss: 0.11853399127721786\n",
      "Epoch: 47, Loss: 0.11728740483522415\n",
      "Epoch: 48, Loss: 0.1155671775341034\n",
      "Epoch: 49, Loss: 0.11357889324426651\n",
      "Epoch: 50, Loss: 0.11167553812265396\n",
      "epoch 5 tensor([ 0.7237, -3.6574, -0.3998,  0.8037,  1.0375], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.34964993596076965\n",
      "Epoch: 2, Loss: 0.27709677815437317\n",
      "Epoch: 3, Loss: 0.218780979514122\n",
      "Epoch: 4, Loss: 0.1668519228696823\n",
      "Epoch: 5, Loss: 0.1469137817621231\n",
      "Epoch: 6, Loss: 0.12785084545612335\n",
      "Epoch: 7, Loss: 0.1266215294599533\n",
      "Epoch: 8, Loss: 0.12130427360534668\n",
      "Epoch: 9, Loss: 0.11438417434692383\n",
      "Epoch: 10, Loss: 0.10334215313196182\n",
      "Epoch: 11, Loss: 0.08572102338075638\n",
      "Epoch: 12, Loss: 0.07338514924049377\n",
      "Epoch: 13, Loss: 0.0613231360912323\n",
      "Epoch: 14, Loss: 0.05661013722419739\n",
      "Epoch: 15, Loss: 0.05415569245815277\n",
      "Epoch: 16, Loss: 0.05002107471227646\n",
      "Epoch: 17, Loss: 0.04620029777288437\n",
      "Epoch: 18, Loss: 0.04008307307958603\n",
      "Epoch: 19, Loss: 0.03680241107940674\n",
      "Epoch: 20, Loss: 0.03355646878480911\n",
      "Epoch: 21, Loss: 0.029841365292668343\n",
      "Epoch: 22, Loss: 0.027582498267292976\n",
      "Epoch: 23, Loss: 0.023812083527445793\n",
      "Epoch: 24, Loss: 0.02104751393198967\n",
      "Epoch: 25, Loss: 0.017441872507333755\n",
      "Epoch: 26, Loss: 0.014446143992245197\n",
      "Epoch: 27, Loss: 0.012363916262984276\n",
      "Epoch: 28, Loss: 0.010532313957810402\n",
      "Epoch: 29, Loss: 0.010354630649089813\n",
      "Epoch: 30, Loss: 0.01003569457679987\n",
      "Epoch: 31, Loss: 0.009983012452721596\n",
      "Epoch: 32, Loss: 0.009211121127009392\n",
      "Epoch: 33, Loss: 0.007764780428260565\n",
      "Epoch: 34, Loss: 0.006401913706213236\n",
      "Epoch: 35, Loss: 0.0049783517606556416\n",
      "Epoch: 36, Loss: 0.0043942551128566265\n",
      "Epoch: 37, Loss: 0.0039504277519881725\n",
      "Epoch: 38, Loss: 0.003924955613911152\n",
      "Epoch: 39, Loss: 0.003709983779117465\n",
      "Epoch: 40, Loss: 0.0033871668856590986\n",
      "Epoch: 41, Loss: 0.0030861052218824625\n",
      "Epoch: 42, Loss: 0.0027430092450231314\n",
      "Epoch: 43, Loss: 0.00262226234190166\n",
      "Epoch: 44, Loss: 0.0024304771795868874\n",
      "Epoch: 45, Loss: 0.0023969889152795076\n",
      "Epoch: 46, Loss: 0.002183060860261321\n",
      "Epoch: 47, Loss: 0.002039029961451888\n",
      "Epoch: 48, Loss: 0.0017920671962201595\n",
      "Epoch: 49, Loss: 0.001690273405984044\n",
      "Epoch: 50, Loss: 0.0015841979766264558\n",
      "epoch 5 tensor([ 0.6595, -3.7720,  0.0065, -0.2834,  0.8899], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.6157253384590149\n",
      "Epoch: 2, Loss: 0.4644879102706909\n",
      "Epoch: 3, Loss: 0.35426947474479675\n",
      "Epoch: 4, Loss: 0.31816133856773376\n",
      "Epoch: 5, Loss: 0.29818183183670044\n",
      "Epoch: 6, Loss: 0.2728816866874695\n",
      "Epoch: 7, Loss: 0.25246918201446533\n",
      "Epoch: 8, Loss: 0.2271590232849121\n",
      "Epoch: 9, Loss: 0.19872188568115234\n",
      "Epoch: 10, Loss: 0.17534799873828888\n",
      "Epoch: 11, Loss: 0.15939410030841827\n",
      "Epoch: 12, Loss: 0.14803536236286163\n",
      "Epoch: 13, Loss: 0.13710154592990875\n",
      "Epoch: 14, Loss: 0.1287240833044052\n",
      "Epoch: 15, Loss: 0.12357740104198456\n",
      "Epoch: 16, Loss: 0.12146976590156555\n",
      "Epoch: 17, Loss: 0.11535125970840454\n",
      "Epoch: 18, Loss: 0.10825599730014801\n",
      "Epoch: 19, Loss: 0.10283079743385315\n",
      "Epoch: 20, Loss: 0.09754937887191772\n",
      "Epoch: 21, Loss: 0.09211334586143494\n",
      "Epoch: 22, Loss: 0.0880795270204544\n",
      "Epoch: 23, Loss: 0.08437659591436386\n",
      "Epoch: 24, Loss: 0.07926006615161896\n",
      "Epoch: 25, Loss: 0.07358746975660324\n",
      "Epoch: 26, Loss: 0.06896762549877167\n",
      "Epoch: 27, Loss: 0.06688135117292404\n",
      "Epoch: 28, Loss: 0.0648178979754448\n",
      "Epoch: 29, Loss: 0.06045772507786751\n",
      "Epoch: 30, Loss: 0.05614042282104492\n",
      "Epoch: 31, Loss: 0.054431620985269547\n",
      "Epoch: 32, Loss: 0.05321914330124855\n",
      "Epoch: 33, Loss: 0.051611047238111496\n",
      "Epoch: 34, Loss: 0.049226898699998856\n",
      "Epoch: 35, Loss: 0.04707546532154083\n",
      "Epoch: 36, Loss: 0.045423250645399094\n",
      "Epoch: 37, Loss: 0.04434856027364731\n",
      "Epoch: 38, Loss: 0.04348192736506462\n",
      "Epoch: 39, Loss: 0.042135003954172134\n",
      "Epoch: 40, Loss: 0.040264979004859924\n",
      "Epoch: 41, Loss: 0.038596898317337036\n",
      "Epoch: 42, Loss: 0.037673164159059525\n",
      "Epoch: 43, Loss: 0.03641141578555107\n",
      "Epoch: 44, Loss: 0.03519311547279358\n",
      "Epoch: 45, Loss: 0.03407876566052437\n",
      "Epoch: 46, Loss: 0.03317391872406006\n",
      "Epoch: 47, Loss: 0.03223090246319771\n",
      "Epoch: 48, Loss: 0.031128792092204094\n",
      "Epoch: 49, Loss: 0.030276909470558167\n",
      "Epoch: 50, Loss: 0.029491690918803215\n",
      "epoch 5 tensor([ 0.6563, -4.0938, -0.2120, -0.1324,  0.6938], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.27040496468544006\n",
      "Epoch: 2, Loss: 0.24026736617088318\n",
      "Epoch: 3, Loss: 0.21374811232089996\n",
      "Epoch: 4, Loss: 0.19732235372066498\n",
      "Epoch: 5, Loss: 0.1794091761112213\n",
      "Epoch: 6, Loss: 0.157423734664917\n",
      "Epoch: 7, Loss: 0.13776975870132446\n",
      "Epoch: 8, Loss: 0.12535957992076874\n",
      "Epoch: 9, Loss: 0.11443936079740524\n",
      "Epoch: 10, Loss: 0.10011878609657288\n",
      "Epoch: 11, Loss: 0.08486613631248474\n",
      "Epoch: 12, Loss: 0.07089176028966904\n",
      "Epoch: 13, Loss: 0.06404034793376923\n",
      "Epoch: 14, Loss: 0.05780359357595444\n",
      "Epoch: 15, Loss: 0.04840650409460068\n",
      "Epoch: 16, Loss: 0.04099062457680702\n",
      "Epoch: 17, Loss: 0.0384022556245327\n",
      "Epoch: 18, Loss: 0.0364282950758934\n",
      "Epoch: 19, Loss: 0.03271150961518288\n",
      "Epoch: 20, Loss: 0.029332231730222702\n",
      "Epoch: 21, Loss: 0.02806566283106804\n",
      "Epoch: 22, Loss: 0.028094392269849777\n",
      "Epoch: 23, Loss: 0.027491869404911995\n",
      "Epoch: 24, Loss: 0.025735922157764435\n",
      "Epoch: 25, Loss: 0.024466730654239655\n",
      "Epoch: 26, Loss: 0.023903921246528625\n",
      "Epoch: 27, Loss: 0.021884499117732048\n",
      "Epoch: 28, Loss: 0.01879933662712574\n",
      "Epoch: 29, Loss: 0.016406262293457985\n",
      "Epoch: 30, Loss: 0.015219314955174923\n",
      "Epoch: 31, Loss: 0.014361969195306301\n",
      "Epoch: 32, Loss: 0.01363311056047678\n",
      "Epoch: 33, Loss: 0.013018892146646976\n",
      "Epoch: 34, Loss: 0.012059667147696018\n",
      "Epoch: 35, Loss: 0.010561663657426834\n",
      "Epoch: 36, Loss: 0.008909803815186024\n",
      "Epoch: 37, Loss: 0.007775057572871447\n",
      "Epoch: 38, Loss: 0.0072024110704660416\n",
      "Epoch: 39, Loss: 0.006578758824616671\n",
      "Epoch: 40, Loss: 0.005784962326288223\n",
      "Epoch: 41, Loss: 0.005111821927130222\n",
      "Epoch: 42, Loss: 0.004473874345421791\n",
      "Epoch: 43, Loss: 0.0038579183164983988\n",
      "Epoch: 44, Loss: 0.0035411708522588015\n",
      "Epoch: 45, Loss: 0.003438138635829091\n",
      "Epoch: 46, Loss: 0.003272482194006443\n",
      "Epoch: 47, Loss: 0.0030273094307631254\n",
      "Epoch: 48, Loss: 0.0027699870988726616\n",
      "Epoch: 49, Loss: 0.002548720221966505\n",
      "Epoch: 50, Loss: 0.002321977401152253\n",
      "epoch 5 tensor([ 0.6704, -3.8389, -0.2167, -0.3768,  0.7084], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.2088489681482315\n",
      "Epoch: 2, Loss: 0.18561363220214844\n",
      "Epoch: 3, Loss: 0.16033662855625153\n",
      "Epoch: 4, Loss: 0.13682672381401062\n",
      "Epoch: 5, Loss: 0.11450373381376266\n",
      "Epoch: 6, Loss: 0.0866614282131195\n",
      "Epoch: 7, Loss: 0.06831035017967224\n",
      "Epoch: 8, Loss: 0.05767432227730751\n",
      "Epoch: 9, Loss: 0.048324573785066605\n",
      "Epoch: 10, Loss: 0.03706412389874458\n",
      "Epoch: 11, Loss: 0.028815124183893204\n",
      "Epoch: 12, Loss: 0.02966250665485859\n",
      "Epoch: 13, Loss: 0.02833632193505764\n",
      "Epoch: 14, Loss: 0.02702460065484047\n",
      "Epoch: 15, Loss: 0.0234509464353323\n",
      "Epoch: 16, Loss: 0.020890993997454643\n",
      "Epoch: 17, Loss: 0.021126434206962585\n",
      "Epoch: 18, Loss: 0.01951582171022892\n",
      "Epoch: 19, Loss: 0.01835797354578972\n",
      "Epoch: 20, Loss: 0.016185812652111053\n",
      "Epoch: 21, Loss: 0.014866950921714306\n",
      "Epoch: 22, Loss: 0.014309663325548172\n",
      "Epoch: 23, Loss: 0.012490153312683105\n",
      "Epoch: 24, Loss: 0.011488128453493118\n",
      "Epoch: 25, Loss: 0.010260061360895634\n",
      "Epoch: 26, Loss: 0.009824869222939014\n",
      "Epoch: 27, Loss: 0.009193846955895424\n",
      "Epoch: 28, Loss: 0.00785070937126875\n",
      "Epoch: 29, Loss: 0.007037662435323\n",
      "Epoch: 30, Loss: 0.006199981551617384\n",
      "Epoch: 31, Loss: 0.005922149401158094\n",
      "Epoch: 32, Loss: 0.005260024219751358\n",
      "Epoch: 33, Loss: 0.004855632316321135\n",
      "Epoch: 34, Loss: 0.004409905523061752\n",
      "Epoch: 35, Loss: 0.004020089283585548\n",
      "Epoch: 36, Loss: 0.0037952791899442673\n",
      "Epoch: 37, Loss: 0.003397206077352166\n",
      "Epoch: 38, Loss: 0.0031502889469265938\n",
      "Epoch: 39, Loss: 0.002735060639679432\n",
      "Epoch: 40, Loss: 0.0025248643942177296\n",
      "Epoch: 41, Loss: 0.002179617527872324\n",
      "Epoch: 42, Loss: 0.0020088839810341597\n",
      "Epoch: 43, Loss: 0.0018871111096814275\n",
      "Epoch: 44, Loss: 0.0017964552389457822\n",
      "Epoch: 45, Loss: 0.0017078041564673185\n",
      "Epoch: 46, Loss: 0.001595720648765564\n",
      "Epoch: 47, Loss: 0.0015142952324822545\n",
      "Epoch: 48, Loss: 0.0013786181807518005\n",
      "Epoch: 49, Loss: 0.0013082377845421433\n",
      "Epoch: 50, Loss: 0.0011744755320250988\n",
      "epoch 5 tensor([ 0.7937, -3.7346, -0.2020, -0.1907,  0.7851], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.21657481789588928\n",
      "Epoch: 2, Loss: 0.1813458949327469\n",
      "Epoch: 3, Loss: 0.14747506380081177\n",
      "Epoch: 4, Loss: 0.12927401065826416\n",
      "Epoch: 5, Loss: 0.11964938789606094\n",
      "Epoch: 6, Loss: 0.11206281930208206\n",
      "Epoch: 7, Loss: 0.10080048441886902\n",
      "Epoch: 8, Loss: 0.08667231351137161\n",
      "Epoch: 9, Loss: 0.07574643939733505\n",
      "Epoch: 10, Loss: 0.07148518413305283\n",
      "Epoch: 11, Loss: 0.07108120620250702\n",
      "Epoch: 12, Loss: 0.06881991028785706\n",
      "Epoch: 13, Loss: 0.063658207654953\n",
      "Epoch: 14, Loss: 0.057583726942539215\n",
      "Epoch: 15, Loss: 0.05416664108633995\n",
      "Epoch: 16, Loss: 0.05336017534136772\n",
      "Epoch: 17, Loss: 0.052373990416526794\n",
      "Epoch: 18, Loss: 0.0490199439227581\n",
      "Epoch: 19, Loss: 0.04492330551147461\n",
      "Epoch: 20, Loss: 0.04184778034687042\n",
      "Epoch: 21, Loss: 0.039880212396383286\n",
      "Epoch: 22, Loss: 0.03911565616726875\n",
      "Epoch: 23, Loss: 0.037256620824337006\n",
      "Epoch: 24, Loss: 0.03529905155301094\n",
      "Epoch: 25, Loss: 0.033936258405447006\n",
      "Epoch: 26, Loss: 0.032959479838609695\n",
      "Epoch: 27, Loss: 0.03208266571164131\n",
      "Epoch: 28, Loss: 0.030425000935792923\n",
      "Epoch: 29, Loss: 0.028168978169560432\n",
      "Epoch: 30, Loss: 0.026532167568802834\n",
      "Epoch: 31, Loss: 0.025729220360517502\n",
      "Epoch: 32, Loss: 0.024796262383461\n",
      "Epoch: 33, Loss: 0.023441938683390617\n",
      "Epoch: 34, Loss: 0.022264856845140457\n",
      "Epoch: 35, Loss: 0.020948166027665138\n",
      "Epoch: 36, Loss: 0.02012353204190731\n",
      "Epoch: 37, Loss: 0.01970888301730156\n",
      "Epoch: 38, Loss: 0.018978407606482506\n",
      "Epoch: 39, Loss: 0.01804034784436226\n",
      "Epoch: 40, Loss: 0.017454754561185837\n",
      "Epoch: 41, Loss: 0.01694069802761078\n",
      "Epoch: 42, Loss: 0.01617506891489029\n",
      "Epoch: 43, Loss: 0.015260479412972927\n",
      "Epoch: 44, Loss: 0.014634289778769016\n",
      "Epoch: 45, Loss: 0.014008400030434132\n",
      "Epoch: 46, Loss: 0.013250989839434624\n",
      "Epoch: 47, Loss: 0.012601585127413273\n",
      "Epoch: 48, Loss: 0.012272391468286514\n",
      "Epoch: 49, Loss: 0.011790755204856396\n",
      "Epoch: 50, Loss: 0.011359277181327343\n",
      "epoch 5 tensor([ 0.6609, -3.7387, -0.2513,  0.3832,  0.6099], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.08669963479042053\n",
      "Epoch: 2, Loss: 0.07816170156002045\n",
      "Epoch: 3, Loss: 0.06788427382707596\n",
      "Epoch: 4, Loss: 0.05819481238722801\n",
      "Epoch: 5, Loss: 0.049909885972738266\n",
      "Epoch: 6, Loss: 0.04314801096916199\n",
      "Epoch: 7, Loss: 0.0386502780020237\n",
      "Epoch: 8, Loss: 0.03549497202038765\n",
      "Epoch: 9, Loss: 0.03281412273645401\n",
      "Epoch: 10, Loss: 0.030230794101953506\n",
      "Epoch: 11, Loss: 0.028510188683867455\n",
      "Epoch: 12, Loss: 0.027225619181990623\n",
      "Epoch: 13, Loss: 0.02564333938062191\n",
      "Epoch: 14, Loss: 0.023919496685266495\n",
      "Epoch: 15, Loss: 0.021819477900862694\n",
      "Epoch: 16, Loss: 0.019656987860798836\n",
      "Epoch: 17, Loss: 0.018386833369731903\n",
      "Epoch: 18, Loss: 0.0167564507573843\n",
      "Epoch: 19, Loss: 0.0150303328409791\n",
      "Epoch: 20, Loss: 0.013759392313659191\n",
      "Epoch: 21, Loss: 0.012796243652701378\n",
      "Epoch: 22, Loss: 0.012355268932878971\n",
      "Epoch: 23, Loss: 0.011749936267733574\n",
      "Epoch: 24, Loss: 0.01106242649257183\n",
      "Epoch: 25, Loss: 0.010114802978932858\n",
      "Epoch: 26, Loss: 0.00950592290610075\n",
      "Epoch: 27, Loss: 0.00870757456868887\n",
      "Epoch: 28, Loss: 0.008078514598309994\n",
      "Epoch: 29, Loss: 0.007461933419108391\n",
      "Epoch: 30, Loss: 0.00722196139395237\n",
      "Epoch: 31, Loss: 0.006852345075458288\n",
      "Epoch: 32, Loss: 0.006410213187336922\n",
      "Epoch: 33, Loss: 0.005994727835059166\n",
      "Epoch: 34, Loss: 0.005457113962620497\n",
      "Epoch: 35, Loss: 0.004904572386294603\n",
      "Epoch: 36, Loss: 0.004473832435905933\n",
      "Epoch: 37, Loss: 0.004041403532028198\n",
      "Epoch: 38, Loss: 0.003638357622548938\n",
      "Epoch: 39, Loss: 0.0033442049752920866\n",
      "Epoch: 40, Loss: 0.003071799175813794\n",
      "Epoch: 41, Loss: 0.002869449555873871\n",
      "Epoch: 42, Loss: 0.0026477756910026073\n",
      "Epoch: 43, Loss: 0.0023655809927731752\n",
      "Epoch: 44, Loss: 0.002167842350900173\n",
      "Epoch: 45, Loss: 0.0018773244228214025\n",
      "Epoch: 46, Loss: 0.001655196538195014\n",
      "Epoch: 47, Loss: 0.0014440460363402963\n",
      "Epoch: 48, Loss: 0.0012755461502820253\n",
      "Epoch: 49, Loss: 0.001162393600679934\n",
      "Epoch: 50, Loss: 0.0010779198491945863\n",
      "epoch 5 tensor([ 0.6844, -3.8379, -0.2340, -0.2696,  0.6403], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.17374683916568756\n",
      "Epoch: 2, Loss: 0.12595891952514648\n",
      "Epoch: 3, Loss: 0.09398430585861206\n",
      "Epoch: 4, Loss: 0.09856824576854706\n",
      "Epoch: 5, Loss: 0.093071848154068\n",
      "Epoch: 6, Loss: 0.07286785542964935\n",
      "Epoch: 7, Loss: 0.05960719287395477\n",
      "Epoch: 8, Loss: 0.05769290030002594\n",
      "Epoch: 9, Loss: 0.05469607189297676\n",
      "Epoch: 10, Loss: 0.04746105149388313\n",
      "Epoch: 11, Loss: 0.04111887142062187\n",
      "Epoch: 12, Loss: 0.03656357154250145\n",
      "Epoch: 13, Loss: 0.0346062071621418\n",
      "Epoch: 14, Loss: 0.034075528383255005\n",
      "Epoch: 15, Loss: 0.031022019684314728\n",
      "Epoch: 16, Loss: 0.025183148682117462\n",
      "Epoch: 17, Loss: 0.020836370065808296\n",
      "Epoch: 18, Loss: 0.021864712238311768\n",
      "Epoch: 19, Loss: 0.024065658450126648\n",
      "Epoch: 20, Loss: 0.022593893110752106\n",
      "Epoch: 21, Loss: 0.019212041050195694\n",
      "Epoch: 22, Loss: 0.01709049753844738\n",
      "Epoch: 23, Loss: 0.01622016355395317\n",
      "Epoch: 24, Loss: 0.015254727564752102\n",
      "Epoch: 25, Loss: 0.013862721621990204\n",
      "Epoch: 26, Loss: 0.012380131520330906\n",
      "Epoch: 27, Loss: 0.011249708011746407\n",
      "Epoch: 28, Loss: 0.010674884542822838\n",
      "Epoch: 29, Loss: 0.010167964734137058\n",
      "Epoch: 30, Loss: 0.00915544480085373\n",
      "Epoch: 31, Loss: 0.007874668575823307\n",
      "Epoch: 32, Loss: 0.00736080389469862\n",
      "Epoch: 33, Loss: 0.007577253971248865\n",
      "Epoch: 34, Loss: 0.007379172369837761\n",
      "Epoch: 35, Loss: 0.00659959064796567\n",
      "Epoch: 36, Loss: 0.005923171062022448\n",
      "Epoch: 37, Loss: 0.005705596879124641\n",
      "Epoch: 38, Loss: 0.005562731064856052\n",
      "Epoch: 39, Loss: 0.005282497499138117\n",
      "Epoch: 40, Loss: 0.004889482632279396\n",
      "Epoch: 41, Loss: 0.004452573601156473\n",
      "Epoch: 42, Loss: 0.004099022597074509\n",
      "Epoch: 43, Loss: 0.0037937152665108442\n",
      "Epoch: 44, Loss: 0.0033949974458664656\n",
      "Epoch: 45, Loss: 0.0029922255780547857\n",
      "Epoch: 46, Loss: 0.002790062688291073\n",
      "Epoch: 47, Loss: 0.002698182128369808\n",
      "Epoch: 48, Loss: 0.00246080057695508\n",
      "Epoch: 49, Loss: 0.0021600506734102964\n",
      "Epoch: 50, Loss: 0.0019793082028627396\n",
      "epoch 5 tensor([ 0.6826, -3.8358, -0.7002, -0.2183,  0.7186], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.21042871475219727\n",
      "Epoch: 2, Loss: 0.16122093796730042\n",
      "Epoch: 3, Loss: 0.12843447923660278\n",
      "Epoch: 4, Loss: 0.11131872981786728\n",
      "Epoch: 5, Loss: 0.09597283601760864\n",
      "Epoch: 6, Loss: 0.08465201407670975\n",
      "Epoch: 7, Loss: 0.07606270909309387\n",
      "Epoch: 8, Loss: 0.06901808828115463\n",
      "Epoch: 9, Loss: 0.06003538519144058\n",
      "Epoch: 10, Loss: 0.0536709800362587\n",
      "Epoch: 11, Loss: 0.050394292920827866\n",
      "Epoch: 12, Loss: 0.047185443341732025\n",
      "Epoch: 13, Loss: 0.04118717834353447\n",
      "Epoch: 14, Loss: 0.03768302500247955\n",
      "Epoch: 15, Loss: 0.036769717931747437\n",
      "Epoch: 16, Loss: 0.03590938821434975\n",
      "Epoch: 17, Loss: 0.032509464770555496\n",
      "Epoch: 18, Loss: 0.028623191639780998\n",
      "Epoch: 19, Loss: 0.025784606114029884\n",
      "Epoch: 20, Loss: 0.024279754608869553\n",
      "Epoch: 21, Loss: 0.022919226437807083\n",
      "Epoch: 22, Loss: 0.021089982241392136\n",
      "Epoch: 23, Loss: 0.01924998313188553\n",
      "Epoch: 24, Loss: 0.017958998680114746\n",
      "Epoch: 25, Loss: 0.017598344013094902\n",
      "Epoch: 26, Loss: 0.017042960971593857\n",
      "Epoch: 27, Loss: 0.01615048199892044\n",
      "Epoch: 28, Loss: 0.01550920121371746\n",
      "Epoch: 29, Loss: 0.014671245589852333\n",
      "Epoch: 30, Loss: 0.013281418941915035\n",
      "Epoch: 31, Loss: 0.012390908785164356\n",
      "Epoch: 32, Loss: 0.012183504179120064\n",
      "Epoch: 33, Loss: 0.01151792611926794\n",
      "Epoch: 34, Loss: 0.010258117690682411\n",
      "Epoch: 35, Loss: 0.009456445463001728\n",
      "Epoch: 36, Loss: 0.00918163824826479\n",
      "Epoch: 37, Loss: 0.008637667633593082\n",
      "Epoch: 38, Loss: 0.007923256605863571\n",
      "Epoch: 39, Loss: 0.007445165421813726\n",
      "Epoch: 40, Loss: 0.006896785460412502\n",
      "Epoch: 41, Loss: 0.006465313024818897\n",
      "Epoch: 42, Loss: 0.006228511221706867\n",
      "Epoch: 43, Loss: 0.006001289002597332\n",
      "Epoch: 44, Loss: 0.0056803906336426735\n",
      "Epoch: 45, Loss: 0.005279054865241051\n",
      "Epoch: 46, Loss: 0.0049551730044186115\n",
      "Epoch: 47, Loss: 0.004688164219260216\n",
      "Epoch: 48, Loss: 0.0042494009248912334\n",
      "Epoch: 49, Loss: 0.003676082007586956\n",
      "Epoch: 50, Loss: 0.0032756912987679243\n",
      "________________________________________\n",
      "epoch 6 tensor([ 0.5488, -3.9753, -0.0145, -0.2731,  0.7395], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.5489416718482971\n",
      "Epoch: 2, Loss: 0.473567396402359\n",
      "Epoch: 3, Loss: 0.40592941641807556\n",
      "Epoch: 4, Loss: 0.35285845398902893\n",
      "Epoch: 5, Loss: 0.30282145738601685\n",
      "Epoch: 6, Loss: 0.25692692399024963\n",
      "Epoch: 7, Loss: 0.22203002870082855\n",
      "Epoch: 8, Loss: 0.19011276960372925\n",
      "Epoch: 9, Loss: 0.1601422280073166\n",
      "Epoch: 10, Loss: 0.13611379265785217\n",
      "Epoch: 11, Loss: 0.11758248507976532\n",
      "Epoch: 12, Loss: 0.10108999907970428\n",
      "Epoch: 13, Loss: 0.08840151876211166\n",
      "Epoch: 14, Loss: 0.0827561467885971\n",
      "Epoch: 15, Loss: 0.07983438670635223\n",
      "Epoch: 16, Loss: 0.07516882568597794\n",
      "Epoch: 17, Loss: 0.06989576667547226\n",
      "Epoch: 18, Loss: 0.06598756462335587\n",
      "Epoch: 19, Loss: 0.06372852623462677\n",
      "Epoch: 20, Loss: 0.058253947645425797\n",
      "Epoch: 21, Loss: 0.05336689576506615\n",
      "Epoch: 22, Loss: 0.04941673204302788\n",
      "Epoch: 23, Loss: 0.04523136466741562\n",
      "Epoch: 24, Loss: 0.04145606607198715\n",
      "Epoch: 25, Loss: 0.03790386766195297\n",
      "Epoch: 26, Loss: 0.034932561218738556\n",
      "Epoch: 27, Loss: 0.03199654445052147\n",
      "Epoch: 28, Loss: 0.029371459037065506\n",
      "Epoch: 29, Loss: 0.02813061885535717\n",
      "Epoch: 30, Loss: 0.026949714869260788\n",
      "Epoch: 31, Loss: 0.0251141507178545\n",
      "Epoch: 32, Loss: 0.023704824969172478\n",
      "Epoch: 33, Loss: 0.023235799744725227\n",
      "Epoch: 34, Loss: 0.022205691784620285\n",
      "Epoch: 35, Loss: 0.02084060199558735\n",
      "Epoch: 36, Loss: 0.019736764952540398\n",
      "Epoch: 37, Loss: 0.018520982936024666\n",
      "Epoch: 38, Loss: 0.017912257462739944\n",
      "Epoch: 39, Loss: 0.016843393445014954\n",
      "Epoch: 40, Loss: 0.015557513572275639\n",
      "Epoch: 41, Loss: 0.014166463166475296\n",
      "Epoch: 42, Loss: 0.013477273285388947\n",
      "Epoch: 43, Loss: 0.012837821617722511\n",
      "Epoch: 44, Loss: 0.011814837343990803\n",
      "Epoch: 45, Loss: 0.01115209236741066\n",
      "Epoch: 46, Loss: 0.010505766607820988\n",
      "Epoch: 47, Loss: 0.009637073613703251\n",
      "Epoch: 48, Loss: 0.009090429171919823\n",
      "Epoch: 49, Loss: 0.008521553128957748\n",
      "Epoch: 50, Loss: 0.00785652082413435\n",
      "epoch 6 tensor([ 0.5780, -3.4091, -0.4904,  0.1825,  0.5670], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.786628007888794\n",
      "Epoch: 2, Loss: 0.6859498023986816\n",
      "Epoch: 3, Loss: 0.5708066821098328\n",
      "Epoch: 4, Loss: 0.4778239130973816\n",
      "Epoch: 5, Loss: 0.41532596945762634\n",
      "Epoch: 6, Loss: 0.3689626455307007\n",
      "Epoch: 7, Loss: 0.33428287506103516\n",
      "Epoch: 8, Loss: 0.308384507894516\n",
      "Epoch: 9, Loss: 0.2868824005126953\n",
      "Epoch: 10, Loss: 0.2680688202381134\n",
      "Epoch: 11, Loss: 0.24493654072284698\n",
      "Epoch: 12, Loss: 0.21579617261886597\n",
      "Epoch: 13, Loss: 0.1871882975101471\n",
      "Epoch: 14, Loss: 0.1624029278755188\n",
      "Epoch: 15, Loss: 0.14470061659812927\n",
      "Epoch: 16, Loss: 0.13395412266254425\n",
      "Epoch: 17, Loss: 0.12813138961791992\n",
      "Epoch: 18, Loss: 0.12214381247758865\n",
      "Epoch: 19, Loss: 0.11676612496376038\n",
      "Epoch: 20, Loss: 0.1087532490491867\n",
      "Epoch: 21, Loss: 0.10003617405891418\n",
      "Epoch: 22, Loss: 0.09118968993425369\n",
      "Epoch: 23, Loss: 0.0863807275891304\n",
      "Epoch: 24, Loss: 0.07740813493728638\n",
      "Epoch: 25, Loss: 0.07035005837678909\n",
      "Epoch: 26, Loss: 0.06259791553020477\n",
      "Epoch: 27, Loss: 0.05591927096247673\n",
      "Epoch: 28, Loss: 0.0514056570827961\n",
      "Epoch: 29, Loss: 0.04645774886012077\n",
      "Epoch: 30, Loss: 0.0439106747508049\n",
      "Epoch: 31, Loss: 0.039782535284757614\n",
      "Epoch: 32, Loss: 0.03666060045361519\n",
      "Epoch: 33, Loss: 0.033915925770998\n",
      "Epoch: 34, Loss: 0.029658138751983643\n",
      "Epoch: 35, Loss: 0.026557737961411476\n",
      "Epoch: 36, Loss: 0.02297402173280716\n",
      "Epoch: 37, Loss: 0.020306413993239403\n",
      "Epoch: 38, Loss: 0.018587131053209305\n",
      "Epoch: 39, Loss: 0.016795478761196136\n",
      "Epoch: 40, Loss: 0.01603824459016323\n",
      "Epoch: 41, Loss: 0.014901900663971901\n",
      "Epoch: 42, Loss: 0.014153476804494858\n",
      "Epoch: 43, Loss: 0.01343790628015995\n",
      "Epoch: 44, Loss: 0.012053873389959335\n",
      "Epoch: 45, Loss: 0.011172772385179996\n",
      "Epoch: 46, Loss: 0.010424833744764328\n",
      "Epoch: 47, Loss: 0.009785868227481842\n",
      "Epoch: 48, Loss: 0.009164690971374512\n",
      "Epoch: 49, Loss: 0.008604736067354679\n",
      "Epoch: 50, Loss: 0.008363954722881317\n",
      "epoch 6 tensor([ 0.6244, -3.9146, -1.7858,  0.0626,  0.6198], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.15655073523521423\n",
      "Epoch: 2, Loss: 0.13795042037963867\n",
      "Epoch: 3, Loss: 0.12635177373886108\n",
      "Epoch: 4, Loss: 0.10723161697387695\n",
      "Epoch: 5, Loss: 0.09114717692136765\n",
      "Epoch: 6, Loss: 0.08149726688861847\n",
      "Epoch: 7, Loss: 0.06832179427146912\n",
      "Epoch: 8, Loss: 0.0599498376250267\n",
      "Epoch: 9, Loss: 0.05427049100399017\n",
      "Epoch: 10, Loss: 0.046627432107925415\n",
      "Epoch: 11, Loss: 0.04275839775800705\n",
      "Epoch: 12, Loss: 0.04075978323817253\n",
      "Epoch: 13, Loss: 0.037201397120952606\n",
      "Epoch: 14, Loss: 0.035967741161584854\n",
      "Epoch: 15, Loss: 0.034894708544015884\n",
      "Epoch: 16, Loss: 0.03143372759222984\n",
      "Epoch: 17, Loss: 0.028998136520385742\n",
      "Epoch: 18, Loss: 0.026378393173217773\n",
      "Epoch: 19, Loss: 0.02319285459816456\n",
      "Epoch: 20, Loss: 0.021774377673864365\n",
      "Epoch: 21, Loss: 0.020090682432055473\n",
      "Epoch: 22, Loss: 0.01817827671766281\n",
      "Epoch: 23, Loss: 0.017178522422909737\n",
      "Epoch: 24, Loss: 0.01553212758153677\n",
      "Epoch: 25, Loss: 0.014329702593386173\n",
      "Epoch: 26, Loss: 0.013698849827051163\n",
      "Epoch: 27, Loss: 0.012091134674847126\n",
      "Epoch: 28, Loss: 0.010684690438210964\n",
      "Epoch: 29, Loss: 0.009353342466056347\n",
      "Epoch: 30, Loss: 0.007731348741799593\n",
      "Epoch: 31, Loss: 0.0067939371801912785\n",
      "Epoch: 32, Loss: 0.005858191754668951\n",
      "Epoch: 33, Loss: 0.004942105617374182\n",
      "Epoch: 34, Loss: 0.004484897945076227\n",
      "Epoch: 35, Loss: 0.003911139443516731\n",
      "Epoch: 36, Loss: 0.0034967055544257164\n",
      "Epoch: 37, Loss: 0.003026975318789482\n",
      "Epoch: 38, Loss: 0.002399244112893939\n",
      "Epoch: 39, Loss: 0.002082366496324539\n",
      "Epoch: 40, Loss: 0.001765177003107965\n",
      "Epoch: 41, Loss: 0.0015623554354533553\n",
      "Epoch: 42, Loss: 0.0015177738387137651\n",
      "Epoch: 43, Loss: 0.0011736464221030474\n",
      "Epoch: 44, Loss: 0.0009563607163727283\n",
      "Epoch: 45, Loss: 0.0008568218327127397\n",
      "Epoch: 46, Loss: 0.0008390005677938461\n",
      "Epoch: 47, Loss: 0.0007808242226019502\n",
      "Epoch: 48, Loss: 0.0006320535903796554\n",
      "Epoch: 49, Loss: 0.0005857360665686429\n",
      "Epoch: 50, Loss: 0.0005185368936508894\n",
      "epoch 6 tensor([ 0.5791, -3.7415, -0.9308, -0.4046,  0.6061], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.18480008840560913\n",
      "Epoch: 2, Loss: 0.1603558361530304\n",
      "Epoch: 3, Loss: 0.135944664478302\n",
      "Epoch: 4, Loss: 0.11976714432239532\n",
      "Epoch: 5, Loss: 0.10885827243328094\n",
      "Epoch: 6, Loss: 0.09833040088415146\n",
      "Epoch: 7, Loss: 0.08825135976076126\n",
      "Epoch: 8, Loss: 0.07993214577436447\n",
      "Epoch: 9, Loss: 0.07392580062150955\n",
      "Epoch: 10, Loss: 0.06838879734277725\n",
      "Epoch: 11, Loss: 0.061303313821554184\n",
      "Epoch: 12, Loss: 0.054924238473176956\n",
      "Epoch: 13, Loss: 0.05133294686675072\n",
      "Epoch: 14, Loss: 0.04840891435742378\n",
      "Epoch: 15, Loss: 0.04345191642642021\n",
      "Epoch: 16, Loss: 0.038281358778476715\n",
      "Epoch: 17, Loss: 0.03403346613049507\n",
      "Epoch: 18, Loss: 0.030462663620710373\n",
      "Epoch: 19, Loss: 0.02722213976085186\n",
      "Epoch: 20, Loss: 0.024471599608659744\n",
      "Epoch: 21, Loss: 0.02137923799455166\n",
      "Epoch: 22, Loss: 0.018351513892412186\n",
      "Epoch: 23, Loss: 0.016507228836417198\n",
      "Epoch: 24, Loss: 0.015275906771421432\n",
      "Epoch: 25, Loss: 0.014140268787741661\n",
      "Epoch: 26, Loss: 0.012944705784320831\n",
      "Epoch: 27, Loss: 0.011390970088541508\n",
      "Epoch: 28, Loss: 0.0097501240670681\n",
      "Epoch: 29, Loss: 0.008664539083838463\n",
      "Epoch: 30, Loss: 0.007871182635426521\n",
      "Epoch: 31, Loss: 0.006957468576729298\n",
      "Epoch: 32, Loss: 0.006327759008854628\n",
      "Epoch: 33, Loss: 0.005875181406736374\n",
      "Epoch: 34, Loss: 0.005335572175681591\n",
      "Epoch: 35, Loss: 0.004767285659909248\n",
      "Epoch: 36, Loss: 0.004370338749140501\n",
      "Epoch: 37, Loss: 0.00419064424932003\n",
      "Epoch: 38, Loss: 0.004158233292400837\n",
      "Epoch: 39, Loss: 0.0038875103928148746\n",
      "Epoch: 40, Loss: 0.003334490116685629\n",
      "Epoch: 41, Loss: 0.0030143163166940212\n",
      "Epoch: 42, Loss: 0.002943292260169983\n",
      "Epoch: 43, Loss: 0.002806349890306592\n",
      "Epoch: 44, Loss: 0.0026654296088963747\n",
      "Epoch: 45, Loss: 0.002587643451988697\n",
      "Epoch: 46, Loss: 0.00244939629919827\n",
      "Epoch: 47, Loss: 0.002287142677232623\n",
      "Epoch: 48, Loss: 0.0021205872762948275\n",
      "Epoch: 49, Loss: 0.0019642666447907686\n",
      "Epoch: 50, Loss: 0.0018810927867889404\n",
      "epoch 6 tensor([ 0.8646, -3.4306, -0.4328, -0.2054,  0.5844], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.05357370525598526\n",
      "Epoch: 2, Loss: 0.03219925984740257\n",
      "Epoch: 3, Loss: 0.028526699170470238\n",
      "Epoch: 4, Loss: 0.030443809926509857\n",
      "Epoch: 5, Loss: 0.02155839465558529\n",
      "Epoch: 6, Loss: 0.012040248140692711\n",
      "Epoch: 7, Loss: 0.014592365361750126\n",
      "Epoch: 8, Loss: 0.019202999770641327\n",
      "Epoch: 9, Loss: 0.012441545724868774\n",
      "Epoch: 10, Loss: 0.006846785545349121\n",
      "Epoch: 11, Loss: 0.00796966627240181\n",
      "Epoch: 12, Loss: 0.01046824548393488\n",
      "Epoch: 13, Loss: 0.007683785632252693\n",
      "Epoch: 14, Loss: 0.00502435490489006\n",
      "Epoch: 15, Loss: 0.006563874892890453\n",
      "Epoch: 16, Loss: 0.008125761523842812\n",
      "Epoch: 17, Loss: 0.005736531224101782\n",
      "Epoch: 18, Loss: 0.003032124601304531\n",
      "Epoch: 19, Loss: 0.003083182964473963\n",
      "Epoch: 20, Loss: 0.004613186698406935\n",
      "Epoch: 21, Loss: 0.004073490388691425\n",
      "Epoch: 22, Loss: 0.002840442582964897\n",
      "Epoch: 23, Loss: 0.002507816767320037\n",
      "Epoch: 24, Loss: 0.002914245706051588\n",
      "Epoch: 25, Loss: 0.0022534888703376055\n",
      "Epoch: 26, Loss: 0.0011387120466679335\n",
      "Epoch: 27, Loss: 0.001054115709848702\n",
      "Epoch: 28, Loss: 0.0016893616411834955\n",
      "Epoch: 29, Loss: 0.0016987998969852924\n",
      "Epoch: 30, Loss: 0.0011226892238482833\n",
      "Epoch: 31, Loss: 0.0009095158311538398\n",
      "Epoch: 32, Loss: 0.0010891722049564123\n",
      "Epoch: 33, Loss: 0.0008875658386386931\n",
      "Epoch: 34, Loss: 0.0006299997330643237\n",
      "Epoch: 35, Loss: 0.0007114349864423275\n",
      "Epoch: 36, Loss: 0.0009223422966897488\n",
      "Epoch: 37, Loss: 0.0006789171602576971\n",
      "Epoch: 38, Loss: 0.0003971713304053992\n",
      "Epoch: 39, Loss: 0.00044713151874020696\n",
      "Epoch: 40, Loss: 0.0005345268291421235\n",
      "Epoch: 41, Loss: 0.0004371589748188853\n",
      "Epoch: 42, Loss: 0.0003284886770416051\n",
      "Epoch: 43, Loss: 0.0004160475800745189\n",
      "Epoch: 44, Loss: 0.00039800029480829835\n",
      "Epoch: 45, Loss: 0.00022223971609491855\n",
      "Epoch: 46, Loss: 0.00015388459723908454\n",
      "Epoch: 47, Loss: 0.000253543839789927\n",
      "Epoch: 48, Loss: 0.00024979253066703677\n",
      "Epoch: 49, Loss: 0.0001681692956481129\n",
      "Epoch: 50, Loss: 0.00016802111349534243\n",
      "epoch 6 tensor([ 0.5824, -3.1592, -0.4460, -0.4099,  0.5805], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.2055487036705017\n",
      "Epoch: 2, Loss: 0.17060090601444244\n",
      "Epoch: 3, Loss: 0.13798625767230988\n",
      "Epoch: 4, Loss: 0.10714057087898254\n",
      "Epoch: 5, Loss: 0.07924225926399231\n",
      "Epoch: 6, Loss: 0.059813257306814194\n",
      "Epoch: 7, Loss: 0.04994632303714752\n",
      "Epoch: 8, Loss: 0.043653927743434906\n",
      "Epoch: 9, Loss: 0.03808620199561119\n",
      "Epoch: 10, Loss: 0.03694108873605728\n",
      "Epoch: 11, Loss: 0.038595639169216156\n",
      "Epoch: 12, Loss: 0.036332305520772934\n",
      "Epoch: 13, Loss: 0.0355619378387928\n",
      "Epoch: 14, Loss: 0.03495689481496811\n",
      "Epoch: 15, Loss: 0.032015420496463776\n",
      "Epoch: 16, Loss: 0.028679518029093742\n",
      "Epoch: 17, Loss: 0.02596719190478325\n",
      "Epoch: 18, Loss: 0.02372114732861519\n",
      "Epoch: 19, Loss: 0.02132067270576954\n",
      "Epoch: 20, Loss: 0.019072802737355232\n",
      "Epoch: 21, Loss: 0.01816089265048504\n",
      "Epoch: 22, Loss: 0.017286326736211777\n",
      "Epoch: 23, Loss: 0.015414850786328316\n",
      "Epoch: 24, Loss: 0.013903315179049969\n",
      "Epoch: 25, Loss: 0.012654346413910389\n",
      "Epoch: 26, Loss: 0.011255418881773949\n",
      "Epoch: 27, Loss: 0.010356055572628975\n",
      "Epoch: 28, Loss: 0.009689387865364552\n",
      "Epoch: 29, Loss: 0.008772635832428932\n",
      "Epoch: 30, Loss: 0.007903563790023327\n",
      "Epoch: 31, Loss: 0.007318468298763037\n",
      "Epoch: 32, Loss: 0.006924407556653023\n",
      "Epoch: 33, Loss: 0.006525436416268349\n",
      "Epoch: 34, Loss: 0.006134352181106806\n",
      "Epoch: 35, Loss: 0.006044928450137377\n",
      "Epoch: 36, Loss: 0.005805515218526125\n",
      "Epoch: 37, Loss: 0.005374636501073837\n",
      "Epoch: 38, Loss: 0.005079552065581083\n",
      "Epoch: 39, Loss: 0.004613169003278017\n",
      "Epoch: 40, Loss: 0.004085638094693422\n",
      "Epoch: 41, Loss: 0.003649876918643713\n",
      "Epoch: 42, Loss: 0.003280910197645426\n",
      "Epoch: 43, Loss: 0.003019350115209818\n",
      "Epoch: 44, Loss: 0.002806557808071375\n",
      "Epoch: 45, Loss: 0.0026696710847318172\n",
      "Epoch: 46, Loss: 0.002487500198185444\n",
      "Epoch: 47, Loss: 0.0023177568800747395\n",
      "Epoch: 48, Loss: 0.002244219183921814\n",
      "Epoch: 49, Loss: 0.0021119697485119104\n",
      "Epoch: 50, Loss: 0.0019724504090845585\n",
      "epoch 6 tensor([ 0.6845, -3.2426, -0.4138, -0.3517,  0.5540], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.25548478960990906\n",
      "Epoch: 2, Loss: 0.18918700516223907\n",
      "Epoch: 3, Loss: 0.1348845511674881\n",
      "Epoch: 4, Loss: 0.10535550862550735\n",
      "Epoch: 5, Loss: 0.09384485334157944\n",
      "Epoch: 6, Loss: 0.09381910413503647\n",
      "Epoch: 7, Loss: 0.09781946986913681\n",
      "Epoch: 8, Loss: 0.08757352828979492\n",
      "Epoch: 9, Loss: 0.06969747692346573\n",
      "Epoch: 10, Loss: 0.05317448452115059\n",
      "Epoch: 11, Loss: 0.043735045939683914\n",
      "Epoch: 12, Loss: 0.0422283299267292\n",
      "Epoch: 13, Loss: 0.045196495950222015\n",
      "Epoch: 14, Loss: 0.047032680362463\n",
      "Epoch: 15, Loss: 0.04287856072187424\n",
      "Epoch: 16, Loss: 0.03437059745192528\n",
      "Epoch: 17, Loss: 0.026601849123835564\n",
      "Epoch: 18, Loss: 0.02197284996509552\n",
      "Epoch: 19, Loss: 0.020193953067064285\n",
      "Epoch: 20, Loss: 0.020239679142832756\n",
      "Epoch: 21, Loss: 0.021275445818901062\n",
      "Epoch: 22, Loss: 0.022130711004137993\n",
      "Epoch: 23, Loss: 0.020949868485331535\n",
      "Epoch: 24, Loss: 0.01742895320057869\n",
      "Epoch: 25, Loss: 0.01390322670340538\n",
      "Epoch: 26, Loss: 0.012132045812904835\n",
      "Epoch: 27, Loss: 0.011693865060806274\n",
      "Epoch: 28, Loss: 0.011288056150078773\n",
      "Epoch: 29, Loss: 0.010537464171648026\n",
      "Epoch: 30, Loss: 0.009761163033545017\n",
      "Epoch: 31, Loss: 0.008711226284503937\n",
      "Epoch: 32, Loss: 0.007001070771366358\n",
      "Epoch: 33, Loss: 0.005419886205345392\n",
      "Epoch: 34, Loss: 0.004863730166107416\n",
      "Epoch: 35, Loss: 0.004881922621279955\n",
      "Epoch: 36, Loss: 0.004945056047290564\n",
      "Epoch: 37, Loss: 0.004609683528542519\n",
      "Epoch: 38, Loss: 0.0038399971090257168\n",
      "Epoch: 39, Loss: 0.0029937440995126963\n",
      "Epoch: 40, Loss: 0.002334513468667865\n",
      "Epoch: 41, Loss: 0.001885519828647375\n",
      "Epoch: 42, Loss: 0.0016912930877879262\n",
      "Epoch: 43, Loss: 0.0017355206655338407\n",
      "Epoch: 44, Loss: 0.0017436071066185832\n",
      "Epoch: 45, Loss: 0.0015038163401186466\n",
      "Epoch: 46, Loss: 0.00110858294647187\n",
      "Epoch: 47, Loss: 0.0008675046847201884\n",
      "Epoch: 48, Loss: 0.0008363538072444499\n",
      "Epoch: 49, Loss: 0.0008891765028238297\n",
      "Epoch: 50, Loss: 0.0009524713386781514\n",
      "epoch 6 tensor([ 0.6376, -3.4985, -0.4046, -0.5988,  0.5731], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.1420804262161255\n",
      "Epoch: 2, Loss: 0.1014300063252449\n",
      "Epoch: 3, Loss: 0.08367545157670975\n",
      "Epoch: 4, Loss: 0.07838507741689682\n",
      "Epoch: 5, Loss: 0.07383660972118378\n",
      "Epoch: 6, Loss: 0.05825513228774071\n",
      "Epoch: 7, Loss: 0.04519350454211235\n",
      "Epoch: 8, Loss: 0.04571669176220894\n",
      "Epoch: 9, Loss: 0.0503128319978714\n",
      "Epoch: 10, Loss: 0.04743693023920059\n",
      "Epoch: 11, Loss: 0.04004752263426781\n",
      "Epoch: 12, Loss: 0.03443167731165886\n",
      "Epoch: 13, Loss: 0.03225603699684143\n",
      "Epoch: 14, Loss: 0.030078351497650146\n",
      "Epoch: 15, Loss: 0.026872456073760986\n",
      "Epoch: 16, Loss: 0.022903237491846085\n",
      "Epoch: 17, Loss: 0.018355099484324455\n",
      "Epoch: 18, Loss: 0.01626046933233738\n",
      "Epoch: 19, Loss: 0.015212390571832657\n",
      "Epoch: 20, Loss: 0.014134743250906467\n",
      "Epoch: 21, Loss: 0.013941895216703415\n",
      "Epoch: 22, Loss: 0.013082155957818031\n",
      "Epoch: 23, Loss: 0.012065950781106949\n",
      "Epoch: 24, Loss: 0.011610082350671291\n",
      "Epoch: 25, Loss: 0.010703818872570992\n",
      "Epoch: 26, Loss: 0.009677251800894737\n",
      "Epoch: 27, Loss: 0.008766661398112774\n",
      "Epoch: 28, Loss: 0.0076912264339625835\n",
      "Epoch: 29, Loss: 0.006994632538408041\n",
      "Epoch: 30, Loss: 0.006902435328811407\n",
      "Epoch: 31, Loss: 0.006953377742320299\n",
      "Epoch: 32, Loss: 0.006498407106846571\n",
      "Epoch: 33, Loss: 0.00587207218632102\n",
      "Epoch: 34, Loss: 0.005744153633713722\n",
      "Epoch: 35, Loss: 0.005693573970347643\n",
      "Epoch: 36, Loss: 0.005433578044176102\n",
      "Epoch: 37, Loss: 0.004917176906019449\n",
      "Epoch: 38, Loss: 0.0045172288082540035\n",
      "Epoch: 39, Loss: 0.004482508637011051\n",
      "Epoch: 40, Loss: 0.004335801582783461\n",
      "Epoch: 41, Loss: 0.004073828458786011\n",
      "Epoch: 42, Loss: 0.0038444609381258488\n",
      "Epoch: 43, Loss: 0.0037072564009577036\n",
      "Epoch: 44, Loss: 0.0036290360148996115\n",
      "Epoch: 45, Loss: 0.0034559231717139482\n",
      "Epoch: 46, Loss: 0.003221450839191675\n",
      "Epoch: 47, Loss: 0.003008356085047126\n",
      "Epoch: 48, Loss: 0.0028072476852685213\n",
      "Epoch: 49, Loss: 0.00263409991748631\n",
      "Epoch: 50, Loss: 0.002465492580085993\n",
      "epoch 6 tensor([ 0.6936, -3.5157, -0.4022, -0.5267,  0.5894], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.2424754500389099\n",
      "Epoch: 2, Loss: 0.21167144179344177\n",
      "Epoch: 3, Loss: 0.1837025135755539\n",
      "Epoch: 4, Loss: 0.16130906343460083\n",
      "Epoch: 5, Loss: 0.1385752409696579\n",
      "Epoch: 6, Loss: 0.12286887317895889\n",
      "Epoch: 7, Loss: 0.11065752059221268\n",
      "Epoch: 8, Loss: 0.09837110340595245\n",
      "Epoch: 9, Loss: 0.08643215894699097\n",
      "Epoch: 10, Loss: 0.07519606500864029\n",
      "Epoch: 11, Loss: 0.06205516681075096\n",
      "Epoch: 12, Loss: 0.04884915426373482\n",
      "Epoch: 13, Loss: 0.039418015629053116\n",
      "Epoch: 14, Loss: 0.035208024084568024\n",
      "Epoch: 15, Loss: 0.03293829411268234\n",
      "Epoch: 16, Loss: 0.030414070934057236\n",
      "Epoch: 17, Loss: 0.026977941393852234\n",
      "Epoch: 18, Loss: 0.02303212694823742\n",
      "Epoch: 19, Loss: 0.019124269485473633\n",
      "Epoch: 20, Loss: 0.01548605877906084\n",
      "Epoch: 21, Loss: 0.013141605071723461\n",
      "Epoch: 22, Loss: 0.011624428443610668\n",
      "Epoch: 23, Loss: 0.01026699785143137\n",
      "Epoch: 24, Loss: 0.009177540428936481\n",
      "Epoch: 25, Loss: 0.00812211912125349\n",
      "Epoch: 26, Loss: 0.0068843550980091095\n",
      "Epoch: 27, Loss: 0.005513800773769617\n",
      "Epoch: 28, Loss: 0.004820330534130335\n",
      "Epoch: 29, Loss: 0.004521477036178112\n",
      "Epoch: 30, Loss: 0.00426261592656374\n",
      "Epoch: 31, Loss: 0.0038987312000244856\n",
      "Epoch: 32, Loss: 0.0034458437003195286\n",
      "Epoch: 33, Loss: 0.002856679493561387\n",
      "Epoch: 34, Loss: 0.002431300235912204\n",
      "Epoch: 35, Loss: 0.002220387803390622\n",
      "Epoch: 36, Loss: 0.0021066286135464907\n",
      "Epoch: 37, Loss: 0.002071087248623371\n",
      "Epoch: 38, Loss: 0.002014008117839694\n",
      "Epoch: 39, Loss: 0.0018651370191946626\n",
      "Epoch: 40, Loss: 0.0016714711673557758\n",
      "Epoch: 41, Loss: 0.0014761360362172127\n",
      "Epoch: 42, Loss: 0.001254125265404582\n",
      "Epoch: 43, Loss: 0.0010857043089345098\n",
      "Epoch: 44, Loss: 0.0009529717499390244\n",
      "Epoch: 45, Loss: 0.0008678407175466418\n",
      "Epoch: 46, Loss: 0.0008513756329193711\n",
      "Epoch: 47, Loss: 0.0008364295936189592\n",
      "Epoch: 48, Loss: 0.0007399229798465967\n",
      "Epoch: 49, Loss: 0.0006318227387964725\n",
      "Epoch: 50, Loss: 0.0005783514934591949\n",
      "epoch 6 tensor([ 0.6459, -3.1799, -0.4548, -0.4204,  0.5762], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.08952969312667847\n",
      "Epoch: 2, Loss: 0.06384119391441345\n",
      "Epoch: 3, Loss: 0.04405200481414795\n",
      "Epoch: 4, Loss: 0.0330030657351017\n",
      "Epoch: 5, Loss: 0.029585907235741615\n",
      "Epoch: 6, Loss: 0.03243158012628555\n",
      "Epoch: 7, Loss: 0.035494208335876465\n",
      "Epoch: 8, Loss: 0.03040301986038685\n",
      "Epoch: 9, Loss: 0.023082725703716278\n",
      "Epoch: 10, Loss: 0.020586535334587097\n",
      "Epoch: 11, Loss: 0.020049026235938072\n",
      "Epoch: 12, Loss: 0.019444989040493965\n",
      "Epoch: 13, Loss: 0.018389727920293808\n",
      "Epoch: 14, Loss: 0.016285471618175507\n",
      "Epoch: 15, Loss: 0.0131610706448555\n",
      "Epoch: 16, Loss: 0.011408794671297073\n",
      "Epoch: 17, Loss: 0.011449107900261879\n",
      "Epoch: 18, Loss: 0.010536428540945053\n",
      "Epoch: 19, Loss: 0.008463473059237003\n",
      "Epoch: 20, Loss: 0.006899398751556873\n",
      "Epoch: 21, Loss: 0.006497190799564123\n",
      "Epoch: 22, Loss: 0.0062906863167881966\n",
      "Epoch: 23, Loss: 0.006063305772840977\n",
      "Epoch: 24, Loss: 0.005896046757698059\n",
      "Epoch: 25, Loss: 0.004912635311484337\n",
      "Epoch: 26, Loss: 0.0036142482422292233\n",
      "Epoch: 27, Loss: 0.002648266265168786\n",
      "Epoch: 28, Loss: 0.002581699751317501\n",
      "Epoch: 29, Loss: 0.002672460163012147\n",
      "Epoch: 30, Loss: 0.002535488922148943\n",
      "Epoch: 31, Loss: 0.0021184615325182676\n",
      "Epoch: 32, Loss: 0.001624665455892682\n",
      "Epoch: 33, Loss: 0.0012796689989045262\n",
      "Epoch: 34, Loss: 0.0012588537065312266\n",
      "Epoch: 35, Loss: 0.0014325141673907638\n",
      "Epoch: 36, Loss: 0.001399496803060174\n",
      "Epoch: 37, Loss: 0.0012421987485140562\n",
      "Epoch: 38, Loss: 0.0008821896626614034\n",
      "Epoch: 39, Loss: 0.0006095424178056419\n",
      "Epoch: 40, Loss: 0.0005605396581813693\n",
      "Epoch: 41, Loss: 0.0006659712526015937\n",
      "Epoch: 42, Loss: 0.0006546566146425903\n",
      "Epoch: 43, Loss: 0.0006460411241278052\n",
      "Epoch: 44, Loss: 0.0005660048336721957\n",
      "Epoch: 45, Loss: 0.0005140479770489037\n",
      "Epoch: 46, Loss: 0.00046439070138148963\n",
      "Epoch: 47, Loss: 0.00046976053272373974\n",
      "Epoch: 48, Loss: 0.00039160007145255804\n",
      "Epoch: 49, Loss: 0.00030203795176930726\n",
      "Epoch: 50, Loss: 0.00024924977333284914\n",
      "________________________________________\n",
      "epoch 7 tensor([ 0.7490, -3.1676, -0.4022, -0.0249,  0.6166], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.4353373050689697\n",
      "Epoch: 2, Loss: 0.30405744910240173\n",
      "Epoch: 3, Loss: 0.24291211366653442\n",
      "Epoch: 4, Loss: 0.22281382977962494\n",
      "Epoch: 5, Loss: 0.20213918387889862\n",
      "Epoch: 6, Loss: 0.19072946906089783\n",
      "Epoch: 7, Loss: 0.16760623455047607\n",
      "Epoch: 8, Loss: 0.13483743369579315\n",
      "Epoch: 9, Loss: 0.11329115182161331\n",
      "Epoch: 10, Loss: 0.10710311681032181\n",
      "Epoch: 11, Loss: 0.09839408844709396\n",
      "Epoch: 12, Loss: 0.08190619200468063\n",
      "Epoch: 13, Loss: 0.06866911053657532\n",
      "Epoch: 14, Loss: 0.06187945976853371\n",
      "Epoch: 15, Loss: 0.05561202019453049\n",
      "Epoch: 16, Loss: 0.04893806576728821\n",
      "Epoch: 17, Loss: 0.04517413303256035\n",
      "Epoch: 18, Loss: 0.04181959107518196\n",
      "Epoch: 19, Loss: 0.036734599620103836\n",
      "Epoch: 20, Loss: 0.03229260817170143\n",
      "Epoch: 21, Loss: 0.030700189992785454\n",
      "Epoch: 22, Loss: 0.026897940784692764\n",
      "Epoch: 23, Loss: 0.020515449345111847\n",
      "Epoch: 24, Loss: 0.016085904091596603\n",
      "Epoch: 25, Loss: 0.014708859845995903\n",
      "Epoch: 26, Loss: 0.013675998896360397\n",
      "Epoch: 27, Loss: 0.012391162104904652\n",
      "Epoch: 28, Loss: 0.011716063134372234\n",
      "Epoch: 29, Loss: 0.010920538567006588\n",
      "Epoch: 30, Loss: 0.009563244879245758\n",
      "Epoch: 31, Loss: 0.00888910423964262\n",
      "Epoch: 32, Loss: 0.008984336629509926\n",
      "Epoch: 33, Loss: 0.008423167280852795\n",
      "Epoch: 34, Loss: 0.007669152691960335\n",
      "Epoch: 35, Loss: 0.007340122014284134\n",
      "Epoch: 36, Loss: 0.006948626600205898\n",
      "Epoch: 37, Loss: 0.0061754328198730946\n",
      "Epoch: 38, Loss: 0.0055511281825602055\n",
      "Epoch: 39, Loss: 0.005138089880347252\n",
      "Epoch: 40, Loss: 0.0048322249203920364\n",
      "Epoch: 41, Loss: 0.004754649940878153\n",
      "Epoch: 42, Loss: 0.0045128148049116135\n",
      "Epoch: 43, Loss: 0.0037424510810524225\n",
      "Epoch: 44, Loss: 0.0030169454403221607\n",
      "Epoch: 45, Loss: 0.002802902366966009\n",
      "Epoch: 46, Loss: 0.002747681923210621\n",
      "Epoch: 47, Loss: 0.0026005995459854603\n",
      "Epoch: 48, Loss: 0.0024010813795030117\n",
      "Epoch: 49, Loss: 0.002072377596050501\n",
      "Epoch: 50, Loss: 0.0017498087836429477\n",
      "epoch 7 tensor([ 1.0116, -2.8284, -0.5840, -0.4403,  1.1566], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.26307034492492676\n",
      "Epoch: 2, Loss: 0.17758403718471527\n",
      "Epoch: 3, Loss: 0.11384109407663345\n",
      "Epoch: 4, Loss: 0.09827340394258499\n",
      "Epoch: 5, Loss: 0.10446125268936157\n",
      "Epoch: 6, Loss: 0.09792787581682205\n",
      "Epoch: 7, Loss: 0.08581230044364929\n",
      "Epoch: 8, Loss: 0.0771646574139595\n",
      "Epoch: 9, Loss: 0.0702829360961914\n",
      "Epoch: 10, Loss: 0.06274012476205826\n",
      "Epoch: 11, Loss: 0.056693848222494125\n",
      "Epoch: 12, Loss: 0.054786041378974915\n",
      "Epoch: 13, Loss: 0.05411417782306671\n",
      "Epoch: 14, Loss: 0.04548916965723038\n",
      "Epoch: 15, Loss: 0.034813638776540756\n",
      "Epoch: 16, Loss: 0.02558155544102192\n",
      "Epoch: 17, Loss: 0.020513959228992462\n",
      "Epoch: 18, Loss: 0.01850500889122486\n",
      "Epoch: 19, Loss: 0.01888985000550747\n",
      "Epoch: 20, Loss: 0.021140241995453835\n",
      "Epoch: 21, Loss: 0.02190658636391163\n",
      "Epoch: 22, Loss: 0.01954653300344944\n",
      "Epoch: 23, Loss: 0.016049906611442566\n",
      "Epoch: 24, Loss: 0.012856794521212578\n",
      "Epoch: 25, Loss: 0.010442969389259815\n",
      "Epoch: 26, Loss: 0.009786021895706654\n",
      "Epoch: 27, Loss: 0.00957831833511591\n",
      "Epoch: 28, Loss: 0.008965526707470417\n",
      "Epoch: 29, Loss: 0.007376553490757942\n",
      "Epoch: 30, Loss: 0.0058543444611132145\n",
      "Epoch: 31, Loss: 0.005596678704023361\n",
      "Epoch: 32, Loss: 0.005673461593687534\n",
      "Epoch: 33, Loss: 0.005219893530011177\n",
      "Epoch: 34, Loss: 0.004975958727300167\n",
      "Epoch: 35, Loss: 0.005063886754214764\n",
      "Epoch: 36, Loss: 0.004483790136873722\n",
      "Epoch: 37, Loss: 0.003293050220236182\n",
      "Epoch: 38, Loss: 0.0026356035377830267\n",
      "Epoch: 39, Loss: 0.002426795894280076\n",
      "Epoch: 40, Loss: 0.002250571735203266\n",
      "Epoch: 41, Loss: 0.0019117215415462852\n",
      "Epoch: 42, Loss: 0.0016658651875331998\n",
      "Epoch: 43, Loss: 0.0014517426025122404\n",
      "Epoch: 44, Loss: 0.0012993243290111423\n",
      "Epoch: 45, Loss: 0.0013615658972412348\n",
      "Epoch: 46, Loss: 0.0014215648407116532\n",
      "Epoch: 47, Loss: 0.0013870446709915996\n",
      "Epoch: 48, Loss: 0.0012040581787005067\n",
      "Epoch: 49, Loss: 0.0009142315248027444\n",
      "Epoch: 50, Loss: 0.0006512205582112074\n",
      "epoch 7 tensor([ 1.9083, -2.4273, -0.6090, -1.3692,  1.7696], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.04702119901776314\n",
      "Epoch: 2, Loss: 0.03689029812812805\n",
      "Epoch: 3, Loss: 0.029713742434978485\n",
      "Epoch: 4, Loss: 0.025709955021739006\n",
      "Epoch: 5, Loss: 0.022462189197540283\n",
      "Epoch: 6, Loss: 0.01863262616097927\n",
      "Epoch: 7, Loss: 0.015046602115035057\n",
      "Epoch: 8, Loss: 0.012682097963988781\n",
      "Epoch: 9, Loss: 0.01094284188002348\n",
      "Epoch: 10, Loss: 0.010251578874886036\n",
      "Epoch: 11, Loss: 0.009646589867770672\n",
      "Epoch: 12, Loss: 0.008908302523195744\n",
      "Epoch: 13, Loss: 0.007952462881803513\n",
      "Epoch: 14, Loss: 0.007084427867084742\n",
      "Epoch: 15, Loss: 0.006605085916817188\n",
      "Epoch: 16, Loss: 0.005865252111107111\n",
      "Epoch: 17, Loss: 0.0049101365730166435\n",
      "Epoch: 18, Loss: 0.0038252556696534157\n",
      "Epoch: 19, Loss: 0.0028469974640756845\n",
      "Epoch: 20, Loss: 0.0025840180460363626\n",
      "Epoch: 21, Loss: 0.0029499272350221872\n",
      "Epoch: 22, Loss: 0.0031265204306691885\n",
      "Epoch: 23, Loss: 0.002907447749748826\n",
      "Epoch: 24, Loss: 0.002634147647768259\n",
      "Epoch: 25, Loss: 0.0023765552323311567\n",
      "Epoch: 26, Loss: 0.0021176286973059177\n",
      "Epoch: 27, Loss: 0.002015327103435993\n",
      "Epoch: 28, Loss: 0.0019419171148911119\n",
      "Epoch: 29, Loss: 0.0016177231445908546\n",
      "Epoch: 30, Loss: 0.0012449276400730014\n",
      "Epoch: 31, Loss: 0.0011271812254562974\n",
      "Epoch: 32, Loss: 0.0011116857640445232\n",
      "Epoch: 33, Loss: 0.0009283109684474766\n",
      "Epoch: 34, Loss: 0.0007257925462909043\n",
      "Epoch: 35, Loss: 0.0006387693574652076\n",
      "Epoch: 36, Loss: 0.0005347073310986161\n",
      "Epoch: 37, Loss: 0.0004415267612785101\n",
      "Epoch: 38, Loss: 0.00043040330638177693\n",
      "Epoch: 39, Loss: 0.0003904677869286388\n",
      "Epoch: 40, Loss: 0.0003123547649011016\n",
      "Epoch: 41, Loss: 0.0002925509470514953\n",
      "Epoch: 42, Loss: 0.0003205186512786895\n",
      "Epoch: 43, Loss: 0.00032520826789550483\n",
      "Epoch: 44, Loss: 0.0003036145062651485\n",
      "Epoch: 45, Loss: 0.0002811719896271825\n",
      "Epoch: 46, Loss: 0.00026461161905899644\n",
      "Epoch: 47, Loss: 0.0002647956716828048\n",
      "Epoch: 48, Loss: 0.0002563699381425977\n",
      "Epoch: 49, Loss: 0.0002219769376097247\n",
      "Epoch: 50, Loss: 0.00018368702149018645\n",
      "epoch 7 tensor([ 1.8864, -2.5167, -0.7074, -1.1078,  1.6962], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.1737070083618164\n",
      "Epoch: 2, Loss: 0.13646289706230164\n",
      "Epoch: 3, Loss: 0.09794070571660995\n",
      "Epoch: 4, Loss: 0.07374119013547897\n",
      "Epoch: 5, Loss: 0.0635390356183052\n",
      "Epoch: 6, Loss: 0.0601227767765522\n",
      "Epoch: 7, Loss: 0.05793773755431175\n",
      "Epoch: 8, Loss: 0.05494382977485657\n",
      "Epoch: 9, Loss: 0.049628280103206635\n",
      "Epoch: 10, Loss: 0.040727194398641586\n",
      "Epoch: 11, Loss: 0.029522787779569626\n",
      "Epoch: 12, Loss: 0.020502755418419838\n",
      "Epoch: 13, Loss: 0.017408475279808044\n",
      "Epoch: 14, Loss: 0.01886984519660473\n",
      "Epoch: 15, Loss: 0.020343158394098282\n",
      "Epoch: 16, Loss: 0.019473379477858543\n",
      "Epoch: 17, Loss: 0.017072206363081932\n",
      "Epoch: 18, Loss: 0.01444458868354559\n",
      "Epoch: 19, Loss: 0.012424876913428307\n",
      "Epoch: 20, Loss: 0.010561984963715076\n",
      "Epoch: 21, Loss: 0.008967487141489983\n",
      "Epoch: 22, Loss: 0.007955498993396759\n",
      "Epoch: 23, Loss: 0.006833788938820362\n",
      "Epoch: 24, Loss: 0.005821121856570244\n",
      "Epoch: 25, Loss: 0.005068653728812933\n",
      "Epoch: 26, Loss: 0.004572036676108837\n",
      "Epoch: 27, Loss: 0.004585373681038618\n",
      "Epoch: 28, Loss: 0.004761282820254564\n",
      "Epoch: 29, Loss: 0.004721698816865683\n",
      "Epoch: 30, Loss: 0.004375349264591932\n",
      "Epoch: 31, Loss: 0.0036894327495247126\n",
      "Epoch: 32, Loss: 0.003087220713496208\n",
      "Epoch: 33, Loss: 0.002739964984357357\n",
      "Epoch: 34, Loss: 0.0025173062458634377\n",
      "Epoch: 35, Loss: 0.0024052748922258615\n",
      "Epoch: 36, Loss: 0.0022342391312122345\n",
      "Epoch: 37, Loss: 0.0019564398098737\n",
      "Epoch: 38, Loss: 0.0015890613431110978\n",
      "Epoch: 39, Loss: 0.0011323078069835901\n",
      "Epoch: 40, Loss: 0.0007877735188230872\n",
      "Epoch: 41, Loss: 0.0006701078382320702\n",
      "Epoch: 42, Loss: 0.0007854854920879006\n",
      "Epoch: 43, Loss: 0.0009987949160858989\n",
      "Epoch: 44, Loss: 0.0010798234725371003\n",
      "Epoch: 45, Loss: 0.0009820875711739063\n",
      "Epoch: 46, Loss: 0.0007573150796815753\n",
      "Epoch: 47, Loss: 0.0005295999580994248\n",
      "Epoch: 48, Loss: 0.0004174928762950003\n",
      "Epoch: 49, Loss: 0.0004009333497378975\n",
      "Epoch: 50, Loss: 0.0004334168042987585\n",
      "epoch 7 tensor([ 0.5808, -2.9976, -0.9297,  0.4844,  1.2727], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.09414484351873398\n",
      "Epoch: 2, Loss: 0.07776811718940735\n",
      "Epoch: 3, Loss: 0.0611935555934906\n",
      "Epoch: 4, Loss: 0.046925440430641174\n",
      "Epoch: 5, Loss: 0.03429730236530304\n",
      "Epoch: 6, Loss: 0.026531169191002846\n",
      "Epoch: 7, Loss: 0.021862829104065895\n",
      "Epoch: 8, Loss: 0.018660830333828926\n",
      "Epoch: 9, Loss: 0.015991654247045517\n",
      "Epoch: 10, Loss: 0.013980889692902565\n",
      "Epoch: 11, Loss: 0.012949900701642036\n",
      "Epoch: 12, Loss: 0.01241056714206934\n",
      "Epoch: 13, Loss: 0.01127311959862709\n",
      "Epoch: 14, Loss: 0.009774203412234783\n",
      "Epoch: 15, Loss: 0.008713042363524437\n",
      "Epoch: 16, Loss: 0.008373000659048557\n",
      "Epoch: 17, Loss: 0.007636789698153734\n",
      "Epoch: 18, Loss: 0.006552670616656542\n",
      "Epoch: 19, Loss: 0.006089644972234964\n",
      "Epoch: 20, Loss: 0.00529393320903182\n",
      "Epoch: 21, Loss: 0.0046174414455890656\n",
      "Epoch: 22, Loss: 0.003733384422957897\n",
      "Epoch: 23, Loss: 0.003533104667440057\n",
      "Epoch: 24, Loss: 0.002608753740787506\n",
      "Epoch: 25, Loss: 0.0022268472239375114\n",
      "Epoch: 26, Loss: 0.0022578316275030375\n",
      "Epoch: 27, Loss: 0.002405863953754306\n",
      "Epoch: 28, Loss: 0.002292768796905875\n",
      "Epoch: 29, Loss: 0.0022773994132876396\n",
      "Epoch: 30, Loss: 0.0022704144939780235\n",
      "Epoch: 31, Loss: 0.0020191604271531105\n",
      "Epoch: 32, Loss: 0.0017931764014065266\n",
      "Epoch: 33, Loss: 0.001593609806150198\n",
      "Epoch: 34, Loss: 0.0013812987599521875\n",
      "Epoch: 35, Loss: 0.0012672857847064734\n",
      "Epoch: 36, Loss: 0.0011097240494564176\n",
      "Epoch: 37, Loss: 0.0008970091002993286\n",
      "Epoch: 38, Loss: 0.0008294186554849148\n",
      "Epoch: 39, Loss: 0.0007548279827460647\n",
      "Epoch: 40, Loss: 0.0006301740650087595\n",
      "Epoch: 41, Loss: 0.0006293955957517028\n",
      "Epoch: 42, Loss: 0.0006244529504328966\n",
      "Epoch: 43, Loss: 0.0005438026855699718\n",
      "Epoch: 44, Loss: 0.0005086142336949706\n",
      "Epoch: 45, Loss: 0.0004960268852300942\n",
      "Epoch: 46, Loss: 0.0004301260341890156\n",
      "Epoch: 47, Loss: 0.0003815008094534278\n",
      "Epoch: 48, Loss: 0.00035650606150738895\n",
      "Epoch: 49, Loss: 0.00028912225388921797\n",
      "Epoch: 50, Loss: 0.00023691981914453208\n",
      "epoch 7 tensor([ 0.8368, -2.8911, -0.7473, -0.3825,  0.3697], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.1123027354478836\n",
      "Epoch: 2, Loss: 0.09203299880027771\n",
      "Epoch: 3, Loss: 0.07302571088075638\n",
      "Epoch: 4, Loss: 0.0557330884039402\n",
      "Epoch: 5, Loss: 0.04156411066651344\n",
      "Epoch: 6, Loss: 0.031060241162776947\n",
      "Epoch: 7, Loss: 0.024399317800998688\n",
      "Epoch: 8, Loss: 0.01893565244972706\n",
      "Epoch: 9, Loss: 0.017299709841609\n",
      "Epoch: 10, Loss: 0.01643211394548416\n",
      "Epoch: 11, Loss: 0.014374473132193089\n",
      "Epoch: 12, Loss: 0.012048469856381416\n",
      "Epoch: 13, Loss: 0.010055788792669773\n",
      "Epoch: 14, Loss: 0.008626976981759071\n",
      "Epoch: 15, Loss: 0.008246761746704578\n",
      "Epoch: 16, Loss: 0.008350182324647903\n",
      "Epoch: 17, Loss: 0.007633519358932972\n",
      "Epoch: 18, Loss: 0.006712609436362982\n",
      "Epoch: 19, Loss: 0.006075477227568626\n",
      "Epoch: 20, Loss: 0.005159247666597366\n",
      "Epoch: 21, Loss: 0.004235963337123394\n",
      "Epoch: 22, Loss: 0.00392002472653985\n",
      "Epoch: 23, Loss: 0.003665223717689514\n",
      "Epoch: 24, Loss: 0.0033592390827834606\n",
      "Epoch: 25, Loss: 0.0032209765631705523\n",
      "Epoch: 26, Loss: 0.0032769241370260715\n",
      "Epoch: 27, Loss: 0.003383062081411481\n",
      "Epoch: 28, Loss: 0.003331705927848816\n",
      "Epoch: 29, Loss: 0.003030515043064952\n",
      "Epoch: 30, Loss: 0.0024662392679601908\n",
      "Epoch: 31, Loss: 0.001840338110923767\n",
      "Epoch: 32, Loss: 0.0013944113161414862\n",
      "Epoch: 33, Loss: 0.0010923015652224422\n",
      "Epoch: 34, Loss: 0.0009056219714693725\n",
      "Epoch: 35, Loss: 0.0008293797145597637\n",
      "Epoch: 36, Loss: 0.0008179739234037697\n",
      "Epoch: 37, Loss: 0.0009183713118545711\n",
      "Epoch: 38, Loss: 0.0009113134583458304\n",
      "Epoch: 39, Loss: 0.0008209621882997453\n",
      "Epoch: 40, Loss: 0.0007594117778353393\n",
      "Epoch: 41, Loss: 0.000698669406119734\n",
      "Epoch: 42, Loss: 0.0006323225097730756\n",
      "Epoch: 43, Loss: 0.0005728645483031869\n",
      "Epoch: 44, Loss: 0.0004825497162528336\n",
      "Epoch: 45, Loss: 0.0004126859421376139\n",
      "Epoch: 46, Loss: 0.0003544319770298898\n",
      "Epoch: 47, Loss: 0.00028751807985827327\n",
      "Epoch: 48, Loss: 0.00025083302170969546\n",
      "Epoch: 49, Loss: 0.00023292202968150377\n",
      "Epoch: 50, Loss: 0.00023305797367356718\n",
      "epoch 7 tensor([ 0.9251, -2.7424, -0.4435, -0.5043,  1.3751], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.28002646565437317\n",
      "Epoch: 2, Loss: 0.23054634034633636\n",
      "Epoch: 3, Loss: 0.18339374661445618\n",
      "Epoch: 4, Loss: 0.14698491990566254\n",
      "Epoch: 5, Loss: 0.13031794130802155\n",
      "Epoch: 6, Loss: 0.12277316302061081\n",
      "Epoch: 7, Loss: 0.10914550721645355\n",
      "Epoch: 8, Loss: 0.09489893168210983\n",
      "Epoch: 9, Loss: 0.08636533468961716\n",
      "Epoch: 10, Loss: 0.07594131678342819\n",
      "Epoch: 11, Loss: 0.06467598676681519\n",
      "Epoch: 12, Loss: 0.055501483380794525\n",
      "Epoch: 13, Loss: 0.048938002437353134\n",
      "Epoch: 14, Loss: 0.04330931231379509\n",
      "Epoch: 15, Loss: 0.03821403905749321\n",
      "Epoch: 16, Loss: 0.0343402624130249\n",
      "Epoch: 17, Loss: 0.03292126953601837\n",
      "Epoch: 18, Loss: 0.03205321356654167\n",
      "Epoch: 19, Loss: 0.03215775638818741\n",
      "Epoch: 20, Loss: 0.02961028553545475\n",
      "Epoch: 21, Loss: 0.025823131203651428\n",
      "Epoch: 22, Loss: 0.023593394085764885\n",
      "Epoch: 23, Loss: 0.022142920643091202\n",
      "Epoch: 24, Loss: 0.02161840908229351\n",
      "Epoch: 25, Loss: 0.02124851942062378\n",
      "Epoch: 26, Loss: 0.020335877314209938\n",
      "Epoch: 27, Loss: 0.019122716039419174\n",
      "Epoch: 28, Loss: 0.017645584419369698\n",
      "Epoch: 29, Loss: 0.016185114160180092\n",
      "Epoch: 30, Loss: 0.014871546998620033\n",
      "Epoch: 31, Loss: 0.013478578068315983\n",
      "Epoch: 32, Loss: 0.012118926271796227\n",
      "Epoch: 33, Loss: 0.011515754275023937\n",
      "Epoch: 34, Loss: 0.010941212065517902\n",
      "Epoch: 35, Loss: 0.010273830033838749\n",
      "Epoch: 36, Loss: 0.009924155659973621\n",
      "Epoch: 37, Loss: 0.009529131464660168\n",
      "Epoch: 38, Loss: 0.00903155654668808\n",
      "Epoch: 39, Loss: 0.008447195403277874\n",
      "Epoch: 40, Loss: 0.008152629248797894\n",
      "Epoch: 41, Loss: 0.007908816449344158\n",
      "Epoch: 42, Loss: 0.0075704860500991344\n",
      "Epoch: 43, Loss: 0.00726695079356432\n",
      "Epoch: 44, Loss: 0.007048098370432854\n",
      "Epoch: 45, Loss: 0.006739858537912369\n",
      "Epoch: 46, Loss: 0.006407282780855894\n",
      "Epoch: 47, Loss: 0.006102174054831266\n",
      "Epoch: 48, Loss: 0.0058325813151896\n",
      "Epoch: 49, Loss: 0.005508299916982651\n",
      "Epoch: 50, Loss: 0.005149604752659798\n",
      "epoch 7 tensor([ 0.8049, -2.5266, -0.3528, -0.3402,  1.1135], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.08837535977363586\n",
      "Epoch: 2, Loss: 0.07389365881681442\n",
      "Epoch: 3, Loss: 0.06227279081940651\n",
      "Epoch: 4, Loss: 0.05038983002305031\n",
      "Epoch: 5, Loss: 0.041969310492277145\n",
      "Epoch: 6, Loss: 0.03499257192015648\n",
      "Epoch: 7, Loss: 0.03538363054394722\n",
      "Epoch: 8, Loss: 0.033417582511901855\n",
      "Epoch: 9, Loss: 0.032318875193595886\n",
      "Epoch: 10, Loss: 0.02988610416650772\n",
      "Epoch: 11, Loss: 0.027172265574336052\n",
      "Epoch: 12, Loss: 0.024962110444903374\n",
      "Epoch: 13, Loss: 0.022243013605475426\n",
      "Epoch: 14, Loss: 0.01944359764456749\n",
      "Epoch: 15, Loss: 0.015799975022673607\n",
      "Epoch: 16, Loss: 0.014150893315672874\n",
      "Epoch: 17, Loss: 0.012763525359332561\n",
      "Epoch: 18, Loss: 0.011223063804209232\n",
      "Epoch: 19, Loss: 0.009862051345407963\n",
      "Epoch: 20, Loss: 0.00885674636811018\n",
      "Epoch: 21, Loss: 0.008551768958568573\n",
      "Epoch: 22, Loss: 0.007595706731081009\n",
      "Epoch: 23, Loss: 0.00696413591504097\n",
      "Epoch: 24, Loss: 0.006218282040208578\n",
      "Epoch: 25, Loss: 0.005389333236962557\n",
      "Epoch: 26, Loss: 0.004550307523459196\n",
      "Epoch: 27, Loss: 0.0038861623033881187\n",
      "Epoch: 28, Loss: 0.0035761413164436817\n",
      "Epoch: 29, Loss: 0.0031000992748886347\n",
      "Epoch: 30, Loss: 0.0027651386335492134\n",
      "Epoch: 31, Loss: 0.0023964226711541414\n",
      "Epoch: 32, Loss: 0.0021642055362462997\n",
      "Epoch: 33, Loss: 0.0018655085004866123\n",
      "Epoch: 34, Loss: 0.001748298411257565\n",
      "Epoch: 35, Loss: 0.0015720364172011614\n",
      "Epoch: 36, Loss: 0.0013502592919394374\n",
      "Epoch: 37, Loss: 0.0011066009756177664\n",
      "Epoch: 38, Loss: 0.0008783338707871735\n",
      "Epoch: 39, Loss: 0.0007582302205264568\n",
      "Epoch: 40, Loss: 0.0007013505091890693\n",
      "Epoch: 41, Loss: 0.0006114544230513275\n",
      "Epoch: 42, Loss: 0.0005692862905561924\n",
      "Epoch: 43, Loss: 0.0005994326784275472\n",
      "Epoch: 44, Loss: 0.0004987388965673745\n",
      "Epoch: 45, Loss: 0.00040029161027632654\n",
      "Epoch: 46, Loss: 0.000334457348799333\n",
      "Epoch: 47, Loss: 0.00029092360637150705\n",
      "Epoch: 48, Loss: 0.00025237700901925564\n",
      "Epoch: 49, Loss: 0.00022200375678949058\n",
      "Epoch: 50, Loss: 0.00021057980484329164\n",
      "epoch 7 tensor([ 0.8307, -3.0406, -0.3761, -0.5140,  0.9185], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.1323532611131668\n",
      "Epoch: 2, Loss: 0.09456521272659302\n",
      "Epoch: 3, Loss: 0.06115932762622833\n",
      "Epoch: 4, Loss: 0.05137215182185173\n",
      "Epoch: 5, Loss: 0.047257423400878906\n",
      "Epoch: 6, Loss: 0.046988941729068756\n",
      "Epoch: 7, Loss: 0.03921110928058624\n",
      "Epoch: 8, Loss: 0.029546046629548073\n",
      "Epoch: 9, Loss: 0.02306077629327774\n",
      "Epoch: 10, Loss: 0.019316408783197403\n",
      "Epoch: 11, Loss: 0.020548250526189804\n",
      "Epoch: 12, Loss: 0.020338578149676323\n",
      "Epoch: 13, Loss: 0.01716146618127823\n",
      "Epoch: 14, Loss: 0.012886691838502884\n",
      "Epoch: 15, Loss: 0.009019809775054455\n",
      "Epoch: 16, Loss: 0.009083799086511135\n",
      "Epoch: 17, Loss: 0.010200382210314274\n",
      "Epoch: 18, Loss: 0.011107406578958035\n",
      "Epoch: 19, Loss: 0.010510824620723724\n",
      "Epoch: 20, Loss: 0.008490334264934063\n",
      "Epoch: 21, Loss: 0.006328569259494543\n",
      "Epoch: 22, Loss: 0.004205417353659868\n",
      "Epoch: 23, Loss: 0.003592518623918295\n",
      "Epoch: 24, Loss: 0.004129981156438589\n",
      "Epoch: 25, Loss: 0.005072844680398703\n",
      "Epoch: 26, Loss: 0.005336991511285305\n",
      "Epoch: 27, Loss: 0.004654048476368189\n",
      "Epoch: 28, Loss: 0.0038891916628926992\n",
      "Epoch: 29, Loss: 0.0030723821837455034\n",
      "Epoch: 30, Loss: 0.0026545377913862467\n",
      "Epoch: 31, Loss: 0.002381043741479516\n",
      "Epoch: 32, Loss: 0.002187828766182065\n",
      "Epoch: 33, Loss: 0.0018503671744838357\n",
      "Epoch: 34, Loss: 0.0014109110925346613\n",
      "Epoch: 35, Loss: 0.001122860936447978\n",
      "Epoch: 36, Loss: 0.0010753301903605461\n",
      "Epoch: 37, Loss: 0.0011931776534765959\n",
      "Epoch: 38, Loss: 0.0011782788205891848\n",
      "Epoch: 39, Loss: 0.0011096872622147202\n",
      "Epoch: 40, Loss: 0.0009907182538881898\n",
      "Epoch: 41, Loss: 0.0009144186042249203\n",
      "Epoch: 42, Loss: 0.0008089852053672075\n",
      "Epoch: 43, Loss: 0.0007396640721708536\n",
      "Epoch: 44, Loss: 0.000699236465152353\n",
      "Epoch: 45, Loss: 0.0006550915422849357\n",
      "Epoch: 46, Loss: 0.0005417217034846544\n",
      "Epoch: 47, Loss: 0.00044046074617654085\n",
      "Epoch: 48, Loss: 0.00036675974843092263\n",
      "Epoch: 49, Loss: 0.0003364283184055239\n",
      "Epoch: 50, Loss: 0.0003312276676297188\n",
      "epoch 7 tensor([ 0.9352, -2.9068, -0.3777, -0.2320,  0.4420], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.13723592460155487\n",
      "Epoch: 2, Loss: 0.10222867131233215\n",
      "Epoch: 3, Loss: 0.07368792593479156\n",
      "Epoch: 4, Loss: 0.053632911294698715\n",
      "Epoch: 5, Loss: 0.04347516596317291\n",
      "Epoch: 6, Loss: 0.04124052822589874\n",
      "Epoch: 7, Loss: 0.03730224445462227\n",
      "Epoch: 8, Loss: 0.03119012899696827\n",
      "Epoch: 9, Loss: 0.027064936235547066\n",
      "Epoch: 10, Loss: 0.02190803550183773\n",
      "Epoch: 11, Loss: 0.017286544665694237\n",
      "Epoch: 12, Loss: 0.01622694544494152\n",
      "Epoch: 13, Loss: 0.016376450657844543\n",
      "Epoch: 14, Loss: 0.014821290969848633\n",
      "Epoch: 15, Loss: 0.013450534082949162\n",
      "Epoch: 16, Loss: 0.011718928813934326\n",
      "Epoch: 17, Loss: 0.01089627668261528\n",
      "Epoch: 18, Loss: 0.009508462622761726\n",
      "Epoch: 19, Loss: 0.009018877521157265\n",
      "Epoch: 20, Loss: 0.008916814811527729\n",
      "Epoch: 21, Loss: 0.007792272139340639\n",
      "Epoch: 22, Loss: 0.007018600590527058\n",
      "Epoch: 23, Loss: 0.006815367843955755\n",
      "Epoch: 24, Loss: 0.005923342891037464\n",
      "Epoch: 25, Loss: 0.005383384879678488\n",
      "Epoch: 26, Loss: 0.005325851496309042\n",
      "Epoch: 27, Loss: 0.004671046976000071\n",
      "Epoch: 28, Loss: 0.003810493042692542\n",
      "Epoch: 29, Loss: 0.0034103032667189837\n",
      "Epoch: 30, Loss: 0.0030311602167785168\n",
      "Epoch: 31, Loss: 0.002626065630465746\n",
      "Epoch: 32, Loss: 0.0027214055880904198\n",
      "Epoch: 33, Loss: 0.0026300731115043163\n",
      "Epoch: 34, Loss: 0.0022507791873067617\n",
      "Epoch: 35, Loss: 0.0019894123543053865\n",
      "Epoch: 36, Loss: 0.0016535563627257943\n",
      "Epoch: 37, Loss: 0.0012189808767288923\n",
      "Epoch: 38, Loss: 0.0011121105635538697\n",
      "Epoch: 39, Loss: 0.0010544514516368508\n",
      "Epoch: 40, Loss: 0.0009695901535451412\n",
      "Epoch: 41, Loss: 0.0009421369177289307\n",
      "Epoch: 42, Loss: 0.0009222655207850039\n",
      "Epoch: 43, Loss: 0.0008037142688408494\n",
      "Epoch: 44, Loss: 0.0007335738628171384\n",
      "Epoch: 45, Loss: 0.000667596934363246\n",
      "Epoch: 46, Loss: 0.0005552488728426397\n",
      "Epoch: 47, Loss: 0.0005091105704195797\n",
      "Epoch: 48, Loss: 0.0004626946756616235\n",
      "Epoch: 49, Loss: 0.00035018750349991024\n",
      "Epoch: 50, Loss: 0.0003464838082436472\n",
      "________________________________________\n",
      "epoch 8 tensor([ 0.8517, -3.1617, -0.3023, -0.3920,  0.6936], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.12419543415307999\n",
      "Epoch: 2, Loss: 0.08430945128202438\n",
      "Epoch: 3, Loss: 0.06047217920422554\n",
      "Epoch: 4, Loss: 0.05660432204604149\n",
      "Epoch: 5, Loss: 0.056148748844861984\n",
      "Epoch: 6, Loss: 0.05437903106212616\n",
      "Epoch: 7, Loss: 0.049225062131881714\n",
      "Epoch: 8, Loss: 0.03784366697072983\n",
      "Epoch: 9, Loss: 0.02740689367055893\n",
      "Epoch: 10, Loss: 0.023470070213079453\n",
      "Epoch: 11, Loss: 0.02337624505162239\n",
      "Epoch: 12, Loss: 0.02346917614340782\n",
      "Epoch: 13, Loss: 0.022557849064469337\n",
      "Epoch: 14, Loss: 0.019295135512948036\n",
      "Epoch: 15, Loss: 0.013859114609658718\n",
      "Epoch: 16, Loss: 0.010109012015163898\n",
      "Epoch: 17, Loss: 0.009900283999741077\n",
      "Epoch: 18, Loss: 0.009950915351510048\n",
      "Epoch: 19, Loss: 0.008368084207177162\n",
      "Epoch: 20, Loss: 0.00621334183961153\n",
      "Epoch: 21, Loss: 0.004890906624495983\n",
      "Epoch: 22, Loss: 0.004589984193444252\n",
      "Epoch: 23, Loss: 0.004822758492082357\n",
      "Epoch: 24, Loss: 0.004784990567713976\n",
      "Epoch: 25, Loss: 0.004155950155109167\n",
      "Epoch: 26, Loss: 0.0035580832045525312\n",
      "Epoch: 27, Loss: 0.0033025341108441353\n",
      "Epoch: 28, Loss: 0.003085516393184662\n",
      "Epoch: 29, Loss: 0.002951723989099264\n",
      "Epoch: 30, Loss: 0.0029191961511969566\n",
      "Epoch: 31, Loss: 0.0025623843539506197\n",
      "Epoch: 32, Loss: 0.001872134511359036\n",
      "Epoch: 33, Loss: 0.001456026453524828\n",
      "Epoch: 34, Loss: 0.0015838886611163616\n",
      "Epoch: 35, Loss: 0.0018831907073035836\n",
      "Epoch: 36, Loss: 0.0018396340310573578\n",
      "Epoch: 37, Loss: 0.0014343109214678407\n",
      "Epoch: 38, Loss: 0.0010735186515375972\n",
      "Epoch: 39, Loss: 0.0010217331582680345\n",
      "Epoch: 40, Loss: 0.0011706266086548567\n",
      "Epoch: 41, Loss: 0.0011677886359393597\n",
      "Epoch: 42, Loss: 0.0009042397723533213\n",
      "Epoch: 43, Loss: 0.0006476625567302108\n",
      "Epoch: 44, Loss: 0.0005378075293265283\n",
      "Epoch: 45, Loss: 0.0004934603348374367\n",
      "Epoch: 46, Loss: 0.0005136952386237681\n",
      "Epoch: 47, Loss: 0.0005483790882863104\n",
      "Epoch: 48, Loss: 0.0004869009426329285\n",
      "Epoch: 49, Loss: 0.0003498552832752466\n",
      "Epoch: 50, Loss: 0.00025382055900990963\n",
      "epoch 8 tensor([ 0.7676, -2.7917, -0.2998, -0.2883,  0.6527], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.10569602251052856\n",
      "Epoch: 2, Loss: 0.08845091611146927\n",
      "Epoch: 3, Loss: 0.07108568400144577\n",
      "Epoch: 4, Loss: 0.05945445969700813\n",
      "Epoch: 5, Loss: 0.051066070795059204\n",
      "Epoch: 6, Loss: 0.04309485852718353\n",
      "Epoch: 7, Loss: 0.0349244624376297\n",
      "Epoch: 8, Loss: 0.027863195165991783\n",
      "Epoch: 9, Loss: 0.02399621531367302\n",
      "Epoch: 10, Loss: 0.020215922966599464\n",
      "Epoch: 11, Loss: 0.01723957434296608\n",
      "Epoch: 12, Loss: 0.015152143314480782\n",
      "Epoch: 13, Loss: 0.012983678840100765\n",
      "Epoch: 14, Loss: 0.010724147781729698\n",
      "Epoch: 15, Loss: 0.008573087863624096\n",
      "Epoch: 16, Loss: 0.007279622368514538\n",
      "Epoch: 17, Loss: 0.006552362348884344\n",
      "Epoch: 18, Loss: 0.006034256890416145\n",
      "Epoch: 19, Loss: 0.0056056915782392025\n",
      "Epoch: 20, Loss: 0.006003124639391899\n",
      "Epoch: 21, Loss: 0.006635947618633509\n",
      "Epoch: 22, Loss: 0.00639223912730813\n",
      "Epoch: 23, Loss: 0.0056326198391616344\n",
      "Epoch: 24, Loss: 0.004955871030688286\n",
      "Epoch: 25, Loss: 0.004806619603186846\n",
      "Epoch: 26, Loss: 0.004660927224904299\n",
      "Epoch: 27, Loss: 0.004222438670694828\n",
      "Epoch: 28, Loss: 0.0036647948436439037\n",
      "Epoch: 29, Loss: 0.0033689283300191164\n",
      "Epoch: 30, Loss: 0.003138938918709755\n",
      "Epoch: 31, Loss: 0.0029258111026138067\n",
      "Epoch: 32, Loss: 0.0027295255567878485\n",
      "Epoch: 33, Loss: 0.0024745999835431576\n",
      "Epoch: 34, Loss: 0.0021187784150242805\n",
      "Epoch: 35, Loss: 0.0017525136936455965\n",
      "Epoch: 36, Loss: 0.0014932501362636685\n",
      "Epoch: 37, Loss: 0.0013341348385438323\n",
      "Epoch: 38, Loss: 0.0011273527052253485\n",
      "Epoch: 39, Loss: 0.0009152357233688235\n",
      "Epoch: 40, Loss: 0.0007843577768653631\n",
      "Epoch: 41, Loss: 0.0007283780723810196\n",
      "Epoch: 42, Loss: 0.0006620498606935143\n",
      "Epoch: 43, Loss: 0.0005973184597678483\n",
      "Epoch: 44, Loss: 0.000559152802452445\n",
      "Epoch: 45, Loss: 0.0005324775702320039\n",
      "Epoch: 46, Loss: 0.0004828032397199422\n",
      "Epoch: 47, Loss: 0.0004378529265522957\n",
      "Epoch: 48, Loss: 0.0004015894955955446\n",
      "Epoch: 49, Loss: 0.0003573664289433509\n",
      "Epoch: 50, Loss: 0.00030835435609333217\n",
      "epoch 8 tensor([ 0.9445, -2.8444,  0.2263, -0.6202,  0.7265], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.08767519891262054\n",
      "Epoch: 2, Loss: 0.06192399933934212\n",
      "Epoch: 3, Loss: 0.044686220586299896\n",
      "Epoch: 4, Loss: 0.033654890954494476\n",
      "Epoch: 5, Loss: 0.026158349588513374\n",
      "Epoch: 6, Loss: 0.02441231906414032\n",
      "Epoch: 7, Loss: 0.02476932480931282\n",
      "Epoch: 8, Loss: 0.022323908284306526\n",
      "Epoch: 9, Loss: 0.017150480300188065\n",
      "Epoch: 10, Loss: 0.01331958919763565\n",
      "Epoch: 11, Loss: 0.012470199726521969\n",
      "Epoch: 12, Loss: 0.013558965176343918\n",
      "Epoch: 13, Loss: 0.01397781353443861\n",
      "Epoch: 14, Loss: 0.012441152706742287\n",
      "Epoch: 15, Loss: 0.010607663542032242\n",
      "Epoch: 16, Loss: 0.009447222575545311\n",
      "Epoch: 17, Loss: 0.007418970577418804\n",
      "Epoch: 18, Loss: 0.0053888107649981976\n",
      "Epoch: 19, Loss: 0.004868011921644211\n",
      "Epoch: 20, Loss: 0.0051686083897948265\n",
      "Epoch: 21, Loss: 0.004779363516718149\n",
      "Epoch: 22, Loss: 0.004025324713438749\n",
      "Epoch: 23, Loss: 0.0035258117131888866\n",
      "Epoch: 24, Loss: 0.0029005580581724644\n",
      "Epoch: 25, Loss: 0.0022433623671531677\n",
      "Epoch: 26, Loss: 0.002059214049950242\n",
      "Epoch: 27, Loss: 0.0020722360350191593\n",
      "Epoch: 28, Loss: 0.0020944729913026094\n",
      "Epoch: 29, Loss: 0.002110104076564312\n",
      "Epoch: 30, Loss: 0.0019562479574233294\n",
      "Epoch: 31, Loss: 0.001584711717441678\n",
      "Epoch: 32, Loss: 0.0012438487028703094\n",
      "Epoch: 33, Loss: 0.001181495375931263\n",
      "Epoch: 34, Loss: 0.0012626827228814363\n",
      "Epoch: 35, Loss: 0.0012024353491142392\n",
      "Epoch: 36, Loss: 0.0010673508513718843\n",
      "Epoch: 37, Loss: 0.0009404254960827529\n",
      "Epoch: 38, Loss: 0.0007795611745677888\n",
      "Epoch: 39, Loss: 0.0005733688012696803\n",
      "Epoch: 40, Loss: 0.0004492854932323098\n",
      "Epoch: 41, Loss: 0.00042392194154672325\n",
      "Epoch: 42, Loss: 0.00041363819036632776\n",
      "Epoch: 43, Loss: 0.00041096089989878237\n",
      "Epoch: 44, Loss: 0.0003628581471275538\n",
      "Epoch: 45, Loss: 0.00030766770942136645\n",
      "Epoch: 46, Loss: 0.00029832698055543005\n",
      "Epoch: 47, Loss: 0.0003202446678187698\n",
      "Epoch: 48, Loss: 0.0003202731895726174\n",
      "Epoch: 49, Loss: 0.00030475418316200376\n",
      "Epoch: 50, Loss: 0.0002895649231504649\n",
      "epoch 8 tensor([ 0.7942, -2.7985,  0.0683, -0.5452,  0.3886], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.07629550993442535\n",
      "Epoch: 2, Loss: 0.05655069276690483\n",
      "Epoch: 3, Loss: 0.04937209188938141\n",
      "Epoch: 4, Loss: 0.034843817353248596\n",
      "Epoch: 5, Loss: 0.029934991151094437\n",
      "Epoch: 6, Loss: 0.02759300172328949\n",
      "Epoch: 7, Loss: 0.019238371402025223\n",
      "Epoch: 8, Loss: 0.015825023874640465\n",
      "Epoch: 9, Loss: 0.015005323104560375\n",
      "Epoch: 10, Loss: 0.011272101663053036\n",
      "Epoch: 11, Loss: 0.010967433452606201\n",
      "Epoch: 12, Loss: 0.011422747746109962\n",
      "Epoch: 13, Loss: 0.008573867380619049\n",
      "Epoch: 14, Loss: 0.007555090822279453\n",
      "Epoch: 15, Loss: 0.00812647957354784\n",
      "Epoch: 16, Loss: 0.006558023858815432\n",
      "Epoch: 17, Loss: 0.006194646470248699\n",
      "Epoch: 18, Loss: 0.006636554375290871\n",
      "Epoch: 19, Loss: 0.005169455893337727\n",
      "Epoch: 20, Loss: 0.004580054432153702\n",
      "Epoch: 21, Loss: 0.00468924455344677\n",
      "Epoch: 22, Loss: 0.0037854225374758244\n",
      "Epoch: 23, Loss: 0.0037760776467621326\n",
      "Epoch: 24, Loss: 0.0039753238670527935\n",
      "Epoch: 25, Loss: 0.0033349834848195314\n",
      "Epoch: 26, Loss: 0.003027028404176235\n",
      "Epoch: 27, Loss: 0.0026381833013147116\n",
      "Epoch: 28, Loss: 0.0018105446361005306\n",
      "Epoch: 29, Loss: 0.0016343147726729512\n",
      "Epoch: 30, Loss: 0.0016575221670791507\n",
      "Epoch: 31, Loss: 0.001390440040268004\n",
      "Epoch: 32, Loss: 0.0015076511772349477\n",
      "Epoch: 33, Loss: 0.0014518643729388714\n",
      "Epoch: 34, Loss: 0.0012252528686076403\n",
      "Epoch: 35, Loss: 0.00120672513730824\n",
      "Epoch: 36, Loss: 0.0009550085524097085\n",
      "Epoch: 37, Loss: 0.0007767192437313497\n",
      "Epoch: 38, Loss: 0.0007595684146508574\n",
      "Epoch: 39, Loss: 0.0006002802983857691\n",
      "Epoch: 40, Loss: 0.000495232583489269\n",
      "Epoch: 41, Loss: 0.0004986526910215616\n",
      "Epoch: 42, Loss: 0.00043870945228263736\n",
      "Epoch: 43, Loss: 0.0004178073722869158\n",
      "Epoch: 44, Loss: 0.000369276269339025\n",
      "Epoch: 45, Loss: 0.0002598955179564655\n",
      "Epoch: 46, Loss: 0.0003121596819255501\n",
      "Epoch: 47, Loss: 0.0003279848024249077\n",
      "Epoch: 48, Loss: 0.0003216660406906158\n",
      "Epoch: 49, Loss: 0.0003153862780891359\n",
      "Epoch: 50, Loss: 0.00021878554252907634\n",
      "epoch 8 tensor([ 0.7817, -3.1838,  0.1290, -0.1620,  0.6165], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.03794240951538086\n",
      "Epoch: 2, Loss: 0.028956184163689613\n",
      "Epoch: 3, Loss: 0.022717533633112907\n",
      "Epoch: 4, Loss: 0.01545754075050354\n",
      "Epoch: 5, Loss: 0.013551655225455761\n",
      "Epoch: 6, Loss: 0.011860852129757404\n",
      "Epoch: 7, Loss: 0.009916281327605247\n",
      "Epoch: 8, Loss: 0.010776391252875328\n",
      "Epoch: 9, Loss: 0.010727874003350735\n",
      "Epoch: 10, Loss: 0.010050014592707157\n",
      "Epoch: 11, Loss: 0.009864878840744495\n",
      "Epoch: 12, Loss: 0.008238065056502819\n",
      "Epoch: 13, Loss: 0.007691319100558758\n",
      "Epoch: 14, Loss: 0.0064962804317474365\n",
      "Epoch: 15, Loss: 0.005168860778212547\n",
      "Epoch: 16, Loss: 0.004330743104219437\n",
      "Epoch: 17, Loss: 0.003748668823391199\n",
      "Epoch: 18, Loss: 0.003169306553900242\n",
      "Epoch: 19, Loss: 0.0033045196905732155\n",
      "Epoch: 20, Loss: 0.0028966162353754044\n",
      "Epoch: 21, Loss: 0.0025076805613934994\n",
      "Epoch: 22, Loss: 0.002355193020775914\n",
      "Epoch: 23, Loss: 0.0021326341666281223\n",
      "Epoch: 24, Loss: 0.0020035754423588514\n",
      "Epoch: 25, Loss: 0.001939231064170599\n",
      "Epoch: 26, Loss: 0.0014781407080590725\n",
      "Epoch: 27, Loss: 0.001108046853914857\n",
      "Epoch: 28, Loss: 0.000807864882517606\n",
      "Epoch: 29, Loss: 0.0008022981928661466\n",
      "Epoch: 30, Loss: 0.0010306693147867918\n",
      "Epoch: 31, Loss: 0.001145499525591731\n",
      "Epoch: 32, Loss: 0.0011217077262699604\n",
      "Epoch: 33, Loss: 0.0010690413182601333\n",
      "Epoch: 34, Loss: 0.0008844149997457862\n",
      "Epoch: 35, Loss: 0.000784210569690913\n",
      "Epoch: 36, Loss: 0.0006019697175361216\n",
      "Epoch: 37, Loss: 0.00045977949048392475\n",
      "Epoch: 38, Loss: 0.00043688013101927936\n",
      "Epoch: 39, Loss: 0.00044789473759010434\n",
      "Epoch: 40, Loss: 0.0004910021089017391\n",
      "Epoch: 41, Loss: 0.0004879574407823384\n",
      "Epoch: 42, Loss: 0.0004465267702471465\n",
      "Epoch: 43, Loss: 0.0004114245530217886\n",
      "Epoch: 44, Loss: 0.000343982974300161\n",
      "Epoch: 45, Loss: 0.00028509055846370757\n",
      "Epoch: 46, Loss: 0.00023795347078703344\n",
      "Epoch: 47, Loss: 0.00019730316125787795\n",
      "Epoch: 48, Loss: 0.00019633818010333925\n",
      "Epoch: 49, Loss: 0.00017467154248151928\n",
      "Epoch: 50, Loss: 0.00015848457405809313\n",
      "epoch 8 tensor([ 0.7594, -2.6170,  0.1290, -0.1118,  0.6714], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.09151692688465118\n",
      "Epoch: 2, Loss: 0.07394874840974808\n",
      "Epoch: 3, Loss: 0.060690876096487045\n",
      "Epoch: 4, Loss: 0.04956534877419472\n",
      "Epoch: 5, Loss: 0.0430058017373085\n",
      "Epoch: 6, Loss: 0.03575793653726578\n",
      "Epoch: 7, Loss: 0.03130299225449562\n",
      "Epoch: 8, Loss: 0.029254285618662834\n",
      "Epoch: 9, Loss: 0.027410702779889107\n",
      "Epoch: 10, Loss: 0.025943918153643608\n",
      "Epoch: 11, Loss: 0.023974986746907234\n",
      "Epoch: 12, Loss: 0.020779753103852272\n",
      "Epoch: 13, Loss: 0.017865633592009544\n",
      "Epoch: 14, Loss: 0.014996515586972237\n",
      "Epoch: 15, Loss: 0.013167815282940865\n",
      "Epoch: 16, Loss: 0.012177896685898304\n",
      "Epoch: 17, Loss: 0.010151326656341553\n",
      "Epoch: 18, Loss: 0.008145233616232872\n",
      "Epoch: 19, Loss: 0.006546013988554478\n",
      "Epoch: 20, Loss: 0.0060480209067463875\n",
      "Epoch: 21, Loss: 0.006119962781667709\n",
      "Epoch: 22, Loss: 0.00600331649184227\n",
      "Epoch: 23, Loss: 0.005689878482371569\n",
      "Epoch: 24, Loss: 0.005480813793838024\n",
      "Epoch: 25, Loss: 0.005380740389227867\n",
      "Epoch: 26, Loss: 0.0053073144517838955\n",
      "Epoch: 27, Loss: 0.004661751911044121\n",
      "Epoch: 28, Loss: 0.0038490763399749994\n",
      "Epoch: 29, Loss: 0.0031998902559280396\n",
      "Epoch: 30, Loss: 0.00286562810651958\n",
      "Epoch: 31, Loss: 0.0027374583296477795\n",
      "Epoch: 32, Loss: 0.0025682190898805857\n",
      "Epoch: 33, Loss: 0.002421934623271227\n",
      "Epoch: 34, Loss: 0.002219798043370247\n",
      "Epoch: 35, Loss: 0.002070653485134244\n",
      "Epoch: 36, Loss: 0.0018851490458473563\n",
      "Epoch: 37, Loss: 0.001689016236923635\n",
      "Epoch: 38, Loss: 0.0014879358932375908\n",
      "Epoch: 39, Loss: 0.0013048966648057103\n",
      "Epoch: 40, Loss: 0.0011454737978056073\n",
      "Epoch: 41, Loss: 0.0010479013435542583\n",
      "Epoch: 42, Loss: 0.000981937162578106\n",
      "Epoch: 43, Loss: 0.0008378222119063139\n",
      "Epoch: 44, Loss: 0.0007200621766969562\n",
      "Epoch: 45, Loss: 0.0006762598641216755\n",
      "Epoch: 46, Loss: 0.0006957994191907346\n",
      "Epoch: 47, Loss: 0.0006678223144263029\n",
      "Epoch: 48, Loss: 0.0006213739980012178\n",
      "Epoch: 49, Loss: 0.000584577617701143\n",
      "Epoch: 50, Loss: 0.0005320959608070552\n",
      "epoch 8 tensor([ 0.7734, -2.5645,  0.2642, -0.3654,  0.5872], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.19355398416519165\n",
      "Epoch: 2, Loss: 0.16584211587905884\n",
      "Epoch: 3, Loss: 0.14076411724090576\n",
      "Epoch: 4, Loss: 0.11453728377819061\n",
      "Epoch: 5, Loss: 0.09853329509496689\n",
      "Epoch: 6, Loss: 0.07903840392827988\n",
      "Epoch: 7, Loss: 0.06867315620183945\n",
      "Epoch: 8, Loss: 0.06344933807849884\n",
      "Epoch: 9, Loss: 0.058973368257284164\n",
      "Epoch: 10, Loss: 0.05767154321074486\n",
      "Epoch: 11, Loss: 0.053877681493759155\n",
      "Epoch: 12, Loss: 0.04810811206698418\n",
      "Epoch: 13, Loss: 0.043566569685935974\n",
      "Epoch: 14, Loss: 0.03750099241733551\n",
      "Epoch: 15, Loss: 0.030882662162184715\n",
      "Epoch: 16, Loss: 0.02613064832985401\n",
      "Epoch: 17, Loss: 0.021558575332164764\n",
      "Epoch: 18, Loss: 0.018734898418188095\n",
      "Epoch: 19, Loss: 0.016727035865187645\n",
      "Epoch: 20, Loss: 0.014185612089931965\n",
      "Epoch: 21, Loss: 0.012833149172365665\n",
      "Epoch: 22, Loss: 0.012360310181975365\n",
      "Epoch: 23, Loss: 0.01220136508345604\n",
      "Epoch: 24, Loss: 0.011727217584848404\n",
      "Epoch: 25, Loss: 0.010779944248497486\n",
      "Epoch: 26, Loss: 0.009634006768465042\n",
      "Epoch: 27, Loss: 0.008639175444841385\n",
      "Epoch: 28, Loss: 0.007717282045632601\n",
      "Epoch: 29, Loss: 0.006728242617100477\n",
      "Epoch: 30, Loss: 0.006075194105505943\n",
      "Epoch: 31, Loss: 0.005223339889198542\n",
      "Epoch: 32, Loss: 0.00462361890822649\n",
      "Epoch: 33, Loss: 0.0042833127081394196\n",
      "Epoch: 34, Loss: 0.0038701968733221292\n",
      "Epoch: 35, Loss: 0.0034353742375969887\n",
      "Epoch: 36, Loss: 0.0029524010606110096\n",
      "Epoch: 37, Loss: 0.0024970066733658314\n",
      "Epoch: 38, Loss: 0.002279010834172368\n",
      "Epoch: 39, Loss: 0.0019291697535663843\n",
      "Epoch: 40, Loss: 0.0014888541772961617\n",
      "Epoch: 41, Loss: 0.001148986048065126\n",
      "Epoch: 42, Loss: 0.0009226652910001576\n",
      "Epoch: 43, Loss: 0.0008662405889481306\n",
      "Epoch: 44, Loss: 0.0008161389268934727\n",
      "Epoch: 45, Loss: 0.0007522271480411291\n",
      "Epoch: 46, Loss: 0.0007015964365564287\n",
      "Epoch: 47, Loss: 0.0006103255436755717\n",
      "Epoch: 48, Loss: 0.0005563129670917988\n",
      "Epoch: 49, Loss: 0.0004943728563375771\n",
      "Epoch: 50, Loss: 0.00045493373181670904\n",
      "epoch 8 tensor([ 0.7692, -2.7306,  0.3515, -0.2830,  0.5251], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.057612352073192596\n",
      "Epoch: 2, Loss: 0.040190111845731735\n",
      "Epoch: 3, Loss: 0.023205388337373734\n",
      "Epoch: 4, Loss: 0.014652328565716743\n",
      "Epoch: 5, Loss: 0.01474786177277565\n",
      "Epoch: 6, Loss: 0.017065798863768578\n",
      "Epoch: 7, Loss: 0.017928503453731537\n",
      "Epoch: 8, Loss: 0.017098501324653625\n",
      "Epoch: 9, Loss: 0.014111817814409733\n",
      "Epoch: 10, Loss: 0.010487186722457409\n",
      "Epoch: 11, Loss: 0.007379717659205198\n",
      "Epoch: 12, Loss: 0.0068740020506083965\n",
      "Epoch: 13, Loss: 0.006557769607752562\n",
      "Epoch: 14, Loss: 0.0062032537534832954\n",
      "Epoch: 15, Loss: 0.0051234131678938866\n",
      "Epoch: 16, Loss: 0.00439199386164546\n",
      "Epoch: 17, Loss: 0.004180199932307005\n",
      "Epoch: 18, Loss: 0.004596896469593048\n",
      "Epoch: 19, Loss: 0.004691910929977894\n",
      "Epoch: 20, Loss: 0.004260747227817774\n",
      "Epoch: 21, Loss: 0.003572119865566492\n",
      "Epoch: 22, Loss: 0.002475092653185129\n",
      "Epoch: 23, Loss: 0.0019212127663195133\n",
      "Epoch: 24, Loss: 0.0017681604949757457\n",
      "Epoch: 25, Loss: 0.0021701857913285494\n",
      "Epoch: 26, Loss: 0.00249853590503335\n",
      "Epoch: 27, Loss: 0.002513158367946744\n",
      "Epoch: 28, Loss: 0.0019240990513935685\n",
      "Epoch: 29, Loss: 0.0012868769699707627\n",
      "Epoch: 30, Loss: 0.0007600486860610545\n",
      "Epoch: 31, Loss: 0.0006235584150999784\n",
      "Epoch: 32, Loss: 0.0007816873257979751\n",
      "Epoch: 33, Loss: 0.0009110122919082642\n",
      "Epoch: 34, Loss: 0.0009198950137943029\n",
      "Epoch: 35, Loss: 0.0008572068181820214\n",
      "Epoch: 36, Loss: 0.0007801965111866593\n",
      "Epoch: 37, Loss: 0.0006483590113930404\n",
      "Epoch: 38, Loss: 0.0005780810606665909\n",
      "Epoch: 39, Loss: 0.0005411863676272333\n",
      "Epoch: 40, Loss: 0.0005117200198583305\n",
      "Epoch: 41, Loss: 0.00041148634045384824\n",
      "Epoch: 42, Loss: 0.00033844876452349126\n",
      "Epoch: 43, Loss: 0.00030749026336707175\n",
      "Epoch: 44, Loss: 0.0003127446398139\n",
      "Epoch: 45, Loss: 0.0002806211996357888\n",
      "Epoch: 46, Loss: 0.00024309882428497076\n",
      "Epoch: 47, Loss: 0.00020030877203680575\n",
      "Epoch: 48, Loss: 0.00017463623953517526\n",
      "Epoch: 49, Loss: 0.00016016433073673397\n",
      "Epoch: 50, Loss: 0.00017110870976466686\n",
      "epoch 8 tensor([ 0.6387, -2.8872,  0.3612, -0.2006,  0.5146], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.10787805914878845\n",
      "Epoch: 2, Loss: 0.08559727668762207\n",
      "Epoch: 3, Loss: 0.06854378432035446\n",
      "Epoch: 4, Loss: 0.05472814664244652\n",
      "Epoch: 5, Loss: 0.04227583855390549\n",
      "Epoch: 6, Loss: 0.030557580292224884\n",
      "Epoch: 7, Loss: 0.02780338004231453\n",
      "Epoch: 8, Loss: 0.024172712117433548\n",
      "Epoch: 9, Loss: 0.022871842607855797\n",
      "Epoch: 10, Loss: 0.020732734352350235\n",
      "Epoch: 11, Loss: 0.016955964267253876\n",
      "Epoch: 12, Loss: 0.016636118292808533\n",
      "Epoch: 13, Loss: 0.015373319387435913\n",
      "Epoch: 14, Loss: 0.012627960182726383\n",
      "Epoch: 15, Loss: 0.011469247750937939\n",
      "Epoch: 16, Loss: 0.011348599568009377\n",
      "Epoch: 17, Loss: 0.011072316206991673\n",
      "Epoch: 18, Loss: 0.009626016952097416\n",
      "Epoch: 19, Loss: 0.00861747469753027\n",
      "Epoch: 20, Loss: 0.008040908724069595\n",
      "Epoch: 21, Loss: 0.006697544828057289\n",
      "Epoch: 22, Loss: 0.005414765328168869\n",
      "Epoch: 23, Loss: 0.004585945978760719\n",
      "Epoch: 24, Loss: 0.0036256196908652782\n",
      "Epoch: 25, Loss: 0.0035971319302916527\n",
      "Epoch: 26, Loss: 0.0031811136286705732\n",
      "Epoch: 27, Loss: 0.0027997016441076994\n",
      "Epoch: 28, Loss: 0.0027834177017211914\n",
      "Epoch: 29, Loss: 0.0026666533667594194\n",
      "Epoch: 30, Loss: 0.002562397625297308\n",
      "Epoch: 31, Loss: 0.0020668867509812117\n",
      "Epoch: 32, Loss: 0.0020678036380559206\n",
      "Epoch: 33, Loss: 0.0017355403397232294\n",
      "Epoch: 34, Loss: 0.0013363308971747756\n",
      "Epoch: 35, Loss: 0.0011972746578976512\n",
      "Epoch: 36, Loss: 0.0009685411932878196\n",
      "Epoch: 37, Loss: 0.0009451846708543599\n",
      "Epoch: 38, Loss: 0.000849038187880069\n",
      "Epoch: 39, Loss: 0.0008261097245849669\n",
      "Epoch: 40, Loss: 0.0007828049128875136\n",
      "Epoch: 41, Loss: 0.0007420488982461393\n",
      "Epoch: 42, Loss: 0.0006469919462688267\n",
      "Epoch: 43, Loss: 0.0005468185991048813\n",
      "Epoch: 44, Loss: 0.0006002201698720455\n",
      "Epoch: 45, Loss: 0.0005078092217445374\n",
      "Epoch: 46, Loss: 0.00045643761404789984\n",
      "Epoch: 47, Loss: 0.0004219774273224175\n",
      "Epoch: 48, Loss: 0.00040697024087421596\n",
      "Epoch: 49, Loss: 0.00034827098716050386\n",
      "Epoch: 50, Loss: 0.0002488011377863586\n",
      "epoch 8 tensor([ 0.7855, -2.9421,  0.4438, -0.2030,  0.3592], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.045091662555933\n",
      "Epoch: 2, Loss: 0.03524547070264816\n",
      "Epoch: 3, Loss: 0.028568338602781296\n",
      "Epoch: 4, Loss: 0.021489771082997322\n",
      "Epoch: 5, Loss: 0.01749643124639988\n",
      "Epoch: 6, Loss: 0.01711270399391651\n",
      "Epoch: 7, Loss: 0.014725366607308388\n",
      "Epoch: 8, Loss: 0.010019706562161446\n",
      "Epoch: 9, Loss: 0.009738825261592865\n",
      "Epoch: 10, Loss: 0.006467146798968315\n",
      "Epoch: 11, Loss: 0.006102259270846844\n",
      "Epoch: 12, Loss: 0.0059865135699510574\n",
      "Epoch: 13, Loss: 0.006032590754330158\n",
      "Epoch: 14, Loss: 0.005158490967005491\n",
      "Epoch: 15, Loss: 0.005251181311905384\n",
      "Epoch: 16, Loss: 0.005088448524475098\n",
      "Epoch: 17, Loss: 0.0035242042504251003\n",
      "Epoch: 18, Loss: 0.003925013355910778\n",
      "Epoch: 19, Loss: 0.003880848875269294\n",
      "Epoch: 20, Loss: 0.003623046213760972\n",
      "Epoch: 21, Loss: 0.003569475607946515\n",
      "Epoch: 22, Loss: 0.0032612041104584932\n",
      "Epoch: 23, Loss: 0.0025197311770170927\n",
      "Epoch: 24, Loss: 0.0018815253861248493\n",
      "Epoch: 25, Loss: 0.002084045670926571\n",
      "Epoch: 26, Loss: 0.0018345304997637868\n",
      "Epoch: 27, Loss: 0.001644832082092762\n",
      "Epoch: 28, Loss: 0.0016703936271369457\n",
      "Epoch: 29, Loss: 0.0013022503117099404\n",
      "Epoch: 30, Loss: 0.0011010929010808468\n",
      "Epoch: 31, Loss: 0.0010167836444452405\n",
      "Epoch: 32, Loss: 0.0009555889409966767\n",
      "Epoch: 33, Loss: 0.0008599553839303553\n",
      "Epoch: 34, Loss: 0.000927754445001483\n",
      "Epoch: 35, Loss: 0.0007938534836284816\n",
      "Epoch: 36, Loss: 0.0006166791426949203\n",
      "Epoch: 37, Loss: 0.0005539121921174228\n",
      "Epoch: 38, Loss: 0.00040524982614442706\n",
      "Epoch: 39, Loss: 0.0003657208289951086\n",
      "Epoch: 40, Loss: 0.00037739903200417757\n",
      "Epoch: 41, Loss: 0.0003205107059329748\n",
      "Epoch: 42, Loss: 0.0002608315262477845\n",
      "Epoch: 43, Loss: 0.0002578837738838047\n",
      "Epoch: 44, Loss: 0.00023631165095139295\n",
      "Epoch: 45, Loss: 0.00021030874631833285\n",
      "Epoch: 46, Loss: 0.00023524195421487093\n",
      "Epoch: 47, Loss: 0.00019353303650859743\n",
      "Epoch: 48, Loss: 0.0001886661339085549\n",
      "Epoch: 49, Loss: 0.0001964387047337368\n",
      "Epoch: 50, Loss: 0.0001474361924920231\n",
      "________________________________________\n",
      "epoch 9 tensor([ 0.7471, -2.8417,  0.4410, -0.2130,  0.2389], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.16478237509727478\n",
      "Epoch: 2, Loss: 0.10334330797195435\n",
      "Epoch: 3, Loss: 0.07391075789928436\n",
      "Epoch: 4, Loss: 0.0732913613319397\n",
      "Epoch: 5, Loss: 0.06190158426761627\n",
      "Epoch: 6, Loss: 0.05145835876464844\n",
      "Epoch: 7, Loss: 0.0467132143676281\n",
      "Epoch: 8, Loss: 0.039617132395505905\n",
      "Epoch: 9, Loss: 0.03213648870587349\n",
      "Epoch: 10, Loss: 0.03190590813755989\n",
      "Epoch: 11, Loss: 0.03469179943203926\n",
      "Epoch: 12, Loss: 0.031043969094753265\n",
      "Epoch: 13, Loss: 0.021965889260172844\n",
      "Epoch: 14, Loss: 0.015517116524279118\n",
      "Epoch: 15, Loss: 0.014644622802734375\n",
      "Epoch: 16, Loss: 0.015434457920491695\n",
      "Epoch: 17, Loss: 0.014391029253602028\n",
      "Epoch: 18, Loss: 0.012538918294012547\n",
      "Epoch: 19, Loss: 0.011453616432845592\n",
      "Epoch: 20, Loss: 0.010549279861152172\n",
      "Epoch: 21, Loss: 0.009221440181136131\n",
      "Epoch: 22, Loss: 0.007902550511062145\n",
      "Epoch: 23, Loss: 0.007576487492769957\n",
      "Epoch: 24, Loss: 0.007390601560473442\n",
      "Epoch: 25, Loss: 0.006580777000635862\n",
      "Epoch: 26, Loss: 0.005953541956841946\n",
      "Epoch: 27, Loss: 0.0057821013033390045\n",
      "Epoch: 28, Loss: 0.005486904177814722\n",
      "Epoch: 29, Loss: 0.004627481568604708\n",
      "Epoch: 30, Loss: 0.0035836007446050644\n",
      "Epoch: 31, Loss: 0.0031494093127548695\n",
      "Epoch: 32, Loss: 0.0031468647066503763\n",
      "Epoch: 33, Loss: 0.0028777956031262875\n",
      "Epoch: 34, Loss: 0.0025864294730126858\n",
      "Epoch: 35, Loss: 0.002510491292923689\n",
      "Epoch: 36, Loss: 0.0024707994889467955\n",
      "Epoch: 37, Loss: 0.0022207444999367\n",
      "Epoch: 38, Loss: 0.0018253326416015625\n",
      "Epoch: 39, Loss: 0.001639451365917921\n",
      "Epoch: 40, Loss: 0.0016253499779850245\n",
      "Epoch: 41, Loss: 0.0014400315703824162\n",
      "Epoch: 42, Loss: 0.001175723853521049\n",
      "Epoch: 43, Loss: 0.0010486558312550187\n",
      "Epoch: 44, Loss: 0.0010065711103379726\n",
      "Epoch: 45, Loss: 0.0009193733567371964\n",
      "Epoch: 46, Loss: 0.0008030679309740663\n",
      "Epoch: 47, Loss: 0.0007825435022823513\n",
      "Epoch: 48, Loss: 0.000808300799690187\n",
      "Epoch: 49, Loss: 0.0007823860505595803\n",
      "Epoch: 50, Loss: 0.0007298266864381731\n",
      "epoch 9 tensor([ 5.7878e-01, -2.6998e+00,  9.0778e-05, -1.2247e-01,  2.0759e-01],\n",
      "       grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.062475986778736115\n",
      "Epoch: 2, Loss: 0.04900931194424629\n",
      "Epoch: 3, Loss: 0.03573872894048691\n",
      "Epoch: 4, Loss: 0.028358235955238342\n",
      "Epoch: 5, Loss: 0.027302691712975502\n",
      "Epoch: 6, Loss: 0.0286499485373497\n",
      "Epoch: 7, Loss: 0.02773912623524666\n",
      "Epoch: 8, Loss: 0.024039842188358307\n",
      "Epoch: 9, Loss: 0.01883794739842415\n",
      "Epoch: 10, Loss: 0.014421889558434486\n",
      "Epoch: 11, Loss: 0.011877593584358692\n",
      "Epoch: 12, Loss: 0.011435077525675297\n",
      "Epoch: 13, Loss: 0.011918132193386555\n",
      "Epoch: 14, Loss: 0.011239022016525269\n",
      "Epoch: 15, Loss: 0.009265005588531494\n",
      "Epoch: 16, Loss: 0.007376429624855518\n",
      "Epoch: 17, Loss: 0.00630610715597868\n",
      "Epoch: 18, Loss: 0.006471733562648296\n",
      "Epoch: 19, Loss: 0.006967985536903143\n",
      "Epoch: 20, Loss: 0.00676074018701911\n",
      "Epoch: 21, Loss: 0.005823437590152025\n",
      "Epoch: 22, Loss: 0.004563906230032444\n",
      "Epoch: 23, Loss: 0.0036148058716207743\n",
      "Epoch: 24, Loss: 0.0032943093683570623\n",
      "Epoch: 25, Loss: 0.0035683743190020323\n",
      "Epoch: 26, Loss: 0.0037519880570471287\n",
      "Epoch: 27, Loss: 0.003266256535425782\n",
      "Epoch: 28, Loss: 0.0024453159421682358\n",
      "Epoch: 29, Loss: 0.0018276008777320385\n",
      "Epoch: 30, Loss: 0.001650574617087841\n",
      "Epoch: 31, Loss: 0.0016834790585562587\n",
      "Epoch: 32, Loss: 0.0016222272533923388\n",
      "Epoch: 33, Loss: 0.0013792985118925571\n",
      "Epoch: 34, Loss: 0.0010645949514582753\n",
      "Epoch: 35, Loss: 0.0008680581813678145\n",
      "Epoch: 36, Loss: 0.0008470461471006274\n",
      "Epoch: 37, Loss: 0.0009541168692521751\n",
      "Epoch: 38, Loss: 0.0009461835725232959\n",
      "Epoch: 39, Loss: 0.0007651151972822845\n",
      "Epoch: 40, Loss: 0.0005355696775950491\n",
      "Epoch: 41, Loss: 0.00042370479786768556\n",
      "Epoch: 42, Loss: 0.000464732846012339\n",
      "Epoch: 43, Loss: 0.0005310207488946617\n",
      "Epoch: 44, Loss: 0.0004934263415634632\n",
      "Epoch: 45, Loss: 0.0003854861715808511\n",
      "Epoch: 46, Loss: 0.00029929057927802205\n",
      "Epoch: 47, Loss: 0.0002690162800718099\n",
      "Epoch: 48, Loss: 0.0002841897658072412\n",
      "Epoch: 49, Loss: 0.0002857689105439931\n",
      "Epoch: 50, Loss: 0.0002401590027147904\n",
      "epoch 9 tensor([ 0.5021, -3.0424,  0.0217, -0.0681,  0.3773], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.032843176275491714\n",
      "Epoch: 2, Loss: 0.025485174730420113\n",
      "Epoch: 3, Loss: 0.020103655755519867\n",
      "Epoch: 4, Loss: 0.01824440062046051\n",
      "Epoch: 5, Loss: 0.01689927652478218\n",
      "Epoch: 6, Loss: 0.014847973361611366\n",
      "Epoch: 7, Loss: 0.012549709528684616\n",
      "Epoch: 8, Loss: 0.011439179070293903\n",
      "Epoch: 9, Loss: 0.010364043526351452\n",
      "Epoch: 10, Loss: 0.009368141181766987\n",
      "Epoch: 11, Loss: 0.009121165610849857\n",
      "Epoch: 12, Loss: 0.008745388127863407\n",
      "Epoch: 13, Loss: 0.007410115096718073\n",
      "Epoch: 14, Loss: 0.0057133459486067295\n",
      "Epoch: 15, Loss: 0.004790067207068205\n",
      "Epoch: 16, Loss: 0.004544959869235754\n",
      "Epoch: 17, Loss: 0.004641355946660042\n",
      "Epoch: 18, Loss: 0.004298818297684193\n",
      "Epoch: 19, Loss: 0.0033892146311700344\n",
      "Epoch: 20, Loss: 0.0024854668881744146\n",
      "Epoch: 21, Loss: 0.0021948926150798798\n",
      "Epoch: 22, Loss: 0.002193124732002616\n",
      "Epoch: 23, Loss: 0.002076117554679513\n",
      "Epoch: 24, Loss: 0.0018754347693175077\n",
      "Epoch: 25, Loss: 0.001610047067515552\n",
      "Epoch: 26, Loss: 0.0013861628249287605\n",
      "Epoch: 27, Loss: 0.0011959527619183064\n",
      "Epoch: 28, Loss: 0.0011156448163092136\n",
      "Epoch: 29, Loss: 0.0010385543573647738\n",
      "Epoch: 30, Loss: 0.000831793702673167\n",
      "Epoch: 31, Loss: 0.0006463737227022648\n",
      "Epoch: 32, Loss: 0.0005733823636546731\n",
      "Epoch: 33, Loss: 0.0005947825848124921\n",
      "Epoch: 34, Loss: 0.0006063386681489646\n",
      "Epoch: 35, Loss: 0.0005347758415155113\n",
      "Epoch: 36, Loss: 0.0004158669034950435\n",
      "Epoch: 37, Loss: 0.0003207968547940254\n",
      "Epoch: 38, Loss: 0.0002743354707490653\n",
      "Epoch: 39, Loss: 0.0002379596116952598\n",
      "Epoch: 40, Loss: 0.00022809053189121187\n",
      "Epoch: 41, Loss: 0.00023937113292049617\n",
      "Epoch: 42, Loss: 0.0002165609475923702\n",
      "Epoch: 43, Loss: 0.0001895183086162433\n",
      "Epoch: 44, Loss: 0.00020408023556228727\n",
      "Epoch: 45, Loss: 0.00021376906079240143\n",
      "Epoch: 46, Loss: 0.00017721571202855557\n",
      "Epoch: 47, Loss: 0.00013734668027609587\n",
      "Epoch: 48, Loss: 0.00011614862887654454\n",
      "Epoch: 49, Loss: 0.00010838987509487197\n",
      "Epoch: 50, Loss: 0.00011457505024736747\n",
      "epoch 9 tensor([ 0.5813, -2.7980, -0.1940, -0.1034,  0.3923], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.02115546725690365\n",
      "Epoch: 2, Loss: 0.014009258709847927\n",
      "Epoch: 3, Loss: 0.008444463834166527\n",
      "Epoch: 4, Loss: 0.008839443325996399\n",
      "Epoch: 5, Loss: 0.009542885236442089\n",
      "Epoch: 6, Loss: 0.009055767208337784\n",
      "Epoch: 7, Loss: 0.0067909834906458855\n",
      "Epoch: 8, Loss: 0.005359738599509001\n",
      "Epoch: 9, Loss: 0.00421232171356678\n",
      "Epoch: 10, Loss: 0.004911064635962248\n",
      "Epoch: 11, Loss: 0.005102004390209913\n",
      "Epoch: 12, Loss: 0.004543144255876541\n",
      "Epoch: 13, Loss: 0.0030001436825841665\n",
      "Epoch: 14, Loss: 0.002443908713757992\n",
      "Epoch: 15, Loss: 0.0025741099379956722\n",
      "Epoch: 16, Loss: 0.002983588958159089\n",
      "Epoch: 17, Loss: 0.0024645004887133837\n",
      "Epoch: 18, Loss: 0.001679791253991425\n",
      "Epoch: 19, Loss: 0.0010535642504692078\n",
      "Epoch: 20, Loss: 0.0009393385262228549\n",
      "Epoch: 21, Loss: 0.001264650491066277\n",
      "Epoch: 22, Loss: 0.0014247840736061335\n",
      "Epoch: 23, Loss: 0.0013135611079633236\n",
      "Epoch: 24, Loss: 0.0008601247682236135\n",
      "Epoch: 25, Loss: 0.0007085348479449749\n",
      "Epoch: 26, Loss: 0.0006972227129153907\n",
      "Epoch: 27, Loss: 0.0008640095475129783\n",
      "Epoch: 28, Loss: 0.0006850630161352456\n",
      "Epoch: 29, Loss: 0.0005012907204218209\n",
      "Epoch: 30, Loss: 0.0003281031677033752\n",
      "Epoch: 31, Loss: 0.00038617858081124723\n",
      "Epoch: 32, Loss: 0.00040105119114741683\n",
      "Epoch: 33, Loss: 0.0003835581010207534\n",
      "Epoch: 34, Loss: 0.0002948614419437945\n",
      "Epoch: 35, Loss: 0.0001952580496435985\n",
      "Epoch: 36, Loss: 0.0002036364166997373\n",
      "Epoch: 37, Loss: 0.00026104881544597447\n",
      "Epoch: 38, Loss: 0.0003152290591970086\n",
      "Epoch: 39, Loss: 0.00022123492090031505\n",
      "Epoch: 40, Loss: 0.00015567452646791935\n",
      "Epoch: 41, Loss: 0.00013897688768338412\n",
      "Epoch: 42, Loss: 0.00015992650878615677\n",
      "Epoch: 43, Loss: 0.00016173196490854025\n",
      "Epoch: 44, Loss: 0.0001299248542636633\n",
      "Epoch: 45, Loss: 0.00010555283370194957\n",
      "Epoch: 46, Loss: 9.035278344526887e-05\n",
      "Epoch: 47, Loss: 0.00010836833098437637\n",
      "Epoch: 48, Loss: 0.00010972034942824394\n",
      "Epoch: 49, Loss: 7.509381248382851e-05\n",
      "Epoch: 50, Loss: 6.557039159815758e-05\n",
      "epoch 9 tensor([ 0.6073, -2.6076, -0.0704, -0.2691,  0.3607], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.020405860617756844\n",
      "Epoch: 2, Loss: 0.014223789796233177\n",
      "Epoch: 3, Loss: 0.011149291880428791\n",
      "Epoch: 4, Loss: 0.008354999125003815\n",
      "Epoch: 5, Loss: 0.009175123646855354\n",
      "Epoch: 6, Loss: 0.006533404812216759\n",
      "Epoch: 7, Loss: 0.004790033679455519\n",
      "Epoch: 8, Loss: 0.004768695682287216\n",
      "Epoch: 9, Loss: 0.003631885629147291\n",
      "Epoch: 10, Loss: 0.0037841342855244875\n",
      "Epoch: 11, Loss: 0.0030140005983412266\n",
      "Epoch: 12, Loss: 0.0025988714769482613\n",
      "Epoch: 13, Loss: 0.0029461286030709743\n",
      "Epoch: 14, Loss: 0.0020181694999337196\n",
      "Epoch: 15, Loss: 0.0016253560315817595\n",
      "Epoch: 16, Loss: 0.0017846920527517796\n",
      "Epoch: 17, Loss: 0.0019979123026132584\n",
      "Epoch: 18, Loss: 0.0022727157920598984\n",
      "Epoch: 19, Loss: 0.0017260444583371282\n",
      "Epoch: 20, Loss: 0.0012366820592433214\n",
      "Epoch: 21, Loss: 0.0014220349257811904\n",
      "Epoch: 22, Loss: 0.0013523601228371263\n",
      "Epoch: 23, Loss: 0.001219748635776341\n",
      "Epoch: 24, Loss: 0.0009739029337652028\n",
      "Epoch: 25, Loss: 0.0007052443688735366\n",
      "Epoch: 26, Loss: 0.000817966996692121\n",
      "Epoch: 27, Loss: 0.000647371110972017\n",
      "Epoch: 28, Loss: 0.0005321599310263991\n",
      "Epoch: 29, Loss: 0.0005299524054862559\n",
      "Epoch: 30, Loss: 0.0004469954874366522\n",
      "Epoch: 31, Loss: 0.0004928857088088989\n",
      "Epoch: 32, Loss: 0.000343236664775759\n",
      "Epoch: 33, Loss: 0.00029728267691098154\n",
      "Epoch: 34, Loss: 0.00034598202910274267\n",
      "Epoch: 35, Loss: 0.00029446062399074435\n",
      "Epoch: 36, Loss: 0.00025974807795137167\n",
      "Epoch: 37, Loss: 0.0002188006037613377\n",
      "Epoch: 38, Loss: 0.000275618425803259\n",
      "Epoch: 39, Loss: 0.0002845599956344813\n",
      "Epoch: 40, Loss: 0.0002294748992426321\n",
      "Epoch: 41, Loss: 0.00018544863269198686\n",
      "Epoch: 42, Loss: 0.0001403498463332653\n",
      "Epoch: 43, Loss: 0.0001466484973207116\n",
      "Epoch: 44, Loss: 0.00012052238162141293\n",
      "Epoch: 45, Loss: 9.289190347772092e-05\n",
      "Epoch: 46, Loss: 9.201865032082424e-05\n",
      "Epoch: 47, Loss: 7.998707587830722e-05\n",
      "Epoch: 48, Loss: 8.576842083130032e-05\n",
      "Epoch: 49, Loss: 7.082948286551982e-05\n",
      "Epoch: 50, Loss: 7.908977568149567e-05\n",
      "epoch 9 tensor([ 0.5339, -2.7207, -0.1558, -0.1012,  0.2214], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.1523052453994751\n",
      "Epoch: 2, Loss: 0.1252770870923996\n",
      "Epoch: 3, Loss: 0.11195830255746841\n",
      "Epoch: 4, Loss: 0.10719368606805801\n",
      "Epoch: 5, Loss: 0.09862568229436874\n",
      "Epoch: 6, Loss: 0.09444406628608704\n",
      "Epoch: 7, Loss: 0.09237989783287048\n",
      "Epoch: 8, Loss: 0.08490000665187836\n",
      "Epoch: 9, Loss: 0.0797564759850502\n",
      "Epoch: 10, Loss: 0.07547032088041306\n",
      "Epoch: 11, Loss: 0.0725107491016388\n",
      "Epoch: 12, Loss: 0.06958861649036407\n",
      "Epoch: 13, Loss: 0.0650559663772583\n",
      "Epoch: 14, Loss: 0.06274924427270889\n",
      "Epoch: 15, Loss: 0.059360571205616\n",
      "Epoch: 16, Loss: 0.05628447234630585\n",
      "Epoch: 17, Loss: 0.052283383905887604\n",
      "Epoch: 18, Loss: 0.049709219485521317\n",
      "Epoch: 19, Loss: 0.047856416553258896\n",
      "Epoch: 20, Loss: 0.045475635677576065\n",
      "Epoch: 21, Loss: 0.04277406260371208\n",
      "Epoch: 22, Loss: 0.04034656658768654\n",
      "Epoch: 23, Loss: 0.03941119834780693\n",
      "Epoch: 24, Loss: 0.038379963487386703\n",
      "Epoch: 25, Loss: 0.03770308941602707\n",
      "Epoch: 26, Loss: 0.03716393560171127\n",
      "Epoch: 27, Loss: 0.03628607466816902\n",
      "Epoch: 28, Loss: 0.03487138822674751\n",
      "Epoch: 29, Loss: 0.03336503356695175\n",
      "Epoch: 30, Loss: 0.03298233449459076\n",
      "Epoch: 31, Loss: 0.03214938938617706\n",
      "Epoch: 32, Loss: 0.03159914165735245\n",
      "Epoch: 33, Loss: 0.030410928651690483\n",
      "Epoch: 34, Loss: 0.029578670859336853\n",
      "Epoch: 35, Loss: 0.02867795154452324\n",
      "Epoch: 36, Loss: 0.027398400008678436\n",
      "Epoch: 37, Loss: 0.026842033490538597\n",
      "Epoch: 38, Loss: 0.025866270065307617\n",
      "Epoch: 39, Loss: 0.024904321879148483\n",
      "Epoch: 40, Loss: 0.024366967380046844\n",
      "Epoch: 41, Loss: 0.023498723283410072\n",
      "Epoch: 42, Loss: 0.022715173661708832\n",
      "Epoch: 43, Loss: 0.022439701482653618\n",
      "Epoch: 44, Loss: 0.02168155275285244\n",
      "Epoch: 45, Loss: 0.021150195971131325\n",
      "Epoch: 46, Loss: 0.020812705159187317\n",
      "Epoch: 47, Loss: 0.019728444516658783\n",
      "Epoch: 48, Loss: 0.019301151856780052\n",
      "Epoch: 49, Loss: 0.01881318911910057\n",
      "Epoch: 50, Loss: 0.018274426460266113\n",
      "epoch 9 tensor([ 0.4465, -2.7583,  0.1451, -0.2108,  0.3493], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.034974582493305206\n",
      "Epoch: 2, Loss: 0.02929498441517353\n",
      "Epoch: 3, Loss: 0.024704352021217346\n",
      "Epoch: 4, Loss: 0.020610496401786804\n",
      "Epoch: 5, Loss: 0.017985451966524124\n",
      "Epoch: 6, Loss: 0.016970083117485046\n",
      "Epoch: 7, Loss: 0.015072591602802277\n",
      "Epoch: 8, Loss: 0.012739398516714573\n",
      "Epoch: 9, Loss: 0.0103633813560009\n",
      "Epoch: 10, Loss: 0.008161064237356186\n",
      "Epoch: 11, Loss: 0.007294254377484322\n",
      "Epoch: 12, Loss: 0.007243296131491661\n",
      "Epoch: 13, Loss: 0.006817839574068785\n",
      "Epoch: 14, Loss: 0.0061178868636488914\n",
      "Epoch: 15, Loss: 0.00557690067216754\n",
      "Epoch: 16, Loss: 0.005196469370275736\n",
      "Epoch: 17, Loss: 0.0050015258602797985\n",
      "Epoch: 18, Loss: 0.005030012223869562\n",
      "Epoch: 19, Loss: 0.004832252394407988\n",
      "Epoch: 20, Loss: 0.00441600289195776\n",
      "Epoch: 21, Loss: 0.004086190834641457\n",
      "Epoch: 22, Loss: 0.003652936778962612\n",
      "Epoch: 23, Loss: 0.0033033418003469706\n",
      "Epoch: 24, Loss: 0.003059759736061096\n",
      "Epoch: 25, Loss: 0.0025790890213102102\n",
      "Epoch: 26, Loss: 0.00211293320171535\n",
      "Epoch: 27, Loss: 0.0018123005283996463\n",
      "Epoch: 28, Loss: 0.0015491748927161098\n",
      "Epoch: 29, Loss: 0.0013554181205108762\n",
      "Epoch: 30, Loss: 0.001215339987538755\n",
      "Epoch: 31, Loss: 0.0011142485309392214\n",
      "Epoch: 32, Loss: 0.0010939018102362752\n",
      "Epoch: 33, Loss: 0.0011112266220152378\n",
      "Epoch: 34, Loss: 0.0010703338775783777\n",
      "Epoch: 35, Loss: 0.001036704401485622\n",
      "Epoch: 36, Loss: 0.0009467346826568246\n",
      "Epoch: 37, Loss: 0.0008233929984271526\n",
      "Epoch: 38, Loss: 0.000816610234323889\n",
      "Epoch: 39, Loss: 0.0008150645880959928\n",
      "Epoch: 40, Loss: 0.0007451826240867376\n",
      "Epoch: 41, Loss: 0.0006356861558742821\n",
      "Epoch: 42, Loss: 0.0005155099206604064\n",
      "Epoch: 43, Loss: 0.0004403857747092843\n",
      "Epoch: 44, Loss: 0.0003986260271631181\n",
      "Epoch: 45, Loss: 0.00037011210224591196\n",
      "Epoch: 46, Loss: 0.0003374246589373797\n",
      "Epoch: 47, Loss: 0.0002978825941681862\n",
      "Epoch: 48, Loss: 0.0002638667938299477\n",
      "Epoch: 49, Loss: 0.0002305128437001258\n",
      "Epoch: 50, Loss: 0.00022734003141522408\n",
      "epoch 9 tensor([ 0.4416, -2.7878, -0.2850, -0.1749,  0.3754], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.02815176174044609\n",
      "Epoch: 2, Loss: 0.021103201434016228\n",
      "Epoch: 3, Loss: 0.017018646001815796\n",
      "Epoch: 4, Loss: 0.011737427674233913\n",
      "Epoch: 5, Loss: 0.00994255393743515\n",
      "Epoch: 6, Loss: 0.007153832353651524\n",
      "Epoch: 7, Loss: 0.005533551797270775\n",
      "Epoch: 8, Loss: 0.004970991984009743\n",
      "Epoch: 9, Loss: 0.00461339158937335\n",
      "Epoch: 10, Loss: 0.004443327430635691\n",
      "Epoch: 11, Loss: 0.003906546626240015\n",
      "Epoch: 12, Loss: 0.0037126995157450438\n",
      "Epoch: 13, Loss: 0.0032912895549088717\n",
      "Epoch: 14, Loss: 0.003895463887602091\n",
      "Epoch: 15, Loss: 0.0038585644215345383\n",
      "Epoch: 16, Loss: 0.0035458472557365894\n",
      "Epoch: 17, Loss: 0.003302567405626178\n",
      "Epoch: 18, Loss: 0.002544596791267395\n",
      "Epoch: 19, Loss: 0.002231420250609517\n",
      "Epoch: 20, Loss: 0.001655386877246201\n",
      "Epoch: 21, Loss: 0.0014411949086934328\n",
      "Epoch: 22, Loss: 0.0012557834852486849\n",
      "Epoch: 23, Loss: 0.0010322482557967305\n",
      "Epoch: 24, Loss: 0.0009221512591466308\n",
      "Epoch: 25, Loss: 0.001035634079016745\n",
      "Epoch: 26, Loss: 0.0008500398835167289\n",
      "Epoch: 27, Loss: 0.0007754442049190402\n",
      "Epoch: 28, Loss: 0.0008092389907687902\n",
      "Epoch: 29, Loss: 0.0008024937706068158\n",
      "Epoch: 30, Loss: 0.0007174859056249261\n",
      "Epoch: 31, Loss: 0.0005988228949718177\n",
      "Epoch: 32, Loss: 0.0005357913905754685\n",
      "Epoch: 33, Loss: 0.0004902224754914641\n",
      "Epoch: 34, Loss: 0.0003749739262275398\n",
      "Epoch: 35, Loss: 0.00029152436763979495\n",
      "Epoch: 36, Loss: 0.0002574222453404218\n",
      "Epoch: 37, Loss: 0.0002770160208456218\n",
      "Epoch: 38, Loss: 0.00030446131131611764\n",
      "Epoch: 39, Loss: 0.000284468726022169\n",
      "Epoch: 40, Loss: 0.00026089572929777205\n",
      "Epoch: 41, Loss: 0.00026552448980510235\n",
      "Epoch: 42, Loss: 0.00023303691705223173\n",
      "Epoch: 43, Loss: 0.00021137174917384982\n",
      "Epoch: 44, Loss: 0.00015954460832290351\n",
      "Epoch: 45, Loss: 0.00013927705003879964\n",
      "Epoch: 46, Loss: 0.00011703254858730361\n",
      "Epoch: 47, Loss: 0.00010808629303937778\n",
      "Epoch: 48, Loss: 8.274212450487539e-05\n",
      "Epoch: 49, Loss: 6.248471618164331e-05\n",
      "Epoch: 50, Loss: 4.98865483677946e-05\n",
      "epoch 9 tensor([ 0.3336, -2.8252, -0.4370, -0.1639,  0.3530], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.04505690559744835\n",
      "Epoch: 2, Loss: 0.035359401255846024\n",
      "Epoch: 3, Loss: 0.028144596144557\n",
      "Epoch: 4, Loss: 0.023861410096287727\n",
      "Epoch: 5, Loss: 0.02160458266735077\n",
      "Epoch: 6, Loss: 0.018770059570670128\n",
      "Epoch: 7, Loss: 0.015119927003979683\n",
      "Epoch: 8, Loss: 0.012451902963221073\n",
      "Epoch: 9, Loss: 0.010702653788030148\n",
      "Epoch: 10, Loss: 0.008556571789085865\n",
      "Epoch: 11, Loss: 0.006174260284751654\n",
      "Epoch: 12, Loss: 0.005647779908031225\n",
      "Epoch: 13, Loss: 0.0053178369998931885\n",
      "Epoch: 14, Loss: 0.005852570757269859\n",
      "Epoch: 15, Loss: 0.005271786358207464\n",
      "Epoch: 16, Loss: 0.003977826330810785\n",
      "Epoch: 17, Loss: 0.00334174744784832\n",
      "Epoch: 18, Loss: 0.003270587418228388\n",
      "Epoch: 19, Loss: 0.002960929647088051\n",
      "Epoch: 20, Loss: 0.00249691610224545\n",
      "Epoch: 21, Loss: 0.0018308823928236961\n",
      "Epoch: 22, Loss: 0.0013141664676368237\n",
      "Epoch: 23, Loss: 0.0015195743180811405\n",
      "Epoch: 24, Loss: 0.0015620281919836998\n",
      "Epoch: 25, Loss: 0.0014749071560800076\n",
      "Epoch: 26, Loss: 0.0011975924717262387\n",
      "Epoch: 27, Loss: 0.0009563720086589456\n",
      "Epoch: 28, Loss: 0.0008641929016448557\n",
      "Epoch: 29, Loss: 0.0008148723863996565\n",
      "Epoch: 30, Loss: 0.0006812946521677077\n",
      "Epoch: 31, Loss: 0.0006145797087810934\n",
      "Epoch: 32, Loss: 0.0006348019815050066\n",
      "Epoch: 33, Loss: 0.000579371175263077\n",
      "Epoch: 34, Loss: 0.0004679954727180302\n",
      "Epoch: 35, Loss: 0.0003414805687498301\n",
      "Epoch: 36, Loss: 0.00029788806568831205\n",
      "Epoch: 37, Loss: 0.0003710217715706676\n",
      "Epoch: 38, Loss: 0.00038522505201399326\n",
      "Epoch: 39, Loss: 0.00037855771370232105\n",
      "Epoch: 40, Loss: 0.00030842155683785677\n",
      "Epoch: 41, Loss: 0.00029254695982672274\n",
      "Epoch: 42, Loss: 0.0002761353680398315\n",
      "Epoch: 43, Loss: 0.00023651868104934692\n",
      "Epoch: 44, Loss: 0.00018542385078035295\n",
      "Epoch: 45, Loss: 0.00015332153998315334\n",
      "Epoch: 46, Loss: 0.00014569764607585967\n",
      "Epoch: 47, Loss: 0.0001534907496534288\n",
      "Epoch: 48, Loss: 0.00012742199760396034\n",
      "Epoch: 49, Loss: 0.00010620227112667635\n",
      "Epoch: 50, Loss: 9.249940194422379e-05\n",
      "epoch 9 tensor([ 0.6951, -2.7972, -0.0668, -0.4296,  0.3005], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.12410653382539749\n",
      "Epoch: 2, Loss: 0.09333719313144684\n",
      "Epoch: 3, Loss: 0.07039040327072144\n",
      "Epoch: 4, Loss: 0.055409952998161316\n",
      "Epoch: 5, Loss: 0.043046288192272186\n",
      "Epoch: 6, Loss: 0.03390642628073692\n",
      "Epoch: 7, Loss: 0.02607496827840805\n",
      "Epoch: 8, Loss: 0.021471256390213966\n",
      "Epoch: 9, Loss: 0.020690517500042915\n",
      "Epoch: 10, Loss: 0.020863275974988937\n",
      "Epoch: 11, Loss: 0.019768206402659416\n",
      "Epoch: 12, Loss: 0.017957277595996857\n",
      "Epoch: 13, Loss: 0.01709994487464428\n",
      "Epoch: 14, Loss: 0.016067732125520706\n",
      "Epoch: 15, Loss: 0.015056920237839222\n",
      "Epoch: 16, Loss: 0.013874931260943413\n",
      "Epoch: 17, Loss: 0.0124702462926507\n",
      "Epoch: 18, Loss: 0.011048735119402409\n",
      "Epoch: 19, Loss: 0.009442437440156937\n",
      "Epoch: 20, Loss: 0.007921461015939713\n",
      "Epoch: 21, Loss: 0.006522857118397951\n",
      "Epoch: 22, Loss: 0.0053101410157978535\n",
      "Epoch: 23, Loss: 0.004643031861633062\n",
      "Epoch: 24, Loss: 0.004331283736974001\n",
      "Epoch: 25, Loss: 0.003850542940199375\n",
      "Epoch: 26, Loss: 0.0034472323022782803\n",
      "Epoch: 27, Loss: 0.0034955476876348257\n",
      "Epoch: 28, Loss: 0.0037019597366452217\n",
      "Epoch: 29, Loss: 0.0036235572770237923\n",
      "Epoch: 30, Loss: 0.0033251941204071045\n",
      "Epoch: 31, Loss: 0.002961442805826664\n",
      "Epoch: 32, Loss: 0.00248788483440876\n",
      "Epoch: 33, Loss: 0.0020182214211672544\n",
      "Epoch: 34, Loss: 0.001663646544329822\n",
      "Epoch: 35, Loss: 0.0013276017270982265\n",
      "Epoch: 36, Loss: 0.0010471086716279387\n",
      "Epoch: 37, Loss: 0.0008734797593206167\n",
      "Epoch: 38, Loss: 0.0008341622306033969\n",
      "Epoch: 39, Loss: 0.0008583543240092695\n",
      "Epoch: 40, Loss: 0.000797565036918968\n",
      "Epoch: 41, Loss: 0.0007174475467763841\n",
      "Epoch: 42, Loss: 0.0006955204880796373\n",
      "Epoch: 43, Loss: 0.0006963178748264909\n",
      "Epoch: 44, Loss: 0.0006723576225340366\n",
      "Epoch: 45, Loss: 0.0006025090697221458\n",
      "Epoch: 46, Loss: 0.000522899441421032\n",
      "Epoch: 47, Loss: 0.0004513172898441553\n",
      "Epoch: 48, Loss: 0.0003890208899974823\n",
      "Epoch: 49, Loss: 0.00030801002867519855\n",
      "Epoch: 50, Loss: 0.00023195575340650976\n",
      "________________________________________\n",
      "epoch 10 tensor([ 0.7150, -2.8833, -0.1465, -0.3548,  0.5517], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.126999631524086\n",
      "Epoch: 2, Loss: 0.10211532562971115\n",
      "Epoch: 3, Loss: 0.09714705497026443\n",
      "Epoch: 4, Loss: 0.07872085273265839\n",
      "Epoch: 5, Loss: 0.06662647426128387\n",
      "Epoch: 6, Loss: 0.06397882103919983\n",
      "Epoch: 7, Loss: 0.05992894247174263\n",
      "Epoch: 8, Loss: 0.05236908048391342\n",
      "Epoch: 9, Loss: 0.049098607152700424\n",
      "Epoch: 10, Loss: 0.04423457011580467\n",
      "Epoch: 11, Loss: 0.03970922902226448\n",
      "Epoch: 12, Loss: 0.036813534796237946\n",
      "Epoch: 13, Loss: 0.031709231436252594\n",
      "Epoch: 14, Loss: 0.03006599470973015\n",
      "Epoch: 15, Loss: 0.029367567971348763\n",
      "Epoch: 16, Loss: 0.02557617425918579\n",
      "Epoch: 17, Loss: 0.02325238659977913\n",
      "Epoch: 18, Loss: 0.02270907163619995\n",
      "Epoch: 19, Loss: 0.021028822287917137\n",
      "Epoch: 20, Loss: 0.018681760877370834\n",
      "Epoch: 21, Loss: 0.018614524975419044\n",
      "Epoch: 22, Loss: 0.018427148461341858\n",
      "Epoch: 23, Loss: 0.016328295692801476\n",
      "Epoch: 24, Loss: 0.015175138600170612\n",
      "Epoch: 25, Loss: 0.014880307018756866\n",
      "Epoch: 26, Loss: 0.01356581225991249\n",
      "Epoch: 27, Loss: 0.01246334332972765\n",
      "Epoch: 28, Loss: 0.012660431675612926\n",
      "Epoch: 29, Loss: 0.012179207056760788\n",
      "Epoch: 30, Loss: 0.0111094880849123\n",
      "Epoch: 31, Loss: 0.010681543499231339\n",
      "Epoch: 32, Loss: 0.010087307542562485\n",
      "Epoch: 33, Loss: 0.009162661619484425\n",
      "Epoch: 34, Loss: 0.008817564696073532\n",
      "Epoch: 35, Loss: 0.008586474694311619\n",
      "Epoch: 36, Loss: 0.007942315191030502\n",
      "Epoch: 37, Loss: 0.007492964155972004\n",
      "Epoch: 38, Loss: 0.007199261337518692\n",
      "Epoch: 39, Loss: 0.006636653561145067\n",
      "Epoch: 40, Loss: 0.006189827341586351\n",
      "Epoch: 41, Loss: 0.0059477705508470535\n",
      "Epoch: 42, Loss: 0.005476257763803005\n",
      "Epoch: 43, Loss: 0.0049891117960214615\n",
      "Epoch: 44, Loss: 0.00470120832324028\n",
      "Epoch: 45, Loss: 0.004366260953247547\n",
      "Epoch: 46, Loss: 0.004052094649523497\n",
      "Epoch: 47, Loss: 0.003906473983079195\n",
      "Epoch: 48, Loss: 0.0036884043365716934\n",
      "Epoch: 49, Loss: 0.0034262719564139843\n",
      "Epoch: 50, Loss: 0.003236133372411132\n",
      "epoch 10 tensor([ 0.6320, -2.6709,  0.4599, -0.6504,  0.3274], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.08194787800312042\n",
      "Epoch: 2, Loss: 0.06235358864068985\n",
      "Epoch: 3, Loss: 0.047741565853357315\n",
      "Epoch: 4, Loss: 0.037731751799583435\n",
      "Epoch: 5, Loss: 0.03401198238134384\n",
      "Epoch: 6, Loss: 0.030497485771775246\n",
      "Epoch: 7, Loss: 0.028066540136933327\n",
      "Epoch: 8, Loss: 0.024340840056538582\n",
      "Epoch: 9, Loss: 0.021331021562218666\n",
      "Epoch: 10, Loss: 0.0188957117497921\n",
      "Epoch: 11, Loss: 0.018861621618270874\n",
      "Epoch: 12, Loss: 0.018168345093727112\n",
      "Epoch: 13, Loss: 0.016686053946614265\n",
      "Epoch: 14, Loss: 0.016874153167009354\n",
      "Epoch: 15, Loss: 0.016454052180051804\n",
      "Epoch: 16, Loss: 0.015059646219015121\n",
      "Epoch: 17, Loss: 0.011952932924032211\n",
      "Epoch: 18, Loss: 0.009208790957927704\n",
      "Epoch: 19, Loss: 0.008121860213577747\n",
      "Epoch: 20, Loss: 0.0074169691652059555\n",
      "Epoch: 21, Loss: 0.007378889247775078\n",
      "Epoch: 22, Loss: 0.007095939479768276\n",
      "Epoch: 23, Loss: 0.006747428327798843\n",
      "Epoch: 24, Loss: 0.005877405405044556\n",
      "Epoch: 25, Loss: 0.005371127277612686\n",
      "Epoch: 26, Loss: 0.005202595144510269\n",
      "Epoch: 27, Loss: 0.004951661452651024\n",
      "Epoch: 28, Loss: 0.0045244754292070866\n",
      "Epoch: 29, Loss: 0.0038063866086304188\n",
      "Epoch: 30, Loss: 0.0033300581853836775\n",
      "Epoch: 31, Loss: 0.0027004193980246782\n",
      "Epoch: 32, Loss: 0.0022035951260477304\n",
      "Epoch: 33, Loss: 0.0018951722886413336\n",
      "Epoch: 34, Loss: 0.001922520692460239\n",
      "Epoch: 35, Loss: 0.0019803016912192106\n",
      "Epoch: 36, Loss: 0.0019104513339698315\n",
      "Epoch: 37, Loss: 0.001722484128549695\n",
      "Epoch: 38, Loss: 0.0014885000418871641\n",
      "Epoch: 39, Loss: 0.001287913415580988\n",
      "Epoch: 40, Loss: 0.0010407568188384175\n",
      "Epoch: 41, Loss: 0.0009461224544793367\n",
      "Epoch: 42, Loss: 0.0007880962803028524\n",
      "Epoch: 43, Loss: 0.0006669914000667632\n",
      "Epoch: 44, Loss: 0.0005746386013925076\n",
      "Epoch: 45, Loss: 0.0005103921284899116\n",
      "Epoch: 46, Loss: 0.00044094116310589015\n",
      "Epoch: 47, Loss: 0.0004534282779786736\n",
      "Epoch: 48, Loss: 0.00046965188812464476\n",
      "Epoch: 49, Loss: 0.00044697694829665124\n",
      "Epoch: 50, Loss: 0.00036962353624403477\n",
      "epoch 10 tensor([ 0.8108, -2.6896,  0.3887, -0.7309,  0.4188], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.04208008944988251\n",
      "Epoch: 2, Loss: 0.03306544944643974\n",
      "Epoch: 3, Loss: 0.026729615405201912\n",
      "Epoch: 4, Loss: 0.021885760128498077\n",
      "Epoch: 5, Loss: 0.020881200209259987\n",
      "Epoch: 6, Loss: 0.019128302112221718\n",
      "Epoch: 7, Loss: 0.016281308606266975\n",
      "Epoch: 8, Loss: 0.01308557391166687\n",
      "Epoch: 9, Loss: 0.010752593167126179\n",
      "Epoch: 10, Loss: 0.009624134749174118\n",
      "Epoch: 11, Loss: 0.00864462275058031\n",
      "Epoch: 12, Loss: 0.008779690600931644\n",
      "Epoch: 13, Loss: 0.008570092730224133\n",
      "Epoch: 14, Loss: 0.007681822869926691\n",
      "Epoch: 15, Loss: 0.006917229853570461\n",
      "Epoch: 16, Loss: 0.006061840802431107\n",
      "Epoch: 17, Loss: 0.005725666880607605\n",
      "Epoch: 18, Loss: 0.005450209602713585\n",
      "Epoch: 19, Loss: 0.004819838795810938\n",
      "Epoch: 20, Loss: 0.004217909183353186\n",
      "Epoch: 21, Loss: 0.0037360298447310925\n",
      "Epoch: 22, Loss: 0.003383854404091835\n",
      "Epoch: 23, Loss: 0.002970034722238779\n",
      "Epoch: 24, Loss: 0.0026546730659902096\n",
      "Epoch: 25, Loss: 0.0023009926080703735\n",
      "Epoch: 26, Loss: 0.0018772524781525135\n",
      "Epoch: 27, Loss: 0.0015244357055053115\n",
      "Epoch: 28, Loss: 0.0011239447630941868\n",
      "Epoch: 29, Loss: 0.0009988362435251474\n",
      "Epoch: 30, Loss: 0.0009760279790498316\n",
      "Epoch: 31, Loss: 0.0009511355892755091\n",
      "Epoch: 32, Loss: 0.0009651537402532995\n",
      "Epoch: 33, Loss: 0.000761069415602833\n",
      "Epoch: 34, Loss: 0.000626768043730408\n",
      "Epoch: 35, Loss: 0.0005355311441235244\n",
      "Epoch: 36, Loss: 0.00041298623546026647\n",
      "Epoch: 37, Loss: 0.00029444703250192106\n",
      "Epoch: 38, Loss: 0.0002583741443231702\n",
      "Epoch: 39, Loss: 0.00025249060126952827\n",
      "Epoch: 40, Loss: 0.00023103963758330792\n",
      "Epoch: 41, Loss: 0.000216723870835267\n",
      "Epoch: 42, Loss: 0.00019282166613265872\n",
      "Epoch: 43, Loss: 0.00021967450447846204\n",
      "Epoch: 44, Loss: 0.00021594723511952907\n",
      "Epoch: 45, Loss: 0.00023284168855752796\n",
      "Epoch: 46, Loss: 0.00021210544218774885\n",
      "Epoch: 47, Loss: 0.00017509843746665865\n",
      "Epoch: 48, Loss: 0.00016212310583796352\n",
      "Epoch: 49, Loss: 0.00015832010831218213\n",
      "Epoch: 50, Loss: 0.00014653088874183595\n",
      "epoch 10 tensor([ 0.7773, -2.6729,  0.1271, -0.5355,  0.4038], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.1712416708469391\n",
      "Epoch: 2, Loss: 0.13829614222049713\n",
      "Epoch: 3, Loss: 0.11250152438879013\n",
      "Epoch: 4, Loss: 0.08287850022315979\n",
      "Epoch: 5, Loss: 0.07025400549173355\n",
      "Epoch: 6, Loss: 0.06092296913266182\n",
      "Epoch: 7, Loss: 0.05187080800533295\n",
      "Epoch: 8, Loss: 0.044422321021556854\n",
      "Epoch: 9, Loss: 0.034642163664102554\n",
      "Epoch: 10, Loss: 0.028120260685682297\n",
      "Epoch: 11, Loss: 0.023759720847010612\n",
      "Epoch: 12, Loss: 0.018979955464601517\n",
      "Epoch: 13, Loss: 0.01740429922938347\n",
      "Epoch: 14, Loss: 0.016111308708786964\n",
      "Epoch: 15, Loss: 0.01325191929936409\n",
      "Epoch: 16, Loss: 0.011617520824074745\n",
      "Epoch: 17, Loss: 0.010633114725351334\n",
      "Epoch: 18, Loss: 0.009335611015558243\n",
      "Epoch: 19, Loss: 0.008436569944024086\n",
      "Epoch: 20, Loss: 0.00790832843631506\n",
      "Epoch: 21, Loss: 0.007918249815702438\n",
      "Epoch: 22, Loss: 0.007615648675709963\n",
      "Epoch: 23, Loss: 0.006310790777206421\n",
      "Epoch: 24, Loss: 0.005373498424887657\n",
      "Epoch: 25, Loss: 0.004758456256240606\n",
      "Epoch: 26, Loss: 0.0038487103302031755\n",
      "Epoch: 27, Loss: 0.0033676070161163807\n",
      "Epoch: 28, Loss: 0.0030586153734475374\n",
      "Epoch: 29, Loss: 0.0027617462910711765\n",
      "Epoch: 30, Loss: 0.0024139005690813065\n",
      "Epoch: 31, Loss: 0.001900139614008367\n",
      "Epoch: 32, Loss: 0.0018623374635353684\n",
      "Epoch: 33, Loss: 0.0019513726001605392\n",
      "Epoch: 34, Loss: 0.0018501677550375462\n",
      "Epoch: 35, Loss: 0.0017218079883605242\n",
      "Epoch: 36, Loss: 0.0013950398424640298\n",
      "Epoch: 37, Loss: 0.0010341013548895717\n",
      "Epoch: 38, Loss: 0.0007135652122087777\n",
      "Epoch: 39, Loss: 0.0005941417766734958\n",
      "Epoch: 40, Loss: 0.000724267796613276\n",
      "Epoch: 41, Loss: 0.0008602903108112514\n",
      "Epoch: 42, Loss: 0.0009947448270395398\n",
      "Epoch: 43, Loss: 0.0009448956698179245\n",
      "Epoch: 44, Loss: 0.0007805534987710416\n",
      "Epoch: 45, Loss: 0.0006440926808863878\n",
      "Epoch: 46, Loss: 0.0005095633678138256\n",
      "Epoch: 47, Loss: 0.0004786602803505957\n",
      "Epoch: 48, Loss: 0.0004383749910630286\n",
      "Epoch: 49, Loss: 0.00042197934817522764\n",
      "Epoch: 50, Loss: 0.0003575907030608505\n",
      "epoch 10 tensor([ 0.7423, -2.6473, -0.3447, -0.2447,  0.2945], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.09883750230073929\n",
      "Epoch: 2, Loss: 0.08372434973716736\n",
      "Epoch: 3, Loss: 0.07111312448978424\n",
      "Epoch: 4, Loss: 0.056382276117801666\n",
      "Epoch: 5, Loss: 0.04578857496380806\n",
      "Epoch: 6, Loss: 0.03733842074871063\n",
      "Epoch: 7, Loss: 0.029480405151844025\n",
      "Epoch: 8, Loss: 0.025936229154467583\n",
      "Epoch: 9, Loss: 0.023350877687335014\n",
      "Epoch: 10, Loss: 0.02166888304054737\n",
      "Epoch: 11, Loss: 0.02263902686536312\n",
      "Epoch: 12, Loss: 0.02255243808031082\n",
      "Epoch: 13, Loss: 0.020792311057448387\n",
      "Epoch: 14, Loss: 0.01976427622139454\n",
      "Epoch: 15, Loss: 0.01799655891954899\n",
      "Epoch: 16, Loss: 0.015403637662529945\n",
      "Epoch: 17, Loss: 0.013320393860340118\n",
      "Epoch: 18, Loss: 0.011389976367354393\n",
      "Epoch: 19, Loss: 0.009705493226647377\n",
      "Epoch: 20, Loss: 0.009138190187513828\n",
      "Epoch: 21, Loss: 0.008658850565552711\n",
      "Epoch: 22, Loss: 0.007700739428400993\n",
      "Epoch: 23, Loss: 0.006604138761758804\n",
      "Epoch: 24, Loss: 0.0053754872642457485\n",
      "Epoch: 25, Loss: 0.004484968259930611\n",
      "Epoch: 26, Loss: 0.003927695564925671\n",
      "Epoch: 27, Loss: 0.0032162184361368418\n",
      "Epoch: 28, Loss: 0.0026262260507792234\n",
      "Epoch: 29, Loss: 0.002508082427084446\n",
      "Epoch: 30, Loss: 0.0023435186594724655\n",
      "Epoch: 31, Loss: 0.0021800221875309944\n",
      "Epoch: 32, Loss: 0.0021395522635430098\n",
      "Epoch: 33, Loss: 0.001985684037208557\n",
      "Epoch: 34, Loss: 0.0017377323238179088\n",
      "Epoch: 35, Loss: 0.0014527164166793227\n",
      "Epoch: 36, Loss: 0.0011470135068520904\n",
      "Epoch: 37, Loss: 0.0008842655806802213\n",
      "Epoch: 38, Loss: 0.0006257269997149706\n",
      "Epoch: 39, Loss: 0.00048500788398087025\n",
      "Epoch: 40, Loss: 0.0005129289347678423\n",
      "Epoch: 41, Loss: 0.0005135517567396164\n",
      "Epoch: 42, Loss: 0.0004773017717525363\n",
      "Epoch: 43, Loss: 0.00047923921374604106\n",
      "Epoch: 44, Loss: 0.0004616905644070357\n",
      "Epoch: 45, Loss: 0.0004524661635514349\n",
      "Epoch: 46, Loss: 0.0004264993476681411\n",
      "Epoch: 47, Loss: 0.0004106588021386415\n",
      "Epoch: 48, Loss: 0.00040817350964061916\n",
      "Epoch: 49, Loss: 0.0003637245390564203\n",
      "Epoch: 50, Loss: 0.00032220102730207145\n",
      "epoch 10 tensor([ 0.6226, -2.5477, -0.5540, -0.4380,  0.6360], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.24115492403507233\n",
      "Epoch: 2, Loss: 0.1936139613389969\n",
      "Epoch: 3, Loss: 0.14914903044700623\n",
      "Epoch: 4, Loss: 0.12186262011528015\n",
      "Epoch: 5, Loss: 0.10493353754281998\n",
      "Epoch: 6, Loss: 0.09717113524675369\n",
      "Epoch: 7, Loss: 0.08696968853473663\n",
      "Epoch: 8, Loss: 0.07046112418174744\n",
      "Epoch: 9, Loss: 0.05363214388489723\n",
      "Epoch: 10, Loss: 0.0409943163394928\n",
      "Epoch: 11, Loss: 0.034169625490903854\n",
      "Epoch: 12, Loss: 0.033469781279563904\n",
      "Epoch: 13, Loss: 0.03541593998670578\n",
      "Epoch: 14, Loss: 0.03561835363507271\n",
      "Epoch: 15, Loss: 0.03308481350541115\n",
      "Epoch: 16, Loss: 0.02864753268659115\n",
      "Epoch: 17, Loss: 0.024659767746925354\n",
      "Epoch: 18, Loss: 0.022139782086014748\n",
      "Epoch: 19, Loss: 0.020931286737322807\n",
      "Epoch: 20, Loss: 0.02033338136970997\n",
      "Epoch: 21, Loss: 0.01886622980237007\n",
      "Epoch: 22, Loss: 0.016840284690260887\n",
      "Epoch: 23, Loss: 0.01425030454993248\n",
      "Epoch: 24, Loss: 0.011875536292791367\n",
      "Epoch: 25, Loss: 0.010331936180591583\n",
      "Epoch: 26, Loss: 0.009646994061768055\n",
      "Epoch: 27, Loss: 0.009437949396669865\n",
      "Epoch: 28, Loss: 0.009245166555047035\n",
      "Epoch: 29, Loss: 0.008707982487976551\n",
      "Epoch: 30, Loss: 0.007893465459346771\n",
      "Epoch: 31, Loss: 0.007130718789994717\n",
      "Epoch: 32, Loss: 0.006757702212780714\n",
      "Epoch: 33, Loss: 0.00665318826213479\n",
      "Epoch: 34, Loss: 0.006533215753734112\n",
      "Epoch: 35, Loss: 0.006219957489520311\n",
      "Epoch: 36, Loss: 0.005585911218076944\n",
      "Epoch: 37, Loss: 0.004780255723744631\n",
      "Epoch: 38, Loss: 0.0041098641231656075\n",
      "Epoch: 39, Loss: 0.0037469249218702316\n",
      "Epoch: 40, Loss: 0.0035343552008271217\n",
      "Epoch: 41, Loss: 0.0032681862358003855\n",
      "Epoch: 42, Loss: 0.0028636320494115353\n",
      "Epoch: 43, Loss: 0.0023453154135495424\n",
      "Epoch: 44, Loss: 0.001854320289567113\n",
      "Epoch: 45, Loss: 0.0015482092276215553\n",
      "Epoch: 46, Loss: 0.0014540065312758088\n",
      "Epoch: 47, Loss: 0.0014346967218443751\n",
      "Epoch: 48, Loss: 0.0013935513561591506\n",
      "Epoch: 49, Loss: 0.0012901091249659657\n",
      "Epoch: 50, Loss: 0.0011391345178708434\n",
      "epoch 10 tensor([ 0.5887, -2.7762, -0.1524, -0.3264,  0.3080], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.44053229689598083\n",
      "Epoch: 2, Loss: 0.3398127853870392\n",
      "Epoch: 3, Loss: 0.24059772491455078\n",
      "Epoch: 4, Loss: 0.1674576997756958\n",
      "Epoch: 5, Loss: 0.11985696107149124\n",
      "Epoch: 6, Loss: 0.08955135196447372\n",
      "Epoch: 7, Loss: 0.0790262296795845\n",
      "Epoch: 8, Loss: 0.08140186220407486\n",
      "Epoch: 9, Loss: 0.08322488516569138\n",
      "Epoch: 10, Loss: 0.07897504419088364\n",
      "Epoch: 11, Loss: 0.07363022118806839\n",
      "Epoch: 12, Loss: 0.0666881576180458\n",
      "Epoch: 13, Loss: 0.05878244340419769\n",
      "Epoch: 14, Loss: 0.050107475370168686\n",
      "Epoch: 15, Loss: 0.040904875844717026\n",
      "Epoch: 16, Loss: 0.03280004486441612\n",
      "Epoch: 17, Loss: 0.0260036401450634\n",
      "Epoch: 18, Loss: 0.020534388720989227\n",
      "Epoch: 19, Loss: 0.01729545369744301\n",
      "Epoch: 20, Loss: 0.017161142081022263\n",
      "Epoch: 21, Loss: 0.01836969703435898\n",
      "Epoch: 22, Loss: 0.01929120533168316\n",
      "Epoch: 23, Loss: 0.019486408680677414\n",
      "Epoch: 24, Loss: 0.018706757575273514\n",
      "Epoch: 25, Loss: 0.016666417941451073\n",
      "Epoch: 26, Loss: 0.013819541782140732\n",
      "Epoch: 27, Loss: 0.009981402195990086\n",
      "Epoch: 28, Loss: 0.007218627259135246\n",
      "Epoch: 29, Loss: 0.005525048356503248\n",
      "Epoch: 30, Loss: 0.004615133628249168\n",
      "Epoch: 31, Loss: 0.0045961723662912846\n",
      "Epoch: 32, Loss: 0.00484880618751049\n",
      "Epoch: 33, Loss: 0.005143017042428255\n",
      "Epoch: 34, Loss: 0.00535468477755785\n",
      "Epoch: 35, Loss: 0.005148908589035273\n",
      "Epoch: 36, Loss: 0.004480298608541489\n",
      "Epoch: 37, Loss: 0.00373061397112906\n",
      "Epoch: 38, Loss: 0.002793620340526104\n",
      "Epoch: 39, Loss: 0.002099010394886136\n",
      "Epoch: 40, Loss: 0.0016174076590687037\n",
      "Epoch: 41, Loss: 0.0012842471478506923\n",
      "Epoch: 42, Loss: 0.0012144759530201554\n",
      "Epoch: 43, Loss: 0.0011837788624688983\n",
      "Epoch: 44, Loss: 0.001288337749429047\n",
      "Epoch: 45, Loss: 0.0014103379799053073\n",
      "Epoch: 46, Loss: 0.0014026608550921082\n",
      "Epoch: 47, Loss: 0.0013498521875590086\n",
      "Epoch: 48, Loss: 0.0011923597194254398\n",
      "Epoch: 49, Loss: 0.0009479864966124296\n",
      "Epoch: 50, Loss: 0.0007272370276041329\n",
      "epoch 10 tensor([ 0.5139, -2.8471, -0.6238, -0.4135,  0.2666], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.10459822416305542\n",
      "Epoch: 2, Loss: 0.09204400330781937\n",
      "Epoch: 3, Loss: 0.07792007178068161\n",
      "Epoch: 4, Loss: 0.06585916876792908\n",
      "Epoch: 5, Loss: 0.05593444034457207\n",
      "Epoch: 6, Loss: 0.047856997698545456\n",
      "Epoch: 7, Loss: 0.041799139231443405\n",
      "Epoch: 8, Loss: 0.036800965666770935\n",
      "Epoch: 9, Loss: 0.03226102143526077\n",
      "Epoch: 10, Loss: 0.02831137925386429\n",
      "Epoch: 11, Loss: 0.025180049240589142\n",
      "Epoch: 12, Loss: 0.022260546684265137\n",
      "Epoch: 13, Loss: 0.019473979249596596\n",
      "Epoch: 14, Loss: 0.017684362828731537\n",
      "Epoch: 15, Loss: 0.016512485221028328\n",
      "Epoch: 16, Loss: 0.015224806033074856\n",
      "Epoch: 17, Loss: 0.013493048027157784\n",
      "Epoch: 18, Loss: 0.011765772476792336\n",
      "Epoch: 19, Loss: 0.01013074442744255\n",
      "Epoch: 20, Loss: 0.00879201851785183\n",
      "Epoch: 21, Loss: 0.00758018484339118\n",
      "Epoch: 22, Loss: 0.006672052666544914\n",
      "Epoch: 23, Loss: 0.005778074264526367\n",
      "Epoch: 24, Loss: 0.00480479933321476\n",
      "Epoch: 25, Loss: 0.004135445225983858\n",
      "Epoch: 26, Loss: 0.0038331025280058384\n",
      "Epoch: 27, Loss: 0.003654568688943982\n",
      "Epoch: 28, Loss: 0.003367240773513913\n",
      "Epoch: 29, Loss: 0.0029998221434652805\n",
      "Epoch: 30, Loss: 0.002606448018923402\n",
      "Epoch: 31, Loss: 0.0023298277519643307\n",
      "Epoch: 32, Loss: 0.00215728348121047\n",
      "Epoch: 33, Loss: 0.002051344607025385\n",
      "Epoch: 34, Loss: 0.0018971720710396767\n",
      "Epoch: 35, Loss: 0.0017397217452526093\n",
      "Epoch: 36, Loss: 0.001575140981003642\n",
      "Epoch: 37, Loss: 0.0014232732355594635\n",
      "Epoch: 38, Loss: 0.0013376404531300068\n",
      "Epoch: 39, Loss: 0.0013032379793003201\n",
      "Epoch: 40, Loss: 0.0012093386612832546\n",
      "Epoch: 41, Loss: 0.0010820163879543543\n",
      "Epoch: 42, Loss: 0.0010021381312981248\n",
      "Epoch: 43, Loss: 0.0008625441114418209\n",
      "Epoch: 44, Loss: 0.0007627502200193703\n",
      "Epoch: 45, Loss: 0.0007200698019005358\n",
      "Epoch: 46, Loss: 0.0006647807313129306\n",
      "Epoch: 47, Loss: 0.0006027207127772272\n",
      "Epoch: 48, Loss: 0.0005336586618795991\n",
      "Epoch: 49, Loss: 0.0004673417715821415\n",
      "Epoch: 50, Loss: 0.00044751024688594043\n",
      "epoch 10 tensor([ 0.8201, -2.8449, -0.6242, -0.4942,  0.5362], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.03739670664072037\n",
      "Epoch: 2, Loss: 0.032850444316864014\n",
      "Epoch: 3, Loss: 0.026943733915686607\n",
      "Epoch: 4, Loss: 0.021972043439745903\n",
      "Epoch: 5, Loss: 0.018545595929026604\n",
      "Epoch: 6, Loss: 0.01591956429183483\n",
      "Epoch: 7, Loss: 0.014293299987912178\n",
      "Epoch: 8, Loss: 0.012083065696060658\n",
      "Epoch: 9, Loss: 0.010593080893158913\n",
      "Epoch: 10, Loss: 0.009708150289952755\n",
      "Epoch: 11, Loss: 0.009023233316838741\n",
      "Epoch: 12, Loss: 0.00916478130966425\n",
      "Epoch: 13, Loss: 0.008991271257400513\n",
      "Epoch: 14, Loss: 0.009263008832931519\n",
      "Epoch: 15, Loss: 0.008575879968702793\n",
      "Epoch: 16, Loss: 0.00805525854229927\n",
      "Epoch: 17, Loss: 0.0070085711777210236\n",
      "Epoch: 18, Loss: 0.006265312898904085\n",
      "Epoch: 19, Loss: 0.005573631729930639\n",
      "Epoch: 20, Loss: 0.004998680204153061\n",
      "Epoch: 21, Loss: 0.004446725361049175\n",
      "Epoch: 22, Loss: 0.003914156462997198\n",
      "Epoch: 23, Loss: 0.0035137757658958435\n",
      "Epoch: 24, Loss: 0.0031225832644850016\n",
      "Epoch: 25, Loss: 0.0029515577480196953\n",
      "Epoch: 26, Loss: 0.002784197684377432\n",
      "Epoch: 27, Loss: 0.0026649481151252985\n",
      "Epoch: 28, Loss: 0.002523229457437992\n",
      "Epoch: 29, Loss: 0.002330236369743943\n",
      "Epoch: 30, Loss: 0.002181607997044921\n",
      "Epoch: 31, Loss: 0.0019657746888697147\n",
      "Epoch: 32, Loss: 0.001822753227315843\n",
      "Epoch: 33, Loss: 0.0016590383602306247\n",
      "Epoch: 34, Loss: 0.0015522486064583063\n",
      "Epoch: 35, Loss: 0.0013912433059886098\n",
      "Epoch: 36, Loss: 0.0012510488741099834\n",
      "Epoch: 37, Loss: 0.0010966453701257706\n",
      "Epoch: 38, Loss: 0.000992544461041689\n",
      "Epoch: 39, Loss: 0.0009331759065389633\n",
      "Epoch: 40, Loss: 0.0009042251040227711\n",
      "Epoch: 41, Loss: 0.0008606817573308945\n",
      "Epoch: 42, Loss: 0.0008192947716452181\n",
      "Epoch: 43, Loss: 0.0007296846597455442\n",
      "Epoch: 44, Loss: 0.0006666740518994629\n",
      "Epoch: 45, Loss: 0.0005726959789171815\n",
      "Epoch: 46, Loss: 0.0005331570864655077\n",
      "Epoch: 47, Loss: 0.0004650047922041267\n",
      "Epoch: 48, Loss: 0.0004135039052926004\n",
      "Epoch: 49, Loss: 0.0003399762499611825\n",
      "Epoch: 50, Loss: 0.00029252449166961014\n",
      "epoch 10 tensor([ 0.6171, -2.7854, -0.3779, -0.4913,  0.4063], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.04144813120365143\n",
      "Epoch: 2, Loss: 0.02923456020653248\n",
      "Epoch: 3, Loss: 0.026201216503977776\n",
      "Epoch: 4, Loss: 0.01733955182135105\n",
      "Epoch: 5, Loss: 0.019404461607336998\n",
      "Epoch: 6, Loss: 0.017091229557991028\n",
      "Epoch: 7, Loss: 0.01252076867967844\n",
      "Epoch: 8, Loss: 0.011830226518213749\n",
      "Epoch: 9, Loss: 0.008012373000383377\n",
      "Epoch: 10, Loss: 0.007384411059319973\n",
      "Epoch: 11, Loss: 0.008111530914902687\n",
      "Epoch: 12, Loss: 0.00548454187810421\n",
      "Epoch: 13, Loss: 0.005748940631747246\n",
      "Epoch: 14, Loss: 0.005804909393191338\n",
      "Epoch: 15, Loss: 0.004074022639542818\n",
      "Epoch: 16, Loss: 0.004622576292604208\n",
      "Epoch: 17, Loss: 0.0047747669741511345\n",
      "Epoch: 18, Loss: 0.0034028636291623116\n",
      "Epoch: 19, Loss: 0.003149541560560465\n",
      "Epoch: 20, Loss: 0.0030301781371235847\n",
      "Epoch: 21, Loss: 0.0024768102448433638\n",
      "Epoch: 22, Loss: 0.0026516031939536333\n",
      "Epoch: 23, Loss: 0.0027362764813005924\n",
      "Epoch: 24, Loss: 0.0020335069857537746\n",
      "Epoch: 25, Loss: 0.001668240875005722\n",
      "Epoch: 26, Loss: 0.0014845931436866522\n",
      "Epoch: 27, Loss: 0.001355794258415699\n",
      "Epoch: 28, Loss: 0.001519125304184854\n",
      "Epoch: 29, Loss: 0.0012559278402477503\n",
      "Epoch: 30, Loss: 0.0009470038348808885\n",
      "Epoch: 31, Loss: 0.0008568176417611539\n",
      "Epoch: 32, Loss: 0.0004955656477250159\n",
      "Epoch: 33, Loss: 0.00047693890519440174\n",
      "Epoch: 34, Loss: 0.0006611658027395606\n",
      "Epoch: 35, Loss: 0.0005170803051441908\n",
      "Epoch: 36, Loss: 0.0005549138295464218\n",
      "Epoch: 37, Loss: 0.0005163783789612353\n",
      "Epoch: 38, Loss: 0.0003047311620321125\n",
      "Epoch: 39, Loss: 0.00036107812775298953\n",
      "Epoch: 40, Loss: 0.00036094337701797485\n",
      "Epoch: 41, Loss: 0.00029142556013539433\n",
      "Epoch: 42, Loss: 0.00029049383010715246\n",
      "Epoch: 43, Loss: 0.00023216208501253277\n",
      "Epoch: 44, Loss: 0.00022579144570045173\n",
      "Epoch: 45, Loss: 0.00021574684069491923\n",
      "Epoch: 46, Loss: 0.0001980063389055431\n",
      "Epoch: 47, Loss: 0.00019941499340347946\n",
      "Epoch: 48, Loss: 0.00015694760077167302\n",
      "Epoch: 49, Loss: 0.00016758970741648227\n",
      "Epoch: 50, Loss: 0.00015441804134752601\n",
      "________________________________________\n",
      "epoch 11 tensor([ 0.5657, -2.5922, -0.5938, -0.2833,  0.3230], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.11730760335922241\n",
      "Epoch: 2, Loss: 0.07852640002965927\n",
      "Epoch: 3, Loss: 0.05401339381933212\n",
      "Epoch: 4, Loss: 0.04515973478555679\n",
      "Epoch: 5, Loss: 0.03957929462194443\n",
      "Epoch: 6, Loss: 0.0351116806268692\n",
      "Epoch: 7, Loss: 0.02959386073052883\n",
      "Epoch: 8, Loss: 0.025473788380622864\n",
      "Epoch: 9, Loss: 0.02227960154414177\n",
      "Epoch: 10, Loss: 0.017802128568291664\n",
      "Epoch: 11, Loss: 0.014265656471252441\n",
      "Epoch: 12, Loss: 0.015075773000717163\n",
      "Epoch: 13, Loss: 0.01733999513089657\n",
      "Epoch: 14, Loss: 0.016910027712583542\n",
      "Epoch: 15, Loss: 0.014072725549340248\n",
      "Epoch: 16, Loss: 0.010710150934755802\n",
      "Epoch: 17, Loss: 0.008876069448888302\n",
      "Epoch: 18, Loss: 0.008968671783804893\n",
      "Epoch: 19, Loss: 0.008809634484350681\n",
      "Epoch: 20, Loss: 0.00711057661101222\n",
      "Epoch: 21, Loss: 0.0055866180919110775\n",
      "Epoch: 22, Loss: 0.004508205223828554\n",
      "Epoch: 23, Loss: 0.0034549979027360678\n",
      "Epoch: 24, Loss: 0.0029223295859992504\n",
      "Epoch: 25, Loss: 0.0029542394913733006\n",
      "Epoch: 26, Loss: 0.0031225315760821104\n",
      "Epoch: 27, Loss: 0.0034407174680382013\n",
      "Epoch: 28, Loss: 0.0033732347656041384\n",
      "Epoch: 29, Loss: 0.0026739442255347967\n",
      "Epoch: 30, Loss: 0.002225471194833517\n",
      "Epoch: 31, Loss: 0.0022318661212921143\n",
      "Epoch: 32, Loss: 0.002129891887307167\n",
      "Epoch: 33, Loss: 0.0018985277274623513\n",
      "Epoch: 34, Loss: 0.0016338118584826589\n",
      "Epoch: 35, Loss: 0.0012899526627734303\n",
      "Epoch: 36, Loss: 0.0010873139835894108\n",
      "Epoch: 37, Loss: 0.0010193982161581516\n",
      "Epoch: 38, Loss: 0.0010390491224825382\n",
      "Epoch: 39, Loss: 0.001132186152972281\n",
      "Epoch: 40, Loss: 0.0010648730676621199\n",
      "Epoch: 41, Loss: 0.0007999925874173641\n",
      "Epoch: 42, Loss: 0.0005999121931381524\n",
      "Epoch: 43, Loss: 0.0005014585913158953\n",
      "Epoch: 44, Loss: 0.0004973187460564077\n",
      "Epoch: 45, Loss: 0.0005574284004978836\n",
      "Epoch: 46, Loss: 0.0005368235870264471\n",
      "Epoch: 47, Loss: 0.00044119477388449013\n",
      "Epoch: 48, Loss: 0.00033548512146808207\n",
      "Epoch: 49, Loss: 0.0002257718297187239\n",
      "Epoch: 50, Loss: 0.00022689640172757208\n",
      "epoch 11 tensor([ 0.5810, -2.2578, -0.2098, -0.2419,  0.4998], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.06846588104963303\n",
      "Epoch: 2, Loss: 0.059438154101371765\n",
      "Epoch: 3, Loss: 0.04894039034843445\n",
      "Epoch: 4, Loss: 0.039924584329128265\n",
      "Epoch: 5, Loss: 0.033818673342466354\n",
      "Epoch: 6, Loss: 0.02910756878554821\n",
      "Epoch: 7, Loss: 0.026347029954195023\n",
      "Epoch: 8, Loss: 0.02279009111225605\n",
      "Epoch: 9, Loss: 0.020005129277706146\n",
      "Epoch: 10, Loss: 0.017067063599824905\n",
      "Epoch: 11, Loss: 0.014613530598580837\n",
      "Epoch: 12, Loss: 0.012616267427802086\n",
      "Epoch: 13, Loss: 0.010808692313730717\n",
      "Epoch: 14, Loss: 0.009752066805958748\n",
      "Epoch: 15, Loss: 0.008793114684522152\n",
      "Epoch: 16, Loss: 0.008118053898215294\n",
      "Epoch: 17, Loss: 0.007123993709683418\n",
      "Epoch: 18, Loss: 0.0058368053287267685\n",
      "Epoch: 19, Loss: 0.0047254059463739395\n",
      "Epoch: 20, Loss: 0.003870963817462325\n",
      "Epoch: 21, Loss: 0.0031216428615152836\n",
      "Epoch: 22, Loss: 0.0026873350143432617\n",
      "Epoch: 23, Loss: 0.002422543242573738\n",
      "Epoch: 24, Loss: 0.0023301532492041588\n",
      "Epoch: 25, Loss: 0.0022796792909502983\n",
      "Epoch: 26, Loss: 0.002013183431699872\n",
      "Epoch: 27, Loss: 0.0017843067180365324\n",
      "Epoch: 28, Loss: 0.0017020510276779532\n",
      "Epoch: 29, Loss: 0.0014886991120874882\n",
      "Epoch: 30, Loss: 0.0013030058471485972\n",
      "Epoch: 31, Loss: 0.0010179559467360377\n",
      "Epoch: 32, Loss: 0.0009243181557394564\n",
      "Epoch: 33, Loss: 0.0008442495600320399\n",
      "Epoch: 34, Loss: 0.0006912642857059836\n",
      "Epoch: 35, Loss: 0.0006585065857507288\n",
      "Epoch: 36, Loss: 0.0006146116065792739\n",
      "Epoch: 37, Loss: 0.0005909265018999577\n",
      "Epoch: 38, Loss: 0.0005116209504194558\n",
      "Epoch: 39, Loss: 0.0004633916250895709\n",
      "Epoch: 40, Loss: 0.00042517419205978513\n",
      "Epoch: 41, Loss: 0.00037870192318223417\n",
      "Epoch: 42, Loss: 0.00036239632754586637\n",
      "Epoch: 43, Loss: 0.0003605696838349104\n",
      "Epoch: 44, Loss: 0.0003551920526660979\n",
      "Epoch: 45, Loss: 0.00032520416425541043\n",
      "Epoch: 46, Loss: 0.00027249756385572255\n",
      "Epoch: 47, Loss: 0.00024171896802727133\n",
      "Epoch: 48, Loss: 0.00020179497369099408\n",
      "Epoch: 49, Loss: 0.0001842040364863351\n",
      "Epoch: 50, Loss: 0.00016943285299930722\n",
      "epoch 11 tensor([ 0.5630, -2.2860, -0.6399, -0.5384,  0.7450], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.022888679057359695\n",
      "Epoch: 2, Loss: 0.016700563952326775\n",
      "Epoch: 3, Loss: 0.011220189742743969\n",
      "Epoch: 4, Loss: 0.009752612560987473\n",
      "Epoch: 5, Loss: 0.010578484274446964\n",
      "Epoch: 6, Loss: 0.007841306738555431\n",
      "Epoch: 7, Loss: 0.007748614996671677\n",
      "Epoch: 8, Loss: 0.007888002321124077\n",
      "Epoch: 9, Loss: 0.006405014544725418\n",
      "Epoch: 10, Loss: 0.00568042928352952\n",
      "Epoch: 11, Loss: 0.0035427105613052845\n",
      "Epoch: 12, Loss: 0.0029073304031044245\n",
      "Epoch: 13, Loss: 0.002248232252895832\n",
      "Epoch: 14, Loss: 0.003144032321870327\n",
      "Epoch: 15, Loss: 0.0027043086010962725\n",
      "Epoch: 16, Loss: 0.0024612760171294212\n",
      "Epoch: 17, Loss: 0.002058898564428091\n",
      "Epoch: 18, Loss: 0.0023070890456438065\n",
      "Epoch: 19, Loss: 0.001962094334885478\n",
      "Epoch: 20, Loss: 0.0015609366819262505\n",
      "Epoch: 21, Loss: 0.001385666080750525\n",
      "Epoch: 22, Loss: 0.0013571179006248713\n",
      "Epoch: 23, Loss: 0.0015218571061268449\n",
      "Epoch: 24, Loss: 0.0013842832995578647\n",
      "Epoch: 25, Loss: 0.0012154695577919483\n",
      "Epoch: 26, Loss: 0.0008496259688399732\n",
      "Epoch: 27, Loss: 0.0008471296750940382\n",
      "Epoch: 28, Loss: 0.0008243429474532604\n",
      "Epoch: 29, Loss: 0.0008081505657173693\n",
      "Epoch: 30, Loss: 0.00058185332454741\n",
      "Epoch: 31, Loss: 0.0005221817409619689\n",
      "Epoch: 32, Loss: 0.0005452041514217854\n",
      "Epoch: 33, Loss: 0.0004370259412098676\n",
      "Epoch: 34, Loss: 0.0003057231369893998\n",
      "Epoch: 35, Loss: 0.0002752512227743864\n",
      "Epoch: 36, Loss: 0.0003474914701655507\n",
      "Epoch: 37, Loss: 0.0002989013446494937\n",
      "Epoch: 38, Loss: 0.00030025895102880895\n",
      "Epoch: 39, Loss: 0.00024339616356883198\n",
      "Epoch: 40, Loss: 0.00021003108122386038\n",
      "Epoch: 41, Loss: 0.0001961852831300348\n",
      "Epoch: 42, Loss: 0.0001300393050769344\n",
      "Epoch: 43, Loss: 0.00013628200395032763\n",
      "Epoch: 44, Loss: 0.00013422385382000357\n",
      "Epoch: 45, Loss: 0.0001514563919045031\n",
      "Epoch: 46, Loss: 0.00011604658357100561\n",
      "Epoch: 47, Loss: 7.99514600657858e-05\n",
      "Epoch: 48, Loss: 7.231350900838152e-05\n",
      "Epoch: 49, Loss: 7.014189031906426e-05\n",
      "Epoch: 50, Loss: 5.7104331062873825e-05\n",
      "epoch 11 tensor([ 0.5521, -2.2325, -0.4421, -0.3285,  0.6189], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.05605725944042206\n",
      "Epoch: 2, Loss: 0.041793812066316605\n",
      "Epoch: 3, Loss: 0.03152494877576828\n",
      "Epoch: 4, Loss: 0.0265143271535635\n",
      "Epoch: 5, Loss: 0.023880960419774055\n",
      "Epoch: 6, Loss: 0.02077002264559269\n",
      "Epoch: 7, Loss: 0.015919853001832962\n",
      "Epoch: 8, Loss: 0.012035209685564041\n",
      "Epoch: 9, Loss: 0.009758256375789642\n",
      "Epoch: 10, Loss: 0.007714375853538513\n",
      "Epoch: 11, Loss: 0.008383890613913536\n",
      "Epoch: 12, Loss: 0.007942765019834042\n",
      "Epoch: 13, Loss: 0.006871853955090046\n",
      "Epoch: 14, Loss: 0.005655818618834019\n",
      "Epoch: 15, Loss: 0.0051940204575657845\n",
      "Epoch: 16, Loss: 0.004258858505636454\n",
      "Epoch: 17, Loss: 0.003684922121465206\n",
      "Epoch: 18, Loss: 0.00298150978051126\n",
      "Epoch: 19, Loss: 0.0028968655969947577\n",
      "Epoch: 20, Loss: 0.0030093351379036903\n",
      "Epoch: 21, Loss: 0.002399194985628128\n",
      "Epoch: 22, Loss: 0.0019954286981374025\n",
      "Epoch: 23, Loss: 0.0016607455909252167\n",
      "Epoch: 24, Loss: 0.0016477740136906505\n",
      "Epoch: 25, Loss: 0.0013627108419314027\n",
      "Epoch: 26, Loss: 0.0013796233106404543\n",
      "Epoch: 27, Loss: 0.0012023368617519736\n",
      "Epoch: 28, Loss: 0.0010565868578851223\n",
      "Epoch: 29, Loss: 0.0008001219248399138\n",
      "Epoch: 30, Loss: 0.000852011376991868\n",
      "Epoch: 31, Loss: 0.0009210300631821156\n",
      "Epoch: 32, Loss: 0.0010259392438456416\n",
      "Epoch: 33, Loss: 0.0008260658942162991\n",
      "Epoch: 34, Loss: 0.0007764282054267824\n",
      "Epoch: 35, Loss: 0.0006531902472488582\n",
      "Epoch: 36, Loss: 0.0005880377721041441\n",
      "Epoch: 37, Loss: 0.00043658536742441356\n",
      "Epoch: 38, Loss: 0.00044075321056880057\n",
      "Epoch: 39, Loss: 0.0003716095525305718\n",
      "Epoch: 40, Loss: 0.00035540052340365946\n",
      "Epoch: 41, Loss: 0.00027918111300095916\n",
      "Epoch: 42, Loss: 0.00026030768640339375\n",
      "Epoch: 43, Loss: 0.000242844398599118\n",
      "Epoch: 44, Loss: 0.0002725317608565092\n",
      "Epoch: 45, Loss: 0.00024113901599776\n",
      "Epoch: 46, Loss: 0.00020877640054095536\n",
      "Epoch: 47, Loss: 0.00015080548473633826\n",
      "Epoch: 48, Loss: 0.00011183614697074518\n",
      "Epoch: 49, Loss: 0.0001120951710618101\n",
      "Epoch: 50, Loss: 0.00011902440019184723\n",
      "epoch 11 tensor([ 0.6244, -2.1780, -0.4953, -0.3462,  0.4654], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.039307430386543274\n",
      "Epoch: 2, Loss: 0.030654797330498695\n",
      "Epoch: 3, Loss: 0.023880019783973694\n",
      "Epoch: 4, Loss: 0.01565483957529068\n",
      "Epoch: 5, Loss: 0.012663234025239944\n",
      "Epoch: 6, Loss: 0.009908998385071754\n",
      "Epoch: 7, Loss: 0.009387930855154991\n",
      "Epoch: 8, Loss: 0.007972927764058113\n",
      "Epoch: 9, Loss: 0.006873801350593567\n",
      "Epoch: 10, Loss: 0.006555229891091585\n",
      "Epoch: 11, Loss: 0.006395880598574877\n",
      "Epoch: 12, Loss: 0.005712647456675768\n",
      "Epoch: 13, Loss: 0.004587831441313028\n",
      "Epoch: 14, Loss: 0.0047048600390553474\n",
      "Epoch: 15, Loss: 0.004041377454996109\n",
      "Epoch: 16, Loss: 0.0032849048729985952\n",
      "Epoch: 17, Loss: 0.003052889136597514\n",
      "Epoch: 18, Loss: 0.0026378356851637363\n",
      "Epoch: 19, Loss: 0.002866271184757352\n",
      "Epoch: 20, Loss: 0.0029251330997794867\n",
      "Epoch: 21, Loss: 0.0026509142480790615\n",
      "Epoch: 22, Loss: 0.002376373391598463\n",
      "Epoch: 23, Loss: 0.0018468624912202358\n",
      "Epoch: 24, Loss: 0.0018301274394616485\n",
      "Epoch: 25, Loss: 0.001714030047878623\n",
      "Epoch: 26, Loss: 0.0013672910863533616\n",
      "Epoch: 27, Loss: 0.0011301718186587095\n",
      "Epoch: 28, Loss: 0.0009054488036781549\n",
      "Epoch: 29, Loss: 0.0009175828308798373\n",
      "Epoch: 30, Loss: 0.0009272296447306871\n",
      "Epoch: 31, Loss: 0.0008746382663957775\n",
      "Epoch: 32, Loss: 0.00066877476638183\n",
      "Epoch: 33, Loss: 0.0006419670535251498\n",
      "Epoch: 34, Loss: 0.0005803073290735483\n",
      "Epoch: 35, Loss: 0.0005793654709123075\n",
      "Epoch: 36, Loss: 0.0005296060699038208\n",
      "Epoch: 37, Loss: 0.0004470435669645667\n",
      "Epoch: 38, Loss: 0.0004067471018061042\n",
      "Epoch: 39, Loss: 0.00033824905403889716\n",
      "Epoch: 40, Loss: 0.00035943504190072417\n",
      "Epoch: 41, Loss: 0.0002991391811519861\n",
      "Epoch: 42, Loss: 0.00026343981153331697\n",
      "Epoch: 43, Loss: 0.00023084439453668892\n",
      "Epoch: 44, Loss: 0.00016749551286920905\n",
      "Epoch: 45, Loss: 0.00015933882968965918\n",
      "Epoch: 46, Loss: 0.00016235352086368948\n",
      "Epoch: 47, Loss: 0.0001722634769976139\n",
      "Epoch: 48, Loss: 0.0001517369964858517\n",
      "Epoch: 49, Loss: 0.0001390628021908924\n",
      "Epoch: 50, Loss: 0.00011976785026490688\n",
      "epoch 11 tensor([ 0.5352, -2.1505, -0.5761, -0.4507,  0.4641], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.018794255331158638\n",
      "Epoch: 2, Loss: 0.013747933320701122\n",
      "Epoch: 3, Loss: 0.010659911669790745\n",
      "Epoch: 4, Loss: 0.008314070291817188\n",
      "Epoch: 5, Loss: 0.00727628031745553\n",
      "Epoch: 6, Loss: 0.006542893126606941\n",
      "Epoch: 7, Loss: 0.005171220283955336\n",
      "Epoch: 8, Loss: 0.0043094707652926445\n",
      "Epoch: 9, Loss: 0.003344814758747816\n",
      "Epoch: 10, Loss: 0.0029051988385617733\n",
      "Epoch: 11, Loss: 0.0029993492644280195\n",
      "Epoch: 12, Loss: 0.002980306511744857\n",
      "Epoch: 13, Loss: 0.0027087703347206116\n",
      "Epoch: 14, Loss: 0.0022232213523238897\n",
      "Epoch: 15, Loss: 0.001976750558242202\n",
      "Epoch: 16, Loss: 0.0015456007095053792\n",
      "Epoch: 17, Loss: 0.0016139912186190486\n",
      "Epoch: 18, Loss: 0.0016020205803215504\n",
      "Epoch: 19, Loss: 0.001629423932172358\n",
      "Epoch: 20, Loss: 0.0014242429751902819\n",
      "Epoch: 21, Loss: 0.001024541212245822\n",
      "Epoch: 22, Loss: 0.0008709441171959043\n",
      "Epoch: 23, Loss: 0.0006534030544571579\n",
      "Epoch: 24, Loss: 0.0007849507965147495\n",
      "Epoch: 25, Loss: 0.0007722455775365233\n",
      "Epoch: 26, Loss: 0.0007274675881490111\n",
      "Epoch: 27, Loss: 0.0007354288827627897\n",
      "Epoch: 28, Loss: 0.0006762307602912188\n",
      "Epoch: 29, Loss: 0.0006624391535297036\n",
      "Epoch: 30, Loss: 0.000594276178162545\n",
      "Epoch: 31, Loss: 0.0005244879284873605\n",
      "Epoch: 32, Loss: 0.0004486431134864688\n",
      "Epoch: 33, Loss: 0.0003615336026996374\n",
      "Epoch: 34, Loss: 0.0002945257583633065\n",
      "Epoch: 35, Loss: 0.0002466421283315867\n",
      "Epoch: 36, Loss: 0.000217002016142942\n",
      "Epoch: 37, Loss: 0.00021983165061101317\n",
      "Epoch: 38, Loss: 0.00024061845033429563\n",
      "Epoch: 39, Loss: 0.00018021065625362098\n",
      "Epoch: 40, Loss: 0.00013857486192137003\n",
      "Epoch: 41, Loss: 0.00010780170850921422\n",
      "Epoch: 42, Loss: 0.00012696284102275968\n",
      "Epoch: 43, Loss: 0.0001285079779336229\n",
      "Epoch: 44, Loss: 0.00011939575779251754\n",
      "Epoch: 45, Loss: 9.526800567982718e-05\n",
      "Epoch: 46, Loss: 7.107597048161551e-05\n",
      "Epoch: 47, Loss: 7.619515963597223e-05\n",
      "Epoch: 48, Loss: 8.420622907578945e-05\n",
      "Epoch: 49, Loss: 7.390994869638234e-05\n",
      "Epoch: 50, Loss: 6.229727296158671e-05\n",
      "epoch 11 tensor([ 0.5450, -2.2719, -0.4290, -0.4763,  0.4319], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.01150476187467575\n",
      "Epoch: 2, Loss: 0.009734691120684147\n",
      "Epoch: 3, Loss: 0.007825893349945545\n",
      "Epoch: 4, Loss: 0.006320327520370483\n",
      "Epoch: 5, Loss: 0.004553824197500944\n",
      "Epoch: 6, Loss: 0.003860429860651493\n",
      "Epoch: 7, Loss: 0.003896897193044424\n",
      "Epoch: 8, Loss: 0.0036174135748296976\n",
      "Epoch: 9, Loss: 0.003267519176006317\n",
      "Epoch: 10, Loss: 0.002126643666997552\n",
      "Epoch: 11, Loss: 0.002066584536805749\n",
      "Epoch: 12, Loss: 0.002158569637686014\n",
      "Epoch: 13, Loss: 0.0015199597692117095\n",
      "Epoch: 14, Loss: 0.0014562341384589672\n",
      "Epoch: 15, Loss: 0.0014951921766623855\n",
      "Epoch: 16, Loss: 0.0012322503607720137\n",
      "Epoch: 17, Loss: 0.0008017274085432291\n",
      "Epoch: 18, Loss: 0.001019936753436923\n",
      "Epoch: 19, Loss: 0.0008901549153961241\n",
      "Epoch: 20, Loss: 0.0007413134444504976\n",
      "Epoch: 21, Loss: 0.000787462224252522\n",
      "Epoch: 22, Loss: 0.0007361287134699523\n",
      "Epoch: 23, Loss: 0.0005717040039598942\n",
      "Epoch: 24, Loss: 0.00048700731713324785\n",
      "Epoch: 25, Loss: 0.000548600044567138\n",
      "Epoch: 26, Loss: 0.00036122568417340517\n",
      "Epoch: 27, Loss: 0.00042225391371175647\n",
      "Epoch: 28, Loss: 0.0003678568755276501\n",
      "Epoch: 29, Loss: 0.00035149711766280234\n",
      "Epoch: 30, Loss: 0.00028847716748714447\n",
      "Epoch: 31, Loss: 0.0003540466714184731\n",
      "Epoch: 32, Loss: 0.000255174731137231\n",
      "Epoch: 33, Loss: 0.00026935749338008463\n",
      "Epoch: 34, Loss: 0.00024805773864500225\n",
      "Epoch: 35, Loss: 0.00021770448074676096\n",
      "Epoch: 36, Loss: 0.00017050009046215564\n",
      "Epoch: 37, Loss: 0.0001885059173218906\n",
      "Epoch: 38, Loss: 0.00017276905418839306\n",
      "Epoch: 39, Loss: 0.00011674923734972253\n",
      "Epoch: 40, Loss: 0.00012196384341223165\n",
      "Epoch: 41, Loss: 0.000108273234218359\n",
      "Epoch: 42, Loss: 9.20808597584255e-05\n",
      "Epoch: 43, Loss: 5.921973934164271e-05\n",
      "Epoch: 44, Loss: 7.4359770223964e-05\n",
      "Epoch: 45, Loss: 5.989037163089961e-05\n",
      "Epoch: 46, Loss: 4.639787948690355e-05\n",
      "Epoch: 47, Loss: 3.9183301851153374e-05\n",
      "Epoch: 48, Loss: 3.86782267014496e-05\n",
      "Epoch: 49, Loss: 5.137624611961655e-05\n",
      "Epoch: 50, Loss: 4.6444180043181404e-05\n",
      "epoch 11 tensor([ 0.5087, -2.2633, -0.2031, -0.5645,  0.4378], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.05564576014876366\n",
      "Epoch: 2, Loss: 0.04495907202363014\n",
      "Epoch: 3, Loss: 0.034155283123254776\n",
      "Epoch: 4, Loss: 0.024677734822034836\n",
      "Epoch: 5, Loss: 0.01739061065018177\n",
      "Epoch: 6, Loss: 0.01212567649781704\n",
      "Epoch: 7, Loss: 0.009511927142739296\n",
      "Epoch: 8, Loss: 0.008026253432035446\n",
      "Epoch: 9, Loss: 0.008076447062194347\n",
      "Epoch: 10, Loss: 0.006806957069784403\n",
      "Epoch: 11, Loss: 0.006305807735770941\n",
      "Epoch: 12, Loss: 0.005212992895394564\n",
      "Epoch: 13, Loss: 0.005450848489999771\n",
      "Epoch: 14, Loss: 0.005038014613091946\n",
      "Epoch: 15, Loss: 0.00494776014238596\n",
      "Epoch: 16, Loss: 0.004361486993730068\n",
      "Epoch: 17, Loss: 0.0035345181822776794\n",
      "Epoch: 18, Loss: 0.0031104725785553455\n",
      "Epoch: 19, Loss: 0.002512096194550395\n",
      "Epoch: 20, Loss: 0.0020356071181595325\n",
      "Epoch: 21, Loss: 0.0016596217174082994\n",
      "Epoch: 22, Loss: 0.0013196307700127363\n",
      "Epoch: 23, Loss: 0.001207431429065764\n",
      "Epoch: 24, Loss: 0.0011804893147200346\n",
      "Epoch: 25, Loss: 0.0010324803879484534\n",
      "Epoch: 26, Loss: 0.0009222386288456619\n",
      "Epoch: 27, Loss: 0.000989089603535831\n",
      "Epoch: 28, Loss: 0.0008795096073299646\n",
      "Epoch: 29, Loss: 0.000957595999352634\n",
      "Epoch: 30, Loss: 0.0010162004036828876\n",
      "Epoch: 31, Loss: 0.0009603577782399952\n",
      "Epoch: 32, Loss: 0.000948085100390017\n",
      "Epoch: 33, Loss: 0.0008439165540039539\n",
      "Epoch: 34, Loss: 0.0008031587349250913\n",
      "Epoch: 35, Loss: 0.0007017706520855427\n",
      "Epoch: 36, Loss: 0.0006237344932742417\n",
      "Epoch: 37, Loss: 0.0005213298136368394\n",
      "Epoch: 38, Loss: 0.0004019350453745574\n",
      "Epoch: 39, Loss: 0.0003565795486792922\n",
      "Epoch: 40, Loss: 0.0002329147537238896\n",
      "Epoch: 41, Loss: 0.00021181184274610132\n",
      "Epoch: 42, Loss: 0.00012213589798193425\n",
      "Epoch: 43, Loss: 0.00011062671546824276\n",
      "Epoch: 44, Loss: 9.390891500515863e-05\n",
      "Epoch: 45, Loss: 9.98572722892277e-05\n",
      "Epoch: 46, Loss: 0.00011129181802971289\n",
      "Epoch: 47, Loss: 0.00011505651491461322\n",
      "Epoch: 48, Loss: 0.00013020745245739818\n",
      "Epoch: 49, Loss: 0.0001409679971402511\n",
      "Epoch: 50, Loss: 0.000136921473313123\n",
      "epoch 11 tensor([ 0.5621, -2.1394, -0.3092, -0.4736,  0.4095], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.12097854912281036\n",
      "Epoch: 2, Loss: 0.08063367009162903\n",
      "Epoch: 3, Loss: 0.06676243990659714\n",
      "Epoch: 4, Loss: 0.05329807102680206\n",
      "Epoch: 5, Loss: 0.04541950300335884\n",
      "Epoch: 6, Loss: 0.039882734417915344\n",
      "Epoch: 7, Loss: 0.03559758514165878\n",
      "Epoch: 8, Loss: 0.03733110427856445\n",
      "Epoch: 9, Loss: 0.034193702042102814\n",
      "Epoch: 10, Loss: 0.02590787597000599\n",
      "Epoch: 11, Loss: 0.02164508029818535\n",
      "Epoch: 12, Loss: 0.02161864936351776\n",
      "Epoch: 13, Loss: 0.020728638395667076\n",
      "Epoch: 14, Loss: 0.01914600282907486\n",
      "Epoch: 15, Loss: 0.017351459711790085\n",
      "Epoch: 16, Loss: 0.016486110165715218\n",
      "Epoch: 17, Loss: 0.018164001405239105\n",
      "Epoch: 18, Loss: 0.018987387418746948\n",
      "Epoch: 19, Loss: 0.016889628022909164\n",
      "Epoch: 20, Loss: 0.0145201925188303\n",
      "Epoch: 21, Loss: 0.013257686980068684\n",
      "Epoch: 22, Loss: 0.012142527848482132\n",
      "Epoch: 23, Loss: 0.010627750307321548\n",
      "Epoch: 24, Loss: 0.009369153529405594\n",
      "Epoch: 25, Loss: 0.00894088950008154\n",
      "Epoch: 26, Loss: 0.009040468372404575\n",
      "Epoch: 27, Loss: 0.008975565433502197\n",
      "Epoch: 28, Loss: 0.00844444427639246\n",
      "Epoch: 29, Loss: 0.007921259850263596\n",
      "Epoch: 30, Loss: 0.007770184427499771\n",
      "Epoch: 31, Loss: 0.007611560635268688\n",
      "Epoch: 32, Loss: 0.007089638616889715\n",
      "Epoch: 33, Loss: 0.006491318345069885\n",
      "Epoch: 34, Loss: 0.006162460893392563\n",
      "Epoch: 35, Loss: 0.006041194777935743\n",
      "Epoch: 36, Loss: 0.0058489637449383736\n",
      "Epoch: 37, Loss: 0.005409690551459789\n",
      "Epoch: 38, Loss: 0.005010964348912239\n",
      "Epoch: 39, Loss: 0.004816519096493721\n",
      "Epoch: 40, Loss: 0.00464452663436532\n",
      "Epoch: 41, Loss: 0.004444245249032974\n",
      "Epoch: 42, Loss: 0.0042976452969014645\n",
      "Epoch: 43, Loss: 0.004168019164353609\n",
      "Epoch: 44, Loss: 0.004009060095995665\n",
      "Epoch: 45, Loss: 0.0037947921082377434\n",
      "Epoch: 46, Loss: 0.003523358376696706\n",
      "Epoch: 47, Loss: 0.0033310996368527412\n",
      "Epoch: 48, Loss: 0.0032132924534380436\n",
      "Epoch: 49, Loss: 0.0030528358183801174\n",
      "Epoch: 50, Loss: 0.0029229745268821716\n",
      "epoch 11 tensor([ 0.3277, -2.2385, -0.3745, -0.3247,  0.3848], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.01508294977247715\n",
      "Epoch: 2, Loss: 0.010355365462601185\n",
      "Epoch: 3, Loss: 0.008282696828246117\n",
      "Epoch: 4, Loss: 0.006959980353713036\n",
      "Epoch: 5, Loss: 0.006144621409475803\n",
      "Epoch: 6, Loss: 0.004789173603057861\n",
      "Epoch: 7, Loss: 0.0036499821580946445\n",
      "Epoch: 8, Loss: 0.003931035287678242\n",
      "Epoch: 9, Loss: 0.0037976005114614964\n",
      "Epoch: 10, Loss: 0.0031628026627004147\n",
      "Epoch: 11, Loss: 0.002732734428718686\n",
      "Epoch: 12, Loss: 0.0022281091660261154\n",
      "Epoch: 13, Loss: 0.0020091466140002012\n",
      "Epoch: 14, Loss: 0.0021400824189186096\n",
      "Epoch: 15, Loss: 0.0020974043291062117\n",
      "Epoch: 16, Loss: 0.0019220213871449232\n",
      "Epoch: 17, Loss: 0.0016024132492020726\n",
      "Epoch: 18, Loss: 0.0015499463770538568\n",
      "Epoch: 19, Loss: 0.0014859391376376152\n",
      "Epoch: 20, Loss: 0.0011606569169089198\n",
      "Epoch: 21, Loss: 0.0009213325101882219\n",
      "Epoch: 22, Loss: 0.0007532348390668631\n",
      "Epoch: 23, Loss: 0.0008029624586924911\n",
      "Epoch: 24, Loss: 0.0007352525135502219\n",
      "Epoch: 25, Loss: 0.0006794713553972542\n",
      "Epoch: 26, Loss: 0.0006570434779860079\n",
      "Epoch: 27, Loss: 0.0005975277163088322\n",
      "Epoch: 28, Loss: 0.0004972456372343004\n",
      "Epoch: 29, Loss: 0.00038118058000691235\n",
      "Epoch: 30, Loss: 0.0003941173490602523\n",
      "Epoch: 31, Loss: 0.0004124920815229416\n",
      "Epoch: 32, Loss: 0.0003395262756384909\n",
      "Epoch: 33, Loss: 0.000295681064017117\n",
      "Epoch: 34, Loss: 0.0002800108923111111\n",
      "Epoch: 35, Loss: 0.0002497857203707099\n",
      "Epoch: 36, Loss: 0.00016505311941727996\n",
      "Epoch: 37, Loss: 0.00014408628339879215\n",
      "Epoch: 38, Loss: 0.0001722343295114115\n",
      "Epoch: 39, Loss: 0.00018495313997846097\n",
      "Epoch: 40, Loss: 0.00018745560373645276\n",
      "Epoch: 41, Loss: 0.0001716604601824656\n",
      "Epoch: 42, Loss: 0.00014774569717701524\n",
      "Epoch: 43, Loss: 0.00012575088476296514\n",
      "Epoch: 44, Loss: 0.0001227659231517464\n",
      "Epoch: 45, Loss: 9.219563798978925e-05\n",
      "Epoch: 46, Loss: 7.339609146583825e-05\n",
      "Epoch: 47, Loss: 7.8634824603796e-05\n",
      "Epoch: 48, Loss: 8.253905252786353e-05\n",
      "Epoch: 49, Loss: 5.6692333600949496e-05\n",
      "Epoch: 50, Loss: 4.6177963668014854e-05\n",
      "________________________________________\n",
      "epoch 12 tensor([ 0.5397, -2.2295, -0.5459, -0.4780,  0.4984], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.030829904600977898\n",
      "Epoch: 2, Loss: 0.02219562791287899\n",
      "Epoch: 3, Loss: 0.020327463746070862\n",
      "Epoch: 4, Loss: 0.015662508085370064\n",
      "Epoch: 5, Loss: 0.014285143464803696\n",
      "Epoch: 6, Loss: 0.010874747298657894\n",
      "Epoch: 7, Loss: 0.011082828976213932\n",
      "Epoch: 8, Loss: 0.010826769284904003\n",
      "Epoch: 9, Loss: 0.007845238782465458\n",
      "Epoch: 10, Loss: 0.008913766592741013\n",
      "Epoch: 11, Loss: 0.008220767602324486\n",
      "Epoch: 12, Loss: 0.006302639376372099\n",
      "Epoch: 13, Loss: 0.006580555811524391\n",
      "Epoch: 14, Loss: 0.00619559595361352\n",
      "Epoch: 15, Loss: 0.005833073984831572\n",
      "Epoch: 16, Loss: 0.0053861611522734165\n",
      "Epoch: 17, Loss: 0.005129845812916756\n",
      "Epoch: 18, Loss: 0.0052108317613601685\n",
      "Epoch: 19, Loss: 0.003924771212041378\n",
      "Epoch: 20, Loss: 0.003457473125308752\n",
      "Epoch: 21, Loss: 0.0037585936952382326\n",
      "Epoch: 22, Loss: 0.003022391814738512\n",
      "Epoch: 23, Loss: 0.002790781669318676\n",
      "Epoch: 24, Loss: 0.0027684024535119534\n",
      "Epoch: 25, Loss: 0.0025113120209425688\n",
      "Epoch: 26, Loss: 0.002396241994574666\n",
      "Epoch: 27, Loss: 0.002170310355722904\n",
      "Epoch: 28, Loss: 0.002216663444414735\n",
      "Epoch: 29, Loss: 0.0018490450456738472\n",
      "Epoch: 30, Loss: 0.0016378862783312798\n",
      "Epoch: 31, Loss: 0.0016767046181485057\n",
      "Epoch: 32, Loss: 0.001373332692310214\n",
      "Epoch: 33, Loss: 0.0012286240234971046\n",
      "Epoch: 34, Loss: 0.0012046792544424534\n",
      "Epoch: 35, Loss: 0.0010571879101917148\n",
      "Epoch: 36, Loss: 0.000943722203373909\n",
      "Epoch: 37, Loss: 0.0008675800054334104\n",
      "Epoch: 38, Loss: 0.0008406033157370985\n",
      "Epoch: 39, Loss: 0.0006893861573189497\n",
      "Epoch: 40, Loss: 0.0006225200486369431\n",
      "Epoch: 41, Loss: 0.000611236784607172\n",
      "Epoch: 42, Loss: 0.00048497956595383584\n",
      "Epoch: 43, Loss: 0.000467971753096208\n",
      "Epoch: 44, Loss: 0.0004346547939348966\n",
      "Epoch: 45, Loss: 0.00036357471253722906\n",
      "Epoch: 46, Loss: 0.0003182298387400806\n",
      "Epoch: 47, Loss: 0.0003059112932533026\n",
      "Epoch: 48, Loss: 0.0002737583126872778\n",
      "Epoch: 49, Loss: 0.00022244887077249587\n",
      "Epoch: 50, Loss: 0.00022941947099752724\n",
      "epoch 12 tensor([ 0.5991, -2.1539,  0.1130, -0.5467,  0.4151], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.047709837555885315\n",
      "Epoch: 2, Loss: 0.03189612925052643\n",
      "Epoch: 3, Loss: 0.02347211167216301\n",
      "Epoch: 4, Loss: 0.017229989171028137\n",
      "Epoch: 5, Loss: 0.0155421057716012\n",
      "Epoch: 6, Loss: 0.015000909566879272\n",
      "Epoch: 7, Loss: 0.012287226505577564\n",
      "Epoch: 8, Loss: 0.011567291803658009\n",
      "Epoch: 9, Loss: 0.011154166422784328\n",
      "Epoch: 10, Loss: 0.00975855439901352\n",
      "Epoch: 11, Loss: 0.009353947825729847\n",
      "Epoch: 12, Loss: 0.00854464527219534\n",
      "Epoch: 13, Loss: 0.007483622059226036\n",
      "Epoch: 14, Loss: 0.007031695917248726\n",
      "Epoch: 15, Loss: 0.006443530321121216\n",
      "Epoch: 16, Loss: 0.0052747298032045364\n",
      "Epoch: 17, Loss: 0.00497160479426384\n",
      "Epoch: 18, Loss: 0.0043699489906430244\n",
      "Epoch: 19, Loss: 0.0037654475308954716\n",
      "Epoch: 20, Loss: 0.0035848768893629313\n",
      "Epoch: 21, Loss: 0.003136466722935438\n",
      "Epoch: 22, Loss: 0.0027728914283216\n",
      "Epoch: 23, Loss: 0.0027927192859351635\n",
      "Epoch: 24, Loss: 0.002428737236186862\n",
      "Epoch: 25, Loss: 0.001998836174607277\n",
      "Epoch: 26, Loss: 0.0016835102578625083\n",
      "Epoch: 27, Loss: 0.0011043965350836515\n",
      "Epoch: 28, Loss: 0.0009558982565067708\n",
      "Epoch: 29, Loss: 0.0009610833367332816\n",
      "Epoch: 30, Loss: 0.000811348611023277\n",
      "Epoch: 31, Loss: 0.0008333071600645781\n",
      "Epoch: 32, Loss: 0.000942162936553359\n",
      "Epoch: 33, Loss: 0.0009202289511449635\n",
      "Epoch: 34, Loss: 0.000862593820784241\n",
      "Epoch: 35, Loss: 0.0006336820661090314\n",
      "Epoch: 36, Loss: 0.0004368007939774543\n",
      "Epoch: 37, Loss: 0.00046867519267834723\n",
      "Epoch: 38, Loss: 0.0004521392984315753\n",
      "Epoch: 39, Loss: 0.00042163769830949605\n",
      "Epoch: 40, Loss: 0.00035908701829612255\n",
      "Epoch: 41, Loss: 0.00024094426771625876\n",
      "Epoch: 42, Loss: 0.0002549167547840625\n",
      "Epoch: 43, Loss: 0.0002604021574370563\n",
      "Epoch: 44, Loss: 0.0002669850073289126\n",
      "Epoch: 45, Loss: 0.00028976620524190366\n",
      "Epoch: 46, Loss: 0.0002365986438235268\n",
      "Epoch: 47, Loss: 0.00021187143283896148\n",
      "Epoch: 48, Loss: 0.00016969420539680868\n",
      "Epoch: 49, Loss: 0.00012392968346830457\n",
      "Epoch: 50, Loss: 0.00012746012362185866\n",
      "epoch 12 tensor([ 0.5991, -2.1638, -0.5741, -0.4557,  0.4955], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.04715384915471077\n",
      "Epoch: 2, Loss: 0.029175858944654465\n",
      "Epoch: 3, Loss: 0.02132510580122471\n",
      "Epoch: 4, Loss: 0.017492838203907013\n",
      "Epoch: 5, Loss: 0.014227204024791718\n",
      "Epoch: 6, Loss: 0.011633102782070637\n",
      "Epoch: 7, Loss: 0.00672637764364481\n",
      "Epoch: 8, Loss: 0.005638508591800928\n",
      "Epoch: 9, Loss: 0.007157845422625542\n",
      "Epoch: 10, Loss: 0.008185125887393951\n",
      "Epoch: 11, Loss: 0.007608089596033096\n",
      "Epoch: 12, Loss: 0.0072130304761230946\n",
      "Epoch: 13, Loss: 0.006597165949642658\n",
      "Epoch: 14, Loss: 0.00556069565936923\n",
      "Epoch: 15, Loss: 0.004354302771389484\n",
      "Epoch: 16, Loss: 0.004002230241894722\n",
      "Epoch: 17, Loss: 0.003507542423903942\n",
      "Epoch: 18, Loss: 0.0029921003151685\n",
      "Epoch: 19, Loss: 0.0029732147231698036\n",
      "Epoch: 20, Loss: 0.00271530426107347\n",
      "Epoch: 21, Loss: 0.002510818187147379\n",
      "Epoch: 22, Loss: 0.002872483106330037\n",
      "Epoch: 23, Loss: 0.0026605536695569754\n",
      "Epoch: 24, Loss: 0.0019743305165320635\n",
      "Epoch: 25, Loss: 0.001630889717489481\n",
      "Epoch: 26, Loss: 0.0013038419419899583\n",
      "Epoch: 27, Loss: 0.0010154228657484055\n",
      "Epoch: 28, Loss: 0.0008211962995119393\n",
      "Epoch: 29, Loss: 0.0008468308369629085\n",
      "Epoch: 30, Loss: 0.0008566957549192011\n",
      "Epoch: 31, Loss: 0.0009603864164091647\n",
      "Epoch: 32, Loss: 0.0010158948134630919\n",
      "Epoch: 33, Loss: 0.0008744104998186231\n",
      "Epoch: 34, Loss: 0.0007623640703968704\n",
      "Epoch: 35, Loss: 0.0007875291048549116\n",
      "Epoch: 36, Loss: 0.0006342481356114149\n",
      "Epoch: 37, Loss: 0.00040167206316255033\n",
      "Epoch: 38, Loss: 0.00027408378082327545\n",
      "Epoch: 39, Loss: 0.00020554062211886048\n",
      "Epoch: 40, Loss: 0.00026603302103467286\n",
      "Epoch: 41, Loss: 0.0003109299286734313\n",
      "Epoch: 42, Loss: 0.0002812972816172987\n",
      "Epoch: 43, Loss: 0.00027586452779360116\n",
      "Epoch: 44, Loss: 0.0003289218002464622\n",
      "Epoch: 45, Loss: 0.00030064399470575154\n",
      "Epoch: 46, Loss: 0.0002277547464473173\n",
      "Epoch: 47, Loss: 0.00018317945068702102\n",
      "Epoch: 48, Loss: 0.00014142401050776243\n",
      "Epoch: 49, Loss: 0.0001280824071727693\n",
      "Epoch: 50, Loss: 0.00011482548870844766\n",
      "epoch 12 tensor([ 0.6248, -2.2109, -0.7017, -0.5818,  0.5497], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.07022977620363235\n",
      "Epoch: 2, Loss: 0.05690046772360802\n",
      "Epoch: 3, Loss: 0.04512364789843559\n",
      "Epoch: 4, Loss: 0.03715595602989197\n",
      "Epoch: 5, Loss: 0.03162257745862007\n",
      "Epoch: 6, Loss: 0.02775251865386963\n",
      "Epoch: 7, Loss: 0.02376878820359707\n",
      "Epoch: 8, Loss: 0.020894240587949753\n",
      "Epoch: 9, Loss: 0.01840383931994438\n",
      "Epoch: 10, Loss: 0.014936820603907108\n",
      "Epoch: 11, Loss: 0.012011910788714886\n",
      "Epoch: 12, Loss: 0.00966410618275404\n",
      "Epoch: 13, Loss: 0.008252572268247604\n",
      "Epoch: 14, Loss: 0.007749706041067839\n",
      "Epoch: 15, Loss: 0.007001529913395643\n",
      "Epoch: 16, Loss: 0.005824765656143427\n",
      "Epoch: 17, Loss: 0.00493180938065052\n",
      "Epoch: 18, Loss: 0.004208990838378668\n",
      "Epoch: 19, Loss: 0.0037555545568466187\n",
      "Epoch: 20, Loss: 0.003546574153006077\n",
      "Epoch: 21, Loss: 0.003455675207078457\n",
      "Epoch: 22, Loss: 0.0034129247069358826\n",
      "Epoch: 23, Loss: 0.0030539855360984802\n",
      "Epoch: 24, Loss: 0.0025616465136408806\n",
      "Epoch: 25, Loss: 0.002336769597604871\n",
      "Epoch: 26, Loss: 0.0020327758975327015\n",
      "Epoch: 27, Loss: 0.0018628841498866677\n",
      "Epoch: 28, Loss: 0.0018005042802542448\n",
      "Epoch: 29, Loss: 0.0016346820630133152\n",
      "Epoch: 30, Loss: 0.0016437721205875278\n",
      "Epoch: 31, Loss: 0.001607262995094061\n",
      "Epoch: 32, Loss: 0.0015147412195801735\n",
      "Epoch: 33, Loss: 0.0013203691923990846\n",
      "Epoch: 34, Loss: 0.000995685695670545\n",
      "Epoch: 35, Loss: 0.000760753289796412\n",
      "Epoch: 36, Loss: 0.0005444050766527653\n",
      "Epoch: 37, Loss: 0.0004678245750255883\n",
      "Epoch: 38, Loss: 0.0004876074963249266\n",
      "Epoch: 39, Loss: 0.0004929716233164072\n",
      "Epoch: 40, Loss: 0.00047738925786688924\n",
      "Epoch: 41, Loss: 0.0003988049866165966\n",
      "Epoch: 42, Loss: 0.000329237780533731\n",
      "Epoch: 43, Loss: 0.000272422592388466\n",
      "Epoch: 44, Loss: 0.00022998826170805842\n",
      "Epoch: 45, Loss: 0.00023220844741445035\n",
      "Epoch: 46, Loss: 0.0002085015585180372\n",
      "Epoch: 47, Loss: 0.0002088675828417763\n",
      "Epoch: 48, Loss: 0.00021190830739215016\n",
      "Epoch: 49, Loss: 0.0001958017237484455\n",
      "Epoch: 50, Loss: 0.00018601449846755713\n",
      "epoch 12 tensor([ 0.6083, -2.1603, -0.2946, -0.5554,  0.6007], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.016501598060131073\n",
      "Epoch: 2, Loss: 0.009007204324007034\n",
      "Epoch: 3, Loss: 0.0075888484716415405\n",
      "Epoch: 4, Loss: 0.009020245634019375\n",
      "Epoch: 5, Loss: 0.007636317051947117\n",
      "Epoch: 6, Loss: 0.004408056847751141\n",
      "Epoch: 7, Loss: 0.003319012001156807\n",
      "Epoch: 8, Loss: 0.004731705412268639\n",
      "Epoch: 9, Loss: 0.00405934127047658\n",
      "Epoch: 10, Loss: 0.002452632412314415\n",
      "Epoch: 11, Loss: 0.0021071387454867363\n",
      "Epoch: 12, Loss: 0.0024690148420631886\n",
      "Epoch: 13, Loss: 0.0025683932472020388\n",
      "Epoch: 14, Loss: 0.0020016194321215153\n",
      "Epoch: 15, Loss: 0.0017582336440682411\n",
      "Epoch: 16, Loss: 0.0019626934081315994\n",
      "Epoch: 17, Loss: 0.0015153995482251048\n",
      "Epoch: 18, Loss: 0.001145784743130207\n",
      "Epoch: 19, Loss: 0.0013184647541493177\n",
      "Epoch: 20, Loss: 0.0014273584820330143\n",
      "Epoch: 21, Loss: 0.0011121397837996483\n",
      "Epoch: 22, Loss: 0.0005882509867660701\n",
      "Epoch: 23, Loss: 0.0006495568086393178\n",
      "Epoch: 24, Loss: 0.0010368686635047197\n",
      "Epoch: 25, Loss: 0.0008724547806195915\n",
      "Epoch: 26, Loss: 0.0004463224031496793\n",
      "Epoch: 27, Loss: 0.0003399426059331745\n",
      "Epoch: 28, Loss: 0.0005681520560756326\n",
      "Epoch: 29, Loss: 0.0005744312074966729\n",
      "Epoch: 30, Loss: 0.0003352025232743472\n",
      "Epoch: 31, Loss: 0.0002559131244197488\n",
      "Epoch: 32, Loss: 0.0003441165026742965\n",
      "Epoch: 33, Loss: 0.0003405461902730167\n",
      "Epoch: 34, Loss: 0.00026201552827842534\n",
      "Epoch: 35, Loss: 0.00023513003543484956\n",
      "Epoch: 36, Loss: 0.00026677080313675106\n",
      "Epoch: 37, Loss: 0.000243160204263404\n",
      "Epoch: 38, Loss: 0.00020513425988610834\n",
      "Epoch: 39, Loss: 0.00020005431724712253\n",
      "Epoch: 40, Loss: 0.00015962222823873162\n",
      "Epoch: 41, Loss: 0.00012383692956063896\n",
      "Epoch: 42, Loss: 0.00013079891505185515\n",
      "Epoch: 43, Loss: 0.00014870977611280978\n",
      "Epoch: 44, Loss: 0.00011191544763278216\n",
      "Epoch: 45, Loss: 6.349565228447318e-05\n",
      "Epoch: 46, Loss: 6.907657370902598e-05\n",
      "Epoch: 47, Loss: 8.200864976970479e-05\n",
      "Epoch: 48, Loss: 6.0012214817106724e-05\n",
      "Epoch: 49, Loss: 3.301611286588013e-05\n",
      "Epoch: 50, Loss: 4.643865395337343e-05\n",
      "epoch 12 tensor([ 0.6238, -2.1230, -0.3600, -0.5675,  0.6002], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.013499962165951729\n",
      "Epoch: 2, Loss: 0.009680190123617649\n",
      "Epoch: 3, Loss: 0.005757467821240425\n",
      "Epoch: 4, Loss: 0.003386685624718666\n",
      "Epoch: 5, Loss: 0.003395365783944726\n",
      "Epoch: 6, Loss: 0.0038117808289825916\n",
      "Epoch: 7, Loss: 0.004189015831798315\n",
      "Epoch: 8, Loss: 0.0034030366223305464\n",
      "Epoch: 9, Loss: 0.002895411802455783\n",
      "Epoch: 10, Loss: 0.002226377371698618\n",
      "Epoch: 11, Loss: 0.0021891831420361996\n",
      "Epoch: 12, Loss: 0.0019862852059304714\n",
      "Epoch: 13, Loss: 0.0016541362274438143\n",
      "Epoch: 14, Loss: 0.0016365915071219206\n",
      "Epoch: 15, Loss: 0.0014451741008087993\n",
      "Epoch: 16, Loss: 0.0013056430034339428\n",
      "Epoch: 17, Loss: 0.0013745271135121584\n",
      "Epoch: 18, Loss: 0.0010869945399463177\n",
      "Epoch: 19, Loss: 0.0009166435920633376\n",
      "Epoch: 20, Loss: 0.0008399509824812412\n",
      "Epoch: 21, Loss: 0.0007528376299887896\n",
      "Epoch: 22, Loss: 0.0006671139854006469\n",
      "Epoch: 23, Loss: 0.0006254391628317535\n",
      "Epoch: 24, Loss: 0.0005359463393688202\n",
      "Epoch: 25, Loss: 0.0005963465664535761\n",
      "Epoch: 26, Loss: 0.0005560314166359603\n",
      "Epoch: 27, Loss: 0.0005320076015777886\n",
      "Epoch: 28, Loss: 0.000424309226218611\n",
      "Epoch: 29, Loss: 0.00031208732980303466\n",
      "Epoch: 30, Loss: 0.0002593734534457326\n",
      "Epoch: 31, Loss: 0.00026074654306285083\n",
      "Epoch: 32, Loss: 0.0002807093842420727\n",
      "Epoch: 33, Loss: 0.0002464561548549682\n",
      "Epoch: 34, Loss: 0.00023060356033965945\n",
      "Epoch: 35, Loss: 0.00016414670972153544\n",
      "Epoch: 36, Loss: 0.00018000155978370458\n",
      "Epoch: 37, Loss: 0.00015221338253468275\n",
      "Epoch: 38, Loss: 0.00015872516087256372\n",
      "Epoch: 39, Loss: 0.0001193584903376177\n",
      "Epoch: 40, Loss: 0.00010571994062047452\n",
      "Epoch: 41, Loss: 0.00010226786253042519\n",
      "Epoch: 42, Loss: 0.00012244591198395938\n",
      "Epoch: 43, Loss: 9.651802247390151e-05\n",
      "Epoch: 44, Loss: 7.559180085081607e-05\n",
      "Epoch: 45, Loss: 4.469648047233932e-05\n",
      "Epoch: 46, Loss: 4.723486927105114e-05\n",
      "Epoch: 47, Loss: 5.11446560267359e-05\n",
      "Epoch: 48, Loss: 6.874849350424483e-05\n",
      "Epoch: 49, Loss: 5.364788739825599e-05\n",
      "Epoch: 50, Loss: 4.264733797754161e-05\n",
      "epoch 12 tensor([ 0.6952, -2.1993, -0.3057, -0.4864,  0.6110], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.014270653948187828\n",
      "Epoch: 2, Loss: 0.009473584592342377\n",
      "Epoch: 3, Loss: 0.005533287301659584\n",
      "Epoch: 4, Loss: 0.004303054418414831\n",
      "Epoch: 5, Loss: 0.004900655709207058\n",
      "Epoch: 6, Loss: 0.005102354101836681\n",
      "Epoch: 7, Loss: 0.004180946387350559\n",
      "Epoch: 8, Loss: 0.003903013654053211\n",
      "Epoch: 9, Loss: 0.003251854097470641\n",
      "Epoch: 10, Loss: 0.0024416528176516294\n",
      "Epoch: 11, Loss: 0.002518002176657319\n",
      "Epoch: 12, Loss: 0.0020127452444285154\n",
      "Epoch: 13, Loss: 0.0018524613697081804\n",
      "Epoch: 14, Loss: 0.0017323747742921114\n",
      "Epoch: 15, Loss: 0.0010925435926765203\n",
      "Epoch: 16, Loss: 0.0012610809644684196\n",
      "Epoch: 17, Loss: 0.0013104729587212205\n",
      "Epoch: 18, Loss: 0.0014138049446046352\n",
      "Epoch: 19, Loss: 0.0014086095616221428\n",
      "Epoch: 20, Loss: 0.0010181483812630177\n",
      "Epoch: 21, Loss: 0.00082565558841452\n",
      "Epoch: 22, Loss: 0.0008153888047672808\n",
      "Epoch: 23, Loss: 0.0007635348010808229\n",
      "Epoch: 24, Loss: 0.000681431673001498\n",
      "Epoch: 25, Loss: 0.0006651387084275484\n",
      "Epoch: 26, Loss: 0.0005044820136390626\n",
      "Epoch: 27, Loss: 0.0005832570604979992\n",
      "Epoch: 28, Loss: 0.000453928776551038\n",
      "Epoch: 29, Loss: 0.00038410292472690344\n",
      "Epoch: 30, Loss: 0.0003411343786865473\n",
      "Epoch: 31, Loss: 0.0002692221023607999\n",
      "Epoch: 32, Loss: 0.0003095094580203295\n",
      "Epoch: 33, Loss: 0.00024192129785660654\n",
      "Epoch: 34, Loss: 0.0001787631044862792\n",
      "Epoch: 35, Loss: 0.00018604373326525092\n",
      "Epoch: 36, Loss: 0.0001646434684516862\n",
      "Epoch: 37, Loss: 0.00019366657943464816\n",
      "Epoch: 38, Loss: 0.00018707536219153553\n",
      "Epoch: 39, Loss: 0.00015177718887571245\n",
      "Epoch: 40, Loss: 0.0001462968357373029\n",
      "Epoch: 41, Loss: 0.00010574695625109598\n",
      "Epoch: 42, Loss: 9.839316044235602e-05\n",
      "Epoch: 43, Loss: 0.00010340275912312791\n",
      "Epoch: 44, Loss: 9.632675210013986e-05\n",
      "Epoch: 45, Loss: 0.00011235983402002603\n",
      "Epoch: 46, Loss: 9.939059964381158e-05\n",
      "Epoch: 47, Loss: 9.991911065299064e-05\n",
      "Epoch: 48, Loss: 0.00012904471077490598\n",
      "Epoch: 49, Loss: 0.00023127585882321\n",
      "Epoch: 50, Loss: 0.00045295231393538415\n",
      "epoch 12 tensor([ 0.7897, -2.1560, -0.2549, -0.5761,  0.6097], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.005793868098407984\n",
      "Epoch: 2, Loss: 0.003809192217886448\n",
      "Epoch: 3, Loss: 0.002713847206905484\n",
      "Epoch: 4, Loss: 0.002040415070950985\n",
      "Epoch: 5, Loss: 0.0019021023763343692\n",
      "Epoch: 6, Loss: 0.0017313234275206923\n",
      "Epoch: 7, Loss: 0.0015202686190605164\n",
      "Epoch: 8, Loss: 0.001270086271688342\n",
      "Epoch: 9, Loss: 0.0015169477555900812\n",
      "Epoch: 10, Loss: 0.0014554187655448914\n",
      "Epoch: 11, Loss: 0.0012696671765297651\n",
      "Epoch: 12, Loss: 0.0011023071128875017\n",
      "Epoch: 13, Loss: 0.0007929096464067698\n",
      "Epoch: 14, Loss: 0.000584673834964633\n",
      "Epoch: 15, Loss: 0.0005463890847750008\n",
      "Epoch: 16, Loss: 0.0006311453180387616\n",
      "Epoch: 17, Loss: 0.0005500250263139606\n",
      "Epoch: 18, Loss: 0.00044531121966429055\n",
      "Epoch: 19, Loss: 0.00041409183177165687\n",
      "Epoch: 20, Loss: 0.00038311912794597447\n",
      "Epoch: 21, Loss: 0.0004226028686389327\n",
      "Epoch: 22, Loss: 0.00034778815461322665\n",
      "Epoch: 23, Loss: 0.00030065118335187435\n",
      "Epoch: 24, Loss: 0.00022253453789744526\n",
      "Epoch: 25, Loss: 0.0001957961212610826\n",
      "Epoch: 26, Loss: 0.00023885096015874296\n",
      "Epoch: 27, Loss: 0.00021654034208040684\n",
      "Epoch: 28, Loss: 0.00022130802972242236\n",
      "Epoch: 29, Loss: 0.0001929742138599977\n",
      "Epoch: 30, Loss: 0.00021008677140343934\n",
      "Epoch: 31, Loss: 0.00019844812049996108\n",
      "Epoch: 32, Loss: 0.00016542235971428454\n",
      "Epoch: 33, Loss: 0.00013700035924557596\n",
      "Epoch: 34, Loss: 0.0001512034359620884\n",
      "Epoch: 35, Loss: 0.0001927430130308494\n",
      "Epoch: 36, Loss: 0.00026320776669308543\n",
      "Epoch: 37, Loss: 0.0003372498322278261\n",
      "Epoch: 38, Loss: 0.00039250191184692085\n",
      "Epoch: 39, Loss: 0.0003554255818016827\n",
      "Epoch: 40, Loss: 0.0002293546131113544\n",
      "Epoch: 41, Loss: 7.704293966526166e-05\n",
      "Epoch: 42, Loss: 4.169983003521338e-05\n",
      "Epoch: 43, Loss: 0.00011558504775166512\n",
      "Epoch: 44, Loss: 0.00020986629533581436\n",
      "Epoch: 45, Loss: 0.00021696166368201375\n",
      "Epoch: 46, Loss: 0.00012235991016495973\n",
      "Epoch: 47, Loss: 3.613165972637944e-05\n",
      "Epoch: 48, Loss: 3.683276372612454e-05\n",
      "Epoch: 49, Loss: 0.00010036709136329591\n",
      "Epoch: 50, Loss: 0.00014063982234802097\n",
      "epoch 12 tensor([ 0.7607, -2.1642, -0.2488, -0.5837,  0.4468], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.007022203877568245\n",
      "Epoch: 2, Loss: 0.004744764883071184\n",
      "Epoch: 3, Loss: 0.004480766132473946\n",
      "Epoch: 4, Loss: 0.004206557758152485\n",
      "Epoch: 5, Loss: 0.002770144259557128\n",
      "Epoch: 6, Loss: 0.0016713958466425538\n",
      "Epoch: 7, Loss: 0.002013961784541607\n",
      "Epoch: 8, Loss: 0.0018829384353011847\n",
      "Epoch: 9, Loss: 0.0012649745913222432\n",
      "Epoch: 10, Loss: 0.0014626316260546446\n",
      "Epoch: 11, Loss: 0.0016463031060993671\n",
      "Epoch: 12, Loss: 0.0011270289542153478\n",
      "Epoch: 13, Loss: 0.001086076139472425\n",
      "Epoch: 14, Loss: 0.000921327096875757\n",
      "Epoch: 15, Loss: 0.0008750373963266611\n",
      "Epoch: 16, Loss: 0.001171856070868671\n",
      "Epoch: 17, Loss: 0.0008959211991168559\n",
      "Epoch: 18, Loss: 0.0006007154588587582\n",
      "Epoch: 19, Loss: 0.0006393755320459604\n",
      "Epoch: 20, Loss: 0.0005854521878063679\n",
      "Epoch: 21, Loss: 0.0004421770281624049\n",
      "Epoch: 22, Loss: 0.00046586699318140745\n",
      "Epoch: 23, Loss: 0.0003680630470626056\n",
      "Epoch: 24, Loss: 0.00028914824360981584\n",
      "Epoch: 25, Loss: 0.0003146993403788656\n",
      "Epoch: 26, Loss: 0.00031287226011045277\n",
      "Epoch: 27, Loss: 0.000336430937750265\n",
      "Epoch: 28, Loss: 0.00028782483423128724\n",
      "Epoch: 29, Loss: 0.00021290790755301714\n",
      "Epoch: 30, Loss: 0.00018262969388160855\n",
      "Epoch: 31, Loss: 0.0001713696838123724\n",
      "Epoch: 32, Loss: 0.00017541619308758527\n",
      "Epoch: 33, Loss: 0.00016534137830603868\n",
      "Epoch: 34, Loss: 0.00011190606892341748\n",
      "Epoch: 35, Loss: 9.694382606539875e-05\n",
      "Epoch: 36, Loss: 0.00012811814667657018\n",
      "Epoch: 37, Loss: 0.0001190226903418079\n",
      "Epoch: 38, Loss: 8.379229984711856e-05\n",
      "Epoch: 39, Loss: 8.023189730010927e-05\n",
      "Epoch: 40, Loss: 8.00856578280218e-05\n",
      "Epoch: 41, Loss: 6.125202344264835e-05\n",
      "Epoch: 42, Loss: 5.994321691105142e-05\n",
      "Epoch: 43, Loss: 6.82611862430349e-05\n",
      "Epoch: 44, Loss: 6.14216914982535e-05\n",
      "Epoch: 45, Loss: 4.6501383621944115e-05\n",
      "Epoch: 46, Loss: 4.7188914322759956e-05\n",
      "Epoch: 47, Loss: 4.44453107775189e-05\n",
      "Epoch: 48, Loss: 2.798972673190292e-05\n",
      "Epoch: 49, Loss: 2.5356423066114075e-05\n",
      "Epoch: 50, Loss: 2.7179952667211182e-05\n",
      "epoch 12 tensor([ 0.6008, -2.1523, -0.3077, -0.6460,  0.4290], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.01174996979534626\n",
      "Epoch: 2, Loss: 0.008244981057941914\n",
      "Epoch: 3, Loss: 0.004525383934378624\n",
      "Epoch: 4, Loss: 0.002617715625092387\n",
      "Epoch: 5, Loss: 0.0027512386441230774\n",
      "Epoch: 6, Loss: 0.0047264425083994865\n",
      "Epoch: 7, Loss: 0.004568885080516338\n",
      "Epoch: 8, Loss: 0.0038511501625180244\n",
      "Epoch: 9, Loss: 0.00302717718295753\n",
      "Epoch: 10, Loss: 0.0018055631080642343\n",
      "Epoch: 11, Loss: 0.0013508882839232683\n",
      "Epoch: 12, Loss: 0.001734867226332426\n",
      "Epoch: 13, Loss: 0.0018674671882763505\n",
      "Epoch: 14, Loss: 0.0017872133757919073\n",
      "Epoch: 15, Loss: 0.0017385530518367887\n",
      "Epoch: 16, Loss: 0.0013927025720477104\n",
      "Epoch: 17, Loss: 0.0010003639617934823\n",
      "Epoch: 18, Loss: 0.0009864207822829485\n",
      "Epoch: 19, Loss: 0.0007815824938006699\n",
      "Epoch: 20, Loss: 0.0008473377674818039\n",
      "Epoch: 21, Loss: 0.0008290510158985853\n",
      "Epoch: 22, Loss: 0.0007254430092871189\n",
      "Epoch: 23, Loss: 0.0004902037908323109\n",
      "Epoch: 24, Loss: 0.0005034061032347381\n",
      "Epoch: 25, Loss: 0.0003852549707517028\n",
      "Epoch: 26, Loss: 0.0003335600486025214\n",
      "Epoch: 27, Loss: 0.00040082939085550606\n",
      "Epoch: 28, Loss: 0.0004188060120213777\n",
      "Epoch: 29, Loss: 0.00032025561085902154\n",
      "Epoch: 30, Loss: 0.00031960324849933386\n",
      "Epoch: 31, Loss: 0.00029547480517067015\n",
      "Epoch: 32, Loss: 0.00024166982620954514\n",
      "Epoch: 33, Loss: 0.00018175413424614817\n",
      "Epoch: 34, Loss: 0.0002135666145477444\n",
      "Epoch: 35, Loss: 0.00019151976448483765\n",
      "Epoch: 36, Loss: 0.00017193000530824065\n",
      "Epoch: 37, Loss: 0.00015204481314867735\n",
      "Epoch: 38, Loss: 0.00014425572589971125\n",
      "Epoch: 39, Loss: 0.00013280964049044997\n",
      "Epoch: 40, Loss: 0.0001259103009942919\n",
      "Epoch: 41, Loss: 0.00010385358473286033\n",
      "Epoch: 42, Loss: 9.911271627061069e-05\n",
      "Epoch: 43, Loss: 7.066261605359614e-05\n",
      "Epoch: 44, Loss: 7.316670962609351e-05\n",
      "Epoch: 45, Loss: 7.761076267343014e-05\n",
      "Epoch: 46, Loss: 6.905282498337328e-05\n",
      "Epoch: 47, Loss: 5.5799227993702516e-05\n",
      "Epoch: 48, Loss: 4.6377383114304394e-05\n",
      "Epoch: 49, Loss: 3.8692596717737615e-05\n",
      "Epoch: 50, Loss: 3.9241553167812526e-05\n",
      "________________________________________\n",
      "epoch 13 tensor([ 0.6001, -2.1114, -0.5511, -0.5669,  0.3923], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.08733868598937988\n",
      "Epoch: 2, Loss: 0.04769982025027275\n",
      "Epoch: 3, Loss: 0.03921008110046387\n",
      "Epoch: 4, Loss: 0.04127262532711029\n",
      "Epoch: 5, Loss: 0.03643062710762024\n",
      "Epoch: 6, Loss: 0.027769898995757103\n",
      "Epoch: 7, Loss: 0.02493022382259369\n",
      "Epoch: 8, Loss: 0.0217104721814394\n",
      "Epoch: 9, Loss: 0.015221419744193554\n",
      "Epoch: 10, Loss: 0.011672829277813435\n",
      "Epoch: 11, Loss: 0.012222038581967354\n",
      "Epoch: 12, Loss: 0.013238011859357357\n",
      "Epoch: 13, Loss: 0.012335739098489285\n",
      "Epoch: 14, Loss: 0.010519190691411495\n",
      "Epoch: 15, Loss: 0.008244902826845646\n",
      "Epoch: 16, Loss: 0.006794908549636602\n",
      "Epoch: 17, Loss: 0.006321240682154894\n",
      "Epoch: 18, Loss: 0.0061171529814600945\n",
      "Epoch: 19, Loss: 0.005964505020529032\n",
      "Epoch: 20, Loss: 0.005335877649486065\n",
      "Epoch: 21, Loss: 0.004107756540179253\n",
      "Epoch: 22, Loss: 0.00253362488001585\n",
      "Epoch: 23, Loss: 0.0016025363001972437\n",
      "Epoch: 24, Loss: 0.002084479434415698\n",
      "Epoch: 25, Loss: 0.003058535745367408\n",
      "Epoch: 26, Loss: 0.002966177649796009\n",
      "Epoch: 27, Loss: 0.0021085026673972607\n",
      "Epoch: 28, Loss: 0.0018158262828364968\n",
      "Epoch: 29, Loss: 0.0018510419176891446\n",
      "Epoch: 30, Loss: 0.0014964744914323092\n",
      "Epoch: 31, Loss: 0.001287894556298852\n",
      "Epoch: 32, Loss: 0.0015798299573361874\n",
      "Epoch: 33, Loss: 0.0016914006555452943\n",
      "Epoch: 34, Loss: 0.0012752303155139089\n",
      "Epoch: 35, Loss: 0.0008173526148311794\n",
      "Epoch: 36, Loss: 0.0006743022822774947\n",
      "Epoch: 37, Loss: 0.0006841421709395945\n",
      "Epoch: 38, Loss: 0.0006458977586589754\n",
      "Epoch: 39, Loss: 0.0005811984883621335\n",
      "Epoch: 40, Loss: 0.0005470932810567319\n",
      "Epoch: 41, Loss: 0.0005038409144617617\n",
      "Epoch: 42, Loss: 0.00045930943451821804\n",
      "Epoch: 43, Loss: 0.0004227693716529757\n",
      "Epoch: 44, Loss: 0.0004084597167093307\n",
      "Epoch: 45, Loss: 0.0004315610567573458\n",
      "Epoch: 46, Loss: 0.00039320121868513525\n",
      "Epoch: 47, Loss: 0.00028695902437902987\n",
      "Epoch: 48, Loss: 0.0002292099961778149\n",
      "Epoch: 49, Loss: 0.0002032059128396213\n",
      "Epoch: 50, Loss: 0.00015500644803978503\n",
      "epoch 13 tensor([ 0.5136, -2.4896, -0.6943, -0.5260,  0.4573], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.032147496938705444\n",
      "Epoch: 2, Loss: 0.023830601945519447\n",
      "Epoch: 3, Loss: 0.016324277967214584\n",
      "Epoch: 4, Loss: 0.01146356575191021\n",
      "Epoch: 5, Loss: 0.009703347459435463\n",
      "Epoch: 6, Loss: 0.00934700295329094\n",
      "Epoch: 7, Loss: 0.008725101128220558\n",
      "Epoch: 8, Loss: 0.0069680046290159225\n",
      "Epoch: 9, Loss: 0.005007848143577576\n",
      "Epoch: 10, Loss: 0.00422263378277421\n",
      "Epoch: 11, Loss: 0.004656790755689144\n",
      "Epoch: 12, Loss: 0.005803149193525314\n",
      "Epoch: 13, Loss: 0.0057700639590620995\n",
      "Epoch: 14, Loss: 0.004634821321815252\n",
      "Epoch: 15, Loss: 0.0032948243897408247\n",
      "Epoch: 16, Loss: 0.002153585897758603\n",
      "Epoch: 17, Loss: 0.0019441189942881465\n",
      "Epoch: 18, Loss: 0.0022836520802229643\n",
      "Epoch: 19, Loss: 0.0025470503605902195\n",
      "Epoch: 20, Loss: 0.002292389515787363\n",
      "Epoch: 21, Loss: 0.0016790665686130524\n",
      "Epoch: 22, Loss: 0.0012864230666309595\n",
      "Epoch: 23, Loss: 0.0012491733068600297\n",
      "Epoch: 24, Loss: 0.0013944777892902493\n",
      "Epoch: 25, Loss: 0.0014368669362738729\n",
      "Epoch: 26, Loss: 0.001377567183226347\n",
      "Epoch: 27, Loss: 0.0011108277831226587\n",
      "Epoch: 28, Loss: 0.0008450099849142134\n",
      "Epoch: 29, Loss: 0.0007436619489453733\n",
      "Epoch: 30, Loss: 0.0007100477814674377\n",
      "Epoch: 31, Loss: 0.0006910693482495844\n",
      "Epoch: 32, Loss: 0.0005727047682739794\n",
      "Epoch: 33, Loss: 0.0004297584528103471\n",
      "Epoch: 34, Loss: 0.00032518422813154757\n",
      "Epoch: 35, Loss: 0.0003228100249543786\n",
      "Epoch: 36, Loss: 0.00038799215690232813\n",
      "Epoch: 37, Loss: 0.00045477788080461323\n",
      "Epoch: 38, Loss: 0.00042437377851456404\n",
      "Epoch: 39, Loss: 0.0003477782884147018\n",
      "Epoch: 40, Loss: 0.00027196292649023235\n",
      "Epoch: 41, Loss: 0.00021082482999190688\n",
      "Epoch: 42, Loss: 0.00019912904826924205\n",
      "Epoch: 43, Loss: 0.00017901163664646447\n",
      "Epoch: 44, Loss: 0.00014369131531566381\n",
      "Epoch: 45, Loss: 9.274002513848245e-05\n",
      "Epoch: 46, Loss: 7.802931941114366e-05\n",
      "Epoch: 47, Loss: 9.931929525919259e-05\n",
      "Epoch: 48, Loss: 0.00012846672325395048\n",
      "Epoch: 49, Loss: 0.00013344180479180068\n",
      "Epoch: 50, Loss: 0.00011430613812990487\n",
      "epoch 13 tensor([ 0.5535, -2.5135, -0.4982, -0.4790,  0.4800], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.10810116678476334\n",
      "Epoch: 2, Loss: 0.07470636069774628\n",
      "Epoch: 3, Loss: 0.060446761548519135\n",
      "Epoch: 4, Loss: 0.048122018575668335\n",
      "Epoch: 5, Loss: 0.04654677212238312\n",
      "Epoch: 6, Loss: 0.047185830771923065\n",
      "Epoch: 7, Loss: 0.04138551652431488\n",
      "Epoch: 8, Loss: 0.035756196826696396\n",
      "Epoch: 9, Loss: 0.030480660498142242\n",
      "Epoch: 10, Loss: 0.026114437729120255\n",
      "Epoch: 11, Loss: 0.02221379056572914\n",
      "Epoch: 12, Loss: 0.021770287305116653\n",
      "Epoch: 13, Loss: 0.021426808089017868\n",
      "Epoch: 14, Loss: 0.01750568114221096\n",
      "Epoch: 15, Loss: 0.013786227442324162\n",
      "Epoch: 16, Loss: 0.01208280585706234\n",
      "Epoch: 17, Loss: 0.010380323976278305\n",
      "Epoch: 18, Loss: 0.009691620245575905\n",
      "Epoch: 19, Loss: 0.00927638541907072\n",
      "Epoch: 20, Loss: 0.007594725117087364\n",
      "Epoch: 21, Loss: 0.006068788934499025\n",
      "Epoch: 22, Loss: 0.005755910649895668\n",
      "Epoch: 23, Loss: 0.005643599666655064\n",
      "Epoch: 24, Loss: 0.004925774876028299\n",
      "Epoch: 25, Loss: 0.0043262639082968235\n",
      "Epoch: 26, Loss: 0.004344572313129902\n",
      "Epoch: 27, Loss: 0.003623225726187229\n",
      "Epoch: 28, Loss: 0.0026114583015441895\n",
      "Epoch: 29, Loss: 0.002644873922690749\n",
      "Epoch: 30, Loss: 0.00272170128300786\n",
      "Epoch: 31, Loss: 0.002044080523774028\n",
      "Epoch: 32, Loss: 0.0013960098149254918\n",
      "Epoch: 33, Loss: 0.0012737747747451067\n",
      "Epoch: 34, Loss: 0.0012091385433450341\n",
      "Epoch: 35, Loss: 0.001121017150580883\n",
      "Epoch: 36, Loss: 0.0013506950344890356\n",
      "Epoch: 37, Loss: 0.0013025103835389018\n",
      "Epoch: 38, Loss: 0.0009145579533651471\n",
      "Epoch: 39, Loss: 0.0006889758515171707\n",
      "Epoch: 40, Loss: 0.0005046814912930131\n",
      "Epoch: 41, Loss: 0.00043749064207077026\n",
      "Epoch: 42, Loss: 0.0005856323405168951\n",
      "Epoch: 43, Loss: 0.0007114700856618583\n",
      "Epoch: 44, Loss: 0.0005786070832982659\n",
      "Epoch: 45, Loss: 0.000488361285533756\n",
      "Epoch: 46, Loss: 0.0004998705699108541\n",
      "Epoch: 47, Loss: 0.0003635066095739603\n",
      "Epoch: 48, Loss: 0.00032754463609308004\n",
      "Epoch: 49, Loss: 0.0003577507159207016\n",
      "Epoch: 50, Loss: 0.0002909704635385424\n",
      "epoch 13 tensor([ 0.6662, -2.0023, -0.8988, -0.8060,  0.5072], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.03961563482880592\n",
      "Epoch: 2, Loss: 0.02675987221300602\n",
      "Epoch: 3, Loss: 0.02282116934657097\n",
      "Epoch: 4, Loss: 0.02351338230073452\n",
      "Epoch: 5, Loss: 0.018630318343639374\n",
      "Epoch: 6, Loss: 0.013230523094534874\n",
      "Epoch: 7, Loss: 0.010840429924428463\n",
      "Epoch: 8, Loss: 0.01023618970066309\n",
      "Epoch: 9, Loss: 0.00776303093880415\n",
      "Epoch: 10, Loss: 0.005840982310473919\n",
      "Epoch: 11, Loss: 0.006670490372925997\n",
      "Epoch: 12, Loss: 0.00508898263797164\n",
      "Epoch: 13, Loss: 0.002697303192690015\n",
      "Epoch: 14, Loss: 0.00175095337908715\n",
      "Epoch: 15, Loss: 0.003400202374905348\n",
      "Epoch: 16, Loss: 0.003777827136218548\n",
      "Epoch: 17, Loss: 0.0032893491443246603\n",
      "Epoch: 18, Loss: 0.002846542978659272\n",
      "Epoch: 19, Loss: 0.0036274301819503307\n",
      "Epoch: 20, Loss: 0.0036006716545671225\n",
      "Epoch: 21, Loss: 0.0029464063700288534\n",
      "Epoch: 22, Loss: 0.0025315911043435335\n",
      "Epoch: 23, Loss: 0.002339849481359124\n",
      "Epoch: 24, Loss: 0.001770924893207848\n",
      "Epoch: 25, Loss: 0.0015277799684554338\n",
      "Epoch: 26, Loss: 0.0016914195148274302\n",
      "Epoch: 27, Loss: 0.0014836901100352407\n",
      "Epoch: 28, Loss: 0.0010581137612462044\n",
      "Epoch: 29, Loss: 0.00082731107249856\n",
      "Epoch: 30, Loss: 0.0009094852139241993\n",
      "Epoch: 31, Loss: 0.0007401257171295583\n",
      "Epoch: 32, Loss: 0.00046634243335574865\n",
      "Epoch: 33, Loss: 0.00040707585867494345\n",
      "Epoch: 34, Loss: 0.0005414959159679711\n",
      "Epoch: 35, Loss: 0.0004529063298832625\n",
      "Epoch: 36, Loss: 0.00046092085540294647\n",
      "Epoch: 37, Loss: 0.0005123015725985169\n",
      "Epoch: 38, Loss: 0.0004650490009225905\n",
      "Epoch: 39, Loss: 0.00037195548065938056\n",
      "Epoch: 40, Loss: 0.00041073697502724826\n",
      "Epoch: 41, Loss: 0.00039587440551258624\n",
      "Epoch: 42, Loss: 0.00029099261155351996\n",
      "Epoch: 43, Loss: 0.00023141676501836628\n",
      "Epoch: 44, Loss: 0.0002847106661647558\n",
      "Epoch: 45, Loss: 0.0002586522314231843\n",
      "Epoch: 46, Loss: 0.00016057337052188814\n",
      "Epoch: 47, Loss: 0.0001543836697237566\n",
      "Epoch: 48, Loss: 0.0001437114697182551\n",
      "Epoch: 49, Loss: 0.0001078595596482046\n",
      "Epoch: 50, Loss: 8.065318979788572e-05\n",
      "epoch 13 tensor([ 0.4975, -1.9641, -0.8447, -0.8014,  0.4937], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.039098311215639114\n",
      "Epoch: 2, Loss: 0.024476535618305206\n",
      "Epoch: 3, Loss: 0.01627134345471859\n",
      "Epoch: 4, Loss: 0.014325098134577274\n",
      "Epoch: 5, Loss: 0.013667965307831764\n",
      "Epoch: 6, Loss: 0.011837853118777275\n",
      "Epoch: 7, Loss: 0.008880093693733215\n",
      "Epoch: 8, Loss: 0.006870889104902744\n",
      "Epoch: 9, Loss: 0.005778374150395393\n",
      "Epoch: 10, Loss: 0.005117161199450493\n",
      "Epoch: 11, Loss: 0.005982959643006325\n",
      "Epoch: 12, Loss: 0.006723282393068075\n",
      "Epoch: 13, Loss: 0.006024925038218498\n",
      "Epoch: 14, Loss: 0.004464219324290752\n",
      "Epoch: 15, Loss: 0.0038154416251927614\n",
      "Epoch: 16, Loss: 0.0037013250403106213\n",
      "Epoch: 17, Loss: 0.0039695738814771175\n",
      "Epoch: 18, Loss: 0.003884717123582959\n",
      "Epoch: 19, Loss: 0.0033772634342312813\n",
      "Epoch: 20, Loss: 0.00260531366802752\n",
      "Epoch: 21, Loss: 0.0020418872591108084\n",
      "Epoch: 22, Loss: 0.0015679107746109366\n",
      "Epoch: 23, Loss: 0.0015187731478363276\n",
      "Epoch: 24, Loss: 0.0017371533904224634\n",
      "Epoch: 25, Loss: 0.0018797819502651691\n",
      "Epoch: 26, Loss: 0.0017128661274909973\n",
      "Epoch: 27, Loss: 0.0013267577160149813\n",
      "Epoch: 28, Loss: 0.0008750365814194083\n",
      "Epoch: 29, Loss: 0.0008763532969169319\n",
      "Epoch: 30, Loss: 0.0011969208717346191\n",
      "Epoch: 31, Loss: 0.0011782225919887424\n",
      "Epoch: 32, Loss: 0.0008377547492273152\n",
      "Epoch: 33, Loss: 0.0005939985858276486\n",
      "Epoch: 34, Loss: 0.0005050651961937547\n",
      "Epoch: 35, Loss: 0.0005295781884342432\n",
      "Epoch: 36, Loss: 0.0004659757832996547\n",
      "Epoch: 37, Loss: 0.0003915762063115835\n",
      "Epoch: 38, Loss: 0.0003134737489745021\n",
      "Epoch: 39, Loss: 0.00021531546371988952\n",
      "Epoch: 40, Loss: 0.00021138062584213912\n",
      "Epoch: 41, Loss: 0.0003518596349749714\n",
      "Epoch: 42, Loss: 0.00040982785867527127\n",
      "Epoch: 43, Loss: 0.0003366410091985017\n",
      "Epoch: 44, Loss: 0.0002272236015414819\n",
      "Epoch: 45, Loss: 0.00018009614723268896\n",
      "Epoch: 46, Loss: 0.0001852813147706911\n",
      "Epoch: 47, Loss: 0.00018019047274719924\n",
      "Epoch: 48, Loss: 0.00017218470748048276\n",
      "Epoch: 49, Loss: 0.00014810780703555793\n",
      "Epoch: 50, Loss: 0.00010337217099731788\n",
      "epoch 13 tensor([ 0.5655, -2.0370, -0.8215, -0.6538,  0.5699], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.010611286386847496\n",
      "Epoch: 2, Loss: 0.008403804153203964\n",
      "Epoch: 3, Loss: 0.007057008799165487\n",
      "Epoch: 4, Loss: 0.005579662974923849\n",
      "Epoch: 5, Loss: 0.004221515730023384\n",
      "Epoch: 6, Loss: 0.003128407057374716\n",
      "Epoch: 7, Loss: 0.0025670344475656748\n",
      "Epoch: 8, Loss: 0.002022676868364215\n",
      "Epoch: 9, Loss: 0.0016330202342942357\n",
      "Epoch: 10, Loss: 0.0017169943312183022\n",
      "Epoch: 11, Loss: 0.0018231900176033378\n",
      "Epoch: 12, Loss: 0.0015441423747688532\n",
      "Epoch: 13, Loss: 0.001318213646300137\n",
      "Epoch: 14, Loss: 0.00113043119199574\n",
      "Epoch: 15, Loss: 0.0008737687603570521\n",
      "Epoch: 16, Loss: 0.0006731599569320679\n",
      "Epoch: 17, Loss: 0.0007379995076917112\n",
      "Epoch: 18, Loss: 0.0008592325611971319\n",
      "Epoch: 19, Loss: 0.0006974933785386384\n",
      "Epoch: 20, Loss: 0.0005874708294868469\n",
      "Epoch: 21, Loss: 0.0006619284977205098\n",
      "Epoch: 22, Loss: 0.0006558573804795742\n",
      "Epoch: 23, Loss: 0.0006660884828306735\n",
      "Epoch: 24, Loss: 0.0006386158638633788\n",
      "Epoch: 25, Loss: 0.0005770837888121605\n",
      "Epoch: 26, Loss: 0.0004548416181933135\n",
      "Epoch: 27, Loss: 0.0003850592765957117\n",
      "Epoch: 28, Loss: 0.00034445279743522406\n",
      "Epoch: 29, Loss: 0.00027531874366104603\n",
      "Epoch: 30, Loss: 0.0002437009970890358\n",
      "Epoch: 31, Loss: 0.00023491900356020778\n",
      "Epoch: 32, Loss: 0.0001840216136770323\n",
      "Epoch: 33, Loss: 0.00015665189130231738\n",
      "Epoch: 34, Loss: 0.0001598420349182561\n",
      "Epoch: 35, Loss: 0.00014298234600573778\n",
      "Epoch: 36, Loss: 0.0001071654332918115\n",
      "Epoch: 37, Loss: 9.409658377990127e-05\n",
      "Epoch: 38, Loss: 8.80075604072772e-05\n",
      "Epoch: 39, Loss: 8.237118163378909e-05\n",
      "Epoch: 40, Loss: 8.941160194808617e-05\n",
      "Epoch: 41, Loss: 8.314741717185825e-05\n",
      "Epoch: 42, Loss: 6.5367974457331e-05\n",
      "Epoch: 43, Loss: 6.128209497546777e-05\n",
      "Epoch: 44, Loss: 5.901455006096512e-05\n",
      "Epoch: 45, Loss: 5.382877861848101e-05\n",
      "Epoch: 46, Loss: 5.8265319239581004e-05\n",
      "Epoch: 47, Loss: 5.138917185831815e-05\n",
      "Epoch: 48, Loss: 4.364364212960936e-05\n",
      "Epoch: 49, Loss: 4.3782849388662726e-05\n",
      "Epoch: 50, Loss: 4.462862852960825e-05\n",
      "epoch 13 tensor([ 0.6387, -1.9872, -0.7624, -0.6294,  0.6395], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.014905917458236217\n",
      "Epoch: 2, Loss: 0.011170241981744766\n",
      "Epoch: 3, Loss: 0.0068094199523329735\n",
      "Epoch: 4, Loss: 0.005416299682110548\n",
      "Epoch: 5, Loss: 0.003883163444697857\n",
      "Epoch: 6, Loss: 0.0032209085766226053\n",
      "Epoch: 7, Loss: 0.003891256172209978\n",
      "Epoch: 8, Loss: 0.004288187250494957\n",
      "Epoch: 9, Loss: 0.004749290179461241\n",
      "Epoch: 10, Loss: 0.0033606947399675846\n",
      "Epoch: 11, Loss: 0.0031128728296607733\n",
      "Epoch: 12, Loss: 0.0019763517193496227\n",
      "Epoch: 13, Loss: 0.0019150502048432827\n",
      "Epoch: 14, Loss: 0.0010859845206141472\n",
      "Epoch: 15, Loss: 0.0015465384349226952\n",
      "Epoch: 16, Loss: 0.0013834390556439757\n",
      "Epoch: 17, Loss: 0.0017481478862464428\n",
      "Epoch: 18, Loss: 0.0012372825294733047\n",
      "Epoch: 19, Loss: 0.0013224129797890782\n",
      "Epoch: 20, Loss: 0.0010696225799620152\n",
      "Epoch: 21, Loss: 0.0009934434201568365\n",
      "Epoch: 22, Loss: 0.0006642293883487582\n",
      "Epoch: 23, Loss: 0.000643969455268234\n",
      "Epoch: 24, Loss: 0.0006592005956918001\n",
      "Epoch: 25, Loss: 0.0005510937189683318\n",
      "Epoch: 26, Loss: 0.00054186797933653\n",
      "Epoch: 27, Loss: 0.0004996081697754562\n",
      "Epoch: 28, Loss: 0.0006081825704313815\n",
      "Epoch: 29, Loss: 0.0004589697637129575\n",
      "Epoch: 30, Loss: 0.00041913508903235197\n",
      "Epoch: 31, Loss: 0.00031788210617378354\n",
      "Epoch: 32, Loss: 0.00036423985147848725\n",
      "Epoch: 33, Loss: 0.0002490455226507038\n",
      "Epoch: 34, Loss: 0.0002214051055489108\n",
      "Epoch: 35, Loss: 0.00017870655574370176\n",
      "Epoch: 36, Loss: 0.00023873710597399622\n",
      "Epoch: 37, Loss: 0.00017766194650903344\n",
      "Epoch: 38, Loss: 0.0001772148098098114\n",
      "Epoch: 39, Loss: 0.0001564142294228077\n",
      "Epoch: 40, Loss: 0.00016917753964662552\n",
      "Epoch: 41, Loss: 0.0001123052861657925\n",
      "Epoch: 42, Loss: 0.00010129330621566623\n",
      "Epoch: 43, Loss: 7.711177022429183e-05\n",
      "Epoch: 44, Loss: 8.108620386337861e-05\n",
      "Epoch: 45, Loss: 5.9228073951089755e-05\n",
      "Epoch: 46, Loss: 6.289380689850077e-05\n",
      "Epoch: 47, Loss: 7.648004248039797e-05\n",
      "Epoch: 48, Loss: 6.442797894123942e-05\n",
      "Epoch: 49, Loss: 6.908737850608304e-05\n",
      "Epoch: 50, Loss: 5.1953848014818504e-05\n",
      "epoch 13 tensor([ 0.5141, -1.9021, -0.7164, -0.5474,  0.4907], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.009924664162099361\n",
      "Epoch: 2, Loss: 0.008081143721938133\n",
      "Epoch: 3, Loss: 0.00456449156627059\n",
      "Epoch: 4, Loss: 0.0048877280205488205\n",
      "Epoch: 5, Loss: 0.003554988419637084\n",
      "Epoch: 6, Loss: 0.003998111002147198\n",
      "Epoch: 7, Loss: 0.0025361967273056507\n",
      "Epoch: 8, Loss: 0.0034997088368982077\n",
      "Epoch: 9, Loss: 0.0026112112682312727\n",
      "Epoch: 10, Loss: 0.002172091044485569\n",
      "Epoch: 11, Loss: 0.001776838325895369\n",
      "Epoch: 12, Loss: 0.0016634297790005803\n",
      "Epoch: 13, Loss: 0.0016640870599076152\n",
      "Epoch: 14, Loss: 0.0016145119443535805\n",
      "Epoch: 15, Loss: 0.0012655958998948336\n",
      "Epoch: 16, Loss: 0.0010853807907551527\n",
      "Epoch: 17, Loss: 0.001257400494068861\n",
      "Epoch: 18, Loss: 0.0008466086583212018\n",
      "Epoch: 19, Loss: 0.001162542263045907\n",
      "Epoch: 20, Loss: 0.0007200693944469094\n",
      "Epoch: 21, Loss: 0.0008020988898351789\n",
      "Epoch: 22, Loss: 0.0007570399320684373\n",
      "Epoch: 23, Loss: 0.0006148706888779998\n",
      "Epoch: 24, Loss: 0.0005792363081127405\n",
      "Epoch: 25, Loss: 0.00048524379963055253\n",
      "Epoch: 26, Loss: 0.00030275381868705153\n",
      "Epoch: 27, Loss: 0.00037475451244972646\n",
      "Epoch: 28, Loss: 0.0003043800825253129\n",
      "Epoch: 29, Loss: 0.00031411886448040605\n",
      "Epoch: 30, Loss: 0.0003378138935659081\n",
      "Epoch: 31, Loss: 0.00024090301303658634\n",
      "Epoch: 32, Loss: 0.0002309496485395357\n",
      "Epoch: 33, Loss: 0.00021861758432351053\n",
      "Epoch: 34, Loss: 0.00017044146079570055\n",
      "Epoch: 35, Loss: 0.0001987835275940597\n",
      "Epoch: 36, Loss: 0.0001823020284064114\n",
      "Epoch: 37, Loss: 0.00014361634384840727\n",
      "Epoch: 38, Loss: 0.0001493701565777883\n",
      "Epoch: 39, Loss: 0.00010189011663896963\n",
      "Epoch: 40, Loss: 0.000128299550851807\n",
      "Epoch: 41, Loss: 0.0001107432326534763\n",
      "Epoch: 42, Loss: 8.447216532658786e-05\n",
      "Epoch: 43, Loss: 8.90630399226211e-05\n",
      "Epoch: 44, Loss: 5.6045581004582345e-05\n",
      "Epoch: 45, Loss: 6.584537914022803e-05\n",
      "Epoch: 46, Loss: 4.60711307823658e-05\n",
      "Epoch: 47, Loss: 5.976450120215304e-05\n",
      "Epoch: 48, Loss: 5.1580591389210895e-05\n",
      "Epoch: 49, Loss: 4.040797284687869e-05\n",
      "Epoch: 50, Loss: 3.667523924377747e-05\n",
      "epoch 13 tensor([ 0.5195, -1.9227, -0.7352, -0.4875,  0.4813], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.005206257104873657\n",
      "Epoch: 2, Loss: 0.0038731780368834734\n",
      "Epoch: 3, Loss: 0.002671104623004794\n",
      "Epoch: 4, Loss: 0.0013651991030201316\n",
      "Epoch: 5, Loss: 0.0017794007435441017\n",
      "Epoch: 6, Loss: 0.0020819646306335926\n",
      "Epoch: 7, Loss: 0.0016112533630803227\n",
      "Epoch: 8, Loss: 0.0013015313306823373\n",
      "Epoch: 9, Loss: 0.0013115747133269906\n",
      "Epoch: 10, Loss: 0.000980047625489533\n",
      "Epoch: 11, Loss: 0.0012690520379692316\n",
      "Epoch: 12, Loss: 0.0011194698745384812\n",
      "Epoch: 13, Loss: 0.0008970190538093448\n",
      "Epoch: 14, Loss: 0.0008132564835250378\n",
      "Epoch: 15, Loss: 0.0006125026266090572\n",
      "Epoch: 16, Loss: 0.0007070709834806621\n",
      "Epoch: 17, Loss: 0.0006888695061206818\n",
      "Epoch: 18, Loss: 0.0005186635535210371\n",
      "Epoch: 19, Loss: 0.0004634233482647687\n",
      "Epoch: 20, Loss: 0.0003260573139414191\n",
      "Epoch: 21, Loss: 0.00020793717703782022\n",
      "Epoch: 22, Loss: 0.00038633428630419075\n",
      "Epoch: 23, Loss: 0.00031416252022609115\n",
      "Epoch: 24, Loss: 0.000322439125739038\n",
      "Epoch: 25, Loss: 0.0002894395147450268\n",
      "Epoch: 26, Loss: 0.00016228426829911768\n",
      "Epoch: 27, Loss: 0.00015681474178563803\n",
      "Epoch: 28, Loss: 0.00023305676586460322\n",
      "Epoch: 29, Loss: 0.0001704124006209895\n",
      "Epoch: 30, Loss: 0.00018287521379534155\n",
      "Epoch: 31, Loss: 0.00015511215315200388\n",
      "Epoch: 32, Loss: 0.00010810675303218886\n",
      "Epoch: 33, Loss: 9.597271855454892e-05\n",
      "Epoch: 34, Loss: 0.00014543873840011656\n",
      "Epoch: 35, Loss: 9.277676872443408e-05\n",
      "Epoch: 36, Loss: 8.121581777231768e-05\n",
      "Epoch: 37, Loss: 7.383416232187301e-05\n",
      "Epoch: 38, Loss: 6.56427291687578e-05\n",
      "Epoch: 39, Loss: 4.701048965216614e-05\n",
      "Epoch: 40, Loss: 7.218943210318685e-05\n",
      "Epoch: 41, Loss: 6.690106965834275e-05\n",
      "Epoch: 42, Loss: 5.3302581363823265e-05\n",
      "Epoch: 43, Loss: 3.857086267089471e-05\n",
      "Epoch: 44, Loss: 5.15401698066853e-05\n",
      "Epoch: 45, Loss: 4.156977229285985e-05\n",
      "Epoch: 46, Loss: 2.5620811356930062e-05\n",
      "Epoch: 47, Loss: 2.1077752535347827e-05\n",
      "Epoch: 48, Loss: 3.093451596214436e-05\n",
      "Epoch: 49, Loss: 2.8610853405552916e-05\n",
      "Epoch: 50, Loss: 2.1518271751119755e-05\n",
      "epoch 13 tensor([ 0.5512, -1.9430, -0.5880, -0.5246,  0.5454], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.004721695091575384\n",
      "Epoch: 2, Loss: 0.0034577269107103348\n",
      "Epoch: 3, Loss: 0.002088548382744193\n",
      "Epoch: 4, Loss: 0.0014128760667517781\n",
      "Epoch: 5, Loss: 0.0016312950756400824\n",
      "Epoch: 6, Loss: 0.0013154399348422885\n",
      "Epoch: 7, Loss: 0.0014287700178101659\n",
      "Epoch: 8, Loss: 0.0012326150899752975\n",
      "Epoch: 9, Loss: 0.001269129104912281\n",
      "Epoch: 10, Loss: 0.0009315740899182856\n",
      "Epoch: 11, Loss: 0.0010684665758162737\n",
      "Epoch: 12, Loss: 0.0011720890179276466\n",
      "Epoch: 13, Loss: 0.0008474588394165039\n",
      "Epoch: 14, Loss: 0.0007798576261848211\n",
      "Epoch: 15, Loss: 0.0006200763746164739\n",
      "Epoch: 16, Loss: 0.0005117417313158512\n",
      "Epoch: 17, Loss: 0.00043226397247053683\n",
      "Epoch: 18, Loss: 0.0003701242385432124\n",
      "Epoch: 19, Loss: 0.0004753324028570205\n",
      "Epoch: 20, Loss: 0.0003928685327991843\n",
      "Epoch: 21, Loss: 0.00032123143319040537\n",
      "Epoch: 22, Loss: 0.00032856696634553373\n",
      "Epoch: 23, Loss: 0.00027018526452593505\n",
      "Epoch: 24, Loss: 0.0003009742358699441\n",
      "Epoch: 25, Loss: 0.0003178369370289147\n",
      "Epoch: 26, Loss: 0.00022831906971987337\n",
      "Epoch: 27, Loss: 0.00014742942585144192\n",
      "Epoch: 28, Loss: 0.00016643227718304843\n",
      "Epoch: 29, Loss: 0.00012889578647445887\n",
      "Epoch: 30, Loss: 0.00018970527162309736\n",
      "Epoch: 31, Loss: 0.00016386355855502188\n",
      "Epoch: 32, Loss: 0.00011540600098669529\n",
      "Epoch: 33, Loss: 7.341475429711863e-05\n",
      "Epoch: 34, Loss: 6.339558603940532e-05\n",
      "Epoch: 35, Loss: 7.194415229605511e-05\n",
      "Epoch: 36, Loss: 9.098816371988505e-05\n",
      "Epoch: 37, Loss: 6.833687075413764e-05\n",
      "Epoch: 38, Loss: 7.345736230490729e-05\n",
      "Epoch: 39, Loss: 5.598161806119606e-05\n",
      "Epoch: 40, Loss: 5.8468765928409994e-05\n",
      "Epoch: 41, Loss: 5.3224863222567365e-05\n",
      "Epoch: 42, Loss: 4.16843977291137e-05\n",
      "Epoch: 43, Loss: 4.091231676284224e-05\n",
      "Epoch: 44, Loss: 3.549043321982026e-05\n",
      "Epoch: 45, Loss: 2.9567221645265818e-05\n",
      "Epoch: 46, Loss: 2.4764458430581726e-05\n",
      "Epoch: 47, Loss: 1.8272530724061653e-05\n",
      "Epoch: 48, Loss: 2.7823160053230822e-05\n",
      "Epoch: 49, Loss: 2.7329777367413044e-05\n",
      "Epoch: 50, Loss: 3.195787940057926e-05\n",
      "________________________________________\n",
      "epoch 14 tensor([ 0.5374, -1.9238, -0.6290, -0.4359,  0.2878], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.024289803579449654\n",
      "Epoch: 2, Loss: 0.02159067802131176\n",
      "Epoch: 3, Loss: 0.011593643575906754\n",
      "Epoch: 4, Loss: 0.011879969388246536\n",
      "Epoch: 5, Loss: 0.006537861190736294\n",
      "Epoch: 6, Loss: 0.008553441613912582\n",
      "Epoch: 7, Loss: 0.0070582302287220955\n",
      "Epoch: 8, Loss: 0.005277128890156746\n",
      "Epoch: 9, Loss: 0.0070841251872479916\n",
      "Epoch: 10, Loss: 0.005174283869564533\n",
      "Epoch: 11, Loss: 0.004451453220099211\n",
      "Epoch: 12, Loss: 0.003908614162355661\n",
      "Epoch: 13, Loss: 0.003493229392915964\n",
      "Epoch: 14, Loss: 0.0037325387820601463\n",
      "Epoch: 15, Loss: 0.002451373264193535\n",
      "Epoch: 16, Loss: 0.0025036288425326347\n",
      "Epoch: 17, Loss: 0.002959289588034153\n",
      "Epoch: 18, Loss: 0.0020661382004618645\n",
      "Epoch: 19, Loss: 0.0018286965787410736\n",
      "Epoch: 20, Loss: 0.0017259846208617091\n",
      "Epoch: 21, Loss: 0.0011043116683140397\n",
      "Epoch: 22, Loss: 0.0009119510650634766\n",
      "Epoch: 23, Loss: 0.001153932185843587\n",
      "Epoch: 24, Loss: 0.001361536211334169\n",
      "Epoch: 25, Loss: 0.0011229088995605707\n",
      "Epoch: 26, Loss: 0.0010036653839051723\n",
      "Epoch: 27, Loss: 0.0011315570445731282\n",
      "Epoch: 28, Loss: 0.0008466491708531976\n",
      "Epoch: 29, Loss: 0.000574882491491735\n",
      "Epoch: 30, Loss: 0.0005556959076784551\n",
      "Epoch: 31, Loss: 0.0004906522808596492\n",
      "Epoch: 32, Loss: 0.00046292893239296973\n",
      "Epoch: 33, Loss: 0.00047153860214166343\n",
      "Epoch: 34, Loss: 0.00042917495011352\n",
      "Epoch: 35, Loss: 0.0003858852433040738\n",
      "Epoch: 36, Loss: 0.00036991320666857064\n",
      "Epoch: 37, Loss: 0.000296690093819052\n",
      "Epoch: 38, Loss: 0.00026443906244821846\n",
      "Epoch: 39, Loss: 0.00024329166626557708\n",
      "Epoch: 40, Loss: 0.000169483624631539\n",
      "Epoch: 41, Loss: 0.0002209734229836613\n",
      "Epoch: 42, Loss: 0.0002443724370095879\n",
      "Epoch: 43, Loss: 0.00017417880007997155\n",
      "Epoch: 44, Loss: 0.00015564067871309817\n",
      "Epoch: 45, Loss: 0.00013446391676552594\n",
      "Epoch: 46, Loss: 0.00010235737863695249\n",
      "Epoch: 47, Loss: 6.802067946409807e-05\n",
      "Epoch: 48, Loss: 8.829058788251132e-05\n",
      "Epoch: 49, Loss: 9.232776938006282e-05\n",
      "Epoch: 50, Loss: 8.711460395716131e-05\n",
      "epoch 14 tensor([ 0.5914, -1.8198, -0.5726, -0.5410,  0.3496], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.03929978981614113\n",
      "Epoch: 2, Loss: 0.026927156373858452\n",
      "Epoch: 3, Loss: 0.01890747994184494\n",
      "Epoch: 4, Loss: 0.012198551557958126\n",
      "Epoch: 5, Loss: 0.01228371262550354\n",
      "Epoch: 6, Loss: 0.011804981157183647\n",
      "Epoch: 7, Loss: 0.009238481521606445\n",
      "Epoch: 8, Loss: 0.008164545521140099\n",
      "Epoch: 9, Loss: 0.006799042224884033\n",
      "Epoch: 10, Loss: 0.006008202210068703\n",
      "Epoch: 11, Loss: 0.006079714745283127\n",
      "Epoch: 12, Loss: 0.00504126213490963\n",
      "Epoch: 13, Loss: 0.004309623036533594\n",
      "Epoch: 14, Loss: 0.003918815869837999\n",
      "Epoch: 15, Loss: 0.0029547743033617735\n",
      "Epoch: 16, Loss: 0.002881495049223304\n",
      "Epoch: 17, Loss: 0.002956029260531068\n",
      "Epoch: 18, Loss: 0.0030330372974276543\n",
      "Epoch: 19, Loss: 0.003638340625911951\n",
      "Epoch: 20, Loss: 0.0036368437577039003\n",
      "Epoch: 21, Loss: 0.0028793031815439463\n",
      "Epoch: 22, Loss: 0.001986487302929163\n",
      "Epoch: 23, Loss: 0.0013385299826040864\n",
      "Epoch: 24, Loss: 0.001280120573937893\n",
      "Epoch: 25, Loss: 0.0014482694678008556\n",
      "Epoch: 26, Loss: 0.0013501491630449891\n",
      "Epoch: 27, Loss: 0.0010839963797479868\n",
      "Epoch: 28, Loss: 0.0008442949620075524\n",
      "Epoch: 29, Loss: 0.0006951275281608105\n",
      "Epoch: 30, Loss: 0.0007385052158497274\n",
      "Epoch: 31, Loss: 0.0007481856155209243\n",
      "Epoch: 32, Loss: 0.0007054960587993264\n",
      "Epoch: 33, Loss: 0.0006580155459232628\n",
      "Epoch: 34, Loss: 0.0005231491522863507\n",
      "Epoch: 35, Loss: 0.0003998645406682044\n",
      "Epoch: 36, Loss: 0.000325894943671301\n",
      "Epoch: 37, Loss: 0.00032852706499397755\n",
      "Epoch: 38, Loss: 0.0004185675352346152\n",
      "Epoch: 39, Loss: 0.0004529031284619123\n",
      "Epoch: 40, Loss: 0.00038118657539598644\n",
      "Epoch: 41, Loss: 0.00026318448362872005\n",
      "Epoch: 42, Loss: 0.0001757536083459854\n",
      "Epoch: 43, Loss: 0.00019133933528792113\n",
      "Epoch: 44, Loss: 0.00021679318160749972\n",
      "Epoch: 45, Loss: 0.00018251720757689327\n",
      "Epoch: 46, Loss: 0.00013578150537796319\n",
      "Epoch: 47, Loss: 0.00010432406998006627\n",
      "Epoch: 48, Loss: 0.00012230635911691934\n",
      "Epoch: 49, Loss: 0.00014651930541731417\n",
      "Epoch: 50, Loss: 0.0001401622430421412\n",
      "epoch 14 tensor([ 0.5579, -1.7862, -0.3997, -0.5610,  0.4305], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.008802760392427444\n",
      "Epoch: 2, Loss: 0.005554497241973877\n",
      "Epoch: 3, Loss: 0.005319218151271343\n",
      "Epoch: 4, Loss: 0.0036814871709793806\n",
      "Epoch: 5, Loss: 0.00394961703568697\n",
      "Epoch: 6, Loss: 0.0017701830947771668\n",
      "Epoch: 7, Loss: 0.003133947029709816\n",
      "Epoch: 8, Loss: 0.0024351750034838915\n",
      "Epoch: 9, Loss: 0.0019355281256139278\n",
      "Epoch: 10, Loss: 0.002302386797964573\n",
      "Epoch: 11, Loss: 0.0020197960548102856\n",
      "Epoch: 12, Loss: 0.0023605620954185724\n",
      "Epoch: 13, Loss: 0.0011719592148438096\n",
      "Epoch: 14, Loss: 0.0014651736710220575\n",
      "Epoch: 15, Loss: 0.0014850205043330789\n",
      "Epoch: 16, Loss: 0.0009565743966959417\n",
      "Epoch: 17, Loss: 0.0008932696073316038\n",
      "Epoch: 18, Loss: 0.000653302064165473\n",
      "Epoch: 19, Loss: 0.0010618068045005202\n",
      "Epoch: 20, Loss: 0.0006513696862384677\n",
      "Epoch: 21, Loss: 0.0005289996042847633\n",
      "Epoch: 22, Loss: 0.0007756376871839166\n",
      "Epoch: 23, Loss: 0.0004823292838409543\n",
      "Epoch: 24, Loss: 0.0004271500511094928\n",
      "Epoch: 25, Loss: 0.0003292923793196678\n",
      "Epoch: 26, Loss: 0.00042328322888351977\n",
      "Epoch: 27, Loss: 0.0003086214419454336\n",
      "Epoch: 28, Loss: 0.00019971861911471933\n",
      "Epoch: 29, Loss: 0.00027259523631073534\n",
      "Epoch: 30, Loss: 0.00019828052609227598\n",
      "Epoch: 31, Loss: 0.0002482944983057678\n",
      "Epoch: 32, Loss: 0.0001755519915604964\n",
      "Epoch: 33, Loss: 0.00024257642508018762\n",
      "Epoch: 34, Loss: 0.00018914820975624025\n",
      "Epoch: 35, Loss: 0.00011481077672215179\n",
      "Epoch: 36, Loss: 0.0001503352541476488\n",
      "Epoch: 37, Loss: 0.000136127375299111\n",
      "Epoch: 38, Loss: 0.00012031512596877292\n",
      "Epoch: 39, Loss: 5.970951315248385e-05\n",
      "Epoch: 40, Loss: 0.00012425630120560527\n",
      "Epoch: 41, Loss: 7.373073458438739e-05\n",
      "Epoch: 42, Loss: 7.10211752448231e-05\n",
      "Epoch: 43, Loss: 7.089409336913377e-05\n",
      "Epoch: 44, Loss: 7.759704749332741e-05\n",
      "Epoch: 45, Loss: 6.276102067204192e-05\n",
      "Epoch: 46, Loss: 6.206437683431432e-05\n",
      "Epoch: 47, Loss: 5.709696051781066e-05\n",
      "Epoch: 48, Loss: 3.348179961903952e-05\n",
      "Epoch: 49, Loss: 4.033092045574449e-05\n",
      "Epoch: 50, Loss: 3.1949715776136145e-05\n",
      "epoch 14 tensor([ 0.6012, -1.8026, -0.4072, -0.5709,  0.4631], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.008564649149775505\n",
      "Epoch: 2, Loss: 0.004600155167281628\n",
      "Epoch: 3, Loss: 0.003022979013621807\n",
      "Epoch: 4, Loss: 0.0028422123286873102\n",
      "Epoch: 5, Loss: 0.0030705779790878296\n",
      "Epoch: 6, Loss: 0.003254766808822751\n",
      "Epoch: 7, Loss: 0.0027512533124536276\n",
      "Epoch: 8, Loss: 0.0018023938173428178\n",
      "Epoch: 9, Loss: 0.0012688253773376346\n",
      "Epoch: 10, Loss: 0.0015674852766096592\n",
      "Epoch: 11, Loss: 0.0016661419067531824\n",
      "Epoch: 12, Loss: 0.001454175915569067\n",
      "Epoch: 13, Loss: 0.0013274858938530087\n",
      "Epoch: 14, Loss: 0.0011164783500134945\n",
      "Epoch: 15, Loss: 0.0007817638106644154\n",
      "Epoch: 16, Loss: 0.0008061627158895135\n",
      "Epoch: 17, Loss: 0.0008991158101707697\n",
      "Epoch: 18, Loss: 0.0008222804754041135\n",
      "Epoch: 19, Loss: 0.0007148320437408984\n",
      "Epoch: 20, Loss: 0.0006498540751636028\n",
      "Epoch: 21, Loss: 0.0005728023825213313\n",
      "Epoch: 22, Loss: 0.0004916653269901872\n",
      "Epoch: 23, Loss: 0.0005081919953227043\n",
      "Epoch: 24, Loss: 0.0004998820368200541\n",
      "Epoch: 25, Loss: 0.0004017912142444402\n",
      "Epoch: 26, Loss: 0.0002569342905189842\n",
      "Epoch: 27, Loss: 0.00020322174532338977\n",
      "Epoch: 28, Loss: 0.00029738497687503695\n",
      "Epoch: 29, Loss: 0.0002909391769208014\n",
      "Epoch: 30, Loss: 0.00018049514619633555\n",
      "Epoch: 31, Loss: 0.0001562875258969143\n",
      "Epoch: 32, Loss: 0.00018591897969599813\n",
      "Epoch: 33, Loss: 0.00018590934632811695\n",
      "Epoch: 34, Loss: 0.00016589784354437143\n",
      "Epoch: 35, Loss: 0.00013790736556984484\n",
      "Epoch: 36, Loss: 0.00012092925317119807\n",
      "Epoch: 37, Loss: 0.00013317888078745455\n",
      "Epoch: 38, Loss: 0.00012119123130105436\n",
      "Epoch: 39, Loss: 8.059338870225474e-05\n",
      "Epoch: 40, Loss: 6.803181167924777e-05\n",
      "Epoch: 41, Loss: 8.129285561153665e-05\n",
      "Epoch: 42, Loss: 8.453778718831018e-05\n",
      "Epoch: 43, Loss: 7.697115506744012e-05\n",
      "Epoch: 44, Loss: 6.570074037881568e-05\n",
      "Epoch: 45, Loss: 5.2937168220523745e-05\n",
      "Epoch: 46, Loss: 4.641140185412951e-05\n",
      "Epoch: 47, Loss: 3.318665039842017e-05\n",
      "Epoch: 48, Loss: 2.6660472940420732e-05\n",
      "Epoch: 49, Loss: 3.17518315569032e-05\n",
      "Epoch: 50, Loss: 3.303277480881661e-05\n",
      "epoch 14 tensor([ 0.5981, -1.8298, -0.2737, -0.5708,  0.4276], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0037282276898622513\n",
      "Epoch: 2, Loss: 0.0028927975799888372\n",
      "Epoch: 3, Loss: 0.0024762405082583427\n",
      "Epoch: 4, Loss: 0.0015496781561523676\n",
      "Epoch: 5, Loss: 0.0012522945180535316\n",
      "Epoch: 6, Loss: 0.0011040142271667719\n",
      "Epoch: 7, Loss: 0.000758553680498153\n",
      "Epoch: 8, Loss: 0.0008581284200772643\n",
      "Epoch: 9, Loss: 0.0010182472178712487\n",
      "Epoch: 10, Loss: 0.0007115615881048143\n",
      "Epoch: 11, Loss: 0.0009135050349868834\n",
      "Epoch: 12, Loss: 0.0008810004801489413\n",
      "Epoch: 13, Loss: 0.0008097795653156936\n",
      "Epoch: 14, Loss: 0.0005692234844900668\n",
      "Epoch: 15, Loss: 0.0006375344237312675\n",
      "Epoch: 16, Loss: 0.00036890379851683974\n",
      "Epoch: 17, Loss: 0.0003574001311790198\n",
      "Epoch: 18, Loss: 0.0003283889964222908\n",
      "Epoch: 19, Loss: 0.00027833436615765095\n",
      "Epoch: 20, Loss: 0.00031157940975390375\n",
      "Epoch: 21, Loss: 0.00035072624450549483\n",
      "Epoch: 22, Loss: 0.0002053701173281297\n",
      "Epoch: 23, Loss: 0.0002742754004430026\n",
      "Epoch: 24, Loss: 0.00022300965792965144\n",
      "Epoch: 25, Loss: 0.00020413583843037486\n",
      "Epoch: 26, Loss: 0.00016127878916449845\n",
      "Epoch: 27, Loss: 0.00015569919196423143\n",
      "Epoch: 28, Loss: 0.00011926785373361781\n",
      "Epoch: 29, Loss: 0.00012929335935041308\n",
      "Epoch: 30, Loss: 9.4821305538062e-05\n",
      "Epoch: 31, Loss: 0.00012527668150141835\n",
      "Epoch: 32, Loss: 9.444435272598639e-05\n",
      "Epoch: 33, Loss: 8.845608681440353e-05\n",
      "Epoch: 34, Loss: 8.840500959195197e-05\n",
      "Epoch: 35, Loss: 7.34808636480011e-05\n",
      "Epoch: 36, Loss: 4.980109224561602e-05\n",
      "Epoch: 37, Loss: 6.158376345410943e-05\n",
      "Epoch: 38, Loss: 4.8538688133703545e-05\n",
      "Epoch: 39, Loss: 4.75661909149494e-05\n",
      "Epoch: 40, Loss: 4.89453632326331e-05\n",
      "Epoch: 41, Loss: 5.878637603018433e-05\n",
      "Epoch: 42, Loss: 9.606110688764602e-05\n",
      "Epoch: 43, Loss: 0.00017374054004903883\n",
      "Epoch: 44, Loss: 0.00041442975634709\n",
      "Epoch: 45, Loss: 0.0006880914443172514\n",
      "Epoch: 46, Loss: 0.0005506977322511375\n",
      "Epoch: 47, Loss: 0.00011120041745016351\n",
      "Epoch: 48, Loss: 0.00015907231136225164\n",
      "Epoch: 49, Loss: 0.00039447142626158893\n",
      "Epoch: 50, Loss: 0.00024452703655697405\n",
      "epoch 14 tensor([ 0.5428, -1.7105, -0.3165, -0.5635,  0.4357], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.006304058246314526\n",
      "Epoch: 2, Loss: 0.004308883100748062\n",
      "Epoch: 3, Loss: 0.002313491189852357\n",
      "Epoch: 4, Loss: 0.0018228664994239807\n",
      "Epoch: 5, Loss: 0.001629684236831963\n",
      "Epoch: 6, Loss: 0.0017908161971718073\n",
      "Epoch: 7, Loss: 0.0019556309562176466\n",
      "Epoch: 8, Loss: 0.0017118897521868348\n",
      "Epoch: 9, Loss: 0.0015733529580757022\n",
      "Epoch: 10, Loss: 0.0012460072757676244\n",
      "Epoch: 11, Loss: 0.0009251481387764215\n",
      "Epoch: 12, Loss: 0.0008333143778145313\n",
      "Epoch: 13, Loss: 0.000754036707803607\n",
      "Epoch: 14, Loss: 0.0007776796701364219\n",
      "Epoch: 15, Loss: 0.0007419317262247205\n",
      "Epoch: 16, Loss: 0.0007389233796857297\n",
      "Epoch: 17, Loss: 0.0006553169805556536\n",
      "Epoch: 18, Loss: 0.0005295334849506617\n",
      "Epoch: 19, Loss: 0.0004392191767692566\n",
      "Epoch: 20, Loss: 0.00033585456549189985\n",
      "Epoch: 21, Loss: 0.0003523713967297226\n",
      "Epoch: 22, Loss: 0.00029459036886692047\n",
      "Epoch: 23, Loss: 0.00026222431915812194\n",
      "Epoch: 24, Loss: 0.00033080129651352763\n",
      "Epoch: 25, Loss: 0.00027872147620655596\n",
      "Epoch: 26, Loss: 0.00021148231462575495\n",
      "Epoch: 27, Loss: 0.0001749205548549071\n",
      "Epoch: 28, Loss: 0.00014503618876915425\n",
      "Epoch: 29, Loss: 0.00016850215615704656\n",
      "Epoch: 30, Loss: 0.00017086394655052572\n",
      "Epoch: 31, Loss: 0.00014216573617886752\n",
      "Epoch: 32, Loss: 0.0001314806577283889\n",
      "Epoch: 33, Loss: 0.00011642735626082867\n",
      "Epoch: 34, Loss: 0.0001349873055005446\n",
      "Epoch: 35, Loss: 0.00017391618166584522\n",
      "Epoch: 36, Loss: 0.00019564547983463854\n",
      "Epoch: 37, Loss: 0.0002328817208763212\n",
      "Epoch: 38, Loss: 0.0002628018846735358\n",
      "Epoch: 39, Loss: 0.0002515996166039258\n",
      "Epoch: 40, Loss: 0.00020010731532238424\n",
      "Epoch: 41, Loss: 0.00011755988816730678\n",
      "Epoch: 42, Loss: 6.624963134527206e-05\n",
      "Epoch: 43, Loss: 0.00010149399167858064\n",
      "Epoch: 44, Loss: 0.00014400522923097014\n",
      "Epoch: 45, Loss: 0.0001275950635317713\n",
      "Epoch: 46, Loss: 8.9275163190905e-05\n",
      "Epoch: 47, Loss: 5.923685966990888e-05\n",
      "Epoch: 48, Loss: 6.764856516383588e-05\n",
      "Epoch: 49, Loss: 0.00011761264613596722\n",
      "Epoch: 50, Loss: 0.00014737126184627414\n",
      "epoch 14 tensor([ 0.5528, -1.8229, -0.3170, -0.5745,  0.3426], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.013272600248456001\n",
      "Epoch: 2, Loss: 0.009746598079800606\n",
      "Epoch: 3, Loss: 0.006556172389537096\n",
      "Epoch: 4, Loss: 0.004122847691178322\n",
      "Epoch: 5, Loss: 0.003695933148264885\n",
      "Epoch: 6, Loss: 0.0033799135126173496\n",
      "Epoch: 7, Loss: 0.0028593612369149923\n",
      "Epoch: 8, Loss: 0.002984888618811965\n",
      "Epoch: 9, Loss: 0.002036162419244647\n",
      "Epoch: 10, Loss: 0.001557184150442481\n",
      "Epoch: 11, Loss: 0.0016293717781081796\n",
      "Epoch: 12, Loss: 0.0017905712593346834\n",
      "Epoch: 13, Loss: 0.002011905424296856\n",
      "Epoch: 14, Loss: 0.0016519470373168588\n",
      "Epoch: 15, Loss: 0.0012970102252438664\n",
      "Epoch: 16, Loss: 0.0012586128432303667\n",
      "Epoch: 17, Loss: 0.0010962323285639286\n",
      "Epoch: 18, Loss: 0.0010346926283091307\n",
      "Epoch: 19, Loss: 0.0007591894245706499\n",
      "Epoch: 20, Loss: 0.0006575999432243407\n",
      "Epoch: 21, Loss: 0.0006867937627248466\n",
      "Epoch: 22, Loss: 0.0005113161751069129\n",
      "Epoch: 23, Loss: 0.0004959356156177819\n",
      "Epoch: 24, Loss: 0.0004831188125535846\n",
      "Epoch: 25, Loss: 0.0005364397657103837\n",
      "Epoch: 26, Loss: 0.0004333503602538258\n",
      "Epoch: 27, Loss: 0.00027116425917483866\n",
      "Epoch: 28, Loss: 0.00023297731240745634\n",
      "Epoch: 29, Loss: 0.0003405930183362216\n",
      "Epoch: 30, Loss: 0.0003082787443418056\n",
      "Epoch: 31, Loss: 0.00028990409919060767\n",
      "Epoch: 32, Loss: 0.00022279132099356502\n",
      "Epoch: 33, Loss: 0.00020932964980602264\n",
      "Epoch: 34, Loss: 0.00020183670858386904\n",
      "Epoch: 35, Loss: 0.00013490315177477896\n",
      "Epoch: 36, Loss: 0.0001233146758750081\n",
      "Epoch: 37, Loss: 0.00017395704344380647\n",
      "Epoch: 38, Loss: 0.00012963962217327207\n",
      "Epoch: 39, Loss: 8.969541522674263e-05\n",
      "Epoch: 40, Loss: 7.838182500563562e-05\n",
      "Epoch: 41, Loss: 7.558440120192245e-05\n",
      "Epoch: 42, Loss: 9.191356366500258e-05\n",
      "Epoch: 43, Loss: 7.648013706784695e-05\n",
      "Epoch: 44, Loss: 5.9418762248242274e-05\n",
      "Epoch: 45, Loss: 5.5400891142198816e-05\n",
      "Epoch: 46, Loss: 7.019585609668866e-05\n",
      "Epoch: 47, Loss: 5.487665475811809e-05\n",
      "Epoch: 48, Loss: 4.007728421129286e-05\n",
      "Epoch: 49, Loss: 4.84015436086338e-05\n",
      "Epoch: 50, Loss: 3.906122947228141e-05\n",
      "epoch 14 tensor([ 0.5396, -1.9096, -0.3784, -0.4633,  0.2028], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.015275494195520878\n",
      "Epoch: 2, Loss: 0.009272773750126362\n",
      "Epoch: 3, Loss: 0.003836539573967457\n",
      "Epoch: 4, Loss: 0.004494794644415379\n",
      "Epoch: 5, Loss: 0.0046212212182581425\n",
      "Epoch: 6, Loss: 0.00510535528883338\n",
      "Epoch: 7, Loss: 0.0034322848077863455\n",
      "Epoch: 8, Loss: 0.003888255450874567\n",
      "Epoch: 9, Loss: 0.003325994359329343\n",
      "Epoch: 10, Loss: 0.002992861671373248\n",
      "Epoch: 11, Loss: 0.0020367116667330265\n",
      "Epoch: 12, Loss: 0.002374975010752678\n",
      "Epoch: 13, Loss: 0.00196396978572011\n",
      "Epoch: 14, Loss: 0.002046214183792472\n",
      "Epoch: 15, Loss: 0.0016441160114482045\n",
      "Epoch: 16, Loss: 0.0014485435094684362\n",
      "Epoch: 17, Loss: 0.0012301524402573705\n",
      "Epoch: 18, Loss: 0.0014238606672734022\n",
      "Epoch: 19, Loss: 0.0008957785903476179\n",
      "Epoch: 20, Loss: 0.0007685180753469467\n",
      "Epoch: 21, Loss: 0.0006458780844695866\n",
      "Epoch: 22, Loss: 0.0008689409005455673\n",
      "Epoch: 23, Loss: 0.0008865062845870852\n",
      "Epoch: 24, Loss: 0.000810515193734318\n",
      "Epoch: 25, Loss: 0.0005653075058944523\n",
      "Epoch: 26, Loss: 0.0006156269810162485\n",
      "Epoch: 27, Loss: 0.0005283470964059234\n",
      "Epoch: 28, Loss: 0.00046328353346325457\n",
      "Epoch: 29, Loss: 0.00028942202334292233\n",
      "Epoch: 30, Loss: 0.0002564375172369182\n",
      "Epoch: 31, Loss: 0.0002308795665157959\n",
      "Epoch: 32, Loss: 0.00032740726601332426\n",
      "Epoch: 33, Loss: 0.0002902394626289606\n",
      "Epoch: 34, Loss: 0.00022895578877069056\n",
      "Epoch: 35, Loss: 0.00023170649365056306\n",
      "Epoch: 36, Loss: 0.00020315044093877077\n",
      "Epoch: 37, Loss: 0.0001841543853515759\n",
      "Epoch: 38, Loss: 0.0001308562932536006\n",
      "Epoch: 39, Loss: 0.00012564178905449808\n",
      "Epoch: 40, Loss: 0.00013075137394480407\n",
      "Epoch: 41, Loss: 0.00014099468535277992\n",
      "Epoch: 42, Loss: 9.829651389736682e-05\n",
      "Epoch: 43, Loss: 9.271961607737467e-05\n",
      "Epoch: 44, Loss: 9.05644556041807e-05\n",
      "Epoch: 45, Loss: 8.545975288143381e-05\n",
      "Epoch: 46, Loss: 7.379041198873892e-05\n",
      "Epoch: 47, Loss: 4.510006692726165e-05\n",
      "Epoch: 48, Loss: 7.336187991313636e-05\n",
      "Epoch: 49, Loss: 0.0001118626823881641\n",
      "Epoch: 50, Loss: 0.00018092057143803686\n",
      "epoch 14 tensor([ 0.5449, -1.7872, -0.5791, -0.5625,  0.4145], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.010251959785819054\n",
      "Epoch: 2, Loss: 0.00721117714419961\n",
      "Epoch: 3, Loss: 0.004987449385225773\n",
      "Epoch: 4, Loss: 0.0028699033427983522\n",
      "Epoch: 5, Loss: 0.002962749917060137\n",
      "Epoch: 6, Loss: 0.0028250976465642452\n",
      "Epoch: 7, Loss: 0.0034840514417737722\n",
      "Epoch: 8, Loss: 0.002726238453760743\n",
      "Epoch: 9, Loss: 0.0023739191237837076\n",
      "Epoch: 10, Loss: 0.001968088559806347\n",
      "Epoch: 11, Loss: 0.0012461874866858125\n",
      "Epoch: 12, Loss: 0.0012659610947594047\n",
      "Epoch: 13, Loss: 0.0012166807428002357\n",
      "Epoch: 14, Loss: 0.0011788951233029366\n",
      "Epoch: 15, Loss: 0.0015546658542007208\n",
      "Epoch: 16, Loss: 0.0014583225129172206\n",
      "Epoch: 17, Loss: 0.0011592113878577948\n",
      "Epoch: 18, Loss: 0.0009290027664974332\n",
      "Epoch: 19, Loss: 0.0007349562365561724\n",
      "Epoch: 20, Loss: 0.0007505111279897392\n",
      "Epoch: 21, Loss: 0.0005733096040785313\n",
      "Epoch: 22, Loss: 0.0006549312965944409\n",
      "Epoch: 23, Loss: 0.0005051784683018923\n",
      "Epoch: 24, Loss: 0.0004496090405154973\n",
      "Epoch: 25, Loss: 0.0005048997700214386\n",
      "Epoch: 26, Loss: 0.0003000005963258445\n",
      "Epoch: 27, Loss: 0.0003183894732501358\n",
      "Epoch: 28, Loss: 0.00024375670182053\n",
      "Epoch: 29, Loss: 0.00025207592989318073\n",
      "Epoch: 30, Loss: 0.00028793877572752535\n",
      "Epoch: 31, Loss: 0.00029619995621033013\n",
      "Epoch: 32, Loss: 0.00032200809800997376\n",
      "Epoch: 33, Loss: 0.00022919110779184848\n",
      "Epoch: 34, Loss: 0.00020361246424727142\n",
      "Epoch: 35, Loss: 0.0001136835417128168\n",
      "Epoch: 36, Loss: 0.00010260137787554413\n",
      "Epoch: 37, Loss: 0.00013112880697008222\n",
      "Epoch: 38, Loss: 0.00012013472587568685\n",
      "Epoch: 39, Loss: 0.00014318703324534\n",
      "Epoch: 40, Loss: 0.000123867008369416\n",
      "Epoch: 41, Loss: 0.00010324368486180902\n",
      "Epoch: 42, Loss: 8.09889315860346e-05\n",
      "Epoch: 43, Loss: 9.262501407647505e-05\n",
      "Epoch: 44, Loss: 0.00011164139868924394\n",
      "Epoch: 45, Loss: 0.00019769780919887125\n",
      "Epoch: 46, Loss: 0.0002977069525513798\n",
      "Epoch: 47, Loss: 0.0004367196816019714\n",
      "Epoch: 48, Loss: 0.0005834939074702561\n",
      "Epoch: 49, Loss: 0.0005359210190363228\n",
      "Epoch: 50, Loss: 0.0002811192243825644\n",
      "epoch 14 tensor([ 0.5492, -1.8366, -0.5611, -0.5650,  0.5322], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.014799189753830433\n",
      "Epoch: 2, Loss: 0.011069773696362972\n",
      "Epoch: 3, Loss: 0.00685402937233448\n",
      "Epoch: 4, Loss: 0.004407869186252356\n",
      "Epoch: 5, Loss: 0.005045943893492222\n",
      "Epoch: 6, Loss: 0.0041597806848585606\n",
      "Epoch: 7, Loss: 0.004381692502647638\n",
      "Epoch: 8, Loss: 0.003975769970566034\n",
      "Epoch: 9, Loss: 0.00279256422072649\n",
      "Epoch: 10, Loss: 0.002266127848997712\n",
      "Epoch: 11, Loss: 0.0011935308575630188\n",
      "Epoch: 12, Loss: 0.0017004121327772737\n",
      "Epoch: 13, Loss: 0.0023280198220163584\n",
      "Epoch: 14, Loss: 0.002469167346134782\n",
      "Epoch: 15, Loss: 0.0025270855985581875\n",
      "Epoch: 16, Loss: 0.0017714363057166338\n",
      "Epoch: 17, Loss: 0.0013262544525787234\n",
      "Epoch: 18, Loss: 0.0010194550268352032\n",
      "Epoch: 19, Loss: 0.0010048826225101948\n",
      "Epoch: 20, Loss: 0.0010583564871922135\n",
      "Epoch: 21, Loss: 0.0008738392498344183\n",
      "Epoch: 22, Loss: 0.0009642399963922799\n",
      "Epoch: 23, Loss: 0.0008147556218318641\n",
      "Epoch: 24, Loss: 0.000575506710447371\n",
      "Epoch: 25, Loss: 0.00038164074067026377\n",
      "Epoch: 26, Loss: 0.00034319848055019975\n",
      "Epoch: 27, Loss: 0.0004615980724338442\n",
      "Epoch: 28, Loss: 0.00047830064431764185\n",
      "Epoch: 29, Loss: 0.0004627335583791137\n",
      "Epoch: 30, Loss: 0.0004534511244855821\n",
      "Epoch: 31, Loss: 0.0003446678165346384\n",
      "Epoch: 32, Loss: 0.0003297459043096751\n",
      "Epoch: 33, Loss: 0.000228440054343082\n",
      "Epoch: 34, Loss: 0.00020417779160197824\n",
      "Epoch: 35, Loss: 0.0002409676817478612\n",
      "Epoch: 36, Loss: 0.0002029295574175194\n",
      "Epoch: 37, Loss: 0.00019635670469142497\n",
      "Epoch: 38, Loss: 0.00015389711188618094\n",
      "Epoch: 39, Loss: 9.985282667912543e-05\n",
      "Epoch: 40, Loss: 9.877844422589988e-05\n",
      "Epoch: 41, Loss: 0.0001082277885871008\n",
      "Epoch: 42, Loss: 8.081471605692059e-05\n",
      "Epoch: 43, Loss: 0.0001066751210601069\n",
      "Epoch: 44, Loss: 0.0001183163549285382\n",
      "Epoch: 45, Loss: 9.809317270992324e-05\n",
      "Epoch: 46, Loss: 8.336880273418501e-05\n",
      "Epoch: 47, Loss: 6.924317131051794e-05\n",
      "Epoch: 48, Loss: 5.73697907384485e-05\n",
      "Epoch: 49, Loss: 5.972681537969038e-05\n",
      "Epoch: 50, Loss: 5.632930333376862e-05\n",
      "________________________________________\n",
      "epoch 15 tensor([ 0.5479, -1.9368, -0.6389, -0.5753,  0.5212], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.019815661013126373\n",
      "Epoch: 2, Loss: 0.008927389979362488\n",
      "Epoch: 3, Loss: 0.010232611559331417\n",
      "Epoch: 4, Loss: 0.010267512872815132\n",
      "Epoch: 5, Loss: 0.007875945419073105\n",
      "Epoch: 6, Loss: 0.003567535663023591\n",
      "Epoch: 7, Loss: 0.005006360821425915\n",
      "Epoch: 8, Loss: 0.005051761399954557\n",
      "Epoch: 9, Loss: 0.003959980793297291\n",
      "Epoch: 10, Loss: 0.003471388714388013\n",
      "Epoch: 11, Loss: 0.0025536478497087955\n",
      "Epoch: 12, Loss: 0.0033053273800760508\n",
      "Epoch: 13, Loss: 0.0028272278141230345\n",
      "Epoch: 14, Loss: 0.0023083831183612347\n",
      "Epoch: 15, Loss: 0.002272394485771656\n",
      "Epoch: 16, Loss: 0.0019954938907176256\n",
      "Epoch: 17, Loss: 0.0019235953222960234\n",
      "Epoch: 18, Loss: 0.001546868123114109\n",
      "Epoch: 19, Loss: 0.0010730389039963484\n",
      "Epoch: 20, Loss: 0.0012545355129987001\n",
      "Epoch: 21, Loss: 0.001387283904477954\n",
      "Epoch: 22, Loss: 0.0009992349660024047\n",
      "Epoch: 23, Loss: 0.000741794123314321\n",
      "Epoch: 24, Loss: 0.0007041860953904688\n",
      "Epoch: 25, Loss: 0.0009165981318801641\n",
      "Epoch: 26, Loss: 0.0008553575025871396\n",
      "Epoch: 27, Loss: 0.0006504884222522378\n",
      "Epoch: 28, Loss: 0.0005568253109231591\n",
      "Epoch: 29, Loss: 0.0005563287995755672\n",
      "Epoch: 30, Loss: 0.0004881500208284706\n",
      "Epoch: 31, Loss: 0.0003742309636436403\n",
      "Epoch: 32, Loss: 0.0002278606843901798\n",
      "Epoch: 33, Loss: 0.0002485156001057476\n",
      "Epoch: 34, Loss: 0.00028710608603432775\n",
      "Epoch: 35, Loss: 0.0003615260939113796\n",
      "Epoch: 36, Loss: 0.00018915307009592652\n",
      "Epoch: 37, Loss: 0.0001958913344424218\n",
      "Epoch: 38, Loss: 0.00022443121997639537\n",
      "Epoch: 39, Loss: 0.0002842632820829749\n",
      "Epoch: 40, Loss: 0.00015484727919101715\n",
      "Epoch: 41, Loss: 0.00012663954112213105\n",
      "Epoch: 42, Loss: 0.00011987276957370341\n",
      "Epoch: 43, Loss: 0.00015734699263703078\n",
      "Epoch: 44, Loss: 0.00010223995195701718\n",
      "Epoch: 45, Loss: 7.873270806157961e-05\n",
      "Epoch: 46, Loss: 9.355176007375121e-05\n",
      "Epoch: 47, Loss: 9.710484300740063e-05\n",
      "Epoch: 48, Loss: 6.65917614242062e-05\n",
      "Epoch: 49, Loss: 4.927979898639023e-05\n",
      "Epoch: 50, Loss: 6.290621240623295e-05\n",
      "epoch 15 tensor([ 0.4934, -1.9462, -0.6150, -0.5858,  0.4150], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.02223808504641056\n",
      "Epoch: 2, Loss: 0.01559776533395052\n",
      "Epoch: 3, Loss: 0.012496565468609333\n",
      "Epoch: 4, Loss: 0.008756309747695923\n",
      "Epoch: 5, Loss: 0.007868203334510326\n",
      "Epoch: 6, Loss: 0.007568263448774815\n",
      "Epoch: 7, Loss: 0.006258483976125717\n",
      "Epoch: 8, Loss: 0.006720448844134808\n",
      "Epoch: 9, Loss: 0.00596211152151227\n",
      "Epoch: 10, Loss: 0.005547007545828819\n",
      "Epoch: 11, Loss: 0.00475611537694931\n",
      "Epoch: 12, Loss: 0.003423634683713317\n",
      "Epoch: 13, Loss: 0.0034085989464074373\n",
      "Epoch: 14, Loss: 0.00297513697296381\n",
      "Epoch: 15, Loss: 0.0021928607020527124\n",
      "Epoch: 16, Loss: 0.0023978836834430695\n",
      "Epoch: 17, Loss: 0.002250103512778878\n",
      "Epoch: 18, Loss: 0.0022637047804892063\n",
      "Epoch: 19, Loss: 0.0022794860415160656\n",
      "Epoch: 20, Loss: 0.0019101056968793273\n",
      "Epoch: 21, Loss: 0.0017752106068655849\n",
      "Epoch: 22, Loss: 0.0016840279567986727\n",
      "Epoch: 23, Loss: 0.0014754408039152622\n",
      "Epoch: 24, Loss: 0.0015284218825399876\n",
      "Epoch: 25, Loss: 0.001268178690224886\n",
      "Epoch: 26, Loss: 0.00108250230550766\n",
      "Epoch: 27, Loss: 0.001032538479194045\n",
      "Epoch: 28, Loss: 0.0007884622900746763\n",
      "Epoch: 29, Loss: 0.0006443174788728356\n",
      "Epoch: 30, Loss: 0.00068047916283831\n",
      "Epoch: 31, Loss: 0.0006259646033868194\n",
      "Epoch: 32, Loss: 0.0006092654657550156\n",
      "Epoch: 33, Loss: 0.0005047756712883711\n",
      "Epoch: 34, Loss: 0.00045435046195052564\n",
      "Epoch: 35, Loss: 0.0004333701799623668\n",
      "Epoch: 36, Loss: 0.0003297697985544801\n",
      "Epoch: 37, Loss: 0.0003013856476172805\n",
      "Epoch: 38, Loss: 0.00022444294882006943\n",
      "Epoch: 39, Loss: 0.00017738674068823457\n",
      "Epoch: 40, Loss: 0.00023857616179157048\n",
      "Epoch: 41, Loss: 0.00022911382257007062\n",
      "Epoch: 42, Loss: 0.00021371558250393718\n",
      "Epoch: 43, Loss: 0.00019463147327769548\n",
      "Epoch: 44, Loss: 0.00014149548951536417\n",
      "Epoch: 45, Loss: 0.00012691839947365224\n",
      "Epoch: 46, Loss: 0.00010292146180290729\n",
      "Epoch: 47, Loss: 9.306592255597934e-05\n",
      "Epoch: 48, Loss: 7.581981481052935e-05\n",
      "Epoch: 49, Loss: 6.979378667892888e-05\n",
      "Epoch: 50, Loss: 8.068951865425333e-05\n",
      "epoch 15 tensor([ 0.4581, -1.9750, -0.5884, -0.5019,  0.3172], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0844583511352539\n",
      "Epoch: 2, Loss: 0.06164908409118652\n",
      "Epoch: 3, Loss: 0.04344984516501427\n",
      "Epoch: 4, Loss: 0.030535219237208366\n",
      "Epoch: 5, Loss: 0.020732736214995384\n",
      "Epoch: 6, Loss: 0.015263649635016918\n",
      "Epoch: 7, Loss: 0.014234516769647598\n",
      "Epoch: 8, Loss: 0.014223044738173485\n",
      "Epoch: 9, Loss: 0.01235960517078638\n",
      "Epoch: 10, Loss: 0.0120114516466856\n",
      "Epoch: 11, Loss: 0.012368657626211643\n",
      "Epoch: 12, Loss: 0.011536682955920696\n",
      "Epoch: 13, Loss: 0.010823373682796955\n",
      "Epoch: 14, Loss: 0.010637381114065647\n",
      "Epoch: 15, Loss: 0.010339861735701561\n",
      "Epoch: 16, Loss: 0.008776886388659477\n",
      "Epoch: 17, Loss: 0.00685746967792511\n",
      "Epoch: 18, Loss: 0.005935552064329386\n",
      "Epoch: 19, Loss: 0.005317484028637409\n",
      "Epoch: 20, Loss: 0.004634722601622343\n",
      "Epoch: 21, Loss: 0.004164903424680233\n",
      "Epoch: 22, Loss: 0.0039220997132360935\n",
      "Epoch: 23, Loss: 0.00351041741669178\n",
      "Epoch: 24, Loss: 0.0028096078895032406\n",
      "Epoch: 25, Loss: 0.0021792759653180838\n",
      "Epoch: 26, Loss: 0.001937703462317586\n",
      "Epoch: 27, Loss: 0.0017968128668144345\n",
      "Epoch: 28, Loss: 0.001723305438645184\n",
      "Epoch: 29, Loss: 0.0018953033722937107\n",
      "Epoch: 30, Loss: 0.002121057128533721\n",
      "Epoch: 31, Loss: 0.002048487775027752\n",
      "Epoch: 32, Loss: 0.0017310896655544639\n",
      "Epoch: 33, Loss: 0.001385222189128399\n",
      "Epoch: 34, Loss: 0.00112712022382766\n",
      "Epoch: 35, Loss: 0.000871691619977355\n",
      "Epoch: 36, Loss: 0.0007274345844052732\n",
      "Epoch: 37, Loss: 0.0007686207536607981\n",
      "Epoch: 38, Loss: 0.0008201455930247903\n",
      "Epoch: 39, Loss: 0.0007497863261960447\n",
      "Epoch: 40, Loss: 0.0006636020261794329\n",
      "Epoch: 41, Loss: 0.0005989092751406133\n",
      "Epoch: 42, Loss: 0.0004862786445301026\n",
      "Epoch: 43, Loss: 0.00036186081706546247\n",
      "Epoch: 44, Loss: 0.00032863341039046645\n",
      "Epoch: 45, Loss: 0.00033021546551026404\n",
      "Epoch: 46, Loss: 0.0002944377192761749\n",
      "Epoch: 47, Loss: 0.00026394915767014027\n",
      "Epoch: 48, Loss: 0.00026708864606916904\n",
      "Epoch: 49, Loss: 0.0002445249701850116\n",
      "Epoch: 50, Loss: 0.00020307734666857868\n",
      "epoch 15 tensor([ 0.5317, -1.9030, -0.5810, -0.5946,  0.5363], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.008314528502523899\n",
      "Epoch: 2, Loss: 0.006840378046035767\n",
      "Epoch: 3, Loss: 0.003927500918507576\n",
      "Epoch: 4, Loss: 0.002778211608529091\n",
      "Epoch: 5, Loss: 0.002468352671712637\n",
      "Epoch: 6, Loss: 0.002372396644204855\n",
      "Epoch: 7, Loss: 0.0020397650077939034\n",
      "Epoch: 8, Loss: 0.0021552136167883873\n",
      "Epoch: 9, Loss: 0.0021930199582129717\n",
      "Epoch: 10, Loss: 0.0018952577374875546\n",
      "Epoch: 11, Loss: 0.0019651700276881456\n",
      "Epoch: 12, Loss: 0.001486338791437447\n",
      "Epoch: 13, Loss: 0.0012544661294668913\n",
      "Epoch: 14, Loss: 0.0010383165208622813\n",
      "Epoch: 15, Loss: 0.0007531240116804838\n",
      "Epoch: 16, Loss: 0.0008183415047824383\n",
      "Epoch: 17, Loss: 0.0008255582069978118\n",
      "Epoch: 18, Loss: 0.0008586023468524218\n",
      "Epoch: 19, Loss: 0.0007821471081115305\n",
      "Epoch: 20, Loss: 0.0007025154773145914\n",
      "Epoch: 21, Loss: 0.0005551077192649245\n",
      "Epoch: 22, Loss: 0.0005602415767498314\n",
      "Epoch: 23, Loss: 0.0005072440835647285\n",
      "Epoch: 24, Loss: 0.00033573541441001\n",
      "Epoch: 25, Loss: 0.0003592506400309503\n",
      "Epoch: 26, Loss: 0.00028442961047403514\n",
      "Epoch: 27, Loss: 0.0002542323200032115\n",
      "Epoch: 28, Loss: 0.0002744559315033257\n",
      "Epoch: 29, Loss: 0.00017064789426513016\n",
      "Epoch: 30, Loss: 0.00016587378922849894\n",
      "Epoch: 31, Loss: 0.00019327212066855282\n",
      "Epoch: 32, Loss: 0.0001857913885032758\n",
      "Epoch: 33, Loss: 0.0001890909916255623\n",
      "Epoch: 34, Loss: 0.00016295182285830379\n",
      "Epoch: 35, Loss: 0.00014210148947313428\n",
      "Epoch: 36, Loss: 0.00012785536819137633\n",
      "Epoch: 37, Loss: 0.00010380634194007143\n",
      "Epoch: 38, Loss: 0.00010442070924909785\n",
      "Epoch: 39, Loss: 0.00010281414142809808\n",
      "Epoch: 40, Loss: 9.122624760493636e-05\n",
      "Epoch: 41, Loss: 9.056644194060937e-05\n",
      "Epoch: 42, Loss: 6.691442831652239e-05\n",
      "Epoch: 43, Loss: 4.4271313527133316e-05\n",
      "Epoch: 44, Loss: 4.096224074601196e-05\n",
      "Epoch: 45, Loss: 3.5343084164196625e-05\n",
      "Epoch: 46, Loss: 3.998317333753221e-05\n",
      "Epoch: 47, Loss: 5.0737671699607745e-05\n",
      "Epoch: 48, Loss: 4.617304148268886e-05\n",
      "Epoch: 49, Loss: 3.237818964407779e-05\n",
      "Epoch: 50, Loss: 2.9374750738497823e-05\n",
      "epoch 15 tensor([ 0.5359, -1.9559, -0.7578, -0.6428,  0.6327], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.01532003190368414\n",
      "Epoch: 2, Loss: 0.013754823245108128\n",
      "Epoch: 3, Loss: 0.008971115574240685\n",
      "Epoch: 4, Loss: 0.0073950085788965225\n",
      "Epoch: 5, Loss: 0.004513738676905632\n",
      "Epoch: 6, Loss: 0.0037432387471199036\n",
      "Epoch: 7, Loss: 0.0033293338492512703\n",
      "Epoch: 8, Loss: 0.0033291345462203026\n",
      "Epoch: 9, Loss: 0.0031498258467763662\n",
      "Epoch: 10, Loss: 0.0027218731120228767\n",
      "Epoch: 11, Loss: 0.0030446306336671114\n",
      "Epoch: 12, Loss: 0.002516557462513447\n",
      "Epoch: 13, Loss: 0.0022758592385798693\n",
      "Epoch: 14, Loss: 0.0024855551309883595\n",
      "Epoch: 15, Loss: 0.001949687022715807\n",
      "Epoch: 16, Loss: 0.0014611866790801287\n",
      "Epoch: 17, Loss: 0.0014303905190899968\n",
      "Epoch: 18, Loss: 0.001217323006130755\n",
      "Epoch: 19, Loss: 0.0007648413884453475\n",
      "Epoch: 20, Loss: 0.0009859786368906498\n",
      "Epoch: 21, Loss: 0.0009262043749913573\n",
      "Epoch: 22, Loss: 0.0008930018520914018\n",
      "Epoch: 23, Loss: 0.0007192852208390832\n",
      "Epoch: 24, Loss: 0.000761914299800992\n",
      "Epoch: 25, Loss: 0.0005748339463025331\n",
      "Epoch: 26, Loss: 0.0005521269049495459\n",
      "Epoch: 27, Loss: 0.00044082553358748555\n",
      "Epoch: 28, Loss: 0.0005376385524868965\n",
      "Epoch: 29, Loss: 0.0004861998313572258\n",
      "Epoch: 30, Loss: 0.000452400476206094\n",
      "Epoch: 31, Loss: 0.0003903755859937519\n",
      "Epoch: 32, Loss: 0.00040760860429145396\n",
      "Epoch: 33, Loss: 0.00027757592033594847\n",
      "Epoch: 34, Loss: 0.00024239577760454267\n",
      "Epoch: 35, Loss: 0.00020887590653728694\n",
      "Epoch: 36, Loss: 0.0001683387963566929\n",
      "Epoch: 37, Loss: 0.00013332656817510724\n",
      "Epoch: 38, Loss: 0.00015334592899307609\n",
      "Epoch: 39, Loss: 0.00013959580974187702\n",
      "Epoch: 40, Loss: 0.00013889046385884285\n",
      "Epoch: 41, Loss: 0.0001306353515246883\n",
      "Epoch: 42, Loss: 0.00012280058581382036\n",
      "Epoch: 43, Loss: 0.00011369431740604341\n",
      "Epoch: 44, Loss: 8.772658475209028e-05\n",
      "Epoch: 45, Loss: 9.437809785595164e-05\n",
      "Epoch: 46, Loss: 7.550459122285247e-05\n",
      "Epoch: 47, Loss: 6.8908731918782e-05\n",
      "Epoch: 48, Loss: 6.351078627631068e-05\n",
      "Epoch: 49, Loss: 6.641767686232924e-05\n",
      "Epoch: 50, Loss: 4.185770740150474e-05\n",
      "epoch 15 tensor([ 0.5484, -2.0102, -0.7735, -0.5485,  0.3716], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.025517869740724564\n",
      "Epoch: 2, Loss: 0.017008719965815544\n",
      "Epoch: 3, Loss: 0.011611392721533775\n",
      "Epoch: 4, Loss: 0.00901835411787033\n",
      "Epoch: 5, Loss: 0.007875118404626846\n",
      "Epoch: 6, Loss: 0.006786086596548557\n",
      "Epoch: 7, Loss: 0.005629411898553371\n",
      "Epoch: 8, Loss: 0.0055730766616761684\n",
      "Epoch: 9, Loss: 0.005604644306004047\n",
      "Epoch: 10, Loss: 0.003955289255827665\n",
      "Epoch: 11, Loss: 0.0032195013482123613\n",
      "Epoch: 12, Loss: 0.0028335023671388626\n",
      "Epoch: 13, Loss: 0.00249357963912189\n",
      "Epoch: 14, Loss: 0.0023394590243697166\n",
      "Epoch: 15, Loss: 0.002456825226545334\n",
      "Epoch: 16, Loss: 0.0022098117042332888\n",
      "Epoch: 17, Loss: 0.002045217202976346\n",
      "Epoch: 18, Loss: 0.0016931440914049745\n",
      "Epoch: 19, Loss: 0.0012508942745625973\n",
      "Epoch: 20, Loss: 0.001085038878954947\n",
      "Epoch: 21, Loss: 0.0012073074467480183\n",
      "Epoch: 22, Loss: 0.0013589937007054687\n",
      "Epoch: 23, Loss: 0.0012930301018059254\n",
      "Epoch: 24, Loss: 0.0010170560562983155\n",
      "Epoch: 25, Loss: 0.0007969830767251551\n",
      "Epoch: 26, Loss: 0.0007150561432354152\n",
      "Epoch: 27, Loss: 0.0005395246553234756\n",
      "Epoch: 28, Loss: 0.00041296734707430005\n",
      "Epoch: 29, Loss: 0.0004161250253673643\n",
      "Epoch: 30, Loss: 0.0005073326174169779\n",
      "Epoch: 31, Loss: 0.00047212117351591587\n",
      "Epoch: 32, Loss: 0.000414241396356374\n",
      "Epoch: 33, Loss: 0.000382849044399336\n",
      "Epoch: 34, Loss: 0.0003612496075220406\n",
      "Epoch: 35, Loss: 0.00028178992215543985\n",
      "Epoch: 36, Loss: 0.00023563325521536171\n",
      "Epoch: 37, Loss: 0.00018905496108345687\n",
      "Epoch: 38, Loss: 0.0002181396121159196\n",
      "Epoch: 39, Loss: 0.0002275139413541183\n",
      "Epoch: 40, Loss: 0.0001973226317204535\n",
      "Epoch: 41, Loss: 0.00014523632125928998\n",
      "Epoch: 42, Loss: 0.00011050984176108614\n",
      "Epoch: 43, Loss: 0.00010463800572324544\n",
      "Epoch: 44, Loss: 0.00010097604535985738\n",
      "Epoch: 45, Loss: 0.00010852495324797928\n",
      "Epoch: 46, Loss: 0.00010372551332693547\n",
      "Epoch: 47, Loss: 8.04988230811432e-05\n",
      "Epoch: 48, Loss: 6.699220830341801e-05\n",
      "Epoch: 49, Loss: 7.16767244739458e-05\n",
      "Epoch: 50, Loss: 7.003415521467105e-05\n",
      "epoch 15 tensor([ 0.5972, -2.0476, -0.5434, -0.5120,  0.4107], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.018612204119563103\n",
      "Epoch: 2, Loss: 0.012243825942277908\n",
      "Epoch: 3, Loss: 0.00889651570469141\n",
      "Epoch: 4, Loss: 0.008483044803142548\n",
      "Epoch: 5, Loss: 0.0051104165613651276\n",
      "Epoch: 6, Loss: 0.005046365316957235\n",
      "Epoch: 7, Loss: 0.0037879440933465958\n",
      "Epoch: 8, Loss: 0.0036328984424471855\n",
      "Epoch: 9, Loss: 0.0035314017441123724\n",
      "Epoch: 10, Loss: 0.003726331517100334\n",
      "Epoch: 11, Loss: 0.0029802564531564713\n",
      "Epoch: 12, Loss: 0.0033958638086915016\n",
      "Epoch: 13, Loss: 0.0027540060691535473\n",
      "Epoch: 14, Loss: 0.0021942888852208853\n",
      "Epoch: 15, Loss: 0.002020888263359666\n",
      "Epoch: 16, Loss: 0.0023566465824842453\n",
      "Epoch: 17, Loss: 0.0016431852709501982\n",
      "Epoch: 18, Loss: 0.0013227562885731459\n",
      "Epoch: 19, Loss: 0.001039167051203549\n",
      "Epoch: 20, Loss: 0.001170734059996903\n",
      "Epoch: 21, Loss: 0.0011953457724303007\n",
      "Epoch: 22, Loss: 0.001466877292841673\n",
      "Epoch: 23, Loss: 0.000977935385890305\n",
      "Epoch: 24, Loss: 0.000710956403054297\n",
      "Epoch: 25, Loss: 0.0006340439431369305\n",
      "Epoch: 26, Loss: 0.0006989482790231705\n",
      "Epoch: 27, Loss: 0.00047530338633805513\n",
      "Epoch: 28, Loss: 0.0005685502546839416\n",
      "Epoch: 29, Loss: 0.0004937360645271838\n",
      "Epoch: 30, Loss: 0.000422141543822363\n",
      "Epoch: 31, Loss: 0.0003759268729481846\n",
      "Epoch: 32, Loss: 0.00043407149496488273\n",
      "Epoch: 33, Loss: 0.00029657286358997226\n",
      "Epoch: 34, Loss: 0.00026579631958156824\n",
      "Epoch: 35, Loss: 0.0002535770763643086\n",
      "Epoch: 36, Loss: 0.0002505765005480498\n",
      "Epoch: 37, Loss: 0.0002299841435160488\n",
      "Epoch: 38, Loss: 0.0001976749481400475\n",
      "Epoch: 39, Loss: 0.0001401984627591446\n",
      "Epoch: 40, Loss: 0.00013721731374971569\n",
      "Epoch: 41, Loss: 0.00014660415763501078\n",
      "Epoch: 42, Loss: 0.00013023959763813764\n",
      "Epoch: 43, Loss: 0.00014579948037862778\n",
      "Epoch: 44, Loss: 0.00012391705240588635\n",
      "Epoch: 45, Loss: 9.017394768306985e-05\n",
      "Epoch: 46, Loss: 9.7275449661538e-05\n",
      "Epoch: 47, Loss: 8.572611841373146e-05\n",
      "Epoch: 48, Loss: 6.777941598556936e-05\n",
      "Epoch: 49, Loss: 6.66406995151192e-05\n",
      "Epoch: 50, Loss: 6.123428465798497e-05\n",
      "epoch 15 tensor([ 0.6027, -1.8183, -0.5633, -0.6774,  0.4712], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.009697756730020046\n",
      "Epoch: 2, Loss: 0.007457232568413019\n",
      "Epoch: 3, Loss: 0.00788730476051569\n",
      "Epoch: 4, Loss: 0.005163037683814764\n",
      "Epoch: 5, Loss: 0.0033781302627176046\n",
      "Epoch: 6, Loss: 0.004466155543923378\n",
      "Epoch: 7, Loss: 0.003016483737155795\n",
      "Epoch: 8, Loss: 0.003781661158427596\n",
      "Epoch: 9, Loss: 0.003011783119291067\n",
      "Epoch: 10, Loss: 0.0021110738161951303\n",
      "Epoch: 11, Loss: 0.0017032873583957553\n",
      "Epoch: 12, Loss: 0.0013534544268622994\n",
      "Epoch: 13, Loss: 0.002085176296532154\n",
      "Epoch: 14, Loss: 0.0012953785480931401\n",
      "Epoch: 15, Loss: 0.001612483523786068\n",
      "Epoch: 16, Loss: 0.0010140554513782263\n",
      "Epoch: 17, Loss: 0.0013437274610623717\n",
      "Epoch: 18, Loss: 0.0008409768342971802\n",
      "Epoch: 19, Loss: 0.0008477420196868479\n",
      "Epoch: 20, Loss: 0.0006902941386215389\n",
      "Epoch: 21, Loss: 0.0006972008268348873\n",
      "Epoch: 22, Loss: 0.0008424997213296592\n",
      "Epoch: 23, Loss: 0.000623823725618422\n",
      "Epoch: 24, Loss: 0.0007252002251334488\n",
      "Epoch: 25, Loss: 0.00040242818067781627\n",
      "Epoch: 26, Loss: 0.0005591737572103739\n",
      "Epoch: 27, Loss: 0.0003842147416435182\n",
      "Epoch: 28, Loss: 0.0003686571726575494\n",
      "Epoch: 29, Loss: 0.0003018142015207559\n",
      "Epoch: 30, Loss: 0.0003299446834716946\n",
      "Epoch: 31, Loss: 0.00037716873339377344\n",
      "Epoch: 32, Loss: 0.00017132442735601217\n",
      "Epoch: 33, Loss: 0.00023413944290950894\n",
      "Epoch: 34, Loss: 0.0001411507691955194\n",
      "Epoch: 35, Loss: 0.00021768668375443667\n",
      "Epoch: 36, Loss: 0.0001696822582744062\n",
      "Epoch: 37, Loss: 0.00014409951108973473\n",
      "Epoch: 38, Loss: 0.00016048135876189917\n",
      "Epoch: 39, Loss: 0.00013169102021493018\n",
      "Epoch: 40, Loss: 0.00012404027802404016\n",
      "Epoch: 41, Loss: 6.475578265963122e-05\n",
      "Epoch: 42, Loss: 6.464801845140755e-05\n",
      "Epoch: 43, Loss: 8.758599142311141e-05\n",
      "Epoch: 44, Loss: 7.321505836443976e-05\n",
      "Epoch: 45, Loss: 8.25901806820184e-05\n",
      "Epoch: 46, Loss: 7.056535105220973e-05\n",
      "Epoch: 47, Loss: 5.270232941256836e-05\n",
      "Epoch: 48, Loss: 6.062606189516373e-05\n",
      "Epoch: 49, Loss: 3.4661719837458804e-05\n",
      "Epoch: 50, Loss: 3.182033105986193e-05\n",
      "epoch 15 tensor([ 0.5224, -1.8359, -0.5986, -0.5072,  0.4530], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.01348655205219984\n",
      "Epoch: 2, Loss: 0.01030954159796238\n",
      "Epoch: 3, Loss: 0.008009934797883034\n",
      "Epoch: 4, Loss: 0.007317123003304005\n",
      "Epoch: 5, Loss: 0.005736081395298243\n",
      "Epoch: 6, Loss: 0.0037885550409555435\n",
      "Epoch: 7, Loss: 0.003744466695934534\n",
      "Epoch: 8, Loss: 0.0028872699476778507\n",
      "Epoch: 9, Loss: 0.0028017458971589804\n",
      "Epoch: 10, Loss: 0.00174415553919971\n",
      "Epoch: 11, Loss: 0.0019168471917510033\n",
      "Epoch: 12, Loss: 0.0019040803890675306\n",
      "Epoch: 13, Loss: 0.0015770867466926575\n",
      "Epoch: 14, Loss: 0.0012871805811300874\n",
      "Epoch: 15, Loss: 0.0012694111792370677\n",
      "Epoch: 16, Loss: 0.0014023169642314315\n",
      "Epoch: 17, Loss: 0.001342398812994361\n",
      "Epoch: 18, Loss: 0.001101309317164123\n",
      "Epoch: 19, Loss: 0.0010514740133658051\n",
      "Epoch: 20, Loss: 0.0010776635026559234\n",
      "Epoch: 21, Loss: 0.0009318405645899475\n",
      "Epoch: 22, Loss: 0.0007452647550962865\n",
      "Epoch: 23, Loss: 0.0005592778907157481\n",
      "Epoch: 24, Loss: 0.0006337207742035389\n",
      "Epoch: 25, Loss: 0.00045733246952295303\n",
      "Epoch: 26, Loss: 0.0004352237156126648\n",
      "Epoch: 27, Loss: 0.0003939343732781708\n",
      "Epoch: 28, Loss: 0.0003736467915587127\n",
      "Epoch: 29, Loss: 0.0002675227588042617\n",
      "Epoch: 30, Loss: 0.0002541930880397558\n",
      "Epoch: 31, Loss: 0.00024407728051301092\n",
      "Epoch: 32, Loss: 0.0002865023270715028\n",
      "Epoch: 33, Loss: 0.00020080724789295346\n",
      "Epoch: 34, Loss: 0.00020223006140440702\n",
      "Epoch: 35, Loss: 0.0002011605101870373\n",
      "Epoch: 36, Loss: 0.00018886869656853378\n",
      "Epoch: 37, Loss: 0.00013997747737448663\n",
      "Epoch: 38, Loss: 0.00013886210217606276\n",
      "Epoch: 39, Loss: 0.0001255675742868334\n",
      "Epoch: 40, Loss: 0.00012351415352895856\n",
      "Epoch: 41, Loss: 8.592242375016212e-05\n",
      "Epoch: 42, Loss: 8.634210826130584e-05\n",
      "Epoch: 43, Loss: 6.877970736240968e-05\n",
      "Epoch: 44, Loss: 6.257878703763708e-05\n",
      "Epoch: 45, Loss: 4.823818017030135e-05\n",
      "Epoch: 46, Loss: 6.656960613327101e-05\n",
      "Epoch: 47, Loss: 5.616580892819911e-05\n",
      "Epoch: 48, Loss: 4.694089147960767e-05\n",
      "Epoch: 49, Loss: 4.350697054178454e-05\n",
      "Epoch: 50, Loss: 4.1510626033414155e-05\n",
      "epoch 15 tensor([ 0.5498, -1.9855, -0.5783, -0.5913,  0.4638], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.003938633017241955\n",
      "Epoch: 2, Loss: 0.002184816636145115\n",
      "Epoch: 3, Loss: 0.0017028595320880413\n",
      "Epoch: 4, Loss: 0.001507763285189867\n",
      "Epoch: 5, Loss: 0.0013510760618373752\n",
      "Epoch: 6, Loss: 0.0015514479018747807\n",
      "Epoch: 7, Loss: 0.0011435634223744273\n",
      "Epoch: 8, Loss: 0.0010991775197908282\n",
      "Epoch: 9, Loss: 0.0010038455948233604\n",
      "Epoch: 10, Loss: 0.0009976322762668133\n",
      "Epoch: 11, Loss: 0.0009098193258978426\n",
      "Epoch: 12, Loss: 0.0008121386053971946\n",
      "Epoch: 13, Loss: 0.0006628995179198682\n",
      "Epoch: 14, Loss: 0.000518490734975785\n",
      "Epoch: 15, Loss: 0.0005338089540600777\n",
      "Epoch: 16, Loss: 0.00039034627843648195\n",
      "Epoch: 17, Loss: 0.00036144908517599106\n",
      "Epoch: 18, Loss: 0.000455084431450814\n",
      "Epoch: 19, Loss: 0.0003772833151742816\n",
      "Epoch: 20, Loss: 0.0002363737439736724\n",
      "Epoch: 21, Loss: 0.0003350048791617155\n",
      "Epoch: 22, Loss: 0.000260045169852674\n",
      "Epoch: 23, Loss: 0.000240214096265845\n",
      "Epoch: 24, Loss: 0.00026835326571017504\n",
      "Epoch: 25, Loss: 0.00020590551139321178\n",
      "Epoch: 26, Loss: 0.00014837282651569694\n",
      "Epoch: 27, Loss: 0.00013651238987222314\n",
      "Epoch: 28, Loss: 0.00014674905105493963\n",
      "Epoch: 29, Loss: 0.000133766487124376\n",
      "Epoch: 30, Loss: 0.00012404302833601832\n",
      "Epoch: 31, Loss: 0.00010198837117059156\n",
      "Epoch: 32, Loss: 0.00010334398393752053\n",
      "Epoch: 33, Loss: 9.71550980466418e-05\n",
      "Epoch: 34, Loss: 8.837362838676199e-05\n",
      "Epoch: 35, Loss: 0.00011200914013898\n",
      "Epoch: 36, Loss: 0.00010097945050802082\n",
      "Epoch: 37, Loss: 5.8477857237448916e-05\n",
      "Epoch: 38, Loss: 4.9966965889325365e-05\n",
      "Epoch: 39, Loss: 4.789948434336111e-05\n",
      "Epoch: 40, Loss: 4.677961624111049e-05\n",
      "Epoch: 41, Loss: 4.6147630200721323e-05\n",
      "Epoch: 42, Loss: 3.461609230726026e-05\n",
      "Epoch: 43, Loss: 3.105710493400693e-05\n",
      "Epoch: 44, Loss: 2.447739643685054e-05\n",
      "Epoch: 45, Loss: 3.2103027479024604e-05\n",
      "Epoch: 46, Loss: 3.818438926828094e-05\n",
      "Epoch: 47, Loss: 3.8942787796258926e-05\n",
      "Epoch: 48, Loss: 6.769485480617732e-05\n",
      "Epoch: 49, Loss: 0.00013922146172262728\n",
      "Epoch: 50, Loss: 0.00033749043359421194\n",
      "________________________________________\n",
      "epoch 16 tensor([ 0.5638, -1.8535, -0.5121, -0.5742,  0.4137], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.04104578495025635\n",
      "Epoch: 2, Loss: 0.028175998479127884\n",
      "Epoch: 3, Loss: 0.01570371352136135\n",
      "Epoch: 4, Loss: 0.011637522839009762\n",
      "Epoch: 5, Loss: 0.01354280486702919\n",
      "Epoch: 6, Loss: 0.01278236135840416\n",
      "Epoch: 7, Loss: 0.010903887450695038\n",
      "Epoch: 8, Loss: 0.007890868000686169\n",
      "Epoch: 9, Loss: 0.007500078529119492\n",
      "Epoch: 10, Loss: 0.009417763911187649\n",
      "Epoch: 11, Loss: 0.008773300796747208\n",
      "Epoch: 12, Loss: 0.006904748268425465\n",
      "Epoch: 13, Loss: 0.004152689594775438\n",
      "Epoch: 14, Loss: 0.002938933903351426\n",
      "Epoch: 15, Loss: 0.0037452662363648415\n",
      "Epoch: 16, Loss: 0.00386782712303102\n",
      "Epoch: 17, Loss: 0.004324059002101421\n",
      "Epoch: 18, Loss: 0.0037769624032080173\n",
      "Epoch: 19, Loss: 0.0026044724509119987\n",
      "Epoch: 20, Loss: 0.0021542618051171303\n",
      "Epoch: 21, Loss: 0.001906790304929018\n",
      "Epoch: 22, Loss: 0.00208834744989872\n",
      "Epoch: 23, Loss: 0.0020622964948415756\n",
      "Epoch: 24, Loss: 0.0015269300201907754\n",
      "Epoch: 25, Loss: 0.0013770563527941704\n",
      "Epoch: 26, Loss: 0.0012135579017922282\n",
      "Epoch: 27, Loss: 0.001033135107718408\n",
      "Epoch: 28, Loss: 0.001104283845052123\n",
      "Epoch: 29, Loss: 0.0010103598469868302\n",
      "Epoch: 30, Loss: 0.0009372401982545853\n",
      "Epoch: 31, Loss: 0.0008551398641429842\n",
      "Epoch: 32, Loss: 0.0006941769388504326\n",
      "Epoch: 33, Loss: 0.0006649426650255919\n",
      "Epoch: 34, Loss: 0.0004639092367142439\n",
      "Epoch: 35, Loss: 0.00041261164005845785\n",
      "Epoch: 36, Loss: 0.00048696986050345004\n",
      "Epoch: 37, Loss: 0.0004638905811589211\n",
      "Epoch: 38, Loss: 0.00045881629921495914\n",
      "Epoch: 39, Loss: 0.0003628525882959366\n",
      "Epoch: 40, Loss: 0.0003200420760549605\n",
      "Epoch: 41, Loss: 0.0002957582182716578\n",
      "Epoch: 42, Loss: 0.00025974903837777674\n",
      "Epoch: 43, Loss: 0.00027720603975467384\n",
      "Epoch: 44, Loss: 0.0001950782025232911\n",
      "Epoch: 45, Loss: 0.00015432509826496243\n",
      "Epoch: 46, Loss: 0.00014804775128141046\n",
      "Epoch: 47, Loss: 0.0001639869442442432\n",
      "Epoch: 48, Loss: 0.00017059080710168928\n",
      "Epoch: 49, Loss: 0.0001378320303047076\n",
      "Epoch: 50, Loss: 0.00011581669241422787\n",
      "epoch 16 tensor([ 0.5886, -1.8615, -0.4815, -0.6519,  0.4145], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.031156664714217186\n",
      "Epoch: 2, Loss: 0.016982603818178177\n",
      "Epoch: 3, Loss: 0.011140530928969383\n",
      "Epoch: 4, Loss: 0.012286262586712837\n",
      "Epoch: 5, Loss: 0.010351215489208698\n",
      "Epoch: 6, Loss: 0.0062668584287166595\n",
      "Epoch: 7, Loss: 0.005460930988192558\n",
      "Epoch: 8, Loss: 0.007966889068484306\n",
      "Epoch: 9, Loss: 0.008147742599248886\n",
      "Epoch: 10, Loss: 0.006384322419762611\n",
      "Epoch: 11, Loss: 0.005081898532807827\n",
      "Epoch: 12, Loss: 0.0043721976689994335\n",
      "Epoch: 13, Loss: 0.004146812483668327\n",
      "Epoch: 14, Loss: 0.003174529178068042\n",
      "Epoch: 15, Loss: 0.0025531460996717215\n",
      "Epoch: 16, Loss: 0.0024979717563837767\n",
      "Epoch: 17, Loss: 0.0027133841067552567\n",
      "Epoch: 18, Loss: 0.0026857824996113777\n",
      "Epoch: 19, Loss: 0.0023739037569612265\n",
      "Epoch: 20, Loss: 0.0020079240202903748\n",
      "Epoch: 21, Loss: 0.0017017312347888947\n",
      "Epoch: 22, Loss: 0.0013227161252871156\n",
      "Epoch: 23, Loss: 0.0012367118615657091\n",
      "Epoch: 24, Loss: 0.0012408647453412414\n",
      "Epoch: 25, Loss: 0.001277171541005373\n",
      "Epoch: 26, Loss: 0.001170485862530768\n",
      "Epoch: 27, Loss: 0.0009910075459629297\n",
      "Epoch: 28, Loss: 0.0009506535716354847\n",
      "Epoch: 29, Loss: 0.0007740568253211677\n",
      "Epoch: 30, Loss: 0.0005110318306833506\n",
      "Epoch: 31, Loss: 0.00033233247813768685\n",
      "Epoch: 32, Loss: 0.0004249040503054857\n",
      "Epoch: 33, Loss: 0.0006150631234049797\n",
      "Epoch: 34, Loss: 0.0006039171130396426\n",
      "Epoch: 35, Loss: 0.0004715991672128439\n",
      "Epoch: 36, Loss: 0.0003855877439491451\n",
      "Epoch: 37, Loss: 0.00036903901491314173\n",
      "Epoch: 38, Loss: 0.00030651988345198333\n",
      "Epoch: 39, Loss: 0.00020506353757809848\n",
      "Epoch: 40, Loss: 0.00020322311320342124\n",
      "Epoch: 41, Loss: 0.00024142238544300199\n",
      "Epoch: 42, Loss: 0.00023779485491104424\n",
      "Epoch: 43, Loss: 0.00017668388318270445\n",
      "Epoch: 44, Loss: 0.00015598481695633382\n",
      "Epoch: 45, Loss: 0.0001575449132360518\n",
      "Epoch: 46, Loss: 0.00011283688218099996\n",
      "Epoch: 47, Loss: 7.66296434449032e-05\n",
      "Epoch: 48, Loss: 8.994473319035023e-05\n",
      "Epoch: 49, Loss: 0.00013790091907139868\n",
      "Epoch: 50, Loss: 0.00011555432138266042\n",
      "epoch 16 tensor([ 0.5091, -1.8829, -0.5917, -0.6149,  0.4584], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.008382326923310757\n",
      "Epoch: 2, Loss: 0.004933162126690149\n",
      "Epoch: 3, Loss: 0.003755058627575636\n",
      "Epoch: 4, Loss: 0.0048021902330219746\n",
      "Epoch: 5, Loss: 0.00347024854272604\n",
      "Epoch: 6, Loss: 0.002323281718418002\n",
      "Epoch: 7, Loss: 0.0025652232579886913\n",
      "Epoch: 8, Loss: 0.0029033636674284935\n",
      "Epoch: 9, Loss: 0.0020509622991085052\n",
      "Epoch: 10, Loss: 0.0012368548195809126\n",
      "Epoch: 11, Loss: 0.0012253648601472378\n",
      "Epoch: 12, Loss: 0.0014414966572076082\n",
      "Epoch: 13, Loss: 0.0015165593940764666\n",
      "Epoch: 14, Loss: 0.0011268255766481161\n",
      "Epoch: 15, Loss: 0.0008782471995800734\n",
      "Epoch: 16, Loss: 0.0006741966935805976\n",
      "Epoch: 17, Loss: 0.0005377486231736839\n",
      "Epoch: 18, Loss: 0.0005500239785760641\n",
      "Epoch: 19, Loss: 0.0006583047797903419\n",
      "Epoch: 20, Loss: 0.000676267605740577\n",
      "Epoch: 21, Loss: 0.0004789464292116463\n",
      "Epoch: 22, Loss: 0.00041184990550391376\n",
      "Epoch: 23, Loss: 0.0003943256742786616\n",
      "Epoch: 24, Loss: 0.00032569587347097695\n",
      "Epoch: 25, Loss: 0.0003390252240933478\n",
      "Epoch: 26, Loss: 0.0004143781843595207\n",
      "Epoch: 27, Loss: 0.00039151564124040306\n",
      "Epoch: 28, Loss: 0.00024339018273167312\n",
      "Epoch: 29, Loss: 0.0001344615884590894\n",
      "Epoch: 30, Loss: 0.00016336102271452546\n",
      "Epoch: 31, Loss: 0.0001991309254663065\n",
      "Epoch: 32, Loss: 0.00017774758453015238\n",
      "Epoch: 33, Loss: 0.00015322542458306998\n",
      "Epoch: 34, Loss: 0.00013204687274992466\n",
      "Epoch: 35, Loss: 0.00012207782128825784\n",
      "Epoch: 36, Loss: 8.971102215582505e-05\n",
      "Epoch: 37, Loss: 0.0001079511275747791\n",
      "Epoch: 38, Loss: 0.00013865927758160979\n",
      "Epoch: 39, Loss: 0.00010026410018326715\n",
      "Epoch: 40, Loss: 4.933825766784139e-05\n",
      "Epoch: 41, Loss: 5.340511415852234e-05\n",
      "Epoch: 42, Loss: 6.0604867030633613e-05\n",
      "Epoch: 43, Loss: 5.260199759504758e-05\n",
      "Epoch: 44, Loss: 5.06808100908529e-05\n",
      "Epoch: 45, Loss: 4.766339770867489e-05\n",
      "Epoch: 46, Loss: 3.7225989217404276e-05\n",
      "Epoch: 47, Loss: 2.7870342819369398e-05\n",
      "Epoch: 48, Loss: 3.36743651132565e-05\n",
      "Epoch: 49, Loss: 4.02398691221606e-05\n",
      "Epoch: 50, Loss: 2.9735885618720204e-05\n",
      "epoch 16 tensor([ 0.5015, -1.8679, -0.5478, -0.5773,  0.4488], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.022887516766786575\n",
      "Epoch: 2, Loss: 0.018381481990218163\n",
      "Epoch: 3, Loss: 0.0145592475309968\n",
      "Epoch: 4, Loss: 0.010955486446619034\n",
      "Epoch: 5, Loss: 0.007695819716900587\n",
      "Epoch: 6, Loss: 0.005560732446610928\n",
      "Epoch: 7, Loss: 0.004685576073825359\n",
      "Epoch: 8, Loss: 0.004731010179966688\n",
      "Epoch: 9, Loss: 0.004197907168418169\n",
      "Epoch: 10, Loss: 0.0033204243518412113\n",
      "Epoch: 11, Loss: 0.002838960848748684\n",
      "Epoch: 12, Loss: 0.0025577798951417208\n",
      "Epoch: 13, Loss: 0.0021347731817513704\n",
      "Epoch: 14, Loss: 0.00165719841606915\n",
      "Epoch: 15, Loss: 0.0014875484630465508\n",
      "Epoch: 16, Loss: 0.0014262608019635081\n",
      "Epoch: 17, Loss: 0.001351136015728116\n",
      "Epoch: 18, Loss: 0.001263445126824081\n",
      "Epoch: 19, Loss: 0.0010931823635473847\n",
      "Epoch: 20, Loss: 0.0010474505834281445\n",
      "Epoch: 21, Loss: 0.0009474354446865618\n",
      "Epoch: 22, Loss: 0.0008596491534262896\n",
      "Epoch: 23, Loss: 0.0008474990027025342\n",
      "Epoch: 24, Loss: 0.0008411295711994171\n",
      "Epoch: 25, Loss: 0.0008185402839444578\n",
      "Epoch: 26, Loss: 0.0007872629794292152\n",
      "Epoch: 27, Loss: 0.0007238690741360188\n",
      "Epoch: 28, Loss: 0.0005689705722033978\n",
      "Epoch: 29, Loss: 0.0004498179769143462\n",
      "Epoch: 30, Loss: 0.0003634463355410844\n",
      "Epoch: 31, Loss: 0.0002827687712851912\n",
      "Epoch: 32, Loss: 0.0002856791252270341\n",
      "Epoch: 33, Loss: 0.00028417244902811944\n",
      "Epoch: 34, Loss: 0.00025472036213614047\n",
      "Epoch: 35, Loss: 0.000215508189285174\n",
      "Epoch: 36, Loss: 0.000193564614164643\n",
      "Epoch: 37, Loss: 0.00017864328401628882\n",
      "Epoch: 38, Loss: 0.00015913270181044936\n",
      "Epoch: 39, Loss: 0.000154599329107441\n",
      "Epoch: 40, Loss: 0.000158898183144629\n",
      "Epoch: 41, Loss: 0.00015656436153221875\n",
      "Epoch: 42, Loss: 0.00013421835319604725\n",
      "Epoch: 43, Loss: 0.0001384143834002316\n",
      "Epoch: 44, Loss: 0.00015081233868841082\n",
      "Epoch: 45, Loss: 0.00016321845760103315\n",
      "Epoch: 46, Loss: 0.00018365858704783022\n",
      "Epoch: 47, Loss: 0.0002054758951999247\n",
      "Epoch: 48, Loss: 0.00021724570251535624\n",
      "Epoch: 49, Loss: 0.000196698572835885\n",
      "Epoch: 50, Loss: 0.00014631359954364598\n",
      "epoch 16 tensor([ 0.4940, -1.8407, -0.5397, -0.5650,  0.4437], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.014043268747627735\n",
      "Epoch: 2, Loss: 0.011299149133265018\n",
      "Epoch: 3, Loss: 0.007873761467635632\n",
      "Epoch: 4, Loss: 0.007076101377606392\n",
      "Epoch: 5, Loss: 0.006028328090906143\n",
      "Epoch: 6, Loss: 0.0048511517234146595\n",
      "Epoch: 7, Loss: 0.0041852472350001335\n",
      "Epoch: 8, Loss: 0.0034440115559846163\n",
      "Epoch: 9, Loss: 0.003398230765014887\n",
      "Epoch: 10, Loss: 0.0025059368927031755\n",
      "Epoch: 11, Loss: 0.002613850636407733\n",
      "Epoch: 12, Loss: 0.002100561745464802\n",
      "Epoch: 13, Loss: 0.0017775021260604262\n",
      "Epoch: 14, Loss: 0.001415578997693956\n",
      "Epoch: 15, Loss: 0.0013120763469487429\n",
      "Epoch: 16, Loss: 0.001372861908748746\n",
      "Epoch: 17, Loss: 0.0012855243403464556\n",
      "Epoch: 18, Loss: 0.000992285436950624\n",
      "Epoch: 19, Loss: 0.0008336830069310963\n",
      "Epoch: 20, Loss: 0.0007207737071439624\n",
      "Epoch: 21, Loss: 0.0007019271142780781\n",
      "Epoch: 22, Loss: 0.0006923401961103082\n",
      "Epoch: 23, Loss: 0.0005439568776637316\n",
      "Epoch: 24, Loss: 0.0005417905631475151\n",
      "Epoch: 25, Loss: 0.00041231123032048345\n",
      "Epoch: 26, Loss: 0.00045793940080329776\n",
      "Epoch: 27, Loss: 0.00038197782123461366\n",
      "Epoch: 28, Loss: 0.000363559287507087\n",
      "Epoch: 29, Loss: 0.00030188399250619113\n",
      "Epoch: 30, Loss: 0.0002706310187932104\n",
      "Epoch: 31, Loss: 0.00030788322328589857\n",
      "Epoch: 32, Loss: 0.00023399826022796333\n",
      "Epoch: 33, Loss: 0.00028724881121888757\n",
      "Epoch: 34, Loss: 0.00021808056044392288\n",
      "Epoch: 35, Loss: 0.0002253283018944785\n",
      "Epoch: 36, Loss: 0.00014181100414134562\n",
      "Epoch: 37, Loss: 0.00012750360474456102\n",
      "Epoch: 38, Loss: 9.597269672667608e-05\n",
      "Epoch: 39, Loss: 9.801427950151265e-05\n",
      "Epoch: 40, Loss: 7.985591946635395e-05\n",
      "Epoch: 41, Loss: 6.208354898262769e-05\n",
      "Epoch: 42, Loss: 7.438143074978143e-05\n",
      "Epoch: 43, Loss: 6.552872946485877e-05\n",
      "Epoch: 44, Loss: 6.966225919313729e-05\n",
      "Epoch: 45, Loss: 5.5827811593189836e-05\n",
      "Epoch: 46, Loss: 7.799714512657374e-05\n",
      "Epoch: 47, Loss: 6.527500954689458e-05\n",
      "Epoch: 48, Loss: 6.553918501595035e-05\n",
      "Epoch: 49, Loss: 7.115230255294591e-05\n",
      "Epoch: 50, Loss: 0.00010499500058358535\n",
      "epoch 16 tensor([ 0.4631, -1.9097, -0.6072, -0.5692,  0.3451], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.013440740294754505\n",
      "Epoch: 2, Loss: 0.011437011882662773\n",
      "Epoch: 3, Loss: 0.009762754663825035\n",
      "Epoch: 4, Loss: 0.006257636472582817\n",
      "Epoch: 5, Loss: 0.004756590351462364\n",
      "Epoch: 6, Loss: 0.005126414820551872\n",
      "Epoch: 7, Loss: 0.0029928472358733416\n",
      "Epoch: 8, Loss: 0.004144655074924231\n",
      "Epoch: 9, Loss: 0.003386623226106167\n",
      "Epoch: 10, Loss: 0.0036900839768350124\n",
      "Epoch: 11, Loss: 0.0037843401078134775\n",
      "Epoch: 12, Loss: 0.0030306566040962934\n",
      "Epoch: 13, Loss: 0.002708535175770521\n",
      "Epoch: 14, Loss: 0.0017411709995940328\n",
      "Epoch: 15, Loss: 0.0016457666642963886\n",
      "Epoch: 16, Loss: 0.0012851126957684755\n",
      "Epoch: 17, Loss: 0.0013949390267953277\n",
      "Epoch: 18, Loss: 0.0010692751966416836\n",
      "Epoch: 19, Loss: 0.0011990489438176155\n",
      "Epoch: 20, Loss: 0.0009317370713688433\n",
      "Epoch: 21, Loss: 0.0009450273355469108\n",
      "Epoch: 22, Loss: 0.0008077868260443211\n",
      "Epoch: 23, Loss: 0.0007526807603426278\n",
      "Epoch: 24, Loss: 0.0006543808267451823\n",
      "Epoch: 25, Loss: 0.0005972290528006852\n",
      "Epoch: 26, Loss: 0.0005183842149563134\n",
      "Epoch: 27, Loss: 0.0005434724153019488\n",
      "Epoch: 28, Loss: 0.0005336532485671341\n",
      "Epoch: 29, Loss: 0.0004424815997481346\n",
      "Epoch: 30, Loss: 0.0004184432327747345\n",
      "Epoch: 31, Loss: 0.0002954397350549698\n",
      "Epoch: 32, Loss: 0.000250247772783041\n",
      "Epoch: 33, Loss: 0.0002329454873688519\n",
      "Epoch: 34, Loss: 0.00017876276979222894\n",
      "Epoch: 35, Loss: 0.00023714340932201594\n",
      "Epoch: 36, Loss: 0.00017776172899175435\n",
      "Epoch: 37, Loss: 0.0001981102250283584\n",
      "Epoch: 38, Loss: 0.0001846780942287296\n",
      "Epoch: 39, Loss: 0.0001633896172279492\n",
      "Epoch: 40, Loss: 0.00016134385077748448\n",
      "Epoch: 41, Loss: 0.00011030328460037708\n",
      "Epoch: 42, Loss: 0.00010365368507336825\n",
      "Epoch: 43, Loss: 8.801423973636702e-05\n",
      "Epoch: 44, Loss: 6.999167817411944e-05\n",
      "Epoch: 45, Loss: 0.00010141386883333325\n",
      "Epoch: 46, Loss: 8.266940858447924e-05\n",
      "Epoch: 47, Loss: 9.37541772145778e-05\n",
      "Epoch: 48, Loss: 7.994331099325791e-05\n",
      "Epoch: 49, Loss: 6.259825750021264e-05\n",
      "Epoch: 50, Loss: 6.292474427027628e-05\n",
      "epoch 16 tensor([ 0.5052, -1.9077, -0.5989, -0.5602,  0.3840], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.00546739948913455\n",
      "Epoch: 2, Loss: 0.003742590546607971\n",
      "Epoch: 3, Loss: 0.0027176819276064634\n",
      "Epoch: 4, Loss: 0.002059461083263159\n",
      "Epoch: 5, Loss: 0.0012365356087684631\n",
      "Epoch: 6, Loss: 0.001606825622729957\n",
      "Epoch: 7, Loss: 0.001038842019625008\n",
      "Epoch: 8, Loss: 0.00099977757781744\n",
      "Epoch: 9, Loss: 0.0010829231468960643\n",
      "Epoch: 10, Loss: 0.0012598298490047455\n",
      "Epoch: 11, Loss: 0.0008347624680027366\n",
      "Epoch: 12, Loss: 0.0010747213382273912\n",
      "Epoch: 13, Loss: 0.0009154416620731354\n",
      "Epoch: 14, Loss: 0.0006750688189640641\n",
      "Epoch: 15, Loss: 0.0007628514431416988\n",
      "Epoch: 16, Loss: 0.0007915368187241256\n",
      "Epoch: 17, Loss: 0.00048743002116680145\n",
      "Epoch: 18, Loss: 0.000449997402029112\n",
      "Epoch: 19, Loss: 0.000456014066003263\n",
      "Epoch: 20, Loss: 0.0003209096903447062\n",
      "Epoch: 21, Loss: 0.00023529920144937932\n",
      "Epoch: 22, Loss: 0.0003227760025765747\n",
      "Epoch: 23, Loss: 0.0002527004398871213\n",
      "Epoch: 24, Loss: 0.00023508709273301065\n",
      "Epoch: 25, Loss: 0.0002619343576952815\n",
      "Epoch: 26, Loss: 0.0002262783091282472\n",
      "Epoch: 27, Loss: 0.00019683795107994229\n",
      "Epoch: 28, Loss: 0.00019781406444963068\n",
      "Epoch: 29, Loss: 0.00013914061128161848\n",
      "Epoch: 30, Loss: 0.00013991529704071581\n",
      "Epoch: 31, Loss: 0.00014274385466706008\n",
      "Epoch: 32, Loss: 0.00010983808169839904\n",
      "Epoch: 33, Loss: 9.754796337801963e-05\n",
      "Epoch: 34, Loss: 0.00010791976092150435\n",
      "Epoch: 35, Loss: 7.927132537588477e-05\n",
      "Epoch: 36, Loss: 6.117589509813115e-05\n",
      "Epoch: 37, Loss: 7.943419041112065e-05\n",
      "Epoch: 38, Loss: 5.45652219443582e-05\n",
      "Epoch: 39, Loss: 6.0462713008746505e-05\n",
      "Epoch: 40, Loss: 6.46792323095724e-05\n",
      "Epoch: 41, Loss: 4.692027505370788e-05\n",
      "Epoch: 42, Loss: 5.086837336421013e-05\n",
      "Epoch: 43, Loss: 3.6502759030554444e-05\n",
      "Epoch: 44, Loss: 2.7908170523005538e-05\n",
      "Epoch: 45, Loss: 3.5308548831380904e-05\n",
      "Epoch: 46, Loss: 2.839053559000604e-05\n",
      "Epoch: 47, Loss: 3.040381307073403e-05\n",
      "Epoch: 48, Loss: 3.484965054667555e-05\n",
      "Epoch: 49, Loss: 3.529539390001446e-05\n",
      "Epoch: 50, Loss: 3.5391058190725744e-05\n",
      "epoch 16 tensor([ 0.5214, -1.8904, -0.5349, -0.5104,  0.3621], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.012332902289927006\n",
      "Epoch: 2, Loss: 0.010629463009536266\n",
      "Epoch: 3, Loss: 0.00799714308232069\n",
      "Epoch: 4, Loss: 0.0069272154942154884\n",
      "Epoch: 5, Loss: 0.005745856557041407\n",
      "Epoch: 6, Loss: 0.005041013937443495\n",
      "Epoch: 7, Loss: 0.00404841173440218\n",
      "Epoch: 8, Loss: 0.004012135323137045\n",
      "Epoch: 9, Loss: 0.002844181377440691\n",
      "Epoch: 10, Loss: 0.003002303885295987\n",
      "Epoch: 11, Loss: 0.002235999098047614\n",
      "Epoch: 12, Loss: 0.0019115182803943753\n",
      "Epoch: 13, Loss: 0.001990081276744604\n",
      "Epoch: 14, Loss: 0.0013525524409487844\n",
      "Epoch: 15, Loss: 0.0013311291113495827\n",
      "Epoch: 16, Loss: 0.0007537752971984446\n",
      "Epoch: 17, Loss: 0.001172281219623983\n",
      "Epoch: 18, Loss: 0.0009006046457216144\n",
      "Epoch: 19, Loss: 0.0009926543571054935\n",
      "Epoch: 20, Loss: 0.0008304472430609167\n",
      "Epoch: 21, Loss: 0.0007262732833623886\n",
      "Epoch: 22, Loss: 0.0008026096038520336\n",
      "Epoch: 23, Loss: 0.0005528996116481721\n",
      "Epoch: 24, Loss: 0.0006738906376995146\n",
      "Epoch: 25, Loss: 0.000430183979915455\n",
      "Epoch: 26, Loss: 0.0006856960244476795\n",
      "Epoch: 27, Loss: 0.0004922093357890844\n",
      "Epoch: 28, Loss: 0.0003695329651236534\n",
      "Epoch: 29, Loss: 0.0002985484024975449\n",
      "Epoch: 30, Loss: 0.00032725275377742946\n",
      "Epoch: 31, Loss: 0.00039008274325169623\n",
      "Epoch: 32, Loss: 0.0002456209622323513\n",
      "Epoch: 33, Loss: 0.00024423771537840366\n",
      "Epoch: 34, Loss: 0.00016528945707250386\n",
      "Epoch: 35, Loss: 0.0002178467984776944\n",
      "Epoch: 36, Loss: 0.000170437793713063\n",
      "Epoch: 37, Loss: 0.00016957128536887467\n",
      "Epoch: 38, Loss: 0.000128521365695633\n",
      "Epoch: 39, Loss: 0.00015991568216122687\n",
      "Epoch: 40, Loss: 8.994126983452588e-05\n",
      "Epoch: 41, Loss: 0.00011649553925963119\n",
      "Epoch: 42, Loss: 9.399999544257298e-05\n",
      "Epoch: 43, Loss: 9.103814227273688e-05\n",
      "Epoch: 44, Loss: 7.883962825872004e-05\n",
      "Epoch: 45, Loss: 7.7163364039734e-05\n",
      "Epoch: 46, Loss: 5.093489744467661e-05\n",
      "Epoch: 47, Loss: 6.291960744420066e-05\n",
      "Epoch: 48, Loss: 5.318124021869153e-05\n",
      "Epoch: 49, Loss: 5.648794103763066e-05\n",
      "Epoch: 50, Loss: 3.7193403841229156e-05\n",
      "epoch 16 tensor([ 0.5010, -1.8591, -0.5545, -0.5636,  0.4617], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.008249464444816113\n",
      "Epoch: 2, Loss: 0.005198937840759754\n",
      "Epoch: 3, Loss: 0.0039335740730166435\n",
      "Epoch: 4, Loss: 0.004146592225879431\n",
      "Epoch: 5, Loss: 0.0032619419507682323\n",
      "Epoch: 6, Loss: 0.002296720165759325\n",
      "Epoch: 7, Loss: 0.0022206304129213095\n",
      "Epoch: 8, Loss: 0.0026625061873346567\n",
      "Epoch: 9, Loss: 0.0023898554500192404\n",
      "Epoch: 10, Loss: 0.0015891934745013714\n",
      "Epoch: 11, Loss: 0.0016553506720811129\n",
      "Epoch: 12, Loss: 0.0016136872582137585\n",
      "Epoch: 13, Loss: 0.0010377668077126145\n",
      "Epoch: 14, Loss: 0.0006419604760594666\n",
      "Epoch: 15, Loss: 0.001034458284266293\n",
      "Epoch: 16, Loss: 0.0011195673141628504\n",
      "Epoch: 17, Loss: 0.0008446371066384017\n",
      "Epoch: 18, Loss: 0.0006938627921044827\n",
      "Epoch: 19, Loss: 0.0007603549165651202\n",
      "Epoch: 20, Loss: 0.0007238972466439009\n",
      "Epoch: 21, Loss: 0.0005101693095639348\n",
      "Epoch: 22, Loss: 0.00043719413224607706\n",
      "Epoch: 23, Loss: 0.0003836559772025794\n",
      "Epoch: 24, Loss: 0.0003778745885938406\n",
      "Epoch: 25, Loss: 0.0003700715606100857\n",
      "Epoch: 26, Loss: 0.0004026513488497585\n",
      "Epoch: 27, Loss: 0.00037676378269679844\n",
      "Epoch: 28, Loss: 0.00028495065635070205\n",
      "Epoch: 29, Loss: 0.0002493305946700275\n",
      "Epoch: 30, Loss: 0.00022135922336019576\n",
      "Epoch: 31, Loss: 0.0002284361544298008\n",
      "Epoch: 32, Loss: 0.00018413686484564096\n",
      "Epoch: 33, Loss: 0.00015061916201375425\n",
      "Epoch: 34, Loss: 0.0001616989029571414\n",
      "Epoch: 35, Loss: 0.00016713497461751103\n",
      "Epoch: 36, Loss: 0.00014870677841827273\n",
      "Epoch: 37, Loss: 0.00010222524724667892\n",
      "Epoch: 38, Loss: 8.909075404517353e-05\n",
      "Epoch: 39, Loss: 0.00010416760778753087\n",
      "Epoch: 40, Loss: 0.00010574224143056199\n",
      "Epoch: 41, Loss: 9.514046541880816e-05\n",
      "Epoch: 42, Loss: 6.9562389398925e-05\n",
      "Epoch: 43, Loss: 5.280966070131399e-05\n",
      "Epoch: 44, Loss: 4.833807543036528e-05\n",
      "Epoch: 45, Loss: 4.6607834519818425e-05\n",
      "Epoch: 46, Loss: 4.99106063216459e-05\n",
      "Epoch: 47, Loss: 5.0612870836630464e-05\n",
      "Epoch: 48, Loss: 5.211523603065871e-05\n",
      "Epoch: 49, Loss: 6.614316953346133e-05\n",
      "Epoch: 50, Loss: 7.985872071003541e-05\n",
      "epoch 16 tensor([ 0.4878, -1.8766, -0.5506, -0.4882,  0.4364], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0022904977668076754\n",
      "Epoch: 2, Loss: 0.0015858740080147982\n",
      "Epoch: 3, Loss: 0.0013563907705247402\n",
      "Epoch: 4, Loss: 0.0011558508267626166\n",
      "Epoch: 5, Loss: 0.00043494670535437763\n",
      "Epoch: 6, Loss: 0.0009693853789940476\n",
      "Epoch: 7, Loss: 0.0004854219441767782\n",
      "Epoch: 8, Loss: 0.000635857111774385\n",
      "Epoch: 9, Loss: 0.0007884278311394155\n",
      "Epoch: 10, Loss: 0.0007868969696573913\n",
      "Epoch: 11, Loss: 0.0004686400934588164\n",
      "Epoch: 12, Loss: 0.0006613802397623658\n",
      "Epoch: 13, Loss: 0.00037046580109745264\n",
      "Epoch: 14, Loss: 0.00032158478279598057\n",
      "Epoch: 15, Loss: 0.00028569300775416195\n",
      "Epoch: 16, Loss: 0.0003373192739672959\n",
      "Epoch: 17, Loss: 0.00017639469297137111\n",
      "Epoch: 18, Loss: 0.0003153432917315513\n",
      "Epoch: 19, Loss: 0.00022119875939097255\n",
      "Epoch: 20, Loss: 0.00026932702166959643\n",
      "Epoch: 21, Loss: 0.00021095189731568098\n",
      "Epoch: 22, Loss: 0.00019203181727789342\n",
      "Epoch: 23, Loss: 0.00014012385508976877\n",
      "Epoch: 24, Loss: 0.0001408998650731519\n",
      "Epoch: 25, Loss: 7.562949758721516e-05\n",
      "Epoch: 26, Loss: 0.00013915065210312605\n",
      "Epoch: 27, Loss: 0.00010857990855583921\n",
      "Epoch: 28, Loss: 9.742970723891631e-05\n",
      "Epoch: 29, Loss: 0.00011470504250610247\n",
      "Epoch: 30, Loss: 0.00010349204967496917\n",
      "Epoch: 31, Loss: 8.758626790950075e-05\n",
      "Epoch: 32, Loss: 9.343051351606846e-05\n",
      "Epoch: 33, Loss: 8.739601616980508e-05\n",
      "Epoch: 34, Loss: 9.156014857580885e-05\n",
      "Epoch: 35, Loss: 0.00012985624198336154\n",
      "Epoch: 36, Loss: 0.00011186728079337627\n",
      "Epoch: 37, Loss: 0.00014790725253988057\n",
      "Epoch: 38, Loss: 0.00014696302241645753\n",
      "Epoch: 39, Loss: 0.00012926245108246803\n",
      "Epoch: 40, Loss: 8.966806490207091e-05\n",
      "Epoch: 41, Loss: 4.481681025936268e-05\n",
      "Epoch: 42, Loss: 2.2791755327489227e-05\n",
      "Epoch: 43, Loss: 3.215477045159787e-05\n",
      "Epoch: 44, Loss: 4.786011777468957e-05\n",
      "Epoch: 45, Loss: 6.137944728834555e-05\n",
      "Epoch: 46, Loss: 9.177566244034097e-05\n",
      "Epoch: 47, Loss: 0.00010624300921335816\n",
      "Epoch: 48, Loss: 0.00012332711776252836\n",
      "Epoch: 49, Loss: 0.0001093134778784588\n",
      "Epoch: 50, Loss: 7.363571057794616e-05\n",
      "________________________________________\n",
      "epoch 17 tensor([ 0.4988, -1.8753, -0.5416, -0.4881,  0.4479], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.005289163440465927\n",
      "Epoch: 2, Loss: 0.004107936751097441\n",
      "Epoch: 3, Loss: 0.0037682580295950174\n",
      "Epoch: 4, Loss: 0.003994126804172993\n",
      "Epoch: 5, Loss: 0.002366387052461505\n",
      "Epoch: 6, Loss: 0.0012831867206841707\n",
      "Epoch: 7, Loss: 0.0027149019297212362\n",
      "Epoch: 8, Loss: 0.001393960090354085\n",
      "Epoch: 9, Loss: 0.001949415309354663\n",
      "Epoch: 10, Loss: 0.0015155671862885356\n",
      "Epoch: 11, Loss: 0.0017629775684326887\n",
      "Epoch: 12, Loss: 0.0010278058471158147\n",
      "Epoch: 13, Loss: 0.0013171614846214652\n",
      "Epoch: 14, Loss: 0.0011457278160378337\n",
      "Epoch: 15, Loss: 0.0010097305057570338\n",
      "Epoch: 16, Loss: 0.0007041564676910639\n",
      "Epoch: 17, Loss: 0.0008108397014439106\n",
      "Epoch: 18, Loss: 0.0006513258558697999\n",
      "Epoch: 19, Loss: 0.0005440251552499831\n",
      "Epoch: 20, Loss: 0.00040616129990667105\n",
      "Epoch: 21, Loss: 0.0006380811100825667\n",
      "Epoch: 22, Loss: 0.00032284363987855613\n",
      "Epoch: 23, Loss: 0.0005061549600213766\n",
      "Epoch: 24, Loss: 0.0002402498066658154\n",
      "Epoch: 25, Loss: 0.0004660990962292999\n",
      "Epoch: 26, Loss: 0.0001741868327371776\n",
      "Epoch: 27, Loss: 0.00031793059315532446\n",
      "Epoch: 28, Loss: 0.00022088727564550936\n",
      "Epoch: 29, Loss: 0.00030393683118745685\n",
      "Epoch: 30, Loss: 0.00013859200407750905\n",
      "Epoch: 31, Loss: 0.0002357124030822888\n",
      "Epoch: 32, Loss: 0.00013279617996886373\n",
      "Epoch: 33, Loss: 0.00017018886865116656\n",
      "Epoch: 34, Loss: 7.22156764823012e-05\n",
      "Epoch: 35, Loss: 0.0001541961682960391\n",
      "Epoch: 36, Loss: 7.40277100703679e-05\n",
      "Epoch: 37, Loss: 0.00011475636711111292\n",
      "Epoch: 38, Loss: 8.401717059314251e-05\n",
      "Epoch: 39, Loss: 0.00010631415352690965\n",
      "Epoch: 40, Loss: 6.243257666938007e-05\n",
      "Epoch: 41, Loss: 7.188338349806145e-05\n",
      "Epoch: 42, Loss: 7.547919813077897e-05\n",
      "Epoch: 43, Loss: 5.303851867211051e-05\n",
      "Epoch: 44, Loss: 4.273517697583884e-05\n",
      "Epoch: 45, Loss: 4.1026738472282887e-05\n",
      "Epoch: 46, Loss: 3.885175465256907e-05\n",
      "Epoch: 47, Loss: 2.2149146388983354e-05\n",
      "Epoch: 48, Loss: 4.4646047172136605e-05\n",
      "Epoch: 49, Loss: 2.4092019884847105e-05\n",
      "Epoch: 50, Loss: 4.175088906777091e-05\n",
      "epoch 17 tensor([ 0.5050, -1.9041, -0.4964, -0.5983,  0.4795], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0071417479775846004\n",
      "Epoch: 2, Loss: 0.004514711443334818\n",
      "Epoch: 3, Loss: 0.0022820744197815657\n",
      "Epoch: 4, Loss: 0.0019755291286855936\n",
      "Epoch: 5, Loss: 0.0016888724640011787\n",
      "Epoch: 6, Loss: 0.002366297412663698\n",
      "Epoch: 7, Loss: 0.0020153445657342672\n",
      "Epoch: 8, Loss: 0.001543431542813778\n",
      "Epoch: 9, Loss: 0.0013657137751579285\n",
      "Epoch: 10, Loss: 0.0014933282509446144\n",
      "Epoch: 11, Loss: 0.0016283844597637653\n",
      "Epoch: 12, Loss: 0.0013650081818923354\n",
      "Epoch: 13, Loss: 0.001210827729664743\n",
      "Epoch: 14, Loss: 0.0006254751933738589\n",
      "Epoch: 15, Loss: 0.0005496228695847094\n",
      "Epoch: 16, Loss: 0.0005442688125185668\n",
      "Epoch: 17, Loss: 0.0007769090589135885\n",
      "Epoch: 18, Loss: 0.0007945237448439002\n",
      "Epoch: 19, Loss: 0.0007590362220071256\n",
      "Epoch: 20, Loss: 0.0005804981919936836\n",
      "Epoch: 21, Loss: 0.00039211948751471937\n",
      "Epoch: 22, Loss: 0.0003995384322479367\n",
      "Epoch: 23, Loss: 0.0003174356243107468\n",
      "Epoch: 24, Loss: 0.0003355267399456352\n",
      "Epoch: 25, Loss: 0.00025007451768033206\n",
      "Epoch: 26, Loss: 0.00024418148677796125\n",
      "Epoch: 27, Loss: 0.00023875439364928752\n",
      "Epoch: 28, Loss: 0.0002508898905944079\n",
      "Epoch: 29, Loss: 0.0002536076935939491\n",
      "Epoch: 30, Loss: 0.0001925603428389877\n",
      "Epoch: 31, Loss: 0.00016232016787398607\n",
      "Epoch: 32, Loss: 0.00011529079347383231\n",
      "Epoch: 33, Loss: 0.00011150867794640362\n",
      "Epoch: 34, Loss: 0.0001350731763523072\n",
      "Epoch: 35, Loss: 0.00011459530651336536\n",
      "Epoch: 36, Loss: 0.00011818693747045472\n",
      "Epoch: 37, Loss: 8.633061224827543e-05\n",
      "Epoch: 38, Loss: 7.173646008595824e-05\n",
      "Epoch: 39, Loss: 8.161287405528128e-05\n",
      "Epoch: 40, Loss: 6.394537922460586e-05\n",
      "Epoch: 41, Loss: 6.129357643658295e-05\n",
      "Epoch: 42, Loss: 5.801915540359914e-05\n",
      "Epoch: 43, Loss: 4.4216401875019073e-05\n",
      "Epoch: 44, Loss: 4.96725260745734e-05\n",
      "Epoch: 45, Loss: 4.5877935917815194e-05\n",
      "Epoch: 46, Loss: 3.0361006793100387e-05\n",
      "Epoch: 47, Loss: 3.639340138761327e-05\n",
      "Epoch: 48, Loss: 3.7923578929621726e-05\n",
      "Epoch: 49, Loss: 4.5212080294732004e-05\n",
      "Epoch: 50, Loss: 7.513969467254356e-05\n",
      "epoch 17 tensor([ 0.4442, -1.7553, -0.5499, -0.5548,  0.5196], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.004469965118914843\n",
      "Epoch: 2, Loss: 0.004934471566230059\n",
      "Epoch: 3, Loss: 0.005244353320449591\n",
      "Epoch: 4, Loss: 0.003250091103836894\n",
      "Epoch: 5, Loss: 0.00264285528101027\n",
      "Epoch: 6, Loss: 0.003431484801694751\n",
      "Epoch: 7, Loss: 0.0023480833042412996\n",
      "Epoch: 8, Loss: 0.002712664660066366\n",
      "Epoch: 9, Loss: 0.0023120734840631485\n",
      "Epoch: 10, Loss: 0.0018203185172751546\n",
      "Epoch: 11, Loss: 0.002109069610014558\n",
      "Epoch: 12, Loss: 0.0015540285967290401\n",
      "Epoch: 13, Loss: 0.0019504806259647012\n",
      "Epoch: 14, Loss: 0.0012828339822590351\n",
      "Epoch: 15, Loss: 0.0015408529434353113\n",
      "Epoch: 16, Loss: 0.0010520742507651448\n",
      "Epoch: 17, Loss: 0.0012061024317517877\n",
      "Epoch: 18, Loss: 0.0008309914846904576\n",
      "Epoch: 19, Loss: 0.0009024206083267927\n",
      "Epoch: 20, Loss: 0.0007508517010137439\n",
      "Epoch: 21, Loss: 0.0006607297691516578\n",
      "Epoch: 22, Loss: 0.0006470137741416693\n",
      "Epoch: 23, Loss: 0.00047892756992951035\n",
      "Epoch: 24, Loss: 0.0006170646520331502\n",
      "Epoch: 25, Loss: 0.00039982766611501575\n",
      "Epoch: 26, Loss: 0.0004968519788235426\n",
      "Epoch: 27, Loss: 0.0002913809148594737\n",
      "Epoch: 28, Loss: 0.000351931230397895\n",
      "Epoch: 29, Loss: 0.0002589293580967933\n",
      "Epoch: 30, Loss: 0.0002413119509583339\n",
      "Epoch: 31, Loss: 0.00022453285055235028\n",
      "Epoch: 32, Loss: 0.0001860906049842015\n",
      "Epoch: 33, Loss: 0.0001826686639105901\n",
      "Epoch: 34, Loss: 0.00012164364306954667\n",
      "Epoch: 35, Loss: 0.00014195655239745975\n",
      "Epoch: 36, Loss: 0.00010535600449657068\n",
      "Epoch: 37, Loss: 0.00012044015602441505\n",
      "Epoch: 38, Loss: 7.912973524071276e-05\n",
      "Epoch: 39, Loss: 8.957290992839262e-05\n",
      "Epoch: 40, Loss: 5.58818610443268e-05\n",
      "Epoch: 41, Loss: 6.784142897231504e-05\n",
      "Epoch: 42, Loss: 4.6612301957793534e-05\n",
      "Epoch: 43, Loss: 4.7417106543434784e-05\n",
      "Epoch: 44, Loss: 4.9461788876214996e-05\n",
      "Epoch: 45, Loss: 2.9038008506176993e-05\n",
      "Epoch: 46, Loss: 2.99947387247812e-05\n",
      "Epoch: 47, Loss: 2.6143237846554257e-05\n",
      "Epoch: 48, Loss: 2.497843888704665e-05\n",
      "Epoch: 49, Loss: 2.939687874459196e-05\n",
      "Epoch: 50, Loss: 1.1141154573124368e-05\n",
      "epoch 17 tensor([ 0.4947, -1.9301, -0.4672, -0.5491,  0.5433], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.005391442682594061\n",
      "Epoch: 2, Loss: 0.0037933243438601494\n",
      "Epoch: 3, Loss: 0.002657312201336026\n",
      "Epoch: 4, Loss: 0.001769132912158966\n",
      "Epoch: 5, Loss: 0.0017170256469398737\n",
      "Epoch: 6, Loss: 0.0015133372507989407\n",
      "Epoch: 7, Loss: 0.0013992732856422663\n",
      "Epoch: 8, Loss: 0.0012485429178923368\n",
      "Epoch: 9, Loss: 0.0008576310356147587\n",
      "Epoch: 10, Loss: 0.0007582810358144343\n",
      "Epoch: 11, Loss: 0.0006944169872440398\n",
      "Epoch: 12, Loss: 0.0008417593198828399\n",
      "Epoch: 13, Loss: 0.000759736867621541\n",
      "Epoch: 14, Loss: 0.0008364354725927114\n",
      "Epoch: 15, Loss: 0.0008246416109614074\n",
      "Epoch: 16, Loss: 0.0006142670172266662\n",
      "Epoch: 17, Loss: 0.0005367062403820455\n",
      "Epoch: 18, Loss: 0.0004898555343970656\n",
      "Epoch: 19, Loss: 0.00047942213132046163\n",
      "Epoch: 20, Loss: 0.00044171910849399865\n",
      "Epoch: 21, Loss: 0.0003977463347837329\n",
      "Epoch: 22, Loss: 0.0003459314757492393\n",
      "Epoch: 23, Loss: 0.00023503393458668143\n",
      "Epoch: 24, Loss: 0.0001917623303597793\n",
      "Epoch: 25, Loss: 0.0001543978287372738\n",
      "Epoch: 26, Loss: 0.0001766109053278342\n",
      "Epoch: 27, Loss: 0.0001531682355562225\n",
      "Epoch: 28, Loss: 0.00018082931637763977\n",
      "Epoch: 29, Loss: 0.00018072126840706915\n",
      "Epoch: 30, Loss: 0.00015553837874904275\n",
      "Epoch: 31, Loss: 0.00014420115621760488\n",
      "Epoch: 32, Loss: 0.0001216162636410445\n",
      "Epoch: 33, Loss: 0.00011511686170706525\n",
      "Epoch: 34, Loss: 8.268121018772945e-05\n",
      "Epoch: 35, Loss: 7.599669334013015e-05\n",
      "Epoch: 36, Loss: 6.667178240604699e-05\n",
      "Epoch: 37, Loss: 8.190307562472299e-05\n",
      "Epoch: 38, Loss: 0.00010432631825096905\n",
      "Epoch: 39, Loss: 0.0002125930623151362\n",
      "Epoch: 40, Loss: 0.000502055452670902\n",
      "Epoch: 41, Loss: 0.0011129598133265972\n",
      "Epoch: 42, Loss: 0.0014171525835990906\n",
      "Epoch: 43, Loss: 0.0005298230098560452\n",
      "Epoch: 44, Loss: 8.2837650552392e-05\n",
      "Epoch: 45, Loss: 0.0008099531987681985\n",
      "Epoch: 46, Loss: 0.0005929477047175169\n",
      "Epoch: 47, Loss: 4.4809989049099386e-05\n",
      "Epoch: 48, Loss: 0.000546917028259486\n",
      "Epoch: 49, Loss: 0.00041937234345823526\n",
      "Epoch: 50, Loss: 8.000743400771171e-05\n",
      "epoch 17 tensor([ 0.4362, -1.9154, -0.5993, -0.5068,  0.4967], grad_fn=<AddBackward0>) 4\n",
      "Epoch: 1, Loss: 0.008906749077141285\n",
      "Epoch: 2, Loss: 0.00538593577221036\n",
      "Epoch: 3, Loss: 0.004282095469534397\n",
      "Epoch: 4, Loss: 0.0047911242581903934\n",
      "Epoch: 5, Loss: 0.004053271841257811\n",
      "Epoch: 6, Loss: 0.0028236526995897293\n",
      "Epoch: 7, Loss: 0.002851505298167467\n",
      "Epoch: 8, Loss: 0.0032526885624974966\n",
      "Epoch: 9, Loss: 0.0026233133394271135\n",
      "Epoch: 10, Loss: 0.001735435682348907\n",
      "Epoch: 11, Loss: 0.0014258803566917777\n",
      "Epoch: 12, Loss: 0.0014706660294905305\n",
      "Epoch: 13, Loss: 0.0012427372857928276\n",
      "Epoch: 14, Loss: 0.0009119387832470238\n",
      "Epoch: 15, Loss: 0.0010328772477805614\n",
      "Epoch: 16, Loss: 0.0010393800912424922\n",
      "Epoch: 17, Loss: 0.0008353631128557026\n",
      "Epoch: 18, Loss: 0.0006996805313974619\n",
      "Epoch: 19, Loss: 0.0005891484906896949\n",
      "Epoch: 20, Loss: 0.0005778296035714447\n",
      "Epoch: 21, Loss: 0.000507732795085758\n",
      "Epoch: 22, Loss: 0.0004586560244206339\n",
      "Epoch: 23, Loss: 0.00041031933506019413\n",
      "Epoch: 24, Loss: 0.00035905156983062625\n",
      "Epoch: 25, Loss: 0.0003730585740413517\n",
      "Epoch: 26, Loss: 0.00036326475674286485\n",
      "Epoch: 27, Loss: 0.0003062458708882332\n",
      "Epoch: 28, Loss: 0.00017598987324163318\n",
      "Epoch: 29, Loss: 0.00015075878764037043\n",
      "Epoch: 30, Loss: 0.00017689765081740916\n",
      "Epoch: 31, Loss: 0.00017684516205918044\n",
      "Epoch: 32, Loss: 0.00014497607480734587\n",
      "Epoch: 33, Loss: 0.00012932938989251852\n",
      "Epoch: 34, Loss: 0.00014784932136535645\n",
      "Epoch: 35, Loss: 0.0001348914229311049\n",
      "Epoch: 36, Loss: 9.814690565690398e-05\n",
      "Epoch: 37, Loss: 6.669654976576567e-05\n",
      "Epoch: 38, Loss: 7.785368507029489e-05\n",
      "Epoch: 39, Loss: 9.600921475794166e-05\n",
      "Epoch: 40, Loss: 8.889805758371949e-05\n",
      "Epoch: 41, Loss: 7.79578258516267e-05\n",
      "Epoch: 42, Loss: 8.211483509512618e-05\n",
      "Epoch: 43, Loss: 8.328452531713992e-05\n",
      "Epoch: 44, Loss: 6.446419138228521e-05\n",
      "Epoch: 45, Loss: 5.460454121930525e-05\n",
      "Epoch: 46, Loss: 5.311938366503455e-05\n",
      "Epoch: 47, Loss: 4.890176569460891e-05\n",
      "Epoch: 48, Loss: 3.9462087443098426e-05\n",
      "Epoch: 49, Loss: 4.5116023102309555e-05\n",
      "Epoch: 50, Loss: 4.695580719271675e-05\n",
      "epoch 17 tensor([ 0.5368, -1.8087, -0.6082, -0.5008,  0.4013], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0044726235792040825\n",
      "Epoch: 2, Loss: 0.002941739046946168\n",
      "Epoch: 3, Loss: 0.0033637159503996372\n",
      "Epoch: 4, Loss: 0.0027966436464339495\n",
      "Epoch: 5, Loss: 0.0018279566429555416\n",
      "Epoch: 6, Loss: 0.002170437015593052\n",
      "Epoch: 7, Loss: 0.002096114680171013\n",
      "Epoch: 8, Loss: 0.0012952819233760238\n",
      "Epoch: 9, Loss: 0.0012273651082068682\n",
      "Epoch: 10, Loss: 0.0011657633585855365\n",
      "Epoch: 11, Loss: 0.001148164737969637\n",
      "Epoch: 12, Loss: 0.0009747629519551992\n",
      "Epoch: 13, Loss: 0.0008961981511674821\n",
      "Epoch: 14, Loss: 0.0008661217289045453\n",
      "Epoch: 15, Loss: 0.000621092040091753\n",
      "Epoch: 16, Loss: 0.0005625683697871864\n",
      "Epoch: 17, Loss: 0.0005887919687665999\n",
      "Epoch: 18, Loss: 0.0004619475803337991\n",
      "Epoch: 19, Loss: 0.00046435260446742177\n",
      "Epoch: 20, Loss: 0.00036701373755931854\n",
      "Epoch: 21, Loss: 0.000409458065405488\n",
      "Epoch: 22, Loss: 0.00042199253221042454\n",
      "Epoch: 23, Loss: 0.0003004117461387068\n",
      "Epoch: 24, Loss: 0.0003371175262145698\n",
      "Epoch: 25, Loss: 0.00024247333931270987\n",
      "Epoch: 26, Loss: 0.000220622998313047\n",
      "Epoch: 27, Loss: 0.00022405966592486948\n",
      "Epoch: 28, Loss: 0.00014578294940292835\n",
      "Epoch: 29, Loss: 0.00022223411360755563\n",
      "Epoch: 30, Loss: 0.00013871205737814307\n",
      "Epoch: 31, Loss: 0.0001132585748564452\n",
      "Epoch: 32, Loss: 0.00010672526695998386\n",
      "Epoch: 33, Loss: 0.00011099441326223314\n",
      "Epoch: 34, Loss: 0.00010854803258553147\n",
      "Epoch: 35, Loss: 9.47349180933088e-05\n",
      "Epoch: 36, Loss: 0.00010996269702445716\n",
      "Epoch: 37, Loss: 7.37346344976686e-05\n",
      "Epoch: 38, Loss: 6.404963642125949e-05\n",
      "Epoch: 39, Loss: 6.402761209756136e-05\n",
      "Epoch: 40, Loss: 4.85677010146901e-05\n",
      "Epoch: 41, Loss: 5.221724495640956e-05\n",
      "Epoch: 42, Loss: 5.3001578635303304e-05\n",
      "Epoch: 43, Loss: 4.6116419980535284e-05\n",
      "Epoch: 44, Loss: 2.9428047128021717e-05\n",
      "Epoch: 45, Loss: 4.017021637992002e-05\n",
      "Epoch: 46, Loss: 3.872811794281006e-05\n",
      "Epoch: 47, Loss: 2.5353185264975764e-05\n",
      "Epoch: 48, Loss: 2.7920936190639623e-05\n",
      "Epoch: 49, Loss: 2.8189786462462507e-05\n",
      "Epoch: 50, Loss: 1.1159258065163158e-05\n",
      "epoch 17 tensor([ 0.5254, -1.8317, -0.5392, -0.5086,  0.4470], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0059731160290539265\n",
      "Epoch: 2, Loss: 0.003642397467046976\n",
      "Epoch: 3, Loss: 0.0032718998845666647\n",
      "Epoch: 4, Loss: 0.0025325396563857794\n",
      "Epoch: 5, Loss: 0.0023192756343632936\n",
      "Epoch: 6, Loss: 0.0024623137433081865\n",
      "Epoch: 7, Loss: 0.0016548145795240998\n",
      "Epoch: 8, Loss: 0.0012071389937773347\n",
      "Epoch: 9, Loss: 0.0015304264379665256\n",
      "Epoch: 10, Loss: 0.001311984029598534\n",
      "Epoch: 11, Loss: 0.001048792153596878\n",
      "Epoch: 12, Loss: 0.0011297701857984066\n",
      "Epoch: 13, Loss: 0.00107151223346591\n",
      "Epoch: 14, Loss: 0.0008763737860135734\n",
      "Epoch: 15, Loss: 0.0008501114207319915\n",
      "Epoch: 16, Loss: 0.0008323501097038388\n",
      "Epoch: 17, Loss: 0.0005575281102210283\n",
      "Epoch: 18, Loss: 0.0004764735931530595\n",
      "Epoch: 19, Loss: 0.0005872183828614652\n",
      "Epoch: 20, Loss: 0.0005035690264776349\n",
      "Epoch: 21, Loss: 0.0003394429513718933\n",
      "Epoch: 22, Loss: 0.00035126242437399924\n",
      "Epoch: 23, Loss: 0.00031763932202011347\n",
      "Epoch: 24, Loss: 0.00027920069987885654\n",
      "Epoch: 25, Loss: 0.00032983263372443616\n",
      "Epoch: 26, Loss: 0.0002965090679936111\n",
      "Epoch: 27, Loss: 0.00022851082030683756\n",
      "Epoch: 28, Loss: 0.00018847148749046028\n",
      "Epoch: 29, Loss: 0.00016446570225525647\n",
      "Epoch: 30, Loss: 0.00015867962792981416\n",
      "Epoch: 31, Loss: 0.00016812629473861307\n",
      "Epoch: 32, Loss: 0.0001291197695536539\n",
      "Epoch: 33, Loss: 0.00010197629308095202\n",
      "Epoch: 34, Loss: 0.0001088171629817225\n",
      "Epoch: 35, Loss: 0.00014524119615089148\n",
      "Epoch: 36, Loss: 0.00022739039559382945\n",
      "Epoch: 37, Loss: 0.00042370162555016577\n",
      "Epoch: 38, Loss: 0.0007577376672998071\n",
      "Epoch: 39, Loss: 0.0009048402425833046\n",
      "Epoch: 40, Loss: 0.0004808901867363602\n",
      "Epoch: 41, Loss: 6.537316949106753e-05\n",
      "Epoch: 42, Loss: 0.00029876106418669224\n",
      "Epoch: 43, Loss: 0.0005479563260450959\n",
      "Epoch: 44, Loss: 0.00024368362210225314\n",
      "Epoch: 45, Loss: 6.050986849004403e-05\n",
      "Epoch: 46, Loss: 0.000305128371110186\n",
      "Epoch: 47, Loss: 0.00029488495783880353\n",
      "Epoch: 48, Loss: 6.967102672206238e-05\n",
      "Epoch: 49, Loss: 0.00014544377336278558\n",
      "Epoch: 50, Loss: 0.00024210067931562662\n",
      "epoch 17 tensor([ 0.5644, -1.9086, -0.5383, -0.5787,  0.4202], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.006710510700941086\n",
      "Epoch: 2, Loss: 0.0035599861294031143\n",
      "Epoch: 3, Loss: 0.0026780387852340937\n",
      "Epoch: 4, Loss: 0.001648114644922316\n",
      "Epoch: 5, Loss: 0.0015382453566417098\n",
      "Epoch: 6, Loss: 0.0024882301222532988\n",
      "Epoch: 7, Loss: 0.0019426887156441808\n",
      "Epoch: 8, Loss: 0.0017058521043509245\n",
      "Epoch: 9, Loss: 0.0018730503506958485\n",
      "Epoch: 10, Loss: 0.0013539172941818833\n",
      "Epoch: 11, Loss: 0.0009505711495876312\n",
      "Epoch: 12, Loss: 0.0011097536189481616\n",
      "Epoch: 13, Loss: 0.0007861986523494124\n",
      "Epoch: 14, Loss: 0.0006659803329966962\n",
      "Epoch: 15, Loss: 0.0008600985747762024\n",
      "Epoch: 16, Loss: 0.0008864363189786673\n",
      "Epoch: 17, Loss: 0.0006982359918765724\n",
      "Epoch: 18, Loss: 0.0006415195530280471\n",
      "Epoch: 19, Loss: 0.00048219916061498225\n",
      "Epoch: 20, Loss: 0.00034629975561983883\n",
      "Epoch: 21, Loss: 0.00038377183955162764\n",
      "Epoch: 22, Loss: 0.0003810380876529962\n",
      "Epoch: 23, Loss: 0.0003824147570412606\n",
      "Epoch: 24, Loss: 0.00041735757258720696\n",
      "Epoch: 25, Loss: 0.0003287965664640069\n",
      "Epoch: 26, Loss: 0.00018090970115736127\n",
      "Epoch: 27, Loss: 0.00020603461598511785\n",
      "Epoch: 28, Loss: 0.00016411930846516043\n",
      "Epoch: 29, Loss: 0.00010810941603267565\n",
      "Epoch: 30, Loss: 0.00015763644478283823\n",
      "Epoch: 31, Loss: 0.00015228084521368146\n",
      "Epoch: 32, Loss: 0.00014088851457927376\n",
      "Epoch: 33, Loss: 0.00016941876674536616\n",
      "Epoch: 34, Loss: 0.00017187393677886575\n",
      "Epoch: 35, Loss: 0.0001755767298163846\n",
      "Epoch: 36, Loss: 0.0002704426588024944\n",
      "Epoch: 37, Loss: 0.0003952878760173917\n",
      "Epoch: 38, Loss: 0.00038778435555286705\n",
      "Epoch: 39, Loss: 0.00018814281793311238\n",
      "Epoch: 40, Loss: 7.588352309539914e-05\n",
      "Epoch: 41, Loss: 0.00020258233416825533\n",
      "Epoch: 42, Loss: 0.00024720365763641894\n",
      "Epoch: 43, Loss: 8.23718000901863e-05\n",
      "Epoch: 44, Loss: 5.41557528777048e-05\n",
      "Epoch: 45, Loss: 0.00017150287749245763\n",
      "Epoch: 46, Loss: 0.0001419829932274297\n",
      "Epoch: 47, Loss: 4.2661544284783304e-05\n",
      "Epoch: 48, Loss: 7.471735443687066e-05\n",
      "Epoch: 49, Loss: 0.00012190718553029001\n",
      "Epoch: 50, Loss: 6.503690383397043e-05\n",
      "epoch 17 tensor([ 0.4869, -1.8812, -0.5534, -0.5246,  0.3945], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0031866105273365974\n",
      "Epoch: 2, Loss: 0.0017161992145702243\n",
      "Epoch: 3, Loss: 0.0011948156170547009\n",
      "Epoch: 4, Loss: 0.003021329641342163\n",
      "Epoch: 5, Loss: 0.004960590973496437\n",
      "Epoch: 6, Loss: 0.0012718808138743043\n",
      "Epoch: 7, Loss: 0.0028187267016619444\n",
      "Epoch: 8, Loss: 0.0021022872533649206\n",
      "Epoch: 9, Loss: 0.001873730099759996\n",
      "Epoch: 10, Loss: 0.0019775102846324444\n",
      "Epoch: 11, Loss: 0.001196672790683806\n",
      "Epoch: 12, Loss: 0.001735393307171762\n",
      "Epoch: 13, Loss: 0.0009010718786157668\n",
      "Epoch: 14, Loss: 0.0014765101950615644\n",
      "Epoch: 15, Loss: 0.0004504252865444869\n",
      "Epoch: 16, Loss: 0.0011874769115820527\n",
      "Epoch: 17, Loss: 0.00045377478818409145\n",
      "Epoch: 18, Loss: 0.0009916172130033374\n",
      "Epoch: 19, Loss: 0.00048495345981791615\n",
      "Epoch: 20, Loss: 0.0006730394088663161\n",
      "Epoch: 21, Loss: 0.0004963163519278169\n",
      "Epoch: 22, Loss: 0.000459705654066056\n",
      "Epoch: 23, Loss: 0.0004936580080538988\n",
      "Epoch: 24, Loss: 0.0002885596768464893\n",
      "Epoch: 25, Loss: 0.0004015499434899539\n",
      "Epoch: 26, Loss: 0.000282357883406803\n",
      "Epoch: 27, Loss: 0.00029176019597798586\n",
      "Epoch: 28, Loss: 0.0002448101295158267\n",
      "Epoch: 29, Loss: 0.00019559125939849764\n",
      "Epoch: 30, Loss: 0.00025077760801650584\n",
      "Epoch: 31, Loss: 0.00016571894229855388\n",
      "Epoch: 32, Loss: 0.00023049300943966955\n",
      "Epoch: 33, Loss: 0.00012404195149429142\n",
      "Epoch: 34, Loss: 0.00015954861009959131\n",
      "Epoch: 35, Loss: 0.00012062831956427544\n",
      "Epoch: 36, Loss: 0.00010225590085610747\n",
      "Epoch: 37, Loss: 0.00010433110583107919\n",
      "Epoch: 38, Loss: 7.097373600117862e-05\n",
      "Epoch: 39, Loss: 0.00011318046017549932\n",
      "Epoch: 40, Loss: 6.434976967284456e-05\n",
      "Epoch: 41, Loss: 9.875332762021571e-05\n",
      "Epoch: 42, Loss: 4.680702477344312e-05\n",
      "Epoch: 43, Loss: 6.871437653899193e-05\n",
      "Epoch: 44, Loss: 4.497111149248667e-05\n",
      "Epoch: 45, Loss: 4.7277855628635734e-05\n",
      "Epoch: 46, Loss: 4.018873005406931e-05\n",
      "Epoch: 47, Loss: 4.057815749547444e-05\n",
      "Epoch: 48, Loss: 3.542631748132408e-05\n",
      "Epoch: 49, Loss: 4.0108290704665706e-05\n",
      "Epoch: 50, Loss: 2.2236597942537628e-05\n",
      "epoch 17 tensor([ 0.5300, -1.8695, -0.5263, -0.5169,  0.4237], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0019103720551356673\n",
      "Epoch: 2, Loss: 0.001392535981722176\n",
      "Epoch: 3, Loss: 0.0009061329183168709\n",
      "Epoch: 4, Loss: 0.0007370822713710368\n",
      "Epoch: 5, Loss: 0.0006384812295436859\n",
      "Epoch: 6, Loss: 0.0004927993286401033\n",
      "Epoch: 7, Loss: 0.0005886598373763263\n",
      "Epoch: 8, Loss: 0.0004581314278766513\n",
      "Epoch: 9, Loss: 0.0004664177540689707\n",
      "Epoch: 10, Loss: 0.0004362048930488527\n",
      "Epoch: 11, Loss: 0.00043485037167556584\n",
      "Epoch: 12, Loss: 0.0004612142511177808\n",
      "Epoch: 13, Loss: 0.0003642874944489449\n",
      "Epoch: 14, Loss: 0.000302430969895795\n",
      "Epoch: 15, Loss: 0.000264849019004032\n",
      "Epoch: 16, Loss: 0.00022327486658468843\n",
      "Epoch: 17, Loss: 0.00024488582857884467\n",
      "Epoch: 18, Loss: 0.00019201982649974525\n",
      "Epoch: 19, Loss: 0.00014996767276898026\n",
      "Epoch: 20, Loss: 0.00017639959696680307\n",
      "Epoch: 21, Loss: 0.0001441301719751209\n",
      "Epoch: 22, Loss: 0.00018144819478038698\n",
      "Epoch: 23, Loss: 0.00021719934011343867\n",
      "Epoch: 24, Loss: 0.0002392195601714775\n",
      "Epoch: 25, Loss: 0.0002707343373913318\n",
      "Epoch: 26, Loss: 0.0002715609152801335\n",
      "Epoch: 27, Loss: 0.00024700540234334767\n",
      "Epoch: 28, Loss: 0.00019064777006860822\n",
      "Epoch: 29, Loss: 8.767849067226052e-05\n",
      "Epoch: 30, Loss: 4.4510463339975104e-05\n",
      "Epoch: 31, Loss: 7.104768883436918e-05\n",
      "Epoch: 32, Loss: 9.846820466918871e-05\n",
      "Epoch: 33, Loss: 0.0001538528158562258\n",
      "Epoch: 34, Loss: 0.000170197818079032\n",
      "Epoch: 35, Loss: 0.00013624739949591458\n",
      "Epoch: 36, Loss: 9.033622336573899e-05\n",
      "Epoch: 37, Loss: 4.150831591687165e-05\n",
      "Epoch: 38, Loss: 2.372169547015801e-05\n",
      "Epoch: 39, Loss: 3.9779391954652965e-05\n",
      "Epoch: 40, Loss: 6.817153916927055e-05\n",
      "Epoch: 41, Loss: 9.503527689957991e-05\n",
      "Epoch: 42, Loss: 0.00012336851796135306\n",
      "Epoch: 43, Loss: 0.00013143183605279773\n",
      "Epoch: 44, Loss: 0.0001133511759690009\n",
      "Epoch: 45, Loss: 8.69383366080001e-05\n",
      "Epoch: 46, Loss: 5.318355397321284e-05\n",
      "Epoch: 47, Loss: 2.073879113595467e-05\n",
      "Epoch: 48, Loss: 9.039520591613837e-06\n",
      "Epoch: 49, Loss: 1.2840401723224204e-05\n",
      "Epoch: 50, Loss: 2.2123578673927113e-05\n",
      "________________________________________\n",
      "epoch 18 tensor([ 0.5213, -1.8725, -0.5669, -0.5363,  0.3784], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.005476708989590406\n",
      "Epoch: 2, Loss: 0.00394542096182704\n",
      "Epoch: 3, Loss: 0.003586590988561511\n",
      "Epoch: 4, Loss: 0.0028503129724413157\n",
      "Epoch: 5, Loss: 0.002052968367934227\n",
      "Epoch: 6, Loss: 0.0020943242125213146\n",
      "Epoch: 7, Loss: 0.001935840817168355\n",
      "Epoch: 8, Loss: 0.0009247296256944537\n",
      "Epoch: 9, Loss: 0.0018232950242236257\n",
      "Epoch: 10, Loss: 0.0010858515743166208\n",
      "Epoch: 11, Loss: 0.0011964647565037012\n",
      "Epoch: 12, Loss: 0.0012826009187847376\n",
      "Epoch: 13, Loss: 0.0012002052972093225\n",
      "Epoch: 14, Loss: 0.0009876330150291324\n",
      "Epoch: 15, Loss: 0.000669047178234905\n",
      "Epoch: 16, Loss: 0.0009628218249417841\n",
      "Epoch: 17, Loss: 0.0003268126747570932\n",
      "Epoch: 18, Loss: 0.0005752368597313762\n",
      "Epoch: 19, Loss: 0.000517212669365108\n",
      "Epoch: 20, Loss: 0.0004055826866533607\n",
      "Epoch: 21, Loss: 0.00045977215631864965\n",
      "Epoch: 22, Loss: 0.0003705318958964199\n",
      "Epoch: 23, Loss: 0.00040839408757165074\n",
      "Epoch: 24, Loss: 0.00021579081658273935\n",
      "Epoch: 25, Loss: 0.0003325722354929894\n",
      "Epoch: 26, Loss: 0.00023974299256224185\n",
      "Epoch: 27, Loss: 0.00022503263608086854\n",
      "Epoch: 28, Loss: 0.0002170542284147814\n",
      "Epoch: 29, Loss: 0.00018475280376151204\n",
      "Epoch: 30, Loss: 0.00020178053819108754\n",
      "Epoch: 31, Loss: 0.00011274872667854652\n",
      "Epoch: 32, Loss: 0.00018392082711216062\n",
      "Epoch: 33, Loss: 0.00012823304859921336\n",
      "Epoch: 34, Loss: 0.0001634106447454542\n",
      "Epoch: 35, Loss: 9.123492782237008e-05\n",
      "Epoch: 36, Loss: 0.00010362456669099629\n",
      "Epoch: 37, Loss: 8.317941683344543e-05\n",
      "Epoch: 38, Loss: 7.264113082783297e-05\n",
      "Epoch: 39, Loss: 6.313807534752414e-05\n",
      "Epoch: 40, Loss: 5.276572846923955e-05\n",
      "Epoch: 41, Loss: 7.152382750064135e-05\n",
      "Epoch: 42, Loss: 5.4356878536054865e-05\n",
      "Epoch: 43, Loss: 5.48058669664897e-05\n",
      "Epoch: 44, Loss: 3.489931987132877e-05\n",
      "Epoch: 45, Loss: 5.485864676302299e-05\n",
      "Epoch: 46, Loss: 2.8755792300216854e-05\n",
      "Epoch: 47, Loss: 4.015309605165385e-05\n",
      "Epoch: 48, Loss: 2.274608050356619e-05\n",
      "Epoch: 49, Loss: 2.6986310331267305e-05\n",
      "Epoch: 50, Loss: 1.2515766684373375e-05\n",
      "epoch 18 tensor([ 0.4773, -1.8907, -0.4823, -0.5420,  0.3691], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.009734518826007843\n",
      "Epoch: 2, Loss: 0.0071863229386508465\n",
      "Epoch: 3, Loss: 0.003984578885138035\n",
      "Epoch: 4, Loss: 0.0026339187752455473\n",
      "Epoch: 5, Loss: 0.0021099746227264404\n",
      "Epoch: 6, Loss: 0.0031988173723220825\n",
      "Epoch: 7, Loss: 0.002228484721854329\n",
      "Epoch: 8, Loss: 0.003218224737793207\n",
      "Epoch: 9, Loss: 0.0026640736032277346\n",
      "Epoch: 10, Loss: 0.0020828768610954285\n",
      "Epoch: 11, Loss: 0.0020068108569830656\n",
      "Epoch: 12, Loss: 0.0014880304224789143\n",
      "Epoch: 13, Loss: 0.0010701512219384313\n",
      "Epoch: 14, Loss: 0.0012870421633124352\n",
      "Epoch: 15, Loss: 0.0011474041966721416\n",
      "Epoch: 16, Loss: 0.0010936650214716792\n",
      "Epoch: 17, Loss: 0.001159475650638342\n",
      "Epoch: 18, Loss: 0.0011041357647627592\n",
      "Epoch: 19, Loss: 0.0006152833811938763\n",
      "Epoch: 20, Loss: 0.0007697310065850616\n",
      "Epoch: 21, Loss: 0.0005037239752709866\n",
      "Epoch: 22, Loss: 0.0005177544662728906\n",
      "Epoch: 23, Loss: 0.0005811235751025379\n",
      "Epoch: 24, Loss: 0.0005059723043814301\n",
      "Epoch: 25, Loss: 0.00036412582267075777\n",
      "Epoch: 26, Loss: 0.0004052415897604078\n",
      "Epoch: 27, Loss: 0.00027536717243492603\n",
      "Epoch: 28, Loss: 0.00029773643473163247\n",
      "Epoch: 29, Loss: 0.000317056110361591\n",
      "Epoch: 30, Loss: 0.00025637945509515703\n",
      "Epoch: 31, Loss: 0.0002850437886081636\n",
      "Epoch: 32, Loss: 0.0002436526701785624\n",
      "Epoch: 33, Loss: 0.00015661318320780993\n",
      "Epoch: 34, Loss: 0.00017111650959122926\n",
      "Epoch: 35, Loss: 0.0001240109995706007\n",
      "Epoch: 36, Loss: 0.0001181175684905611\n",
      "Epoch: 37, Loss: 0.00014644836483057588\n",
      "Epoch: 38, Loss: 0.00011855879711220041\n",
      "Epoch: 39, Loss: 0.00011652852117549628\n",
      "Epoch: 40, Loss: 0.00011230829113628715\n",
      "Epoch: 41, Loss: 6.784286961192265e-05\n",
      "Epoch: 42, Loss: 6.895997648825869e-05\n",
      "Epoch: 43, Loss: 5.544477971852757e-05\n",
      "Epoch: 44, Loss: 5.6495478929718956e-05\n",
      "Epoch: 45, Loss: 6.540160393342376e-05\n",
      "Epoch: 46, Loss: 6.134824070613831e-05\n",
      "Epoch: 47, Loss: 5.4765059758210555e-05\n",
      "Epoch: 48, Loss: 5.682820119545795e-05\n",
      "Epoch: 49, Loss: 3.95003444282338e-05\n",
      "Epoch: 50, Loss: 7.78907269705087e-05\n",
      "epoch 18 tensor([ 0.4820, -1.8696, -0.4466, -0.5176,  0.4189], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0036892590578645468\n",
      "Epoch: 2, Loss: 0.0027313383761793375\n",
      "Epoch: 3, Loss: 0.0018347841687500477\n",
      "Epoch: 4, Loss: 0.0016597321955487132\n",
      "Epoch: 5, Loss: 0.0019526469986885786\n",
      "Epoch: 6, Loss: 0.001586238038726151\n",
      "Epoch: 7, Loss: 0.0015776404179632664\n",
      "Epoch: 8, Loss: 0.0011370008578523993\n",
      "Epoch: 9, Loss: 0.001005054684355855\n",
      "Epoch: 10, Loss: 0.0011711048427969217\n",
      "Epoch: 11, Loss: 0.0011826399713754654\n",
      "Epoch: 12, Loss: 0.0007658008253201842\n",
      "Epoch: 13, Loss: 0.0007803242187947035\n",
      "Epoch: 14, Loss: 0.0004339037404861301\n",
      "Epoch: 15, Loss: 0.000574777543079108\n",
      "Epoch: 16, Loss: 0.0005119382403790951\n",
      "Epoch: 17, Loss: 0.00040135422023013234\n",
      "Epoch: 18, Loss: 0.0003494023985695094\n",
      "Epoch: 19, Loss: 0.0003190964926034212\n",
      "Epoch: 20, Loss: 0.0004277311381883919\n",
      "Epoch: 21, Loss: 0.00025477263261564076\n",
      "Epoch: 22, Loss: 0.0003072309191338718\n",
      "Epoch: 23, Loss: 0.00021205577650107443\n",
      "Epoch: 24, Loss: 0.00023385319218505174\n",
      "Epoch: 25, Loss: 0.00023874116595834494\n",
      "Epoch: 26, Loss: 0.00015812041237950325\n",
      "Epoch: 27, Loss: 0.00016147777205333114\n",
      "Epoch: 28, Loss: 0.0001494344905950129\n",
      "Epoch: 29, Loss: 0.00015123591583687812\n",
      "Epoch: 30, Loss: 0.0001205097432830371\n",
      "Epoch: 31, Loss: 0.00011373087909305468\n",
      "Epoch: 32, Loss: 7.066340185701847e-05\n",
      "Epoch: 33, Loss: 0.00010022320930147544\n",
      "Epoch: 34, Loss: 8.477939263684675e-05\n",
      "Epoch: 35, Loss: 0.00012006627366645262\n",
      "Epoch: 36, Loss: 9.176763705909252e-05\n",
      "Epoch: 37, Loss: 6.732734618708491e-05\n",
      "Epoch: 38, Loss: 6.318304076557979e-05\n",
      "Epoch: 39, Loss: 5.403744580689818e-05\n",
      "Epoch: 40, Loss: 4.113881732337177e-05\n",
      "Epoch: 41, Loss: 4.3827705667354167e-05\n",
      "Epoch: 42, Loss: 5.1744646043516695e-05\n",
      "Epoch: 43, Loss: 4.949250796926208e-05\n",
      "Epoch: 44, Loss: 6.65456973365508e-05\n",
      "Epoch: 45, Loss: 8.073672506725416e-05\n",
      "Epoch: 46, Loss: 0.00011778788029914722\n",
      "Epoch: 47, Loss: 0.00017743976786732674\n",
      "Epoch: 48, Loss: 0.0002540028071962297\n",
      "Epoch: 49, Loss: 0.0003108402597717941\n",
      "Epoch: 50, Loss: 0.00031277386005967855\n",
      "epoch 18 tensor([ 0.4956, -1.8936, -0.4953, -0.5257,  0.3821], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0027911595534533262\n",
      "Epoch: 2, Loss: 0.0014186936896294355\n",
      "Epoch: 3, Loss: 0.001086734700948\n",
      "Epoch: 4, Loss: 0.0010462505742907524\n",
      "Epoch: 5, Loss: 0.0008535411907359958\n",
      "Epoch: 6, Loss: 0.0009815230732783675\n",
      "Epoch: 7, Loss: 0.0010988683206960559\n",
      "Epoch: 8, Loss: 0.0006561121554113925\n",
      "Epoch: 9, Loss: 0.0005066310986876488\n",
      "Epoch: 10, Loss: 0.0005278958124108613\n",
      "Epoch: 11, Loss: 0.0006252508028410375\n",
      "Epoch: 12, Loss: 0.000572800578083843\n",
      "Epoch: 13, Loss: 0.0004416937008500099\n",
      "Epoch: 14, Loss: 0.0003878807765431702\n",
      "Epoch: 15, Loss: 0.00023814832093194127\n",
      "Epoch: 16, Loss: 0.0003293288464192301\n",
      "Epoch: 17, Loss: 0.0003355886146891862\n",
      "Epoch: 18, Loss: 0.00031611110898666084\n",
      "Epoch: 19, Loss: 0.0002746240352280438\n",
      "Epoch: 20, Loss: 0.00024165659851860255\n",
      "Epoch: 21, Loss: 0.0001952207530848682\n",
      "Epoch: 22, Loss: 9.738960943650454e-05\n",
      "Epoch: 23, Loss: 0.00013694116205442697\n",
      "Epoch: 24, Loss: 0.00019660247198771685\n",
      "Epoch: 25, Loss: 0.00017765798838809133\n",
      "Epoch: 26, Loss: 0.00012124257773393765\n",
      "Epoch: 27, Loss: 0.00011905359860975295\n",
      "Epoch: 28, Loss: 7.145845302147791e-05\n",
      "Epoch: 29, Loss: 8.35104365251027e-05\n",
      "Epoch: 30, Loss: 0.00010528275015531108\n",
      "Epoch: 31, Loss: 9.451806545257568e-05\n",
      "Epoch: 32, Loss: 6.482017488451675e-05\n",
      "Epoch: 33, Loss: 5.901811528019607e-05\n",
      "Epoch: 34, Loss: 5.842097743880004e-05\n",
      "Epoch: 35, Loss: 6.254371692193672e-05\n",
      "Epoch: 36, Loss: 5.7988356275018305e-05\n",
      "Epoch: 37, Loss: 4.5442659029504284e-05\n",
      "Epoch: 38, Loss: 2.8459679015213624e-05\n",
      "Epoch: 39, Loss: 2.2978394554229453e-05\n",
      "Epoch: 40, Loss: 3.02367152471561e-05\n",
      "Epoch: 41, Loss: 3.10125105897896e-05\n",
      "Epoch: 42, Loss: 2.8092075808672234e-05\n",
      "Epoch: 43, Loss: 3.067444413318299e-05\n",
      "Epoch: 44, Loss: 4.261960202711634e-05\n",
      "Epoch: 45, Loss: 8.624292240710929e-05\n",
      "Epoch: 46, Loss: 0.00020706614304799587\n",
      "Epoch: 47, Loss: 0.00048750382848083973\n",
      "Epoch: 48, Loss: 0.0009097031434066594\n",
      "Epoch: 49, Loss: 0.0009593312279321253\n",
      "Epoch: 50, Loss: 0.0002887409646064043\n",
      "epoch 18 tensor([ 0.5013, -1.8998, -0.5032, -0.5693,  0.4236], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0014757676981389523\n",
      "Epoch: 2, Loss: 0.0012583456700667739\n",
      "Epoch: 3, Loss: 0.0009227373520843685\n",
      "Epoch: 4, Loss: 0.0008123900624923408\n",
      "Epoch: 5, Loss: 0.0014483946142718196\n",
      "Epoch: 6, Loss: 0.0022830963134765625\n",
      "Epoch: 7, Loss: 0.0013940635835751891\n",
      "Epoch: 8, Loss: 0.0007709279889240861\n",
      "Epoch: 9, Loss: 0.0014406975824385881\n",
      "Epoch: 10, Loss: 0.0007037968025542796\n",
      "Epoch: 11, Loss: 0.001058138906955719\n",
      "Epoch: 12, Loss: 0.0007227866444736719\n",
      "Epoch: 13, Loss: 0.0007650710176676512\n",
      "Epoch: 14, Loss: 0.0007264707237482071\n",
      "Epoch: 15, Loss: 0.0004957625642418861\n",
      "Epoch: 16, Loss: 0.0006622151122428477\n",
      "Epoch: 17, Loss: 0.00027485095779411495\n",
      "Epoch: 18, Loss: 0.0005837351200170815\n",
      "Epoch: 19, Loss: 0.0002018953673541546\n",
      "Epoch: 20, Loss: 0.0004540513036772609\n",
      "Epoch: 21, Loss: 0.00019405620696488768\n",
      "Epoch: 22, Loss: 0.00033835365320555866\n",
      "Epoch: 23, Loss: 0.00024696861510165036\n",
      "Epoch: 24, Loss: 0.00020769782713614404\n",
      "Epoch: 25, Loss: 0.00027132383547723293\n",
      "Epoch: 26, Loss: 9.588434477336705e-05\n",
      "Epoch: 27, Loss: 0.0002635164128150791\n",
      "Epoch: 28, Loss: 6.63489627186209e-05\n",
      "Epoch: 29, Loss: 0.00020502327242866158\n",
      "Epoch: 30, Loss: 0.00010179065429838374\n",
      "Epoch: 31, Loss: 0.000110677006887272\n",
      "Epoch: 32, Loss: 0.0001322799944318831\n",
      "Epoch: 33, Loss: 3.966079020756297e-05\n",
      "Epoch: 34, Loss: 0.00015741254901513457\n",
      "Epoch: 35, Loss: 2.9830736821168102e-05\n",
      "Epoch: 36, Loss: 0.00010048745025414973\n",
      "Epoch: 37, Loss: 5.684268762706779e-05\n",
      "Epoch: 38, Loss: 4.0337155951419845e-05\n",
      "Epoch: 39, Loss: 8.25949537102133e-05\n",
      "Epoch: 40, Loss: 1.1183891729160678e-05\n",
      "Epoch: 41, Loss: 6.626387039432302e-05\n",
      "Epoch: 42, Loss: 3.49400652339682e-05\n",
      "Epoch: 43, Loss: 2.975105780933518e-05\n",
      "Epoch: 44, Loss: 5.2773513743886724e-05\n",
      "Epoch: 45, Loss: 1.698332380328793e-05\n",
      "Epoch: 46, Loss: 3.639069109340198e-05\n",
      "Epoch: 47, Loss: 2.8155727704870515e-05\n",
      "Epoch: 48, Loss: 1.1516111044329591e-05\n",
      "Epoch: 49, Loss: 3.1548941478831694e-05\n",
      "Epoch: 50, Loss: 1.4408070455829147e-05\n",
      "epoch 18 tensor([ 0.4785, -1.8620, -0.5746, -0.5371,  0.4196], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0034627874847501516\n",
      "Epoch: 2, Loss: 0.0020412644371390343\n",
      "Epoch: 3, Loss: 0.0013124407269060612\n",
      "Epoch: 4, Loss: 0.0015295116463676095\n",
      "Epoch: 5, Loss: 0.001276616589166224\n",
      "Epoch: 6, Loss: 0.0009567576926201582\n",
      "Epoch: 7, Loss: 0.000931119080632925\n",
      "Epoch: 8, Loss: 0.0006467489874921739\n",
      "Epoch: 9, Loss: 0.0007292652153410017\n",
      "Epoch: 10, Loss: 0.0004113774630241096\n",
      "Epoch: 11, Loss: 0.0004493954766076058\n",
      "Epoch: 12, Loss: 0.0004907388356514275\n",
      "Epoch: 13, Loss: 0.00044715777039527893\n",
      "Epoch: 14, Loss: 0.00046009846846573055\n",
      "Epoch: 15, Loss: 0.00023921282263472676\n",
      "Epoch: 16, Loss: 0.000385388353606686\n",
      "Epoch: 17, Loss: 0.0003125809598714113\n",
      "Epoch: 18, Loss: 0.00035162712447345257\n",
      "Epoch: 19, Loss: 0.0002301501081092283\n",
      "Epoch: 20, Loss: 0.00025422245380468667\n",
      "Epoch: 21, Loss: 0.00021756868227384984\n",
      "Epoch: 22, Loss: 0.0001392905251123011\n",
      "Epoch: 23, Loss: 0.0002067612367682159\n",
      "Epoch: 24, Loss: 0.00014568568440154195\n",
      "Epoch: 25, Loss: 0.0001779225713107735\n",
      "Epoch: 26, Loss: 9.05968772713095e-05\n",
      "Epoch: 27, Loss: 0.00012727831199299544\n",
      "Epoch: 28, Loss: 8.114636148093268e-05\n",
      "Epoch: 29, Loss: 0.00011682702461257577\n",
      "Epoch: 30, Loss: 7.769998774165288e-05\n",
      "Epoch: 31, Loss: 6.798592221457511e-05\n",
      "Epoch: 32, Loss: 5.540083657251671e-05\n",
      "Epoch: 33, Loss: 6.0691741964546964e-05\n",
      "Epoch: 34, Loss: 6.133383431006223e-05\n",
      "Epoch: 35, Loss: 5.0684120651567355e-05\n",
      "Epoch: 36, Loss: 4.973005343344994e-05\n",
      "Epoch: 37, Loss: 3.05298381135799e-05\n",
      "Epoch: 38, Loss: 3.443003515712917e-05\n",
      "Epoch: 39, Loss: 2.6089730454259552e-05\n",
      "Epoch: 40, Loss: 3.956434011342935e-05\n",
      "Epoch: 41, Loss: 2.9372960852924734e-05\n",
      "Epoch: 42, Loss: 4.5607401261804625e-05\n",
      "Epoch: 43, Loss: 3.4390373912174255e-05\n",
      "Epoch: 44, Loss: 4.8513607907807454e-05\n",
      "Epoch: 45, Loss: 4.417063610162586e-05\n",
      "Epoch: 46, Loss: 5.8218847698299214e-05\n",
      "Epoch: 47, Loss: 6.182083598105237e-05\n",
      "Epoch: 48, Loss: 8.65667752805166e-05\n",
      "Epoch: 49, Loss: 0.00011201572488062084\n",
      "Epoch: 50, Loss: 0.00015783656272105873\n",
      "epoch 18 tensor([ 0.5186, -1.8573, -0.5142, -0.5950,  0.4234], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.007866157218813896\n",
      "Epoch: 2, Loss: 0.004739170894026756\n",
      "Epoch: 3, Loss: 0.004771137144416571\n",
      "Epoch: 4, Loss: 0.005213616881519556\n",
      "Epoch: 5, Loss: 0.002122099744156003\n",
      "Epoch: 6, Loss: 0.004004098474979401\n",
      "Epoch: 7, Loss: 0.002476651221513748\n",
      "Epoch: 8, Loss: 0.0024786600843071938\n",
      "Epoch: 9, Loss: 0.0023138136602938175\n",
      "Epoch: 10, Loss: 0.001828083535656333\n",
      "Epoch: 11, Loss: 0.001625793520361185\n",
      "Epoch: 12, Loss: 0.0014734342694282532\n",
      "Epoch: 13, Loss: 0.0017781862989068031\n",
      "Epoch: 14, Loss: 0.0017680185846984386\n",
      "Epoch: 15, Loss: 0.0010441755875945091\n",
      "Epoch: 16, Loss: 0.001008521649055183\n",
      "Epoch: 17, Loss: 0.0006160852499306202\n",
      "Epoch: 18, Loss: 0.000856575439684093\n",
      "Epoch: 19, Loss: 0.0005390428123064339\n",
      "Epoch: 20, Loss: 0.0006400416023097932\n",
      "Epoch: 21, Loss: 0.0005909471656195819\n",
      "Epoch: 22, Loss: 0.0006604584050364792\n",
      "Epoch: 23, Loss: 0.0005892057088203728\n",
      "Epoch: 24, Loss: 0.0005050493637099862\n",
      "Epoch: 25, Loss: 0.0004759673320222646\n",
      "Epoch: 26, Loss: 0.0003524661296978593\n",
      "Epoch: 27, Loss: 0.0003920641902368516\n",
      "Epoch: 28, Loss: 0.0003511106187943369\n",
      "Epoch: 29, Loss: 0.0002627406211104244\n",
      "Epoch: 30, Loss: 0.00017706010839901865\n",
      "Epoch: 31, Loss: 0.0001878746843431145\n",
      "Epoch: 32, Loss: 0.00024744312395341694\n",
      "Epoch: 33, Loss: 0.0001811936526792124\n",
      "Epoch: 34, Loss: 0.00013245391892269254\n",
      "Epoch: 35, Loss: 0.0001705074537312612\n",
      "Epoch: 36, Loss: 0.00012463383609429002\n",
      "Epoch: 37, Loss: 0.0001730598451104015\n",
      "Epoch: 38, Loss: 0.00011462604015832767\n",
      "Epoch: 39, Loss: 0.00011032513430109248\n",
      "Epoch: 40, Loss: 6.114398274803534e-05\n",
      "Epoch: 41, Loss: 6.781749107176438e-05\n",
      "Epoch: 42, Loss: 7.336398266488686e-05\n",
      "Epoch: 43, Loss: 5.7135704992106184e-05\n",
      "Epoch: 44, Loss: 6.639504135819152e-05\n",
      "Epoch: 45, Loss: 6.551895057782531e-05\n",
      "Epoch: 46, Loss: 6.719917291775346e-05\n",
      "Epoch: 47, Loss: 3.7707399314967915e-05\n",
      "Epoch: 48, Loss: 4.6557586756534874e-05\n",
      "Epoch: 49, Loss: 3.784082946367562e-05\n",
      "Epoch: 50, Loss: 4.276746403775178e-05\n",
      "epoch 18 tensor([ 0.4799, -1.8349, -0.5027, -0.5905,  0.4001], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0034956890158355236\n",
      "Epoch: 2, Loss: 0.002200225368142128\n",
      "Epoch: 3, Loss: 0.0014680633321404457\n",
      "Epoch: 4, Loss: 0.0014978066319599748\n",
      "Epoch: 5, Loss: 0.001214350457303226\n",
      "Epoch: 6, Loss: 0.0009916649432852864\n",
      "Epoch: 7, Loss: 0.0008495295769535005\n",
      "Epoch: 8, Loss: 0.0007183907437138259\n",
      "Epoch: 9, Loss: 0.000594146316871047\n",
      "Epoch: 10, Loss: 0.0006337474333122373\n",
      "Epoch: 11, Loss: 0.0006796400994062424\n",
      "Epoch: 12, Loss: 0.0006222112569957972\n",
      "Epoch: 13, Loss: 0.0005623573088087142\n",
      "Epoch: 14, Loss: 0.0005165403708815575\n",
      "Epoch: 15, Loss: 0.0003482363827060908\n",
      "Epoch: 16, Loss: 0.0002806851698551327\n",
      "Epoch: 17, Loss: 0.00029661523876711726\n",
      "Epoch: 18, Loss: 0.0004042339278385043\n",
      "Epoch: 19, Loss: 0.0003860813449136913\n",
      "Epoch: 20, Loss: 0.00028510455740615726\n",
      "Epoch: 21, Loss: 0.00021496329281944782\n",
      "Epoch: 22, Loss: 0.00019771877850871533\n",
      "Epoch: 23, Loss: 0.000192842329852283\n",
      "Epoch: 24, Loss: 0.0001955448678927496\n",
      "Epoch: 25, Loss: 0.00017667427891865373\n",
      "Epoch: 26, Loss: 0.0001364229101454839\n",
      "Epoch: 27, Loss: 0.00014192576054483652\n",
      "Epoch: 28, Loss: 0.00014070153702050447\n",
      "Epoch: 29, Loss: 0.0001440911291865632\n",
      "Epoch: 30, Loss: 0.00013311454677022994\n",
      "Epoch: 31, Loss: 0.0001327701029367745\n",
      "Epoch: 32, Loss: 0.00014485351857729256\n",
      "Epoch: 33, Loss: 0.00013724120799452066\n",
      "Epoch: 34, Loss: 0.0001497105840826407\n",
      "Epoch: 35, Loss: 0.00016675402002874762\n",
      "Epoch: 36, Loss: 0.00016614634660072625\n",
      "Epoch: 37, Loss: 0.0001301349257119\n",
      "Epoch: 38, Loss: 9.982714254874736e-05\n",
      "Epoch: 39, Loss: 0.00010033202124759555\n",
      "Epoch: 40, Loss: 0.00010083562665386125\n",
      "Epoch: 41, Loss: 9.790790500119328e-05\n",
      "Epoch: 42, Loss: 8.50936776259914e-05\n",
      "Epoch: 43, Loss: 6.84723854647018e-05\n",
      "Epoch: 44, Loss: 4.941047154716216e-05\n",
      "Epoch: 45, Loss: 3.4111035347450525e-05\n",
      "Epoch: 46, Loss: 2.627532376209274e-05\n",
      "Epoch: 47, Loss: 2.1588024537777528e-05\n",
      "Epoch: 48, Loss: 2.6728765078587458e-05\n",
      "Epoch: 49, Loss: 4.0974638977786526e-05\n",
      "Epoch: 50, Loss: 6.312339246505871e-05\n",
      "epoch 18 tensor([ 0.5114, -1.8299, -0.4697, -0.6214,  0.4864], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0010470105335116386\n",
      "Epoch: 2, Loss: 0.0008859697263687849\n",
      "Epoch: 3, Loss: 0.0008851731545291841\n",
      "Epoch: 4, Loss: 0.0005238674348220229\n",
      "Epoch: 5, Loss: 0.0005375239998102188\n",
      "Epoch: 6, Loss: 0.0004939876380376518\n",
      "Epoch: 7, Loss: 0.0004613698401954025\n",
      "Epoch: 8, Loss: 0.0004359236336313188\n",
      "Epoch: 9, Loss: 0.0002580998698249459\n",
      "Epoch: 10, Loss: 0.00038001875509507954\n",
      "Epoch: 11, Loss: 0.0002558237174525857\n",
      "Epoch: 12, Loss: 0.0001354592968709767\n",
      "Epoch: 13, Loss: 0.00030103002791292965\n",
      "Epoch: 14, Loss: 0.00018417644605506212\n",
      "Epoch: 15, Loss: 0.00014466718130279332\n",
      "Epoch: 16, Loss: 0.0001845107035478577\n",
      "Epoch: 17, Loss: 0.00013351354573387653\n",
      "Epoch: 18, Loss: 0.000184561125934124\n",
      "Epoch: 19, Loss: 0.0001291892840526998\n",
      "Epoch: 20, Loss: 0.0001204822983709164\n",
      "Epoch: 21, Loss: 0.00015953188994899392\n",
      "Epoch: 22, Loss: 6.95859853294678e-05\n",
      "Epoch: 23, Loss: 9.199278429150581e-05\n",
      "Epoch: 24, Loss: 0.00010286671749781817\n",
      "Epoch: 25, Loss: 5.778836930403486e-05\n",
      "Epoch: 26, Loss: 8.079504914348945e-05\n",
      "Epoch: 27, Loss: 6.755442154826596e-05\n",
      "Epoch: 28, Loss: 6.071784446248785e-05\n",
      "Epoch: 29, Loss: 6.729347660439089e-05\n",
      "Epoch: 30, Loss: 5.859144584974274e-05\n",
      "Epoch: 31, Loss: 8.837257337290794e-05\n",
      "Epoch: 32, Loss: 0.00019037970923818648\n",
      "Epoch: 33, Loss: 0.00043241382809355855\n",
      "Epoch: 34, Loss: 0.0008008217555470765\n",
      "Epoch: 35, Loss: 0.0009104598429985344\n",
      "Epoch: 36, Loss: 0.00032307286164723337\n",
      "Epoch: 37, Loss: 3.6986442864872515e-05\n",
      "Epoch: 38, Loss: 0.00047874468145892024\n",
      "Epoch: 39, Loss: 0.0004696698160842061\n",
      "Epoch: 40, Loss: 6.347525049932301e-05\n",
      "Epoch: 41, Loss: 0.00021258907509036362\n",
      "Epoch: 42, Loss: 0.0003574875299818814\n",
      "Epoch: 43, Loss: 0.00011200940934941173\n",
      "Epoch: 44, Loss: 0.00012894943938590586\n",
      "Epoch: 45, Loss: 0.0002514167863409966\n",
      "Epoch: 46, Loss: 9.991319529945031e-05\n",
      "Epoch: 47, Loss: 8.822033123578876e-05\n",
      "Epoch: 48, Loss: 0.00019946639076806605\n",
      "Epoch: 49, Loss: 7.677891699131578e-05\n",
      "Epoch: 50, Loss: 3.9671500417171046e-05\n",
      "epoch 18 tensor([ 0.5067, -1.8581, -0.4940, -0.6036,  0.4578], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0014149014605209231\n",
      "Epoch: 2, Loss: 0.001276068389415741\n",
      "Epoch: 3, Loss: 0.00140099017880857\n",
      "Epoch: 4, Loss: 0.0009505810448899865\n",
      "Epoch: 5, Loss: 0.0006790547631680965\n",
      "Epoch: 6, Loss: 0.0013020755723118782\n",
      "Epoch: 7, Loss: 0.0008633086690679193\n",
      "Epoch: 8, Loss: 0.00034668255830183625\n",
      "Epoch: 9, Loss: 0.0007167964358814061\n",
      "Epoch: 10, Loss: 0.0007305184844881296\n",
      "Epoch: 11, Loss: 0.00041697995038703084\n",
      "Epoch: 12, Loss: 0.0006444719620049\n",
      "Epoch: 13, Loss: 0.00038999144453555346\n",
      "Epoch: 14, Loss: 0.000417637376813218\n",
      "Epoch: 15, Loss: 0.00042404435225762427\n",
      "Epoch: 16, Loss: 0.00019087477994617075\n",
      "Epoch: 17, Loss: 0.00033256440656259656\n",
      "Epoch: 18, Loss: 0.000281872577033937\n",
      "Epoch: 19, Loss: 9.916426643030718e-05\n",
      "Epoch: 20, Loss: 0.0002816241467371583\n",
      "Epoch: 21, Loss: 0.0001823020720621571\n",
      "Epoch: 22, Loss: 0.000154011431732215\n",
      "Epoch: 23, Loss: 0.00018681504298001528\n",
      "Epoch: 24, Loss: 0.00012459600111469626\n",
      "Epoch: 25, Loss: 0.00013299283455125988\n",
      "Epoch: 26, Loss: 0.0001444092340534553\n",
      "Epoch: 27, Loss: 6.598800246138126e-05\n",
      "Epoch: 28, Loss: 9.706819400889799e-05\n",
      "Epoch: 29, Loss: 0.00010938915511360392\n",
      "Epoch: 30, Loss: 4.0672646719031036e-05\n",
      "Epoch: 31, Loss: 8.713138959137723e-05\n",
      "Epoch: 32, Loss: 7.13534900569357e-05\n",
      "Epoch: 33, Loss: 4.956185512128286e-05\n",
      "Epoch: 34, Loss: 7.06070932210423e-05\n",
      "Epoch: 35, Loss: 6.608491821680218e-05\n",
      "Epoch: 36, Loss: 2.3097138182492927e-05\n",
      "Epoch: 37, Loss: 3.3760796213755384e-05\n",
      "Epoch: 38, Loss: 4.8034198698587716e-05\n",
      "Epoch: 39, Loss: 2.69779975496931e-05\n",
      "Epoch: 40, Loss: 3.245827610953711e-05\n",
      "Epoch: 41, Loss: 4.54442051704973e-05\n",
      "Epoch: 42, Loss: 3.786407251027413e-05\n",
      "Epoch: 43, Loss: 1.398657877871301e-05\n",
      "Epoch: 44, Loss: 2.3243061150424182e-05\n",
      "Epoch: 45, Loss: 2.7268892154097557e-05\n",
      "Epoch: 46, Loss: 1.2410791896400042e-05\n",
      "Epoch: 47, Loss: 9.970875908038579e-06\n",
      "Epoch: 48, Loss: 1.3002864761801902e-05\n",
      "Epoch: 49, Loss: 1.8801198166329414e-05\n",
      "Epoch: 50, Loss: 1.3784087059320882e-05\n",
      "________________________________________\n",
      "epoch 19 tensor([ 0.4804, -1.8499, -0.5121, -0.5208,  0.4169], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.007102103438228369\n",
      "Epoch: 2, Loss: 0.004455761518329382\n",
      "Epoch: 3, Loss: 0.0031981763895601034\n",
      "Epoch: 4, Loss: 0.0019316476536914706\n",
      "Epoch: 5, Loss: 0.0023809317499399185\n",
      "Epoch: 6, Loss: 0.001956560183316469\n",
      "Epoch: 7, Loss: 0.0018356345826759934\n",
      "Epoch: 8, Loss: 0.0013785646297037601\n",
      "Epoch: 9, Loss: 0.0012657928746193647\n",
      "Epoch: 10, Loss: 0.0014118311228230596\n",
      "Epoch: 11, Loss: 0.001300577074289322\n",
      "Epoch: 12, Loss: 0.000986398314125836\n",
      "Epoch: 13, Loss: 0.0008847454446367919\n",
      "Epoch: 14, Loss: 0.000812832557130605\n",
      "Epoch: 15, Loss: 0.0007739795837551355\n",
      "Epoch: 16, Loss: 0.0006997553864493966\n",
      "Epoch: 17, Loss: 0.0005979437264613807\n",
      "Epoch: 18, Loss: 0.0005704064969904721\n",
      "Epoch: 19, Loss: 0.00047386810183525085\n",
      "Epoch: 20, Loss: 0.0004212707281112671\n",
      "Epoch: 21, Loss: 0.00042944212327711284\n",
      "Epoch: 22, Loss: 0.0003518264275044203\n",
      "Epoch: 23, Loss: 0.00027679026243276894\n",
      "Epoch: 24, Loss: 0.0003087781078647822\n",
      "Epoch: 25, Loss: 0.00022817897843196988\n",
      "Epoch: 26, Loss: 0.00025393030955456197\n",
      "Epoch: 27, Loss: 0.0002426912251394242\n",
      "Epoch: 28, Loss: 0.00017333548748865724\n",
      "Epoch: 29, Loss: 0.00014454248594120145\n",
      "Epoch: 30, Loss: 0.00016601549577899277\n",
      "Epoch: 31, Loss: 0.00014994278899393976\n",
      "Epoch: 32, Loss: 0.00013420214236248285\n",
      "Epoch: 33, Loss: 9.571548434905708e-05\n",
      "Epoch: 34, Loss: 9.060947195393965e-05\n",
      "Epoch: 35, Loss: 0.00010238050163025036\n",
      "Epoch: 36, Loss: 0.00011378683848306537\n",
      "Epoch: 37, Loss: 0.00010430017573526129\n",
      "Epoch: 38, Loss: 7.869197725085542e-05\n",
      "Epoch: 39, Loss: 5.885364589630626e-05\n",
      "Epoch: 40, Loss: 5.835176489199512e-05\n",
      "Epoch: 41, Loss: 6.726171704940498e-05\n",
      "Epoch: 42, Loss: 6.723499245708808e-05\n",
      "Epoch: 43, Loss: 8.01739442977123e-05\n",
      "Epoch: 44, Loss: 0.0001239789417013526\n",
      "Epoch: 45, Loss: 0.00022322106815408915\n",
      "Epoch: 46, Loss: 0.0004252713406458497\n",
      "Epoch: 47, Loss: 0.0006288143922574818\n",
      "Epoch: 48, Loss: 0.000606446759775281\n",
      "Epoch: 49, Loss: 0.00023959513055160642\n",
      "Epoch: 50, Loss: 2.319387931493111e-05\n",
      "epoch 19 tensor([ 0.4982, -1.7358, -0.5271, -0.4079,  0.2974], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.006390352733433247\n",
      "Epoch: 2, Loss: 0.005405905190855265\n",
      "Epoch: 3, Loss: 0.003464838257059455\n",
      "Epoch: 4, Loss: 0.002465559635311365\n",
      "Epoch: 5, Loss: 0.0031026971992105246\n",
      "Epoch: 6, Loss: 0.002137339673936367\n",
      "Epoch: 7, Loss: 0.00237731309607625\n",
      "Epoch: 8, Loss: 0.0020062625408172607\n",
      "Epoch: 9, Loss: 0.001614713342860341\n",
      "Epoch: 10, Loss: 0.001609599101357162\n",
      "Epoch: 11, Loss: 0.0007903040968813002\n",
      "Epoch: 12, Loss: 0.001161437132395804\n",
      "Epoch: 13, Loss: 0.0005650488310493529\n",
      "Epoch: 14, Loss: 0.0009237474296241999\n",
      "Epoch: 15, Loss: 0.0006917653372511268\n",
      "Epoch: 16, Loss: 0.0009198002517223358\n",
      "Epoch: 17, Loss: 0.0006973823183216155\n",
      "Epoch: 18, Loss: 0.0006799470866099\n",
      "Epoch: 19, Loss: 0.0004602768167387694\n",
      "Epoch: 20, Loss: 0.00044358038576319814\n",
      "Epoch: 21, Loss: 0.0004024571680929512\n",
      "Epoch: 22, Loss: 0.00043839134741574526\n",
      "Epoch: 23, Loss: 0.00036791193997487426\n",
      "Epoch: 24, Loss: 0.0003885109326802194\n",
      "Epoch: 25, Loss: 0.0003332885098643601\n",
      "Epoch: 26, Loss: 0.00032319314777851105\n",
      "Epoch: 27, Loss: 0.00024408946046605706\n",
      "Epoch: 28, Loss: 0.0002476909721735865\n",
      "Epoch: 29, Loss: 0.0002032421325566247\n",
      "Epoch: 30, Loss: 0.00020394354942254722\n",
      "Epoch: 31, Loss: 0.0001679083361523226\n",
      "Epoch: 32, Loss: 0.00015601074846927077\n",
      "Epoch: 33, Loss: 0.00013326802582014352\n",
      "Epoch: 34, Loss: 0.0001058589550666511\n",
      "Epoch: 35, Loss: 0.00011980786803178489\n",
      "Epoch: 36, Loss: 7.321952580241486e-05\n",
      "Epoch: 37, Loss: 0.00011267574154771864\n",
      "Epoch: 38, Loss: 6.648529233643785e-05\n",
      "Epoch: 39, Loss: 7.10765307303518e-05\n",
      "Epoch: 40, Loss: 7.232229108922184e-05\n",
      "Epoch: 41, Loss: 5.594830872723833e-05\n",
      "Epoch: 42, Loss: 6.642612424911931e-05\n",
      "Epoch: 43, Loss: 5.1973285735584795e-05\n",
      "Epoch: 44, Loss: 4.281567453290336e-05\n",
      "Epoch: 45, Loss: 3.6711757275043055e-05\n",
      "Epoch: 46, Loss: 4.335975245339796e-05\n",
      "Epoch: 47, Loss: 3.8111327739898115e-05\n",
      "Epoch: 48, Loss: 3.0528441129717976e-05\n",
      "Epoch: 49, Loss: 2.9193846785346977e-05\n",
      "Epoch: 50, Loss: 2.5975736207328737e-05\n",
      "epoch 19 tensor([ 0.4396, -1.7413, -0.5960, -0.3759,  0.3057], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.007453488186001778\n",
      "Epoch: 2, Loss: 0.003531096037477255\n",
      "Epoch: 3, Loss: 0.002572335535660386\n",
      "Epoch: 4, Loss: 0.0043922970071434975\n",
      "Epoch: 5, Loss: 0.00413264986127615\n",
      "Epoch: 6, Loss: 0.0018352896440774202\n",
      "Epoch: 7, Loss: 0.0012119075981900096\n",
      "Epoch: 8, Loss: 0.002487054094672203\n",
      "Epoch: 9, Loss: 0.0026769645046442747\n",
      "Epoch: 10, Loss: 0.0016170531744137406\n",
      "Epoch: 11, Loss: 0.0008288142853416502\n",
      "Epoch: 12, Loss: 0.0009887595660984516\n",
      "Epoch: 13, Loss: 0.0018422864377498627\n",
      "Epoch: 14, Loss: 0.0013240068219602108\n",
      "Epoch: 15, Loss: 0.0009284596890211105\n",
      "Epoch: 16, Loss: 0.00048566405894234776\n",
      "Epoch: 17, Loss: 0.0008657921571284533\n",
      "Epoch: 18, Loss: 0.0010131376329809427\n",
      "Epoch: 19, Loss: 0.0007313497480936348\n",
      "Epoch: 20, Loss: 0.00034680997487157583\n",
      "Epoch: 21, Loss: 0.0005150343640707433\n",
      "Epoch: 22, Loss: 0.0005054002976976335\n",
      "Epoch: 23, Loss: 0.000604482542257756\n",
      "Epoch: 24, Loss: 0.0003196635516360402\n",
      "Epoch: 25, Loss: 0.0002756616158876568\n",
      "Epoch: 26, Loss: 0.00031766286701895297\n",
      "Epoch: 27, Loss: 0.00034387141931802034\n",
      "Epoch: 28, Loss: 0.0002727593237068504\n",
      "Epoch: 29, Loss: 0.00019497843459248543\n",
      "Epoch: 30, Loss: 0.00018656141764950007\n",
      "Epoch: 31, Loss: 0.00020433352619875222\n",
      "Epoch: 32, Loss: 0.00019448854436632246\n",
      "Epoch: 33, Loss: 0.00015753059415146708\n",
      "Epoch: 34, Loss: 0.00015189929399639368\n",
      "Epoch: 35, Loss: 0.00011994572560070083\n",
      "Epoch: 36, Loss: 0.00014049970195628703\n",
      "Epoch: 37, Loss: 8.697256271261722e-05\n",
      "Epoch: 38, Loss: 0.00010334872058592737\n",
      "Epoch: 39, Loss: 8.751715358812362e-05\n",
      "Epoch: 40, Loss: 7.334573456319049e-05\n",
      "Epoch: 41, Loss: 8.743142825551331e-05\n",
      "Epoch: 42, Loss: 6.926294008735567e-05\n",
      "Epoch: 43, Loss: 0.0001199194448417984\n",
      "Epoch: 44, Loss: 0.00016863300697878003\n",
      "Epoch: 45, Loss: 0.0003601574571803212\n",
      "Epoch: 46, Loss: 0.0007271801587194204\n",
      "Epoch: 47, Loss: 0.0008996176766231656\n",
      "Epoch: 48, Loss: 0.00040438026189804077\n",
      "Epoch: 49, Loss: 2.7161157049704343e-05\n",
      "Epoch: 50, Loss: 0.0003988894750364125\n",
      "epoch 19 tensor([ 0.4233, -1.7318, -0.5535, -0.3759,  0.3689], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0035383892245590687\n",
      "Epoch: 2, Loss: 0.002069565001875162\n",
      "Epoch: 3, Loss: 0.001048559439368546\n",
      "Epoch: 4, Loss: 0.0012693846365436912\n",
      "Epoch: 5, Loss: 0.001175199868157506\n",
      "Epoch: 6, Loss: 0.001065814751200378\n",
      "Epoch: 7, Loss: 0.0009819329716265202\n",
      "Epoch: 8, Loss: 0.000988879008218646\n",
      "Epoch: 9, Loss: 0.0005865060957148671\n",
      "Epoch: 10, Loss: 0.0005996832624077797\n",
      "Epoch: 11, Loss: 0.0006493457476608455\n",
      "Epoch: 12, Loss: 0.0006861806032247841\n",
      "Epoch: 13, Loss: 0.0005235313437879086\n",
      "Epoch: 14, Loss: 0.0004878370091319084\n",
      "Epoch: 15, Loss: 0.0004410099354572594\n",
      "Epoch: 16, Loss: 0.0003965289506595582\n",
      "Epoch: 17, Loss: 0.000345786742400378\n",
      "Epoch: 18, Loss: 0.0003644743701443076\n",
      "Epoch: 19, Loss: 0.0003416919207666069\n",
      "Epoch: 20, Loss: 0.00021949803340248764\n",
      "Epoch: 21, Loss: 0.00018540245946496725\n",
      "Epoch: 22, Loss: 0.00020228525681886822\n",
      "Epoch: 23, Loss: 0.00021905064932070673\n",
      "Epoch: 24, Loss: 0.0001749526709318161\n",
      "Epoch: 25, Loss: 0.00018714118050411344\n",
      "Epoch: 26, Loss: 0.0001526586274849251\n",
      "Epoch: 27, Loss: 0.00015664011880289763\n",
      "Epoch: 28, Loss: 0.00010968768037855625\n",
      "Epoch: 29, Loss: 8.518153481418267e-05\n",
      "Epoch: 30, Loss: 7.429745164699852e-05\n",
      "Epoch: 31, Loss: 8.425465784966946e-05\n",
      "Epoch: 32, Loss: 9.524935012450442e-05\n",
      "Epoch: 33, Loss: 7.522234955104068e-05\n",
      "Epoch: 34, Loss: 6.792103522457182e-05\n",
      "Epoch: 35, Loss: 5.787547706859186e-05\n",
      "Epoch: 36, Loss: 5.8656274632085115e-05\n",
      "Epoch: 37, Loss: 5.520172999240458e-05\n",
      "Epoch: 38, Loss: 5.620343654300086e-05\n",
      "Epoch: 39, Loss: 5.694280480383895e-05\n",
      "Epoch: 40, Loss: 4.645832450478338e-05\n",
      "Epoch: 41, Loss: 3.8140136894071475e-05\n",
      "Epoch: 42, Loss: 2.9431263101287186e-05\n",
      "Epoch: 43, Loss: 2.5852314138319343e-05\n",
      "Epoch: 44, Loss: 2.9132517738617025e-05\n",
      "Epoch: 45, Loss: 2.5112214643741027e-05\n",
      "Epoch: 46, Loss: 2.0330531697254628e-05\n",
      "Epoch: 47, Loss: 1.921570219565183e-05\n",
      "Epoch: 48, Loss: 2.160028088837862e-05\n",
      "Epoch: 49, Loss: 3.211346120224334e-05\n",
      "Epoch: 50, Loss: 4.905034802504815e-05\n",
      "epoch 19 tensor([ 0.4643, -1.7582, -0.4896, -0.4788,  0.4437], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.002445769961923361\n",
      "Epoch: 2, Loss: 0.0019257847452536225\n",
      "Epoch: 3, Loss: 0.0011345300590619445\n",
      "Epoch: 4, Loss: 0.0009532325202599168\n",
      "Epoch: 5, Loss: 0.0008251836406998336\n",
      "Epoch: 6, Loss: 0.0006863942835479975\n",
      "Epoch: 7, Loss: 0.0008108969777822495\n",
      "Epoch: 8, Loss: 0.0006333806086331606\n",
      "Epoch: 9, Loss: 0.0008169863140210509\n",
      "Epoch: 10, Loss: 0.0006129462854005396\n",
      "Epoch: 11, Loss: 0.000531739613506943\n",
      "Epoch: 12, Loss: 0.0005569425411522388\n",
      "Epoch: 13, Loss: 0.000356632168404758\n",
      "Epoch: 14, Loss: 0.0004202027921564877\n",
      "Epoch: 15, Loss: 0.0003448918869253248\n",
      "Epoch: 16, Loss: 0.00025665407883934677\n",
      "Epoch: 17, Loss: 0.0003153241705149412\n",
      "Epoch: 18, Loss: 0.00030977907590568066\n",
      "Epoch: 19, Loss: 0.0002757655456662178\n",
      "Epoch: 20, Loss: 0.00032190908677875996\n",
      "Epoch: 21, Loss: 0.0003005102917086333\n",
      "Epoch: 22, Loss: 0.00028265180299058557\n",
      "Epoch: 23, Loss: 0.0003273903566878289\n",
      "Epoch: 24, Loss: 0.00022764848836231977\n",
      "Epoch: 25, Loss: 0.00023563698050566018\n",
      "Epoch: 26, Loss: 0.0001863770594354719\n",
      "Epoch: 27, Loss: 0.00012916816922370344\n",
      "Epoch: 28, Loss: 0.0001393606944475323\n",
      "Epoch: 29, Loss: 9.67012601904571e-05\n",
      "Epoch: 30, Loss: 0.00012855109525844455\n",
      "Epoch: 31, Loss: 0.00015001089195720851\n",
      "Epoch: 32, Loss: 0.00017368968110531569\n",
      "Epoch: 33, Loss: 0.00019447664089966565\n",
      "Epoch: 34, Loss: 0.0001730342919472605\n",
      "Epoch: 35, Loss: 0.00016041497292462736\n",
      "Epoch: 36, Loss: 0.00010802075848914683\n",
      "Epoch: 37, Loss: 7.108049612725154e-05\n",
      "Epoch: 38, Loss: 4.149193409830332e-05\n",
      "Epoch: 39, Loss: 2.9379685656749643e-05\n",
      "Epoch: 40, Loss: 4.787450598087162e-05\n",
      "Epoch: 41, Loss: 6.313979247352108e-05\n",
      "Epoch: 42, Loss: 0.00010192135960096493\n",
      "Epoch: 43, Loss: 0.00014319740876089782\n",
      "Epoch: 44, Loss: 0.0001969696895685047\n",
      "Epoch: 45, Loss: 0.0002620057493913919\n",
      "Epoch: 46, Loss: 0.00028200302040204406\n",
      "Epoch: 47, Loss: 0.0002524459850974381\n",
      "Epoch: 48, Loss: 0.00015057867858558893\n",
      "Epoch: 49, Loss: 4.617282684193924e-05\n",
      "Epoch: 50, Loss: 1.8592643755255267e-05\n",
      "epoch 19 tensor([ 0.4428, -1.7394, -0.5412, -0.4308,  0.3793], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0009961685864254832\n",
      "Epoch: 2, Loss: 0.000978418393060565\n",
      "Epoch: 3, Loss: 0.0013150483136996627\n",
      "Epoch: 4, Loss: 0.002176194917410612\n",
      "Epoch: 5, Loss: 0.002443525241687894\n",
      "Epoch: 6, Loss: 0.0006819746922701597\n",
      "Epoch: 7, Loss: 0.0015839210245758295\n",
      "Epoch: 8, Loss: 0.001102527603507042\n",
      "Epoch: 9, Loss: 0.0006542361807078123\n",
      "Epoch: 10, Loss: 0.0012137810699641705\n",
      "Epoch: 11, Loss: 0.00034930542460642755\n",
      "Epoch: 12, Loss: 0.0010133408941328526\n",
      "Epoch: 13, Loss: 0.0003145524824503809\n",
      "Epoch: 14, Loss: 0.0007012718706391752\n",
      "Epoch: 15, Loss: 0.00039253916474990547\n",
      "Epoch: 16, Loss: 0.0004170451429672539\n",
      "Epoch: 17, Loss: 0.00046436506090685725\n",
      "Epoch: 18, Loss: 0.00023015022452455014\n",
      "Epoch: 19, Loss: 0.00044059325591661036\n",
      "Epoch: 20, Loss: 0.00011782661749748513\n",
      "Epoch: 21, Loss: 0.0004112202732358128\n",
      "Epoch: 22, Loss: 0.00012422996223904192\n",
      "Epoch: 23, Loss: 0.00025609415024518967\n",
      "Epoch: 24, Loss: 0.00020770993432961404\n",
      "Epoch: 25, Loss: 9.546667570248246e-05\n",
      "Epoch: 26, Loss: 0.0002513453655410558\n",
      "Epoch: 27, Loss: 5.177739149075933e-05\n",
      "Epoch: 28, Loss: 0.00021368238958530128\n",
      "Epoch: 29, Loss: 7.526358240284026e-05\n",
      "Epoch: 30, Loss: 0.00011898124648723751\n",
      "Epoch: 31, Loss: 0.000125745267723687\n",
      "Epoch: 32, Loss: 4.5945405872771516e-05\n",
      "Epoch: 33, Loss: 0.00013382520410232246\n",
      "Epoch: 34, Loss: 4.329343209974468e-05\n",
      "Epoch: 35, Loss: 8.530007471563295e-05\n",
      "Epoch: 36, Loss: 7.387580262729898e-05\n",
      "Epoch: 37, Loss: 3.047766222152859e-05\n",
      "Epoch: 38, Loss: 8.978880214272067e-05\n",
      "Epoch: 39, Loss: 1.94395561265992e-05\n",
      "Epoch: 40, Loss: 5.608865831163712e-05\n",
      "Epoch: 41, Loss: 4.2586252675391734e-05\n",
      "Epoch: 42, Loss: 2.097463766403962e-05\n",
      "Epoch: 43, Loss: 4.5512908400269225e-05\n",
      "Epoch: 44, Loss: 2.3695673007750884e-05\n",
      "Epoch: 45, Loss: 1.9835448256344534e-05\n",
      "Epoch: 46, Loss: 3.3866595913423225e-05\n",
      "Epoch: 47, Loss: 1.3241362466942519e-05\n",
      "Epoch: 48, Loss: 1.7977343304664828e-05\n",
      "Epoch: 49, Loss: 2.882404805859551e-05\n",
      "Epoch: 50, Loss: 4.777671620104229e-06\n",
      "epoch 19 tensor([ 0.4416, -1.7288, -0.5388, -0.4233,  0.3807], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0010445646476000547\n",
      "Epoch: 2, Loss: 0.0005784007371403277\n",
      "Epoch: 3, Loss: 0.0005535308737307787\n",
      "Epoch: 4, Loss: 0.0010156650096178055\n",
      "Epoch: 5, Loss: 0.002233170671388507\n",
      "Epoch: 6, Loss: 0.002352423733100295\n",
      "Epoch: 7, Loss: 0.0013733889209106565\n",
      "Epoch: 8, Loss: 0.0012184252263978124\n",
      "Epoch: 9, Loss: 0.0011143231531605124\n",
      "Epoch: 10, Loss: 0.001345801050774753\n",
      "Epoch: 11, Loss: 0.0005508477916009724\n",
      "Epoch: 12, Loss: 0.0011547927279025316\n",
      "Epoch: 13, Loss: 0.00047632577479816973\n",
      "Epoch: 14, Loss: 0.0008056385559029877\n",
      "Epoch: 15, Loss: 0.0005811962764710188\n",
      "Epoch: 16, Loss: 0.00044107853318564594\n",
      "Epoch: 17, Loss: 0.0005709799588657916\n",
      "Epoch: 18, Loss: 0.0003048032522201538\n",
      "Epoch: 19, Loss: 0.0004985716659575701\n",
      "Epoch: 20, Loss: 0.0002715109440032393\n",
      "Epoch: 21, Loss: 0.0003556513402145356\n",
      "Epoch: 22, Loss: 0.00024554674746468663\n",
      "Epoch: 23, Loss: 0.00027742161182686687\n",
      "Epoch: 24, Loss: 0.00021151672990527004\n",
      "Epoch: 25, Loss: 0.00022907380480319262\n",
      "Epoch: 26, Loss: 0.00015552027616649866\n",
      "Epoch: 27, Loss: 0.00021119228040333837\n",
      "Epoch: 28, Loss: 0.0001324822660535574\n",
      "Epoch: 29, Loss: 0.00016280259296763688\n",
      "Epoch: 30, Loss: 0.00013798920554108918\n",
      "Epoch: 31, Loss: 9.508018410997465e-05\n",
      "Epoch: 32, Loss: 0.00014041410759091377\n",
      "Epoch: 33, Loss: 5.632456304738298e-05\n",
      "Epoch: 34, Loss: 0.00013990962179377675\n",
      "Epoch: 35, Loss: 4.0216931665781885e-05\n",
      "Epoch: 36, Loss: 0.00010433213174110278\n",
      "Epoch: 37, Loss: 3.6056648241356015e-05\n",
      "Epoch: 38, Loss: 9.975398279493675e-05\n",
      "Epoch: 39, Loss: 2.3992135538719594e-05\n",
      "Epoch: 40, Loss: 7.282513979589567e-05\n",
      "Epoch: 41, Loss: 3.035104055015836e-05\n",
      "Epoch: 42, Loss: 4.0501236071577296e-05\n",
      "Epoch: 43, Loss: 4.858463944401592e-05\n",
      "Epoch: 44, Loss: 1.3911395399190951e-05\n",
      "Epoch: 45, Loss: 4.650479240808636e-05\n",
      "Epoch: 46, Loss: 1.2025283467664849e-05\n",
      "Epoch: 47, Loss: 3.98936026613228e-05\n",
      "Epoch: 48, Loss: 1.2271080777281895e-05\n",
      "Epoch: 49, Loss: 2.584089816082269e-05\n",
      "Epoch: 50, Loss: 2.2683298084302805e-05\n",
      "epoch 19 tensor([ 0.4410, -1.7649, -0.5352, -0.4129,  0.3784], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.003749237162992358\n",
      "Epoch: 2, Loss: 0.0029968530870974064\n",
      "Epoch: 3, Loss: 0.0023677777498960495\n",
      "Epoch: 4, Loss: 0.0019518339540809393\n",
      "Epoch: 5, Loss: 0.0017230573575943708\n",
      "Epoch: 6, Loss: 0.0014403867535293102\n",
      "Epoch: 7, Loss: 0.0011643270263448358\n",
      "Epoch: 8, Loss: 0.0010445511434227228\n",
      "Epoch: 9, Loss: 0.000898413301911205\n",
      "Epoch: 10, Loss: 0.0007014964357949793\n",
      "Epoch: 11, Loss: 0.0005500823026522994\n",
      "Epoch: 12, Loss: 0.0004375031276140362\n",
      "Epoch: 13, Loss: 0.0003033865359611809\n",
      "Epoch: 14, Loss: 0.00020241465244907886\n",
      "Epoch: 15, Loss: 0.0002249887038487941\n",
      "Epoch: 16, Loss: 0.00024016840325202793\n",
      "Epoch: 17, Loss: 0.0002506412856746465\n",
      "Epoch: 18, Loss: 0.0002839157241396606\n",
      "Epoch: 19, Loss: 0.0002970813657157123\n",
      "Epoch: 20, Loss: 0.00032431911677122116\n",
      "Epoch: 21, Loss: 0.00033433001954108477\n",
      "Epoch: 22, Loss: 0.0003261411329731345\n",
      "Epoch: 23, Loss: 0.00028662028489634395\n",
      "Epoch: 24, Loss: 0.00023982721904758364\n",
      "Epoch: 25, Loss: 0.0002111546928063035\n",
      "Epoch: 26, Loss: 0.00019477726891636848\n",
      "Epoch: 27, Loss: 0.00019283259462099522\n",
      "Epoch: 28, Loss: 0.0001538542128400877\n",
      "Epoch: 29, Loss: 0.00011000913218595088\n",
      "Epoch: 30, Loss: 9.052966925082728e-05\n",
      "Epoch: 31, Loss: 7.233205542434007e-05\n",
      "Epoch: 32, Loss: 5.9577123465714976e-05\n",
      "Epoch: 33, Loss: 5.942789721302688e-05\n",
      "Epoch: 34, Loss: 7.917398761492223e-05\n",
      "Epoch: 35, Loss: 0.0001515093754278496\n",
      "Epoch: 36, Loss: 0.0003514012205414474\n",
      "Epoch: 37, Loss: 0.0006972026894800365\n",
      "Epoch: 38, Loss: 0.000869054114446044\n",
      "Epoch: 39, Loss: 0.00040964913205243647\n",
      "Epoch: 40, Loss: 5.4257718147709966e-05\n",
      "Epoch: 41, Loss: 0.00037555291783064604\n",
      "Epoch: 42, Loss: 0.00047894270392134786\n",
      "Epoch: 43, Loss: 0.00012637437612283975\n",
      "Epoch: 44, Loss: 0.00017716949514579028\n",
      "Epoch: 45, Loss: 0.00034725709701888263\n",
      "Epoch: 46, Loss: 0.00012493631220422685\n",
      "Epoch: 47, Loss: 0.00011983236618107185\n",
      "Epoch: 48, Loss: 0.00027143186889588833\n",
      "Epoch: 49, Loss: 9.405116725247353e-05\n",
      "Epoch: 50, Loss: 4.970514783053659e-05\n",
      "epoch 19 tensor([ 0.4429, -1.7316, -0.5376, -0.3901,  0.3587], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.00340886227786541\n",
      "Epoch: 2, Loss: 0.002298522973433137\n",
      "Epoch: 3, Loss: 0.0016051138518378139\n",
      "Epoch: 4, Loss: 0.001395666622556746\n",
      "Epoch: 5, Loss: 0.0006304180715233088\n",
      "Epoch: 6, Loss: 0.0008862732211127877\n",
      "Epoch: 7, Loss: 0.0007808207883499563\n",
      "Epoch: 8, Loss: 0.0009126280783675611\n",
      "Epoch: 9, Loss: 0.0007197718368843198\n",
      "Epoch: 10, Loss: 0.000659333891235292\n",
      "Epoch: 11, Loss: 0.0006850098143331707\n",
      "Epoch: 12, Loss: 0.0005032310145907104\n",
      "Epoch: 13, Loss: 0.0006591032724827528\n",
      "Epoch: 14, Loss: 0.000580428633838892\n",
      "Epoch: 15, Loss: 0.0005565747851505876\n",
      "Epoch: 16, Loss: 0.0004009270342066884\n",
      "Epoch: 17, Loss: 0.00036135187838226557\n",
      "Epoch: 18, Loss: 0.00023997024982236326\n",
      "Epoch: 19, Loss: 0.0001897118636406958\n",
      "Epoch: 20, Loss: 0.0002491718914825469\n",
      "Epoch: 21, Loss: 0.00017500156536698341\n",
      "Epoch: 22, Loss: 0.00021779439703095704\n",
      "Epoch: 23, Loss: 0.0001752371754264459\n",
      "Epoch: 24, Loss: 0.00018333093612454832\n",
      "Epoch: 25, Loss: 0.0001669365883572027\n",
      "Epoch: 26, Loss: 0.00012979275197722018\n",
      "Epoch: 27, Loss: 0.0001668449694989249\n",
      "Epoch: 28, Loss: 0.00013521929213311523\n",
      "Epoch: 29, Loss: 0.00016831434913910925\n",
      "Epoch: 30, Loss: 0.0002110791829181835\n",
      "Epoch: 31, Loss: 0.000282800174318254\n",
      "Epoch: 32, Loss: 0.0004943523090332747\n",
      "Epoch: 33, Loss: 0.0006104297935962677\n",
      "Epoch: 34, Loss: 0.00047045506653375924\n",
      "Epoch: 35, Loss: 0.00015670595166739076\n",
      "Epoch: 36, Loss: 8.922941924538463e-05\n",
      "Epoch: 37, Loss: 0.00030724602402187884\n",
      "Epoch: 38, Loss: 0.0003697100328281522\n",
      "Epoch: 39, Loss: 0.00015961537428665906\n",
      "Epoch: 40, Loss: 3.6642319173552096e-05\n",
      "Epoch: 41, Loss: 0.0001792203838704154\n",
      "Epoch: 42, Loss: 0.00025716080563142896\n",
      "Epoch: 43, Loss: 9.778447565622628e-05\n",
      "Epoch: 44, Loss: 3.784515865845606e-05\n",
      "Epoch: 45, Loss: 0.00012958512525074184\n",
      "Epoch: 46, Loss: 0.00016225306899286807\n",
      "Epoch: 47, Loss: 8.368403359781951e-05\n",
      "Epoch: 48, Loss: 2.2607930077356286e-05\n",
      "Epoch: 49, Loss: 7.44113713153638e-05\n",
      "Epoch: 50, Loss: 0.00012748695735353976\n",
      "epoch 19 tensor([ 0.4521, -1.7597, -0.5504, -0.3960,  0.3400], grad_fn=<AddBackward0>) 0\n",
      "Epoch: 1, Loss: 0.0007766562048345804\n",
      "Epoch: 2, Loss: 0.000525501964148134\n",
      "Epoch: 3, Loss: 0.0004363946500234306\n",
      "Epoch: 4, Loss: 0.00032387732062488794\n",
      "Epoch: 5, Loss: 0.00021333448239602149\n",
      "Epoch: 6, Loss: 0.00023564562434330583\n",
      "Epoch: 7, Loss: 0.0002293615398230031\n",
      "Epoch: 8, Loss: 0.00023387699911836535\n",
      "Epoch: 9, Loss: 0.00020100653637200594\n",
      "Epoch: 10, Loss: 0.0001693480444373563\n",
      "Epoch: 11, Loss: 0.00014807446859776974\n",
      "Epoch: 12, Loss: 0.00017615797696635127\n",
      "Epoch: 13, Loss: 0.00015287534915842116\n",
      "Epoch: 14, Loss: 0.00013892739661969244\n",
      "Epoch: 15, Loss: 0.00012427048932295293\n",
      "Epoch: 16, Loss: 0.00010413441486889496\n",
      "Epoch: 17, Loss: 0.00010134870535694063\n",
      "Epoch: 18, Loss: 8.636949496576563e-05\n",
      "Epoch: 19, Loss: 7.267586624948308e-05\n",
      "Epoch: 20, Loss: 7.352480315603316e-05\n",
      "Epoch: 21, Loss: 6.234175089048222e-05\n",
      "Epoch: 22, Loss: 5.936577872489579e-05\n",
      "Epoch: 23, Loss: 4.8879232053877786e-05\n",
      "Epoch: 24, Loss: 4.5594664698001e-05\n",
      "Epoch: 25, Loss: 3.330248364363797e-05\n",
      "Epoch: 26, Loss: 4.69651204184629e-05\n",
      "Epoch: 27, Loss: 5.019536183681339e-05\n",
      "Epoch: 28, Loss: 7.002801430644467e-05\n",
      "Epoch: 29, Loss: 9.383793076267466e-05\n",
      "Epoch: 30, Loss: 0.00012650915596168488\n",
      "Epoch: 31, Loss: 0.00019872798293363303\n",
      "Epoch: 32, Loss: 0.0002858726365957409\n",
      "Epoch: 33, Loss: 0.00033695047022774816\n",
      "Epoch: 34, Loss: 0.0002808014687616378\n",
      "Epoch: 35, Loss: 0.0001278251875191927\n",
      "Epoch: 36, Loss: 2.0346111341495998e-05\n",
      "Epoch: 37, Loss: 5.382800009101629e-05\n",
      "Epoch: 38, Loss: 0.00015520812303293496\n",
      "Epoch: 39, Loss: 0.00020009321451652795\n",
      "Epoch: 40, Loss: 0.00013636332005262375\n",
      "Epoch: 41, Loss: 4.1843304643407464e-05\n",
      "Epoch: 42, Loss: 2.2529615307576023e-05\n",
      "Epoch: 43, Loss: 8.029887248994783e-05\n",
      "Epoch: 44, Loss: 0.00012526693171821535\n",
      "Epoch: 45, Loss: 0.0001079909416148439\n",
      "Epoch: 46, Loss: 5.081189738120884e-05\n",
      "Epoch: 47, Loss: 1.7839891370385885e-05\n",
      "Epoch: 48, Loss: 3.5405442758928984e-05\n",
      "Epoch: 49, Loss: 7.560932863270864e-05\n",
      "Epoch: 50, Loss: 9.51683396124281e-05\n",
      "________________________________________\n",
      "0 0 tensor([ 0.4361, -1.7401, -0.6167, -0.3587,  0.3440], grad_fn=<AddBackward0>) 0\n",
      "0 1 tensor([ 0.5513, -1.0749,  0.3416, -0.3158,  0.4609], grad_fn=<AddBackward0>) 0\n",
      "0 2 tensor([ 0.7149, -1.9357,  0.3859, -0.1922,  0.5531], grad_fn=<AddBackward0>) 0\n",
      "0 3 tensor([ 1.0894, -4.0173,  0.5568, -0.1303,  0.6992], grad_fn=<AddBackward0>) 0\n",
      "0 4 tensor([0.0964, 1.1975, 0.7206, 0.2761, 1.0712], grad_fn=<AddBackward0>) 1\n",
      "1 0 tensor([-1.0723,  3.9260,  2.1562,  0.3949, -1.8159], grad_fn=<AddBackward0>) 1\n",
      "1 1 tensor([-1.8928,  4.9226, -1.8460,  0.4462, -1.0693], grad_fn=<AddBackward0>) 1\n",
      "1 2 tensor([-3.9497,  3.8221, -1.0662,  0.5327, -1.9897], grad_fn=<AddBackward0>) 1\n",
      "1 3 tensor([ 1.2195, -1.8659, -2.0502,  0.6457, -4.1428], grad_fn=<AddBackward0>) 0\n",
      "1 4 tensor([ 0.2614,  1.5489, -4.0182,  1.0158,  1.1216], grad_fn=<AddBackward0>) 1\n",
      "2 0 tensor([ 4.9058,  3.1591,  2.7352, -1.8524,  3.9036], grad_fn=<AddBackward0>) 0\n",
      "2 1 tensor([ 3.9068, -1.0838,  3.9280, -1.0818,  4.9045], grad_fn=<AddBackward0>) 4\n",
      "2 2 tensor([-1.9000,  3.1344,  4.9258, -1.8787,  3.9249], grad_fn=<AddBackward0>) 2\n",
      "2 3 tensor([ 1.5564,  2.3726,  3.9327, -4.0264, -1.7325], grad_fn=<AddBackward0>) 2\n",
      "2 4 tensor([ 0.6223,  1.9777, -1.8873,  1.0325,  1.3988], grad_fn=<AddBackward0>) 1\n",
      "3 0 tensor([-0.9685,  2.4798,  1.8646,  3.9455,  3.1502], grad_fn=<AddBackward0>) 3\n",
      "3 1 tensor([ 3.1195,  2.1292,  3.1664,  4.8612, -1.0929], grad_fn=<AddBackward0>) 3\n",
      "3 2 tensor([ 2.4731,  2.5393, -1.0793,  3.9186,  3.0472], grad_fn=<AddBackward0>) 3\n",
      "3 3 tensor([ 1.7788,  1.9806,  3.1387, -1.8481,  2.3770], grad_fn=<AddBackward0>) 2\n",
      "3 4 tensor([ 1.0364, -3.3364,  2.5422,  1.5626,  1.8127], grad_fn=<AddBackward0>) 2\n",
      "4 0 tensor([2.0528, 1.4710, 1.4808, 3.1570, 2.9881], grad_fn=<AddBackward0>) 3\n",
      "4 1 tensor([ 2.4788,  1.3933,  2.6562, -0.7814,  2.0745], grad_fn=<AddBackward0>) 2\n",
      "4 2 tensor([2.1388, 1.6566, 1.8608, 2.9284, 2.4744], grad_fn=<AddBackward0>) 3\n",
      "4 3 tensor([-2.0776,  1.1059,  2.3783,  2.5196,  1.7559], grad_fn=<AddBackward0>) 3\n",
      "4 4 tensor([ 1.2453,  0.1038,  1.4856,  1.9689, -1.2427], grad_fn=<AddBackward0>) 3\n"
     ]
    }
   ],
   "source": [
    "import taichi as ti\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "ti.init(ti.cpu)\n",
    "pixel_size=60\n",
    "grid_width=5\n",
    "grid_height=5\n",
    "width=pixel_size*grid_width\n",
    "height=pixel_size*grid_height\n",
    "step=1/grid_width\n",
    "gamma=0.8\n",
    "punishment=-5\n",
    "dataset_size=1000\n",
    "reward_list=[]\n",
    "\n",
    "#网格图类\n",
    "class grid:\n",
    "    def __init__(self,width,height) -> None:\n",
    "        self.canvas=np.ones((width,height,3))\n",
    "\n",
    "    def set_color(self,x,y,color):\n",
    "        self.canvas[x*pixel_size:(x+1)*pixel_size,y*pixel_size:(y+1)*pixel_size,:]=color\n",
    "\n",
    "#智能体\n",
    "class agent:\n",
    "    def __init__(self,x,y) -> None:\n",
    "        self.pos=[(x+0.5)/grid_width,(y+0.5)/grid_height]\n",
    "\n",
    "    def move(self,dir):\n",
    "        if(dir==0):#上\n",
    "            self.pos[1]+=step\n",
    "        elif(dir==1):#右\n",
    "            self.pos[0]+=step  \n",
    "        elif(dir==2):#下\n",
    "            self.pos[1]-=step\n",
    "        elif(dir==3):#左\n",
    "            self.pos[0]-=step\n",
    "        elif(dir==4):\n",
    "            pass\n",
    "class state:\n",
    "    def __init__(self,x,y) -> None:\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.reward=[0,0,0,0,0]\n",
    "        self.kind=0#1为目标，2为障碍\n",
    "        self.policy=0\n",
    "        self.value=0\n",
    "        self.q_value=[0,0,0,0,0]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"[{self.x},{self.y},reward{self.reward}]\"\n",
    "    \n",
    "def init_reward(x,y):\n",
    "    state=state_list[x][y].kind\n",
    "    if(state==1):\n",
    "        return 1\n",
    "    elif(state==2):\n",
    "        return punishment\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def next_state(x,y,dir):\n",
    "    if(dir==4):\n",
    "        return x,y\n",
    "    elif(dir==0):\n",
    "        if(y+1==grid_height):\n",
    "            return x,y\n",
    "        else:\n",
    "            return x,y+1\n",
    "    #右\n",
    "    elif(dir==1):\n",
    "        return (x,y) if x+1==grid_width else (x+1,y)\n",
    "    \n",
    "    #下\n",
    "    elif(dir==2):\n",
    "        return (x,y) if y==0 else (x,y-1)\n",
    "\n",
    "    #左\n",
    "    elif(dir==3):\n",
    "        return (x,y) if x==0 else (x-1,y)\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__() #初始化 nn.Module \n",
    "        \n",
    "        # self.mlp_s1=nn.Linear(2,300)\n",
    "        # self.mlp_s2=nn.Linear(300,5)\n",
    "        \n",
    "        self.mlp1=nn.Linear(2,40)\n",
    "        self.mlp2=nn.Linear(40,300)\n",
    "        self.mlp3=nn.Linear(300,50)\n",
    "        self.mlp4=nn.Linear(50,5) # 5个action\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.mlp4(self.relu(self.mlp3(self.relu(self.mlp2(self.relu(self.mlp1(x)))))))\n",
    "        # return self.mlp_s2(self.mlp_s1(x))\n",
    "            \n",
    "state_list=[]\n",
    "for i in range(grid_width):\n",
    "    tmp=[]\n",
    "    for j in range(grid_height):\n",
    "        tmp.append(state(i,j))\n",
    "    state_list.append(tmp)\n",
    "state_list[2][1].kind=1\n",
    "state_list[1][0].kind=2\n",
    "state_list[1][1].kind=2\n",
    "state_list[1][3].kind=2\n",
    "state_list[1][2].kind=2\n",
    "state_list[2][3].kind=2\n",
    "state_list[3][1].kind=2\n",
    "state_list[4][4].kind=2\n",
    "\n",
    "for i in range(grid_width):\n",
    "    tmp=[]\n",
    "    for j in range(grid_height):\n",
    "        obj=state_list[i][j]\n",
    "        x=obj.x\n",
    "        y=obj.y\n",
    "        #上\n",
    "        if(y+1==grid_height):\n",
    "            obj.reward[0]=-1\n",
    "        else:\n",
    "            obj.reward[0]=init_reward(x,y+1)\n",
    "        #右\n",
    "        if(x+1==grid_width):\n",
    "            obj.reward[1]=-1\n",
    "        else:\n",
    "            obj.reward[1]=init_reward(x+1,y)\n",
    "        #下\n",
    "        if(y==0):\n",
    "            obj.reward[2]=-1\n",
    "        else:\n",
    "            obj.reward[2]=init_reward(x,y-1)\n",
    "        #左\n",
    "        if(x==0):\n",
    "            obj.reward[3]=-1\n",
    "        else:\n",
    "            obj.reward[3]=init_reward(x-1,y)\n",
    "        #stay\n",
    "        obj.reward[4]=init_reward(x,y)\n",
    "    \n",
    "policy_b=[0.2,0.2,0.2,0.2,0.2]\n",
    "\n",
    "#generate data\n",
    "\n",
    "x,y=0,0\n",
    "target_network=Network()\n",
    "main_network=Network()\n",
    "learning_epoch=50\n",
    "main_epoch=20\n",
    "epsilon=0.6\n",
    "epochs=10\n",
    "mse = nn.MSELoss()\n",
    "optimizer = optim.Adam(main_network.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# generate datasest\n",
    "dataset=[]\n",
    "for i in range(dataset_size):\n",
    "    pv_x,pv_y=x,y\n",
    "    cur_dir = random.choices(range(len(policy_b)), weights=policy_b)[0]\n",
    "    r=state_list[pv_x][pv_y].reward[cur_dir]\n",
    "    x,y=next_state(x,y,cur_dir)\n",
    "    dataset.append([[pv_x,pv_y],cur_dir,r,[x,y]])\n",
    "\n",
    "batch_size=100\n",
    "for main_e in range(main_epoch):\n",
    "    for epoch in range(epochs):\n",
    "        q_value=main_network(torch.tensor([0,0],dtype=torch.float32))\n",
    "        policy=torch.argmax(q_value)\n",
    "        print(f\"epoch {main_e} {q_value} {policy}\")\n",
    "        reward_list.append(max(q_value))\n",
    "        batch=random.sample(dataset,batch_size)\n",
    "        input=torch.zeros((batch_size,2))\n",
    "        next_input=torch.zeros((batch_size,2)) # 下一个状态输入\n",
    "        R=torch.zeros(batch_size)\n",
    "        A=torch.zeros(batch_size)\n",
    "        for i,data in enumerate(batch):\n",
    "            input[i,0]=data[0][0] # x\n",
    "            input[i,1]=data[0][1] # y\n",
    "            next_input[i,0]=data[3][0]\n",
    "            next_input[i,1]=data[3][1] \n",
    "            R[i]=data[2]\n",
    "            A[i]=data[1]\n",
    "        q_output=target_network(next_input)\n",
    "        max_q, _=torch.max(q_output,dim=1)\n",
    "        y_T=R+gamma*max_q\n",
    "        for i in range(learning_epoch):\n",
    "            optimizer.zero_grad()\n",
    "            main_output=main_network(input)\n",
    "            indexed_output = torch.zeros(batch_size)\n",
    "            for j in range(batch_size):\n",
    "                indexed_output[j] = main_output[j, A[j].long()]\n",
    "            loss=mse(indexed_output,y_T)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            print(f\"Epoch: {i+1}, Loss: {loss.item()}\")\n",
    "    target_network.load_state_dict(main_network.state_dict())\n",
    "    x,y=0,0\n",
    "    dataset=[]\n",
    "    for i in range(dataset_size):\n",
    "        pv_x,pv_y=x,y\n",
    "        q_value=main_network(torch.tensor([x,y],dtype=torch.float32))\n",
    "        cur_dir = torch.argmax(q_value)\n",
    "        prob_list=np.zeros(5)\n",
    "        for i in range(5):\n",
    "            if(i==cur_dir):\n",
    "                prob_list[i]=1-epsilon*4/5\n",
    "            else:\n",
    "                prob_list[i]=epsilon/5\n",
    "        cur_dir=random.choices(range(5), weights=prob_list)[0]\n",
    "        r=state_list[pv_x][pv_y].reward[cur_dir]\n",
    "        x,y=next_state(x,y,cur_dir)\n",
    "        dataset.append([[pv_x,pv_y],cur_dir,r,[x,y]])\n",
    "    print(\"________________________________________\")\n",
    "    \n",
    "    \n",
    "\n",
    "# greed policy\n",
    "for i in range(grid_width):\n",
    "    for j in range(grid_height):\n",
    "        q_value=main_network(torch.tensor([i,j],dtype=torch.float32))\n",
    "        policy=torch.argmax(q_value)\n",
    "        print(f\"{i} {j} {q_value} {policy}\")\n",
    "        state_list[i][j].policy=policy\n",
    "        \n",
    "line_b=np.array([[x,0] for x in range(pixel_size,width,pixel_size)])/width\n",
    "line_b1=np.array([[0,y] for y in range(pixel_size,height,pixel_size)])/height\n",
    "line_e=np.array([[x,width-1] for x in range(pixel_size,width,pixel_size)])/width\n",
    "line_e1=np.array([[height-1,y] for y in range(pixel_size,height,pixel_size)])/height\n",
    "grid_world=grid(width,height)\n",
    "for i in range(grid_width):\n",
    "    for j in range(grid_height):\n",
    "        if(state_list[i][j].kind==1):\n",
    "            grid_world.set_color(i,j,[120/255,152/255,232/255])\n",
    "        elif(state_list[i][j].kind==2):\n",
    "            grid_world.set_color(i,j,[245/255,151/255,148/255])\n",
    "\n",
    "agent_x=0\n",
    "agent_y=0\n",
    "myagent=agent(agent_x,agent_y)\n",
    "\n",
    "dt=0.5\n",
    "N=0\n",
    "\n",
    "gui=ti.GUI(\"grid\",(width,height))\n",
    "\n",
    "while gui.running:\n",
    "    N+=1\n",
    "    if(N==dt*60):\n",
    "        N=0\n",
    "        dir=state_list[agent_x][agent_y].policy\n",
    "        agent_x,agent_y=next_state(agent_x,agent_y,dir)\n",
    "        myagent=agent(agent_x,agent_y)\n",
    "    gui.set_image(grid_world.canvas)\n",
    "    gui.lines(begin=np.concatenate((line_b,line_b1),axis=0), end=np.concatenate((line_e,line_e1),axis=0), radius=1, color=0x000000)\n",
    "    gui.circle(myagent.pos,color=0x000000,radius=5)\n",
    "    for i in range(grid_width):\n",
    "        for j in range(grid_height):\n",
    "            gui.text(content=str(state_list[i][j].value)[:4], pos=[i/grid_width,(j+1)/grid_height], font_size=20, color=0x000000)\n",
    "    gui.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "origin",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.0941360741853714,
          -0.9128007888793945,
          -0.1533590704202652,
          -1.0963958501815796,
          -0.31328803300857544,
          0.1541031152009964,
          -0.8786334991455078,
          -0.4499201774597168,
          0.09180410206317902,
          0.14620190858840942,
          0.2059280276298523,
          0.4652402698993683,
          0.6565873622894287,
          0.5414801836013794,
          0.23646828532218933,
          0.6634326577186584,
          0.7213402986526489,
          1.1555057764053345,
          0.6844149827957153,
          0.6157956123352051,
          1.1592787504196167,
          0.538304328918457,
          0.6962223649024963,
          0.8941243290901184,
          1.6329587697982788,
          0.8310397863388062,
          0.8840985298156738,
          0.7395840883255005,
          0.8415858149528503,
          0.9642388224601746,
          1.2971878051757812,
          1.449078917503357,
          1.2613228559494019,
          1.2712723016738892,
          1.0479217767715454,
          1.0204219818115234,
          1.0615613460540771,
          1.0494961738586426,
          1.0399689674377441,
          1.027020812034607,
          1.0514293909072876,
          0.9212227463722229,
          0.9034752249717712,
          0.9815230965614319,
          1.4697918891906738,
          1.6386072635650635,
          1.333919644355774,
          0.9120674133300781,
          0.9099020957946777,
          0.8960083723068237,
          0.9051555395126343,
          1.4633702039718628,
          1.0374993085861206,
          0.889914333820343,
          0.6937538385391235,
          0.7083612680435181,
          0.793671727180481,
          0.6608895063400269,
          0.6843660473823547,
          0.718603253364563,
          0.7395308017730713,
          0.577968955039978,
          0.6244496703147888,
          0.6061358451843262,
          0.8646296262741089,
          0.582430362701416,
          0.6845201253890991,
          0.6376263499259949,
          0.6935940980911255,
          0.6458832621574402,
          0.7489889860153198,
          1.1566241979599,
          1.9083080291748047,
          1.886431336402893,
          1.2726688385009766,
          0.8367758393287659,
          1.3751164674758911,
          1.1134765148162842,
          0.9185100793838501,
          0.9351949691772461,
          0.8517056107521057,
          0.7675797939300537,
          0.9445458650588989,
          0.7941694855690002,
          0.7817403078079224,
          0.7593920230865479,
          0.773393988609314,
          0.7692472338676453,
          0.6387461423873901,
          0.7855232954025269,
          0.7471455931663513,
          0.5787810683250427,
          0.5021101832389832,
          0.5812703371047974,
          0.6072981357574463,
          0.5339138507843018,
          0.4464573264122009,
          0.44155555963516235,
          0.35296064615249634,
          0.6950900554656982,
          0.7150455117225647,
          0.6320141553878784,
          0.8108109831809998,
          0.7773280143737793,
          0.7422662377357483,
          0.6359717845916748,
          0.588663637638092,
          0.5138943791389465,
          0.8201297521591187,
          0.6171156167984009,
          0.5657431483268738,
          0.5809557437896729,
          0.7450466156005859,
          0.6189432144165039,
          0.6244193315505981,
          0.5352253913879395,
          0.5450301766395569,
          0.508658766746521,
          0.5621234178543091,
          0.3848092257976532,
          0.5397308468818665,
          0.5990907549858093,
          0.5990892648696899,
          0.6247925758361816,
          0.6083194017410278,
          0.6238037943840027,
          0.6951941847801208,
          0.7897274494171143,
          0.7607142925262451,
          0.6008411645889282,
          0.6001113653182983,
          0.5136006474494934,
          0.5534694790840149,
          0.6662404537200928,
          0.4974960684776306,
          0.5698957443237305,
          0.6395217776298523,
          0.5140513181686401,
          0.5195226073265076,
          0.5511550903320312,
          0.5373660922050476,
          0.591400146484375,
          0.5578790903091431,
          0.6012348532676697,
          0.5980856418609619,
          0.5427579283714294,
          0.5527731776237488,
          0.5396188497543335,
          0.5448956489562988,
          0.5492071509361267,
          0.5478531122207642,
          0.4934336543083191,
          0.45805203914642334,
          0.536320686340332,
          0.6327289342880249,
          0.54839026927948,
          0.5971721410751343,
          0.6026735901832581,
          0.5223697423934937,
          0.54975426197052,
          0.5638281106948853,
          0.588645875453949,
          0.5090705156326294,
          0.5015352964401245,
          0.4940134882926941,
          0.4631369113922119,
          0.5051755309104919,
          0.5213634967803955,
          0.5009922981262207,
          0.4877524673938751,
          0.49879804253578186,
          0.5049864053726196,
          0.5195558071136475,
          0.5432717800140381,
          0.4966588318347931,
          0.5367540121078491,
          0.5253660678863525,
          0.5643849968910217,
          0.48686355352401733,
          0.5299521684646606,
          0.521274209022522,
          0.47734272480010986,
          0.4819534122943878,
          0.4955933690071106,
          0.501329243183136,
          0.4784696698188782,
          0.5186442136764526,
          0.4798656702041626,
          0.511367917060852,
          0.5066964626312256,
          0.48038169741630554,
          0.4982350468635559,
          0.4395750164985657,
          0.4232518672943115,
          0.46430742740631104,
          0.4428357481956482,
          0.4415585398674011,
          0.4410053491592407,
          0.4428560137748718,
          0.45211440324783325
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "月表建造示例—强化学习收敛曲线"
        },
        "xaxis": {
         "title": {
          "text": "训练轮数"
         }
        },
        "yaxis": {
         "title": {
          "text": "输出奖励"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"56e6f1f4-eae1-4168-afab-30dd262ac6ef\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"56e6f1f4-eae1-4168-afab-30dd262ac6ef\")) {                    Plotly.newPlot(                        \"56e6f1f4-eae1-4168-afab-30dd262ac6ef\",                        [{\"name\":\"origin\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199],\"y\":[0.0941360741853714,-0.9128007888793945,-0.1533590704202652,-1.0963958501815796,-0.31328803300857544,0.1541031152009964,-0.8786334991455078,-0.4499201774597168,0.09180410206317902,0.14620190858840942,0.2059280276298523,0.4652402698993683,0.6565873622894287,0.5414801836013794,0.23646828532218933,0.6634326577186584,0.7213402986526489,1.1555057764053345,0.6844149827957153,0.6157956123352051,1.1592787504196167,0.538304328918457,0.6962223649024963,0.8941243290901184,1.6329587697982788,0.8310397863388062,0.8840985298156738,0.7395840883255005,0.8415858149528503,0.9642388224601746,1.2971878051757812,1.449078917503357,1.2613228559494019,1.2712723016738892,1.0479217767715454,1.0204219818115234,1.0615613460540771,1.0494961738586426,1.0399689674377441,1.027020812034607,1.0514293909072876,0.9212227463722229,0.9034752249717712,0.9815230965614319,1.4697918891906738,1.6386072635650635,1.333919644355774,0.9120674133300781,0.9099020957946777,0.8960083723068237,0.9051555395126343,1.4633702039718628,1.0374993085861206,0.889914333820343,0.6937538385391235,0.7083612680435181,0.793671727180481,0.6608895063400269,0.6843660473823547,0.718603253364563,0.7395308017730713,0.577968955039978,0.6244496703147888,0.6061358451843262,0.8646296262741089,0.582430362701416,0.6845201253890991,0.6376263499259949,0.6935940980911255,0.6458832621574402,0.7489889860153198,1.1566241979599,1.9083080291748047,1.886431336402893,1.2726688385009766,0.8367758393287659,1.3751164674758911,1.1134765148162842,0.9185100793838501,0.9351949691772461,0.8517056107521057,0.7675797939300537,0.9445458650588989,0.7941694855690002,0.7817403078079224,0.7593920230865479,0.773393988609314,0.7692472338676453,0.6387461423873901,0.7855232954025269,0.7471455931663513,0.5787810683250427,0.5021101832389832,0.5812703371047974,0.6072981357574463,0.5339138507843018,0.4464573264122009,0.44155555963516235,0.35296064615249634,0.6950900554656982,0.7150455117225647,0.6320141553878784,0.8108109831809998,0.7773280143737793,0.7422662377357483,0.6359717845916748,0.588663637638092,0.5138943791389465,0.8201297521591187,0.6171156167984009,0.5657431483268738,0.5809557437896729,0.7450466156005859,0.6189432144165039,0.6244193315505981,0.5352253913879395,0.5450301766395569,0.508658766746521,0.5621234178543091,0.3848092257976532,0.5397308468818665,0.5990907549858093,0.5990892648696899,0.6247925758361816,0.6083194017410278,0.6238037943840027,0.6951941847801208,0.7897274494171143,0.7607142925262451,0.6008411645889282,0.6001113653182983,0.5136006474494934,0.5534694790840149,0.6662404537200928,0.4974960684776306,0.5698957443237305,0.6395217776298523,0.5140513181686401,0.5195226073265076,0.5511550903320312,0.5373660922050476,0.591400146484375,0.5578790903091431,0.6012348532676697,0.5980856418609619,0.5427579283714294,0.5527731776237488,0.5396188497543335,0.5448956489562988,0.5492071509361267,0.5478531122207642,0.4934336543083191,0.45805203914642334,0.536320686340332,0.6327289342880249,0.54839026927948,0.5971721410751343,0.6026735901832581,0.5223697423934937,0.54975426197052,0.5638281106948853,0.588645875453949,0.5090705156326294,0.5015352964401245,0.4940134882926941,0.4631369113922119,0.5051755309104919,0.5213634967803955,0.5009922981262207,0.4877524673938751,0.49879804253578186,0.5049864053726196,0.5195558071136475,0.5432717800140381,0.4966588318347931,0.5367540121078491,0.5253660678863525,0.5643849968910217,0.48686355352401733,0.5299521684646606,0.521274209022522,0.47734272480010986,0.4819534122943878,0.4955933690071106,0.501329243183136,0.4784696698188782,0.5186442136764526,0.4798656702041626,0.511367917060852,0.5066964626312256,0.48038169741630554,0.4982350468635559,0.4395750164985657,0.4232518672943115,0.46430742740631104,0.4428357481956482,0.4415585398674011,0.4410053491592407,0.4428560137748718,0.45211440324783325],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"训练轮数\"}},\"yaxis\":{\"title\":{\"text\":\"输出奖励\"}},\"title\":{\"text\":\"月表建造示例—强化学习收敛曲线\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('56e6f1f4-eae1-4168-afab-30dd262ac6ef');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "reward_list1=[r.detach() for r in reward_list]\n",
    "reward=pd.Series(reward_list1)\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(len(reward))),y=reward,name='origin')) \n",
    "fig.update_layout(xaxis_title='训练轮数',yaxis_title='输出奖励',title=\"月表建造示例—强化学习收敛曲线\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
