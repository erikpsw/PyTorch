{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出的为每一类的置信值$\\bf y$\n",
    "\n",
    "$$\\hat{y}=\\argmax _i{o_i}$$\n",
    "\n",
    "对于特殊,要拉开距离\n",
    "$$o_y-o_i\\ge \\Delta (y,i)$$\n",
    "\n",
    "将结果转换为概率\n",
    "$$\\hat{\\mathbf{y}} = \\mathrm{softmax}(\\mathbf{o})\\quad \\text{其中}\\quad \\hat{y}_j = \\frac{\\exp(o_j)}{\\sum_k \\exp(o_k)}$$\n",
    "\n",
    "信息熵\n",
    "$$H[P] = \\sum_j - P(j) \\log P(j)$$\n",
    "交叉熵\n",
    "$$l(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{j=1}^q y_j \\log \\hat{y}_j$$\n",
    "$\\bf y$是一个长度$q$为的独热编码向量,其中只有$y_y=1$\n",
    "\n",
    "所以$l(\\mathbf{y}, \\hat{\\mathbf{y}}) = -\\log \\hat{y}_y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{split}\\begin{aligned}\n",
    "l(\\mathbf{y}, \\hat{\\mathbf{y}}) &=  - \\sum_{j=1}^q y_j \\log \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} \\\\\n",
    "&= \\sum_{j=1}^q y_j \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j\\\\\n",
    "&= \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j.\n",
    "\\end{aligned}\\end{split}\\\\\n",
    "\\partial_{o_j} l(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} - y_j = \\mathrm{softmax}(\\mathbf{o})_j - y_j.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mine_torch\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\n",
    "# 并除以255使得所有像素的数值均在0到1之间\n",
    "trans = torchvision.transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=trans, download=True)\n",
    "plt.imshow(mnist_train[0][0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0][0]#第0维是某个example\n",
    "#第一维为一个元组(data,lable)\n",
    "#图像为(1,28,28),1代表单通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axes=plt.subplots(2,3)\n",
    "axes=axes.flatten()#一维\n",
    "for i in range(6):\n",
    "    ax=axes[i]\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.imshow(mnist_train[i][0][0])\n",
    "    ax.set_title(mnist_train[i][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "num_input=28*28\n",
    "num_output=10\n",
    "\n",
    "train_iter=data.DataLoader(mnist_train,256,True)\n",
    "test_iter=data.DataLoader(mnist_test,256,True)\n",
    "W=torch.normal(0,0.01,size=(num_input,num_output),requires_grad=True)\n",
    "b=torch.zeros(num_output,requires_grad=True)\n",
    "\n",
    "def softmax(X):\n",
    "    X_exp=torch.exp(X)\n",
    "    partition=X_exp.sum(dim=1,keepdim=True)#dim=0 列 1为行\n",
    "    return X_exp/partition#广播机制 自动补全\n",
    "\n",
    "def net(X):#数据(256*784) W(784,10)\n",
    "    return softmax(torch.matmul(X.reshape((-1,num_input)),W)+b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.5000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([0, 2])#直接写索引就行\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y_hat[[0, 1], y]#[y_hat[0,0],y_hat[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_reshape(X):\n",
    "    temp=[i[0].reshape(num_input) for i in X]\n",
    "    res=torch.zeros(len(X),num_input)#形状必须完全一致\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        res[i]=temp[i]\n",
    "    return res\n",
    "\n",
    "mnist_train_features=my_reshape(mnist_train)\n",
    "mnist_test_features=my_reshape(mnist_test)\n",
    "mnist_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def one_hot_lables(X):#独热化标签\n",
    "    lable_temp=torch.zeros(len(X),num_output)\n",
    "    index=[i[1] for i in X]\n",
    "    for i in range(len(X)):\n",
    "        lable_temp[i][index[i]]=1\n",
    "    return lable_temp\n",
    "one_hot_lables(mnist_train).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(mnist_train_features)[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(X,y):\n",
    "    tot=0\n",
    "    for i in range(X.shape[0]):\n",
    "        if(net(X[i]).argmax()==y[i]):\n",
    "            tot+=1\n",
    "    return tot/X.shape[0]\n",
    "#计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10706666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=torch.tensor([i[1] for i in mnist_train])\n",
    "y_test=torch.tensor([i[1] for i in mnist_test])\n",
    "\n",
    "cal_acc(mnist_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.298024\n",
      "epoch 2, loss 2.212611\n",
      "epoch 3, loss 2.133730\n",
      "epoch 4, loss 2.060031\n",
      "epoch 5, loss 1.990839\n",
      "epoch 6, loss 1.925763\n",
      "epoch 7, loss 1.864524\n",
      "epoch 8, loss 1.806897\n",
      "epoch 9, loss 1.752674\n",
      "epoch 10, loss 1.701655\n",
      "epoch 11, loss 1.653649\n",
      "epoch 12, loss 1.608468\n",
      "epoch 13, loss 1.565933\n",
      "epoch 14, loss 1.525872\n",
      "epoch 15, loss 1.488119\n",
      "epoch 16, loss 1.452519\n",
      "epoch 17, loss 1.418926\n",
      "epoch 18, loss 1.387202\n",
      "epoch 19, loss 1.357217\n",
      "epoch 20, loss 1.328853\n",
      "epoch 21, loss 1.301997\n",
      "epoch 22, loss 1.276546\n",
      "epoch 23, loss 1.252404\n",
      "epoch 24, loss 1.229481\n",
      "epoch 25, loss 1.207696\n",
      "epoch 26, loss 1.186973\n",
      "epoch 27, loss 1.167241\n",
      "epoch 28, loss 1.148435\n",
      "epoch 29, loss 1.130497\n",
      "epoch 30, loss 1.113369\n",
      "epoch 31, loss 1.097001\n",
      "epoch 32, loss 1.081346\n",
      "epoch 33, loss 1.066359\n",
      "epoch 34, loss 1.052001\n",
      "epoch 35, loss 1.038234\n",
      "epoch 36, loss 1.025022\n",
      "epoch 37, loss 1.012334\n",
      "epoch 38, loss 1.000140\n",
      "epoch 39, loss 0.988412\n",
      "epoch 40, loss 0.977123\n",
      "epoch 41, loss 0.966251\n",
      "epoch 42, loss 0.955772\n",
      "epoch 43, loss 0.945665\n",
      "epoch 44, loss 0.935912\n",
      "epoch 45, loss 0.926493\n",
      "epoch 46, loss 0.917392\n",
      "epoch 47, loss 0.908593\n",
      "epoch 48, loss 0.900081\n",
      "epoch 49, loss 0.891842\n",
      "epoch 50, loss 0.883863\n",
      "epoch 51, loss 0.876132\n",
      "epoch 52, loss 0.868637\n",
      "epoch 53, loss 0.861367\n",
      "epoch 54, loss 0.854312\n",
      "epoch 55, loss 0.847462\n",
      "epoch 56, loss 0.840810\n",
      "epoch 57, loss 0.834345\n",
      "epoch 58, loss 0.828060\n",
      "epoch 59, loss 0.821947\n",
      "epoch 60, loss 0.815999\n",
      "epoch 61, loss 0.810210\n",
      "epoch 62, loss 0.804572\n",
      "epoch 63, loss 0.799080\n",
      "epoch 64, loss 0.793729\n",
      "epoch 65, loss 0.788512\n",
      "epoch 66, loss 0.783424\n",
      "epoch 67, loss 0.778461\n",
      "epoch 68, loss 0.773617\n",
      "epoch 69, loss 0.768889\n",
      "epoch 70, loss 0.764272\n",
      "epoch 71, loss 0.759762\n",
      "epoch 72, loss 0.755356\n",
      "epoch 73, loss 0.751049\n",
      "epoch 74, loss 0.746838\n",
      "epoch 75, loss 0.742720\n",
      "epoch 76, loss 0.738692\n",
      "epoch 77, loss 0.734750\n",
      "epoch 78, loss 0.730892\n",
      "epoch 79, loss 0.727115\n",
      "epoch 80, loss 0.723416\n",
      "epoch 81, loss 0.719794\n",
      "epoch 82, loss 0.716244\n",
      "epoch 83, loss 0.712766\n",
      "epoch 84, loss 0.709357\n",
      "epoch 85, loss 0.706014\n",
      "epoch 86, loss 0.702736\n",
      "epoch 87, loss 0.699521\n",
      "epoch 88, loss 0.696367\n",
      "epoch 89, loss 0.693272\n",
      "epoch 90, loss 0.690234\n",
      "epoch 91, loss 0.687252\n",
      "epoch 92, loss 0.684324\n",
      "epoch 93, loss 0.681449\n",
      "epoch 94, loss 0.678624\n",
      "epoch 95, loss 0.675850\n",
      "epoch 96, loss 0.673123\n",
      "epoch 97, loss 0.670444\n",
      "epoch 98, loss 0.667811\n",
      "epoch 99, loss 0.665222\n",
      "epoch 100, loss 0.662676\n"
     ]
    }
   ],
   "source": [
    "loss=cross_entropy(net(mnist_train_features),y_train).mean()\n",
    "\n",
    "epochs=100\n",
    "lr=0.08\n",
    "acc=[]#准确率\n",
    "length=len(mnist_train)\n",
    "for epoch in range(epochs):\n",
    "    loss=cross_entropy(net(mnist_train_features),y_train).mean()\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():#更新时不用计算梯度\n",
    "        #非常重要\n",
    "        W-=(W.grad)*lr\n",
    "        W.grad.zero_()\n",
    "        b-=(b.grad)*lr\n",
    "        b.grad.zero_()\n",
    "    if(epoch%10==0):\n",
    "        acc.append(cal_acc(mnist_train_features,y_train))\n",
    "    print(f'epoch {epoch + 1}, loss {loss.item():f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8552166666666666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_acc(mnist_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:5 real:5\n",
      "predict:0 real:0\n",
      "predict:4 real:4\n",
      "predict:1 real:1\n",
      "predict:9 real:9\n",
      "predict:2 real:2\n",
      "predict:1 real:1\n",
      "predict:3 real:3\n",
      "predict:1 real:1\n",
      "predict:4 real:4\n",
      "predict:3 real:3\n",
      "predict:2 real:5\n",
      "predict:3 real:3\n",
      "predict:6 real:6\n",
      "predict:1 real:1\n",
      "predict:7 real:7\n",
      "predict:2 real:2\n",
      "predict:8 real:8\n",
      "predict:6 real:6\n",
      "predict:7 real:9\n",
      "predict:4 real:4\n",
      "predict:0 real:0\n",
      "predict:9 real:9\n",
      "predict:1 real:1\n",
      "predict:6 real:1\n",
      "predict:2 real:2\n",
      "predict:4 real:4\n",
      "predict:3 real:3\n",
      "predict:7 real:2\n",
      "predict:7 real:7\n",
      "predict:3 real:3\n",
      "predict:8 real:8\n",
      "predict:6 real:6\n",
      "predict:7 real:9\n",
      "predict:0 real:0\n",
      "predict:5 real:5\n",
      "predict:6 real:6\n",
      "predict:0 real:0\n",
      "predict:7 real:7\n",
      "predict:6 real:6\n",
      "predict:1 real:1\n",
      "predict:8 real:8\n",
      "predict:7 real:7\n",
      "predict:9 real:9\n",
      "predict:3 real:3\n",
      "predict:9 real:9\n",
      "predict:8 real:8\n",
      "predict:5 real:5\n",
      "predict:5 real:9\n",
      "predict:3 real:3\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(f'predict:{net(mnist_train_features[i]).argmax()} real:{y_train[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e94b9a9d50>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "fig,ax=plt.subplots()\n",
    "ax.set_title(\"accuracy\")\n",
    "ax.scatter(range(int(epochs/10)),acc)\n",
    "ax.plot(range(int(epochs/10)),acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8648"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_acc(mnist_test_features,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, accuracy 0.349683\n",
      "epoch 10, accuracy 0.747567\n",
      "epoch 20, accuracy 0.794283\n",
      "epoch 30, accuracy 0.805483\n",
      "epoch 40, accuracy 0.818317\n",
      "epoch 50, accuracy 0.832100\n",
      "epoch 60, accuracy 0.834150\n",
      "epoch 70, accuracy 0.843567\n",
      "epoch 80, accuracy 0.850367\n",
      "epoch 90, accuracy 0.850017\n"
     ]
    }
   ],
   "source": [
    "#实现批量梯度下降\n",
    "#ratio指acc的百分比\n",
    "ratio=10\n",
    "W=torch.normal(0,0.01,size=(num_input,num_output),requires_grad=True)\n",
    "b=torch.zeros(num_output,requires_grad=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    out=mine_torch.select(mnist_train_features,y_train,256)\n",
    "    loss=cross_entropy(net(out[0]),out[1]).mean()\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():#更新时不用计算梯度\n",
    "        #非常重要\n",
    "        W-=(W.grad)*lr\n",
    "        W.grad.zero_()  \n",
    "        b-=(b.grad)*lr\n",
    "        b.grad.zero_()\n",
    "    if(epoch%ratio==0):\n",
    "        print(f'epoch {epoch }, accuracy {cal_acc(mnist_train_features,y_train):f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_acc(mnist_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0004,  0.0135, -0.0215,  ...,  0.0055,  0.0064, -0.0034],\n",
       "        [ 0.0114, -0.0013,  0.0094,  ..., -0.0012,  0.0072, -0.0104],\n",
       "        [-0.0143,  0.0015,  0.0249,  ..., -0.0174,  0.0164, -0.0057],\n",
       "        ...,\n",
       "        [-0.0043,  0.0042,  0.0100,  ...,  0.0039, -0.0056, -0.0051],\n",
       "        [-0.0125,  0.0099,  0.0010,  ..., -0.0012,  0.0108, -0.0112],\n",
       "        [ 0.0235, -0.0099,  0.0093,  ..., -0.0098,  0.0084, -0.0042]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#简洁实现\n",
    "# 将图片展平\n",
    "net=nn.Sequential(nn.Flatten(),nn.Linear(784,10))\n",
    "net[1].weight.data.normal_(0,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.CrossEntropyLoss()\n",
    "trainer=torch.optim.SGD(net.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.198996\n",
      "epoch 2, loss 2.110306\n",
      "epoch 3, loss 2.012805\n",
      "epoch 4, loss 1.932960\n",
      "epoch 5, loss 1.855852\n",
      "epoch 6, loss 1.785201\n",
      "epoch 7, loss 1.721590\n",
      "epoch 8, loss 1.661037\n",
      "epoch 9, loss 1.604266\n",
      "epoch 10, loss 1.553753\n",
      "epoch 11, loss 1.503500\n",
      "epoch 12, loss 1.458217\n",
      "epoch 13, loss 1.417983\n",
      "epoch 14, loss 1.376527\n",
      "epoch 15, loss 1.338860\n",
      "epoch 16, loss 1.307583\n",
      "epoch 17, loss 1.275011\n",
      "epoch 18, loss 1.241011\n",
      "epoch 19, loss 1.214283\n",
      "epoch 20, loss 1.185017\n",
      "epoch 21, loss 1.161221\n",
      "epoch 22, loss 1.137506\n",
      "epoch 23, loss 1.114617\n",
      "epoch 24, loss 1.095041\n",
      "epoch 25, loss 1.075628\n",
      "epoch 26, loss 1.055705\n",
      "epoch 27, loss 1.039978\n",
      "epoch 28, loss 1.023703\n",
      "epoch 29, loss 1.009192\n",
      "epoch 30, loss 0.993098\n",
      "epoch 31, loss 0.978209\n",
      "epoch 32, loss 0.964902\n",
      "epoch 33, loss 0.953392\n",
      "epoch 34, loss 0.941091\n",
      "epoch 35, loss 0.929619\n",
      "epoch 36, loss 0.917405\n",
      "epoch 37, loss 0.905104\n",
      "epoch 38, loss 0.894440\n",
      "epoch 39, loss 0.884973\n",
      "epoch 40, loss 0.876351\n",
      "epoch 41, loss 0.867675\n",
      "epoch 42, loss 0.858731\n",
      "epoch 43, loss 0.849612\n",
      "epoch 44, loss 0.843251\n",
      "epoch 45, loss 0.835893\n",
      "epoch 46, loss 0.829139\n",
      "epoch 47, loss 0.821646\n",
      "epoch 48, loss 0.811336\n",
      "epoch 49, loss 0.807032\n",
      "epoch 50, loss 0.800902\n",
      "epoch 51, loss 0.791467\n",
      "epoch 52, loss 0.784356\n",
      "epoch 53, loss 0.777307\n",
      "epoch 54, loss 0.772023\n",
      "epoch 55, loss 0.765807\n",
      "epoch 56, loss 0.760223\n",
      "epoch 57, loss 0.754436\n",
      "epoch 58, loss 0.748659\n",
      "epoch 59, loss 0.743565\n",
      "epoch 60, loss 0.738883\n",
      "epoch 61, loss 0.733669\n",
      "epoch 62, loss 0.729334\n",
      "epoch 63, loss 0.725644\n",
      "epoch 64, loss 0.720450\n",
      "epoch 65, loss 0.716620\n",
      "epoch 66, loss 0.711832\n",
      "epoch 67, loss 0.707984\n",
      "epoch 68, loss 0.703174\n",
      "epoch 69, loss 0.699876\n",
      "epoch 70, loss 0.695844\n",
      "epoch 71, loss 0.691746\n",
      "epoch 72, loss 0.688842\n",
      "epoch 73, loss 0.684870\n",
      "epoch 74, loss 0.682905\n",
      "epoch 75, loss 0.679318\n",
      "epoch 76, loss 0.675000\n",
      "epoch 77, loss 0.670766\n",
      "epoch 78, loss 0.667691\n",
      "epoch 79, loss 0.664319\n",
      "epoch 80, loss 0.661278\n",
      "epoch 81, loss 0.658954\n",
      "epoch 82, loss 0.655699\n",
      "epoch 83, loss 0.652610\n",
      "epoch 84, loss 0.650204\n",
      "epoch 85, loss 0.647484\n",
      "epoch 86, loss 0.644698\n",
      "epoch 87, loss 0.642375\n",
      "epoch 88, loss 0.638530\n",
      "epoch 89, loss 0.636019\n",
      "epoch 90, loss 0.633412\n",
      "epoch 91, loss 0.630862\n",
      "epoch 92, loss 0.628174\n",
      "epoch 93, loss 0.626476\n",
      "epoch 94, loss 0.624271\n",
      "epoch 95, loss 0.621537\n",
      "epoch 96, loss 0.619151\n",
      "epoch 97, loss 0.616131\n",
      "epoch 98, loss 0.613820\n",
      "epoch 99, loss 0.611843\n",
      "epoch 100, loss 0.610684\n",
      "epoch 101, loss 0.608256\n",
      "epoch 102, loss 0.606077\n",
      "epoch 103, loss 0.604523\n",
      "epoch 104, loss 0.603236\n",
      "epoch 105, loss 0.600846\n",
      "epoch 106, loss 0.598779\n",
      "epoch 107, loss 0.595926\n",
      "epoch 108, loss 0.592978\n",
      "epoch 109, loss 0.591274\n",
      "epoch 110, loss 0.590162\n",
      "epoch 111, loss 0.588051\n",
      "epoch 112, loss 0.585525\n",
      "epoch 113, loss 0.584543\n",
      "epoch 114, loss 0.582029\n",
      "epoch 115, loss 0.580333\n",
      "epoch 116, loss 0.578510\n",
      "epoch 117, loss 0.576896\n",
      "epoch 118, loss 0.575210\n",
      "epoch 119, loss 0.573560\n",
      "epoch 120, loss 0.572004\n",
      "epoch 121, loss 0.570723\n",
      "epoch 122, loss 0.568752\n",
      "epoch 123, loss 0.567228\n",
      "epoch 124, loss 0.566135\n",
      "epoch 125, loss 0.564906\n",
      "epoch 126, loss 0.563200\n",
      "epoch 127, loss 0.561771\n",
      "epoch 128, loss 0.560907\n",
      "epoch 129, loss 0.559598\n",
      "epoch 130, loss 0.558390\n",
      "epoch 131, loss 0.556621\n",
      "epoch 132, loss 0.554817\n",
      "epoch 133, loss 0.553498\n",
      "epoch 134, loss 0.552815\n",
      "epoch 135, loss 0.551858\n",
      "epoch 136, loss 0.550598\n",
      "epoch 137, loss 0.548955\n",
      "epoch 138, loss 0.547177\n",
      "epoch 139, loss 0.545824\n",
      "epoch 140, loss 0.544744\n",
      "epoch 141, loss 0.543703\n",
      "epoch 142, loss 0.541886\n",
      "epoch 143, loss 0.540635\n",
      "epoch 144, loss 0.539729\n",
      "epoch 145, loss 0.539324\n",
      "epoch 146, loss 0.537341\n",
      "epoch 147, loss 0.536127\n",
      "epoch 148, loss 0.535507\n",
      "epoch 149, loss 0.535168\n",
      "epoch 150, loss 0.533556\n",
      "epoch 151, loss 0.532117\n",
      "epoch 152, loss 0.531818\n",
      "epoch 153, loss 0.530676\n",
      "epoch 154, loss 0.528739\n",
      "epoch 155, loss 0.527611\n",
      "epoch 156, loss 0.526546\n",
      "epoch 157, loss 0.525900\n",
      "epoch 158, loss 0.525218\n",
      "epoch 159, loss 0.524833\n",
      "epoch 160, loss 0.523663\n",
      "epoch 161, loss 0.521619\n",
      "epoch 162, loss 0.521438\n",
      "epoch 163, loss 0.520166\n",
      "epoch 164, loss 0.519859\n",
      "epoch 165, loss 0.518021\n",
      "epoch 166, loss 0.517439\n",
      "epoch 167, loss 0.516438\n",
      "epoch 168, loss 0.516035\n",
      "epoch 169, loss 0.514609\n",
      "epoch 170, loss 0.514308\n",
      "epoch 171, loss 0.513374\n",
      "epoch 172, loss 0.513272\n",
      "epoch 173, loss 0.511504\n",
      "epoch 174, loss 0.510528\n",
      "epoch 175, loss 0.509763\n",
      "epoch 176, loss 0.508966\n",
      "epoch 177, loss 0.507836\n",
      "epoch 178, loss 0.507043\n",
      "epoch 179, loss 0.505630\n",
      "epoch 180, loss 0.504964\n",
      "epoch 181, loss 0.504213\n",
      "epoch 182, loss 0.503381\n",
      "epoch 183, loss 0.502445\n",
      "epoch 184, loss 0.501562\n",
      "epoch 185, loss 0.501556\n",
      "epoch 186, loss 0.500897\n",
      "epoch 187, loss 0.499441\n",
      "epoch 188, loss 0.498493\n",
      "epoch 189, loss 0.497760\n",
      "epoch 190, loss 0.496972\n",
      "epoch 191, loss 0.496060\n",
      "epoch 192, loss 0.495443\n",
      "epoch 193, loss 0.494718\n",
      "epoch 194, loss 0.494416\n",
      "epoch 195, loss 0.493915\n",
      "epoch 196, loss 0.492866\n",
      "epoch 197, loss 0.492287\n",
      "epoch 198, loss 0.491321\n",
      "epoch 199, loss 0.490263\n",
      "epoch 200, loss 0.489914\n",
      "epoch 201, loss 0.489423\n",
      "epoch 202, loss 0.488587\n",
      "epoch 203, loss 0.487916\n",
      "epoch 204, loss 0.486909\n",
      "epoch 205, loss 0.485999\n",
      "epoch 206, loss 0.485640\n",
      "epoch 207, loss 0.484987\n",
      "epoch 208, loss 0.484371\n",
      "epoch 209, loss 0.484365\n",
      "epoch 210, loss 0.484875\n",
      "epoch 211, loss 0.483613\n",
      "epoch 212, loss 0.482696\n",
      "epoch 213, loss 0.482832\n",
      "epoch 214, loss 0.481583\n",
      "epoch 215, loss 0.481309\n",
      "epoch 216, loss 0.480649\n",
      "epoch 217, loss 0.479403\n",
      "epoch 218, loss 0.479016\n",
      "epoch 219, loss 0.478509\n",
      "epoch 220, loss 0.477828\n",
      "epoch 221, loss 0.477054\n",
      "epoch 222, loss 0.476486\n",
      "epoch 223, loss 0.475666\n",
      "epoch 224, loss 0.475315\n",
      "epoch 225, loss 0.474511\n",
      "epoch 226, loss 0.474137\n",
      "epoch 227, loss 0.474113\n",
      "epoch 228, loss 0.473611\n",
      "epoch 229, loss 0.473252\n",
      "epoch 230, loss 0.471784\n",
      "epoch 231, loss 0.471144\n",
      "epoch 232, loss 0.470713\n",
      "epoch 233, loss 0.470343\n",
      "epoch 234, loss 0.469809\n",
      "epoch 235, loss 0.469968\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for X, y in train_iter:#迭代器每次返回X和y\n",
    "    l = loss(net(X) ,y)\n",
    "    trainer.zero_grad()#清零梯度\n",
    "    l.backward()\n",
    "    trainer.step()#自动前进\n",
    "    l = loss(net(mnist_train_features), y_train)#每轮再计算loss\n",
    "    print(f'epoch {i + 1}, loss {l:f}')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2152, -3.4967, -0.6406,  0.8267, -0.6291, -1.0345, -2.7525,  6.1915,\n",
       "         -0.4394,  1.9429]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(mnist_test_features[0].unsqueeze(0))#在0维上升维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def torch_cal_acc(X,y):\n",
    "    tot=0\n",
    "    for i in range(X.shape[0]):\n",
    "        if(net(X[i].unsqueeze(0)).argmax()==y[i]):\n",
    "            tot+=1\n",
    "    return tot/X.shape[0]\n",
    "\n",
    "torch_cal_acc(mnist_test_features,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09f4728b05d69e74b0ea9aff0073f9d58b230df2a643ed862911c4fa3d476aa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
